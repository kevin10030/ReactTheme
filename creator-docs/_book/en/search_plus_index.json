{"./":{"url":"./","title":"Introduction","keywords":"","body":"Cocos Creator 3.0 User Manual Welcome to the Cocos Creator 3.0 user manual! This manual includes detailed instructions, a workflow for users, and a step-by-step tutorial for beginners. This manual can help you quickly learn how to develop cross-platform games with Cocos Creator 3.0. Note: please select the corresponding manual version in the upper right corner according to the Cocos Creator 3.0 version you are using. General guide Use the feature map to quickly understand engine features: Function Map Graphics rendering Material Lighting Particle System UI system Animation System Audio Physical Simulation Scripting Guide and Event System Components Assets Scene and Environment Settings Beginner's guide Beginner Dashboard Hello World! Quick start: making your first game Caution Editor Manual Quick Start Panel Introduction Project Preview Debugging Game View Particle Editor Animation System Terrain System Build release Export mesh asset from DCC Engine Manual Scenes and Environment Lighting Material Sound Particle Animation Easing Physics UI Components Scripting Guide and Event Mechanism Resource Manual Demo and example projects Example collection: From the use of basic components to the display of rendering effects, this project includes multiple scenarios with different functions and multiple game demo projects for user reference. One Step, Two Steps: This is the Quick Start document Step-by-step explanation of the game. Examples of Physics: Includes some Physics test cases and examples, such as Engulfing Black Hole, Simple Car, Falling ball, etc. The test casesintroduce some basic functions and usage methods, so that you can understand the physical functions in combination with the documentation. Simple Games: Users can use this case study to complete some simple and famous games. Module display collection: The example project of each function of the engine, which basically covers most of the function modules of the engine. Users can refer to it when using the functions Development in this project. UI Show Demo: Demo of various UI components combined use Demo. Jump Ball 3D: Users can make jump ball games through this project. Taxi Game 3D: Physics-based game demo, users can make taxi games through this project. Note: the above items will be updated from time to time. Their default branch on GitHub is master, which generally corresponds to the latest Cocos Creator 3.0 version. If you are still using an older version of Cocos Creator 3.0, these projects may not open, try to switch to the same named branch as the old version. "},"getting-started/":{"url":"getting-started/","title":"Getting Started","keywords":"","body":"Beginning your Cocos Creator Journey Welcome to using Cocos Creator. Before learning to use it, please follow the steps below to install the editor development environment. After installing the editor, you can get familiar with the editor by reading Hello world!, or refer to our first game demo to start your own development. This chapter includes the following: Dashboard Hello world! Quick start: making your first game Support Caution "},"getting-started/dashboard/":{"url":"getting-started/dashboard/","title":"Dashboard","keywords":"","body":"Using the Dashboard The Dashboard is the starting page, you can browse, create, and import projects. Interface Overview Opening a project Select Open Project from the tab bar. Creating a New Project Select New Project from the tab bar. Next, select a project template and path, and click the New Project button below. Getting Help Select Help from the tab bar to help you get an initial understanding of Cocos Creator. "},"getting-started/helloworld/":{"url":"getting-started/helloworld/","title":"Hello world!","keywords":"","body":"Hello World project This is the very first Cocos Creator project, and it aims to demonstrate the following: Creating a project Understanding the project directory Creating an object Modifying Camera properties Creating, modifying, and binding scripts Running projects Creating a New Project In the Dashboard panel, click the New button in the lower right corner and select Creator in the pop-up menu. Select an empty template, set the project path, and click the Create button below. The Editor interface This is the default layout of the Editor interface: The layout is customizable, if you don't find the default layout suitable. Project Directory Usually, the most commonly used directory is assets. There are others: assets (resources directory) build (build directory) library (imported resources directory) local (log file directory) profiles (editor configuration) temp (temporary file directory) package.json (project configuration) Creating a New Scene In the bottom left Assets panel, click the right mouse button and select New -> Scene. Creating an Object Upper left Hierarchy panel, click the right mouse button, select Create -> 3D object -> Cube cube. The created cube will appear in the scene editor. Modifying the Camera Selecting the Camera object In the Hierarchy panel, select Camera, and the scene editor will select it and display a Gizmo. Modifying the Camera position In the scene editor, drag the Gizmo so that the Camera can see the created cube. Modifying the Camera background color In the Inspector panel panel, click the Color property and select black as the background color. Adding a script Creating a new script In the Assets panel, click the right mouse button, select New -> TypeScript. Life cycle functions Life cycle functions (called in the following order): onLoad Called when the script is initialized onEnable Called when the enabled property of the component changes from false to true start Called when the component is first activated update Update object call before rendering each frame lateUpdate Called after the update of all components has been executed onDisable Called when the enabled property of the component changes from true to false onDestroy Called when the component or node is destroyed Adding code Add start() function to output Hello world: import { _decorator, Component, Node } from 'cc'; const {ccclass, property} = _decorator; @ccclass('HelloWorld') export class HelloWorld extends Component { /* class member could be defined like this */ // dummy =''; /* use `property` decorator if your want the member to be serializable */ // @property // serializableDummy = 0; start () { // Your initialization goes here. console.info('Hello world'); } // // update (deltaTime: number) { // // Your update function goes here. //} } Bind scripts to objects Select the created cube and click Add component -> Custom Script->HelloWorld Running a project In the Editor, from the menu bar click Project -> Run preview, or Click the Run button in the middle. Debuging a project In the Editor, from the menu bar click Developer -> Scene Debugging Tool It is also may be necessary to Log information. The Console panel displays all log output. Breakpoints can also be placed for stopping execution of the debugger to examine values. Select the Source option on the tab bar and press CTRL+P, Search for HelloWorld.ts, set a breakpoint in the start() function, and then run the preview to debug. "},"getting-started/first-game/":{"url":"getting-started/first-game/","title":"Quick Start: First Game","keywords":"","body":"Quick start: making your first game. The power of the Cocos Creator editor is that it allows developers to quickly prototype games. Let's follow a guided tutorial to make a magical game named Mind Your Step. This game tests the player's reaction ability, and chooses whether to jump one step or two steps according to traffic conditions. You can try out the completed the game here. New Project If you still don’t know how to download and run Cocos Creator, please review the Installation and Starting documentation. To start a new project: Start Cocos Creator and then create a new project named MindYourStep. If you don’t know how to create a project, please read the Hello World! documentation. After creating a new project, you should see the following editor interface: Creating a game scene In Cocos Creator, Scene is the center for organizing game content during development and the container for presenting all game content to players. The game scene will generally include the following components: Scene objects Roles User interface elements Game logic, in the form of scripts, attached to Scene Nodes as Components When the player runs the game, the game scene will be loaded. After the game scene is loaded, scripts of the included components will be automatically run. Apart from assets, game scenes are the foundation of all content creation. Now, to create a new Scene: In the Asset panel, click to select the assets directory, click the + button in the upper left corner, select the folder, and name it Scenes. Example: Click the Scenes directory first (the following pictures create some common folders in advance), click the right mouse button, and select Scene Files from the pop-up menu. Example: We created a Scene file named New Scene. After the creation, the name of the scene file New Scene will be in the edit state. Rename it from New Scene to Main. Double-click Main to open this Scene in Scene panel and Hierarchy panel. Adding a road Our main character needs to run from left to right on a road composed of cubes (blocks). Let's make the road by using a built-in cube. Right click on Scene Node in the Hierarchy panel, then choose Create -> 3D Object -> Cube Clone the cube to make two more cube with the shortcut key Ctrl+D. Assign the Cubes each a unique position: First one at position (0, -1.5, 0). Second one at position (1, -1.5, 0). Third one at position (2, -1.5, 0). The result is as follows: Add a main character Create a main character node First, create an empty node named Player. Second, create a Model Component named Body under the Player node. For convenience, let's use the built-in Capsule model as the body of our main character. The advantage of being divided into two nodes is that we can use the script to control the Player node to move the main character in the horizontal direction, and do some vertical animations on the Body node (such as falling after jumping in place), the two are superimposed to form a jumping animation. Third, set the Player node to the (0, 0, 0) position so that it can stand on the first square. The effect is as follows: Writing a script for the main character It is necessary for the main character to be affected when the mouse moves. To do this a custom script needs to be written. Creating a script If you have not yet created a Scripts folder, right-click the assets folder in the Assets panel, select New -> Folder, and rename the newly created folder to Scripts. Right-click the Scripts folder and select New -> TypeScript to create a new, blank TypeScript script. For TypeScript information, you can view the TypeScript Official Website. Change the name of the newly created script to PlayerController and the double-click the script to open the code editor (in, for example, VSCode). Note: the name of the script in Cocos Creator 3.0 is the name of the component. This name is case sensitive! If the capitalization of the component name is incorrect, the component cannot be used correctly by the name! Writing script code There are already some pre-set code blocks in the PlayerController script. Example: import { _decorator, Component } from \"cc\"; const { ccclass, property } = _decorator; @ccclass(\"PlayerController\") export class PlayerController extends Component { /* class member could be defined like this */ // dummy = ''; /* use `property` decorator if your want the member to be serializable */ // @property // serializableDummy = 0; start () { // Your initialization goes here. } // update (deltaTime: number) { // // Your update function goes here. // } } This code is the structure needed to write a component. Scripts with this structure are Components in Cocos Creator. They can be attached to nodes in a Scene and provide various functionality for controlling nodes. For detailed information review the Script documentation. Monitoring of mouse events needs to be added in the script to let the Player node move. Modify the code in PlayerController as follows: import { _decorator, Component, Vec3, systemEvent, SystemEvent, EventMouse, Animation } from \"cc\"; const { ccclass, property } = _decorator; @ccclass(\"PlayerController\") export class PlayerController extends Component { /* class member could be defined like this */ // dummy = ''; /* use `property` decorator if your want the member to be serializable */ // @property // serializableDummy = 0; // for fake tween private _startJump: boolean = false; private _jumpStep: number = 0; private _curJumpTime: number = 0; private _jumpTime: number = 0.1; private _curJumpSpeed: number = 0; private _curPos: Vec3 = new Vec3(); private _deltaPos: Vec3 = new Vec3(0, 0, 0); private _targetPos: Vec3 = new Vec3(); private _isMoving = false; start () { // Your initialization goes here. systemEvent.on(SystemEvent.EventType.MOUSE_UP, this.onMouseUp, this); } onMouseUp(event: EventMouse) { if (event.getButton() === 0) { this.jumpByStep(1); } else if (event.getButton() === 2) { this.jumpByStep(2); } } jumpByStep(step: number) { if (this._isMoving) { return; } this._startJump = true; this._jumpStep = step; this._curJumpTime = 0; this._curJumpSpeed = this._jumpStep / this._jumpTime; this.node.getPosition(this._curPos); Vec3.add(this._targetPos, this._curPos, new Vec3(this._jumpStep, 0, 0)); this._isMoving = true; } onOnceJumpEnd() { this._isMoving = false; } update (deltaTime: number) { if (this._startJump) { this._curJumpTime += deltaTime; if (this._curJumpTime > this._jumpTime) { // end this.node.setPosition(this._targetPos); this._startJump = false; this.onOnceJumpEnd(); } else { // tween this.node.getPosition(this._curPos); this._deltaPos.x = this._curJumpSpeed * deltaTime; Vec3.add(this._curPos, this._curPos, this._deltaPos); this.node.setPosition(this._curPos); } } } } Next, attach the PlayerController component to the Player node. Select the Player node in the Hierarchy panel, then click the Add Component button in the Inspector panel, select Custom Script Component- > PlayerController to the Player node to add the PlayerController component. In-order to see the object at runtime, we need to adjust some parameters of the Camera in the scene, set the position to (0, 0, 13), and set the ClearColor to (50, 90, 255, 255): Now, click the Play button. Once running, click the left and right mouse buttons on the opened web page, you can see the following screen: For additional details please refer to the Project Preview Debugging documentation. Adding character animations The Player can be moved in a horizontal direction. This is a start, but not good enough. Player must become more life-like. This effect can be achieved by adding a vertical animation to the character. Note: before proceeding, please read the Animation Editor documentation. After reading and understanding the capabilities of the Animation Editor character animations can be implemented! Locate the Animation panel, at the bottom of the editor alongside the Assets Preview and the Console panels. Select the Body node in the Scene and click to add an Animation Component and then click again tp create a new Animation Clip. Give this new Animation Clip a name of oneStep. Enter animation editing mode in-order to add the position attribute. Next, add three key frames with position values ​​of (0, 0, 0), (0, 0.5, 0), (0, 0, 0). Note: remember to save the animation before exiting the animation editing mode, otherwise the animation will be lost. Animation Clips can also be created using the Asset panel. Next, Create a Clip named twoStep and add it to the Animation component on Body. Note: the panel layout was adjusted for recording convenience. Enter the animation editing mode, select and edit the twoStep clip. Similar to the second step, add three key frames at positions (0, 0, 0), (0, 1, 0), (0, 0, 0). Reference the Animation component in thePlayerController Component, as different animations need to be played according to the number of steps Player jumped. First, reference the Animation component on the Body in the PlayerController component. @property({type: Animation}) public BodyAnim: Animation|null = null; Then in the Inspector panel, drag the Animation to the Body variable. Add the animation playback code to the jump function jumpByStep: if (this.BodyAnim) { if (step === 1) { this.BodyAnim.play('oneStep'); } else if (step === 2) { this.BodyAnim.play('twoStep'); } } Click the Play button. When playing, click the left and right mouse buttons, you can see the new jump effect in action: Upgrading the road In-order to make the gameplay longer and more enjoyable, we need a long stretch of road to let the Player run all the way to the right. Copying a bunch of cubes in the Scene and editing the position of each cube to form the road is not a wise practice. We can, however, complete this by using a script to automatically create the road pieces. A \"Game Manager\" can help Most games have a manager, which is mainly responsible for the management of the entire game life-cycle. You can put the code for the dynamic creation of the road in this same manager. Create a node named GameManager in the Scene. Next, create a TypesScript file named GameManager in assets/Scripts and add it to the GameManager node. Making a Prefab For a node that needs to be generated repeatedly, it can be saved as a Prefab (prefabricated) resource. This means it can be used as a template when we dynamically generate other nodes of this same type. Note: before proceeding, please read the Prefab Resources documentation. It is necessary to make the basic element cube of the road into a Prefab, after which all three cubes in the Scene can be deleted. Adding the automatic road creation A very long road is needed. The ideal method is to dynamically increase the length of the road, so that the Player can run forever. First, generate a fixed-length road with a length that is arbitrary. To do so, replace the code in the GameManager script with the following code: import { _decorator, Component, Prefab, instantiate, Node, CCInteger} from \"cc\"; const { ccclass, property } = _decorator; enum BlockType{ BT_NONE, BT_STONE, }; @ccclass(\"GameManager\") export class GameManager extends Component { @property({type: Prefab}) public cubePrfb: Prefab|null = null; @property({type: CCInteger}) public roadLength: Number = 50; private _road: number[] = []; start () { this.generateRoad(); } generateRoad() { this.node.removeAllChildren(); this._road = []; // startPos this._road.push(BlockType.BT_STONE); for (let i = 1; i Assign the Cube prefab that made previously to the CubePrfb property in GameManager Inspector. The length of the road can be changed by modifying the value of roadLength in the Properties panel for the GameManager. When previewing, the road is now automatically generated, however, because the Camera does not follow the Player, the road behind cannot be seen. Changing the Camera in the Scene to be a child node of the Player can help solve this. Now, the Camera will follow the Player's movement. Adding a start menu The start menu is an indispensable part of most any game. Add the game name, game introduction, production staff and other information here. Creating a simple start menu starts with some basic steps: Add a button called Play This operation creates a Canvas node, a PlayButton node, and a Label node. Because the UI component needs to be displayed under the parent node with Canvas, the editor will automatically add one when it finds that there is not a node with this component in the current Scene. After creating the button, change the String property of cc.Label on the Label node from Button to Play. Create an empty node named StartMenu under Canvas and drag PlayButton under it. We can switch to the 2D editing view for UI editing operations by clicking the 2D/3D button on the toolbar. Note: 2D View is this toolbar button . Note: before proceeding, please read the Scene Editing documentation. Add a background frame by creating a Sprite node named BG under StartMenu. Adjust BG's position to above the PlayButton, setting the W(width) and H(height) of ContentSize to (200, 200), and setting its SpriteFrame to internal/default_ui/ default_sprite_splash. Add a Label called Title for the title of the start menu. Modify the text for Title and adjust it's position, text size and color. Adjust the position of the PlayButton. The layout of a simple start menu is complete. Add game state logic, generally it can be divided into three states: Init: display the game menu and initialize some resources. Playing: hide the game menu, players can operate the game. End: end the game and display the ending menu. Use an enum type to represent these states. enum BlockType{ BT_NONE, BT_STONE, }; enum GameState{ GS_INIT, GS_PLAYING, GS_END, }; Add a private variable that represents the current state to the GameManager script private _curState: GameState = GameState.GS_INIT; In-order not to let the user operate the character at the beginning, but to allow the user to operate the character while the game is in progress, we need to dynamically turn on and off the character's monitoring of mouse messages. This can be done with the following changes to PlayerController: start () { // Your initialization goes here. //systemEvent.on(SystemEvent.EventType.MOUSE_UP, this.onMouseUp, this); } setInputActive(active: boolean) { if (active) { systemEvent.on(SystemEvent.EventType.MOUSE_UP, this.onMouseUp, this); } else { systemEvent.off(SystemEvent.EventType.MOUSE_UP, this.onMouseUp, this); } } Next, reference PlayerController in the GameManager script. Drag the Player variable in the Inspector panel. @property({type: PlayerController}) public playerCtrl: PlayerController = null; In-order to dynamically open/close the open menu, the StartMenu needs to be referenced in the GameManager. Drag the StartMenu of the scene into this variable in the Inspector panel. @property({type: Node}) public startMenu: Node = null; Modify the code in the GameManger: start () { this.curState = GameState.GS_INIT; } init() { if (this.startMenu) { this.startMenu.active = true; } this.generateRoad(); if (this.playerCtrl) { this.playerCtrl.setInputActive(false); this.playerCtrl.node.setPosition(Vec3.ZERO); } } set curState (value: GameState) { switch(value) { case GameState.GS_INIT: this.init(); break; case GameState.GS_PLAYING: if (this.startMenu) { this.startMenu.active = false; } // Directly setting active will directly start monitoring // mouse events, and do a little delay processing setTimeout(() => { if (this.playerCtrl) { this.playerCtrl.setInputActive(true); } }, 0.1); break; case GameState.GS_END: break; } this._curState = value; } Add event monitoring to the Play button. In-order to start the game after clicking the Play button, the button needs to respond to click events. Add code that responds to the button click in the GameManager script, and click to enter the game's Playing state: onStartButtonClicked() { this.curState = GameState.GS_PLAYING; } Next, add the response function of Click Events in the Inspector panel for the Play button. Now, preview the scene by clicking the Play button to start the game. Adding game end logic The game character is just running forward, with no purpose. Adding game rules to make the game play more challenging would make the game more playable and give it a purpose. The character needs to send a message at the end of each jump. This message should record how many steps the character jumped and its current position. This can be done in PlayerController. private _curMoveIndex = 0; // ... jumpByStep(step: number) { // ... this._curMoveIndex += step; } Send a message at the end of each jump: onOnceJumpEnd() { this._isMoving = false; this.node.emit('JumpEnd', this._curMoveIndex); } Monitor the character's jumping end event in GameManager, and judge the winning or losing of the game, according to the rules. Increase the failure and ending logic to judge how the game is being played.If Player jumps to an empty square or exceeds the maximum length value, the game will end: checkResult(moveIndex: number) { if (moveIndex Monitor the character's jump message and call a function to decide: start () { this.curState = GameState.GS_INIT; this.playerCtrl?.node.on('JumpEnd', this.onPlayerJumpEnd, this); } // ... onPlayerJumpEnd(moveIndex: number) { this.checkResult(moveIndex); } If you preview playing the game now, there will be a logic error when restarting the game. This is because we did not reset the _curMoveIndex property value in PlayerController when the game restarts. To fix this, add a reset function in PlayerController. reset() { this._curMoveIndex = 0; } Call reset() in the init function of GameManager to reset the properties of PlayerController. init() { // ... this.playerCtrl.reset(); } Step counting display We can display the current number of steps jumped in the interface. Perhaps watching the continuous growth of steps during the jump will be very fulfilling to the player. Create a new label named Steps under Canvas, adjust the position, font size and other properties. Reference the Steps label in GameManager @property({type: Label}) public stepsLabel: Label|null = null; Update the current Step data to appear in new Steps Label. A game ending interface has yet to be created, for now, reset the number of steps to 0 when restarting playing. set curState (value: GameState) { switch(value) { case GameState.GS_INIT: this.init(); break; case GameState.GS_PLAYING: if (this.startMenu) { this.startMenu.active = false; } if (this.stepsLabel) { // reset the number of steps to 0 this.stepsLabel.string = '0'; } // set active directly to start listening for mouse events directly setTimeout(() => { if (this.playerCtrl) { this.playerCtrl.setInputActive(true); } }, 0.1); break; case GameState.GS_END: break; } this._curState = value; } Update the Steps Label in a function that responds to the character jumping. It should make sense that recording the number of Steps would take place after each and every jump for accuracy. onPlayerJumpEnd(moveIndex: number) { this.stepsLabel.string = '' + moveIndex; this.checkResult(moveIndex); } Lights and shadows Where there is light, there will be a shadow. Light and shadows create a 3D world where light and dark intersect. Next, let's add a simple shadow to the character. Turning on shadows In the Hierarchy panel, click the Scene node at the top, check Enabled in the shadows property, and modify the Distance and Normal parameters Click the Body node, under the Player node, and set ShadowCastingMode under MeshRenderer to ON. A patch of shadow can be seen in the in the Scene editor. However, this shadow cannot be seen when previewing because it is covered by the capsule body that is directly behind the model. Adjusting the light When creating a new scene, a DirectionalLight will be added by default, and the shadow will be calculated from this parallel light. The direction of this parallel light can be adjusted in-order to display the shadow in another position. In the Hierarchy panel, click to select the Main Light node and adjust the Rotation parameter to (-10, 17, 0). Preview the game and you can see this effect: Adding a character model Using the capsule body as the character is a bit shabby, we can change this to make a Cocos character. Importing model resources Copy the cocos folder under the assets directory in Project Engineering to the assets directory of your own project. Adding to the scene A prefab called Cocos has been included in the cocos file, drag it to the Body node under Player in the scene. Remove the Capsule model at the same time. The model is a little dark and a spotlight can be added to highlight its shiny brain. Adding a jumping animation When previewing the game, the character will initially have a standby animation, but a jumping animation needs to be used during a jump. First, add a variable in the PlayerController class that references the model animation: @property({type: SkeletalAnimation}) public CocosAnim: SkeletalAnimation = null; Then, in the Inspector, drag the Cocos node into this variable. The jump animation needs to be used in the jumpByStep function. jumpByStep(step: number) { if (this._isMoving) { return; } this._startJump = true; this._jumpStep = step; this._curJumpTime = 0; this._curJumpSpeed = this._jumpStep / this._jumpTime; this.node.getPosition(this._curPos); Vec3.add(this._targetPos, this._curPos, new Vec3(this._jumpStep, 0, 0)); this._isMoving = true; if (this.CocosAnim) { // The jumping animation takes a long time, here is accelerated playback this.CocosAnim.getState('cocos_anim_jump').speed = 3.5; // Play jumping animation this.CocosAnim.play('cocos_anim_jump'); } if (this.BodyAnim) { if (step === 1) { //this.BodyAnim.play('oneStep'); } else if (step === 2) { this.BodyAnim.play('twoStep'); } } this._curMoveIndex += step; } In the onOnceJumpEnd function, change to the standby state and play the standby animation. onOnceJumpEnd() { this._isMoving = false; if (this.CocosAnim) { this.CocosAnim.play('cocos_anim_idle'); } this.node.emit('JumpEnd', this._curMoveIndex); } When previewing, the results are as follows: Final Code The final code for PlayerController.ts should look like this: import { _decorator, Component, Vec3, systemEvent, SystemEvent, EventMouse, Animation, SkeletalAnimation } from \"cc\"; const { ccclass, property } = _decorator; @ccclass(\"PlayerController\") export class PlayerController extends Component { @property({type: Animation}) public BodyAnim: Animation = null; @property({type: SkeletalAnimation}) public CocosAnim: SkeletalAnimation = null; // for fake tween private _startJump: boolean = false; private _jumpStep: number = 0; private _curJumpTime: number = 0; private _jumpTime: number = 0.3; private _curJumpSpeed: number = 0; private _curPos: Vec3 = new Vec3(); private _deltaPos: Vec3 = new Vec3(0, 0, 0); private _targetPos: Vec3 = new Vec3(); private _isMoving = false; private _curMoveIndex = 0; start () { } reset() { this._curMoveIndex = 0; } setInputActive(active: boolean) { if (active) { systemEvent.on(SystemEvent.EventType.MOUSE_UP, this.onMouseUp, this); } else { systemEvent.off(SystemEvent.EventType.MOUSE_UP, this.onMouseUp, this); } } onMouseUp(event: EventMouse) { if (event.getButton() === 0) { this.jumpByStep(1); } else if (event.getButton() === 2) { this.jumpByStep(2); } } jumpByStep(step: number) { if (this._isMoving) { return; } this._startJump = true; this._jumpStep = step; this._curJumpTime = 0; this._curJumpSpeed = this._jumpStep / this._jumpTime; this.node.getPosition(this._curPos); Vec3.add(this._targetPos, this._curPos, new Vec3(this._jumpStep, 0, 0)); this._isMoving = true; if (this.CocosAnim) { // The jumping animation takes a long time, here is accelerated playback this.CocosAnim.getState('cocos_anim_jump').speed = 3.5; // Play jumping animation this.CocosAnim.play('cocos_anim_jump'); } if (this.BodyAnim) { if (step === 1) { //this.BodyAnim.play('oneStep'); } else if (step === 2) { this.BodyAnim.play('twoStep'); } } this._curMoveIndex += step; } onOnceJumpEnd() { this._isMoving = false; this.CocosAnim.play('cocos_anim_idle'); this.node.emit('JumpEnd', this._curMoveIndex); } update (deltaTime: number) { if (this._startJump) { this._curJumpTime += deltaTime; if (this._curJumpTime > this._jumpTime) { // end this.node.setPosition(this._targetPos); this._startJump = false; this.onOnceJumpEnd(); } else { // tween this.node.getPosition(this._curPos); this._deltaPos.x = this._curJumpSpeed * deltaTime; Vec3.add(this._curPos, this._curPos, this._deltaPos); this.node.setPosition(this._curPos); } } } } The final code for GameManager.ts should look like this: import { _decorator, Component, Prefab, instantiate, Node, Label, CCInteger, Vec3 } from \"cc\"; import { PlayerController } from \"./PlayerController\"; const { ccclass, property } = _decorator; enum BlockType{ BT_NONE, BT_STONE, }; enum GameState{ GS_INIT, GS_PLAYING, GS_END, }; @ccclass(\"GameManager\") export class GameManager extends Component { @property({type: Prefab}) public cubePrfb: Prefab|null = null; @property({type: CCInteger}) public roadLength: Number = 50; private _road: number[] = []; @property({type: Node}) public startMenu: Node|null = null; @property({type: PlayerController}) public playerCtrl: PlayerController|null = null; private _curState: GameState = GameState.GS_INIT; @property({type: Label}) public stepsLabel: Label|null = null; start () { this.curState = GameState.GS_INIT; this.playerCtrl?.node.on('JumpEnd', this.onPlayerJumpEnd, this); } init() { if (this.startMenu) { this.startMenu.active = true; } this.generateRoad(); if (this.playerCtrl) { this.playerCtrl.setInputActive(false); this.playerCtrl.node.setPosition(Vec3.ZERO); this.playerCtrl.reset(); } } set curState (value: GameState) { switch(value) { case GameState.GS_INIT: this.init(); break; case GameState.GS_PLAYING: if (this.startMenu) { this.startMenu.active = false; } if (this.stepsLabel) { // reset the number of steps to 0 this.stepsLabel.string = '0'; } // set active directly to start listening for mouse events directly setTimeout(() => { if (this.playerCtrl) { this.playerCtrl.setInputActive(true); } }, 0.1); break; case GameState.GS_END: break; } this._curState = value; } generateRoad() { this.node.removeAllChildren(); this._road = []; // startPos this._road.push(BlockType.BT_STONE); for (let i = 1; i The end! Congratulations on completing your first game made with Cocos Creator! The complete project can be downloaded on our GitHub. The hope is this quick start tutorial will help you understand the Cocos Creator game development process, basic concepts and workflow. Next, you can continue to improve all aspects of the game. Here are some ideas for improvement: Increase the difficulty of the game, when the character stays in place for 1 second it fails. Change to infinite runway, dynamically delete the runway that has been run, and extend the runway behind. Add game sound effects. Add an end menu interface to the game, and count the number of jumping steps and time spent by the player. Replace characters and runways with prettier assets. Can add some pickable items to guide players to \"make mistakes\" Add some particle special effects, such as trailing when the character moves, dust when landing Add two operation buttons for touch screen devices instead of left and right mouse button operation Lastly, why not share this game with your friends? You can publish the completed game to a server of your choice using the Publishing Workflow documentation. "},"getting-started/support.html":{"url":"getting-started/support.html","title":"Support","keywords":"","body":"Get Help and Support More tutorials More engine dynamics, quality tutorials, and interviews can be viewed at or . Demo and example projects Note: all demo and example projects on GitHub will be updated with the version of Cocos Creator. The default branch corresponds to the latest Cocos Creator version. The old version of the project will be distinguished by the branch name like v0.7. The branch name will match the Cocos Creator version, please be careful to distinguish the version when downloading and using. Example collection: From the use of basic components to the display of rendering effects, this project includes multiple scenarios with different functions and multiple game demo projects for user reference. One Step, Two Steps: This is the Quick Start document Step-by-step explanation of the game. Examples of Physics: Includes some Physics test cases and examples, such as Engulfing Black Hole, Simple Car, Falling ball, etc. The test casesintroduce some basic functions and usage methods, so that you can understand the physical functions in combination with the documentation. Simple Games: Users can use this case study to complete some simple and famous games. Module display collection: The example project of each function of the engine, which basically covers most of the function modules of the engine. Users can refer to it when using the functions Development in this project. UI Show Demo: Demo of various UI components combined use Demo. Jump Ball 3D: Users can make jump ball games through this project. Taxi Game 3D: Physics-based game demo, users can make taxi games through this project. Third-party tools and resources for newcomers Code IDE VS Code Recommended coding environment for Cocos Creator. WebStorm Tools for generating texture packer TexturePacker Zwoptex Tools for generating Bitmap font Glyph Designer Hiero BMFont (Windows) 2D skeleton animation tools Spine Spriter DragonBones Tools for making special effect particles Particle Designer Particle2dx: Free online tool Other game development resources Cocos Store: Various game art assets, extension tools Send problems and feedback Apart from the information provided in this guide, you can also obtain information from or send feedback to the Cocos Creator development group through the following channels at any time: Cocos Creator Forum Cocos Tech Support "},"getting-started/attention/":{"url":"getting-started/attention/","title":"Caution!","keywords":"","body":"Precautions Syntax format Cocos Creator 3.0 and Cocos Creator v2.x use a different syntax format. Cocos Creator 3.0 has full support for ES6 and TypeScript. Therefore, Cocos Creator 3.0 only supports ES6 and TypeScript classes. In addition, we also support TypeScript syntax hints. Cocos Creator supports only ES5 classes. Please keep this precaution in mind. "},"release-notes/upgrade-guide-v3.0.html":{"url":"release-notes/upgrade-guide-v3.0.html","title":"Cocos Creator 3.0 Preview Upgrade Guide","keywords":"","body":"Cocos Creator 3.0 Upgrade Guide Version introduction Cocos Creator 3.0 integrates all the functions of the original 2D and 3D products, brings many major updates, and will become the main version of Cocos Creator. At the same time, 3.0 also continues Cocos's advantages of light weight and high efficiency in 2D categories, and provides an efficient development experience for 3D heavy games. In order to ensure the smooth transition of an existing Cocos Creator 2.4 project, we will use 2.4 as the LTS (long-term support) version and provide continuous updates for the next two years! In 2021, 2.4 will continue to be updated to provide bug fixes and new mini-game platform support to ensure the successful launch of your project; in 2022, we will continue to provide developers with the key to 2.4 bug fixes to ensure the smooth operation of online games! Therefore, Existing 2.x projects can continue to develop without compulsory upgrade to 3.0. For new projects, it is recommended to use version 3.0 for development. We will continue to optimize the development experience and operating efficiency of 3.0 to support the smooth launch of heavy games of different categories such as 2D and 3D. Cocos Creator 3.0 uses a new future-oriented engine architecture, which will bring high-performance, data-oriented and load-balanced renderers to the engine, and seamlessly support Vulkan & Metal multi-backend rendering. In the future, it will also support mobile VR/AR and some Host platform. For a detailed introduction to the Cocos Creator 3.0, please go to Official Website Update Instructions. How to migrate How to migrate Cocos Creator 2.x projects Although we do not recommend projects under development, especially projects that are about to go live, to upgrade to v3.0, there will be a v2.x resource migration tool in Cocos Creator 3.0. This tool supports importing old projects, project resources, and project code very well. Code-assisted migration will convert JavaScript into TypeScript, and automatically add component type declarations, attribute declarations and function declarations. The references of components in the scene will be preserved, and the code inside the function will be imported in the form of comments, which can reduce the difficulty of upgrading. Developers only need to click File -> Import Cocos Creator 2.x project in the main menu. Next, select the root directory of the Cocos Creator 2.x project in the file browse dialog that pops up. Note: it is recommended to upgrade to Cocos Creator 2.4.3 or above before importing to Cocos Creator 3.0 for older projects, otherwise the correctness of the import result cannot be ensured. All the resources in the Cocos Creator 2.x project will be automatically presented in the popup Import Cocos Creator 2.x Project panel. Developers can reconfirm the resources to be imported and then click the Import button in the bottom right corner of the panel to complete the import. If the developer wants to switch the imported 2.x project, click the search icon button in the image below to reselect the project. The Manual button in the bottom left corner of the panel will take you to the GitHub repository for the Import Plugin, which can be used to update the Import Plugin or submit feedback. Old version developers quickly get started Engine API upgrade Asset loading The API for Cocos Creator 3.0 asset loading is consistent with v2.4, please refer to the Asset Manager Overview. UI related interfaces on the obsolete node The UI-related interface changes on the node are as follows: The interfaces related to coordinate transformation calculation (e.g. size or anchor) are as follows: Please get the UITransform component on the node first, and then use the corresponding interface, for example: const uiTrans = node.getComponent(UITransform)!; uiTrans.anchorX = 0.5; uiTrans.setContentSize(size); The remaining interfaces are as follows: color: needs to get the rendering component on the node first (e.g. Sprite component), and then use the corresponding interface. opacity: If there is a rendering component on the node, set the color of the rendering component directly. If there is no rendering component, you can set the rendering component's color by adding the UIOpacity component and setting the related property. skew: The interface has been removed. group: change to layer. CCSpriteFrame: Remove the interfaces: copyWithZone, copy, clone and ensureLoadTexture. Change the interface: setFlipX and isFlipX -> flipUVX, setFlipY and isFlipY -> flipUVY, getTexture and setTexture -> texture (where the type is Texture2D/ RenderTexture). The remaining methods corresponding to get and set (e.g. getOffset) all correspond directly to properties of the same name (e.g. offset) in 3.0. CCTexture2D: Change the interface: genMipmaps -> mipmaps, initWithElement -> image. initWithData, the whole method is removed, similarly the use is to pass the original ArrayBufferView data to the new ImageAsset, and then ImageAsset to the new Texture2D to get a copy of the image resource. Action: Remove all related. Physics: 2D changed components: cc.Collider -> Collider2D, cc.BoxCollider -> BoxCollider2D, cc.RigidBody -> RigidBody2D, etc. 3D changed components: cc.Collider3D -> Collider, cc.BoxCollider3D -> BoxCollider, cc.RigidBody3D -> RigidBody, etc. tween: Change the interface: cc.repeatForever -> Tween.repeatForever、cc.reverseTime -> Tween.reverseTime、cc.show -> Tween.show, etc. Animation: Change the interface: addClip-> createState、getClips-> clips、playAdditive-> crossFade、getAnimationState-> getState, etc. Camera: Remove the interfaces: findCamera、alignWithScreen、main、cameras、zoomRatio and containsNode. Change the interface: backgroundColor -> clearColor、cullingMask -。 > visibility、depth->clearDepth、getScreenToWorldPoint->screenToWorld、getWorldToScreenPoint->worldToScreen、getRay->screenPointToRay, etc. Audio: Change the interface: getLoop and setLoop -> loop, getVolume and setVolume -> volume, getCurrentTime and setCurrentTime -> currentTime, src -> clip. Materials: All relevant changes need to be done by getting a Material instance on MeshRenderer or its subclasses. Remove the interfaces: setBlend, setDepth, setStencilEnabled, setStencil and setCullMode and call overridePipelineStates to complete the update. define calls recompileShaders to complete the update. The platform variable changes under sys are as follows: Cocos Creator 2.x Cocos Creator 3.0 BAIDU_GAME BAIDU_MINI_GAME VIVO_GAME VIVO_MINI_GAME OPPO_GAME OPPO_MINI_GAME HUAWEI_GAME HUAWEI_QUICK_GAME XIAOMI_GAME XIAOMI_QUICK_GAME JKW_GAME COCOSPLAY ALIPAY_GAME ALIPAY_MINI_GAME BYTEDANCE_GAME BYTEDANCE_MINI_GAME The global variables are changed as follows： Cocos Creator 2.x Cocos Creator 3.0 CC_BUILD BUILD CC_TEST TEST CC_EDITOR EDITOR CC_PREVIEW PREVIEW CC_DEV DEV CC_DEBUG DEBUG CC_JSB JSB CC_WECHATGAME WECHATGAME CC_RUNTIME RUNTIME_BASED CC_SUPPORT_JIT SUPPORT_JIT Dynamic Loading: When using bundle.load or resources.load to dynamically load a sprite-frame or texture in v3.0, the path needs to be specified to a specific sub-resource. // load texture // v2.x resources.load('background', cc.Texture2D, () => {}); // v3.0 resources.load('background/texture', Texture2D, () => {}); // load sprite frame // v2.x resources.load('background', cc.SpriteFrame, () => {}); // v3.0 resources.load('background/spriteFrame', SpriteFrame, () => {}); Editor upgrade Build Panel The builds of all platforms in Cocos Creator 3.0 are built-in plug-ins, so the Build panel is also different from v2.4. The unique build options of each platform will be placed in a foldable section control separately. After clicking the build button, it will jump to the Build Tasks panel, where all built platforms will be displayed. You can modify the build options of the built project in this panel and then rebuild, view the build log, open the project directory, etc. If you need to compile for other platforms, click the New Build Task button at the top left of the panel. In addition, it supports the construction of multi-module results with file separation during construction, which facilitates concurrent loading of multiple modules and dynamic loading of modules, and the WeChat engine plug-in supports the selection of different physical engine backends. The settings.js generated after the build is also changed to settings.json and placed under src directory, allowing it to be used as a resource upload server. Asset Preview Panel Select the resource in the Asset panel to display resource thumbnails in the Asset Preview panel. If the folder where the resource is located is selected, the thumbnails of all resources under the folder can be displayed for easy viewing. Animation Panel Upgrade Support the search and display filtering of nodes in the node tree panel. Support using the system clipboard to copy and paste all animation data (nodes, tracks, and key frames) on nodes. Support multi-select nodes to add attribute tracks in batches. Optimize the experience of selecting and deselecting key frames (Ctrl + mouse click to select key frames to deselect them). Support continuing to edit node attributes in the animation editing state, including particle and model material attributes, etc. Project Setting Panel Update It is divided into three parts: Engine Manager, Project Setting, and Build. The Physics Collision Group uses the PhysicsSystem.PhysicsGroup type independently, and no longer shares the group configuration with Node.Layers: Texture Compression is modified to configure the preset in the Project Setting panel, then select the image resource in the Asset panel, and then select the preset method. After the old project is upgraded, the editor will automatically scan all the compressed texture configurations in the project and sort out several presets. Since it is automatically scanned, the generated name may not be what you want, you can modify it here. Powerful extension system Cocos Creator v3.0 has a more powerful extension system. Almost all internal modules of the editor are built with extension system. You can quickly create your own extensions in the extended menu to achieve the customizations you want. In addition, Creator v3.0 also provides an Extension Manager, which can easily manage the operation and uninstallation of all extensions. Build Directory Differences Cocos Creator 2.x and Cocos Creator 3.0 differ to a certain extent in the directories generated after building on different platforms. Let's take v2.4.3 as an example and compare it with v3.0 on Web, Native and WeChat Mini Game platforms respectively. Web The directory generated by Cocos Creator 2.4.3 after building the Web Desktop is as follows: The directory generated by Cocos Creator 3.0 after building the Web Desktop is as follows: From the above two figures, notice the directory generated after building the Web Desktop, v2.4.3 and v3.0 are mostly the same, except with the following differences: Cocos Creator 3.0 puts all engine related code, such as core modules, physics modules, plugin scripts, etc., into the web-desktop/cocos-js directory, which looks clearer than v2.4.3, which was decentralized in the web-desktop directory. Cocos Creator 2.4.3 has only one startup script main.js, while v3.0 has the following two startup scripts: index.js -- Used to do some pre-processing work. application.js -- Used to start the game. The src/settings.js used to manage configuration in v2.4.3 is changed to src/settings.json in v3.0. The splash screen splash.png in v2.4.3 is stored in settings.json by default in v3.0. The style-desktop.css and style-mobile.css in v2.4.3 are combined into a single style.css in v3.0. WeChat Mini Game The directory generated by Cocos Creator 2.4.3 after building the WeChat Mini Game is as follows: The directory generated by Cocos Creator 3.0 after building the WeChat Mini Game is as follows: From the above two figures, notice the directory generated after building the WeChat Mini Game, v2.4.3 and v3.0 are mostly the same, except with the following differences: Cocos Creator 3.0 puts all engine related code, such as core modules, physics modules, plugin scripts, etc., into the wechatgame/cocos-js directory. While v2.4.3 scattered part of it in the wechatgame directory and part of it in the wechatgame/cocos directory. Cocos Creator 2.4.3 compiles all the adaptation layer code of mini games into adapter-min.js, while v3.0 stores all the adaptation layer code as loose files in the libs directory, without compilation. The startup script for v2.4.3 is main.js, and for v3.0 it is application.js. Cocos Creator 2.4.3 records all references of dynamic code in ccRequire.js. While v3.0 currently does not have this feature. The src/settings.js used to manage configuration in v2.4.3 is changed to src/settings.json in v3.0. Native Note: this part has not been updated to the latest version yet, please refer to the actual build result. The directory generated by Cocos Creator 2.4.3 after building the Windows platform is as follows: The directory generated by Cocos Creator 3.0 after building the Windows platform is as follows: As you can see from the above two figures, there is a big difference between v2.4.3 and v3.0 in the directory generated after building the Windows platform. Since the underlying C++ code generated after building on each native platform (e.g. Android, Windows) is completely consistent. Cocos Creator 3.0 extracts the underlying C++ code that was stored in the jsb-link/frameworks/runtime-src/Classes directory in v2.4.3 and placed it in a shared common-link folder. This way, when building the native platform, if the common-link folder is detected to already exist, this part will no longer be processed, to speed up the build. The Windows folder is used by v3.0 to store the native-related content for the current built (or the android folder if the build is for Android). Let's take a look at the jsb-link directory generated after the build in v2.4.3. The main differences between them include the following: The files belonging to the application layer in the v2.4.3 build directory have been merged into the assets directory in v3.0. The application layer files include the following: assets -- Resource directory. jsb-adapter -- Directory, store the adaptation layer code. src -- Directory, store engine related code, plugin scripts, settings.js etc. Related configuration files (.cocos-project.json, cocos-project-template.json, project.json). The startup script (main.js). The assets directory structure of v3.0 is as follows: Cocos Creator 3.0 has also made adjustments and changes accordingly during the merging process. All the engine related code (such as core modules, physics modules, plugin scripts, etc.) that was originally placed in the src/cocos2d-jsb.js file in v2.4.3 is moved to the assets/src/cocos-js directory. Cocos Creator 2.4.3 has only one startup script main.js, while v3.0 adds a new startup script application.js in the src directory to startup the game in addition to main.js. The src/settings.js used to manage configuration in v2.4.3 is changed to src/settings.json in v3.0. Cocos Creator 2.4.3 generates all the native build projects in the frameworks/runtime-src directory. While v3.0 generates the native build project in the build directory and only generates the native build project for the current built. As shown below: Some resources needed for compilation, such as application icons, application startup scripts, etc., v2.4.3 are stored in the build project, while v3.0 are stored in the windows/proj directory. TypeScript Reference Tutorial TypeScript Official Website TypeScript - Classes TypeScript - Decorators TypeScript - DefinitelyTyped Learn TypeScript in Y minutes [cn] TypeScript GitHub The Best Resources For Learning TypeScript for Game Development "},"editor/":{"url":"editor/","title":"Editor Introduction","keywords":"","body":"Editor panel overview This chapter will introduce the editor panel and get familiar with each of the panels, menus and functional buttons that make up the editor. The Cocos Creator 3.0 editor is composed of multiple panels which can be moved and combined freely to meet the needs of different projects and developers. Here we will take the default editor layout as an example to quickly browse the name and function of each panel: Scene Scene panel is used to show and edit the visible working area in the scene. WYSIWYG scene building work is all done depending on the display in the Scene. For further information please read the Scene panel. Hierarchy Hierarchy panel displays all the nodes and their hierarchy in the form of a list tree. For all the content you can see in the Scene, the corresponding node entry can be found in the Hierarchy. The content in these two panels when editing the scene will synchronize the display and we normally use these two panels at the same time to build the scene. For further information please read the Hierarchy panel. Assets Assets panel shows all the assets in the project asset file (assets). It will show the folder in a dendritic structure and auto-sync the content changes in the project resource folder from the operating system. You can drag files in or use the menu to import resources. For further information please read the Assets panel. Inspector Inspector panel is the working area where we view and edit the currently selected node and component property. This panel will display and edit the attribute data defined by the script in the most suitable way. For further information please read the Inspector panel. Console Console panel will report errors, warnings or other log informations generated by Cocos Creator 3.0 editor and engine. For further information please read the Console panel. Animation Animation panel is suitable for making some less complex animations that need to be linked with logic, such as UI animations. For further information please read the Animation panel. Preferences Preferences panel provides various personalized global settings for editor, including native development environments, game previews, script editing tools, and so on. For further information please read the Preferences panel. Project Settings Project Settings panel provides various project specific personalization settings, including grouping settings, module settings, preview runs, and so on. For further information please read the Project Settings. "},"editor/scene/":{"url":"editor/scene/","title":"Scene","keywords":"","body":"Scene Panel Scene panel is the core working area of content creation, You will use it to choose an place the scene image, character, effect, UI and other game elements. In this working area, you can select and use the Transform Tool to change the position, rotation, scale, size and other attributes of node, also you will preview the WYSIWYG scene. View Introduction Navigation There are some differences between 3D view and 2D view navigation. you can change between 3D view and 2D view by click the 3D/2D button on the toolbar. 3D view is used for 3D scene editing, 2D is used for UI and Sprite editing. 3D View In 3D view, you can move and rotate the view of the Scene panel by the following operations: left mouse button + Alt: rotate editor camera around view center. middle mouse button: pan view. mouse scroll: move editor camera back and forth. right mouse button + WASD: wandering in scene editor. F shortcut: focus editor to the selected node. 2D View In 2D view, you can move and rotate the view of the Scene panel by the following operations: middle mouse button: pan view. mouse scroll: scale view based on the current mouse position. right mouse button: pan view. F shortcut: focus editor to the selected node. Coordinate System And Grid The Grid in a scene is an important reference information for us to layout scene elements. For information on relationship between coordinate system and node attributes, like position, please read the Transform documentation. Scene Gizmo The Scene Gizmo is in the upper-right corner of the Scene view. It indicates the view direction of editor camera in Scene view. You can change view direction quickly by clicking on it. Click on the six arrows, you can change to the top, down, left, right, front, back views separately. Click on the cube in the center, you can switch between ortho camera mode and perspective camera mode. Selecting a node The node will be selected upon left-clicking the mouse on the node in the Scene panel. Use transform tools (like position, rotation) to do basic node operations when it is selected. Gizmo Operation Introduction The main function of the Scene panel is to edit and arrange the visible elements in the scene and get a WYSIWYG scene immediately. Mainly Gizmo tools are used to assist in the visual editing of the scene. Please review the following documentation: Transform Gizmo Camera Gizmo Light Gizmo Collider Gizmo ParticleSystem Gizmo "},"editor/hierarchy/":{"url":"editor/hierarchy/","title":"Hierarchy","keywords":"","body":"Hierarchy Panel The Hierarchy panel is the panel used to show the hierarchical relationship of most nodes in the current scene. There are some nodes in the scene that do not need to be displayed, which are generally the necessary factors to support the display of the scene, but they are not operable and can be ignored by the user. If there is a plug-in, you can see the details of the plug-in. You can select, create, move, rename or delete nodes in the Hierarchy panel. Any node can create a child node. The coordinate system of the child node is relative to the parent node. Hierarchy Manager introduction The Hierarchy panel contains a top menu area and a bottom tree list area on the panel: The functions of the top menu are: New Node Button, Search Type Button, Search Box, Fold All or Expand Button, Refresh List Button. The tree-like list area at the bottom mainly reflects the hierarchical relationship of nodes. The root node is scene node. When editing the prefab file, is the root node scene node, but the top node of itself. There is a blank area with a height of 20px at the end of the tree-shaped area. Click here to uncheck, that is, the Hierarchy panel can have no selected items. The panel supports right-click menus, and the content of right-click menus in different positions and nodes will be different. The panel supports keyboard shortcuts: Copy: Ctrl or Cmd + C Paste: Ctrl or Cmd + V Duplicate: Ctrl or Cmd + D, Ctrl + drag node Delete: Delete Up and down selection: up and down arrows Collapse of nodes: left arrow or Backspace Expansion of nodes: right arrow or Enter Multi-select: Ctrl or Cmd + click Multi-select: Shift + click Rename: Enter/F2 Cancel: input: Esc New Node Click the New Node button When adding a node, a input box will appear first. It is required to fill in the name of the node. The name of the node is allowed to be empty. If an item is not selected in the tree list, it will be newly created at the current root node by default. If there are multiple selected items, it will be newly created at the first selected node. In addition, there is a New entry in the right-click menu of the node. For the UI node, in order for it to display properly, at least one of its parent nodes must contain a UITransform component, so when it is created, if it does not meet the rules, it will assist in adding a Canvas node as it's parent. In addition, a node can be generated by dragging a prefab asset from the Asset Manager to the Hierarchy panel. You can generate a asset by dragging a prefab node into the Asset Manager through the Hierarchy panel. Moving a Node The movement is divided into moved node and target placement node, in which the height of target placement node is identified in three parts: upper, middle, and lower. These indicate: On the upper side, move the moved node above the target placement node, the two are level. In the middle, move the moved node to the target placement node, at the end. On the lower side, move the moved node below the target placement node, the two are level. Searching for a Node The search types are: search name, search UUID, search path and search component name. search component name is the search node component. The component name can be viewed in the Inspector panel, as MeshRenderer. The Search box is searched in real time. When a node is selected in the search results, after clearing the search content, it will be relocated to the selected node. Renaming a node Select a node, press the shortcut key Enter or F2, or right-click the menu and select Rename to modify. The node name is allowed to be empty, press the shortcut key Esc to cancel this rename. Different nodes can have the same name. "},"editor/assets/":{"url":"editor/assets/","title":"Assets","keywords":"","body":"Assets The Assets panel is an important tool used to access and manage project assets. When starting to make a game, importing assets is usually a necessary step. Use the Hello World template project as a starting point when creating a new project. After you create and open a new project, various types of assets are visible in the Assets panel. Assets Panel introduction The Assets panel is the main panel. It has a heads-up menu area, a central tree list area, and a bottom information display area. The functions of the heads-up menu area are: New asset button, Sort by button, Search type button, Search box, Fold or expand all button, and Refresh list button. The central tree list area mainly reflects the hierarchical relationship of assets. The root node is the asset root folder corresponding to the file manager of the operating system. The editor calls an asset database (DB for short), and is located in the project folder. It belongs to the project asset; Internal DB comes with the editor and provides some built-in necessary assets. It is a read-only asset. It cannot be added, deleted, modified, but can be directly referenced or copied. The right-click menu of the panel is also an important function. The contents of the right-click menu in different locations are different, and the unavailable menus are grayed out. The shortcut of the panel currently supports the operation of assets: Copy: Ctrl or Cmd + C Paste: Ctrl or Cmd + V Copy: Ctrl or Cmd + D, Ctrl + drag asset Delete: Delete Up and down selection: up and down arrows Folder folding: left arrow or Backspace Expand the folder: right arrow or Enter Multi-select: Ctrl or Cmd + click Multi-select: Shift + click Rename: Enter/F2 Cancel Rename: Esc New Assets There are two ways to create a new asset, one is to click the + button at the top left of Assets panel. The other is to right-click in the Assets panel and select Create. When adding a asset, an input box will appear. The name of the asset is required. If the input is empty, the asset will not be created. If there is no selected item in the tree list, it will be newly created on the root node of Asset DB by default; if there are multiple selected items, it will be newly created in the first selected item at this time. Selecting Assets Use the following operations to select assets in the list: Click to single-select assets. The up and down arrows on the keyboard can be used to select. Hold down Ctrl/Cmd + click to select multiple assets. Hold down Shift + clickto select multiple assets. Dragging Resources Assets can also be added by dragging: Move the asset, drag the asset from one folder in the tree list to another folder. At this time, the location box of a target folder will follow the change. Drag out assets to the Scene panel or Hierarchy panel to generate nodes. Currently, cc.Prefab, cc.Mesh, cc.SpriteFrame assets are supported. Drag files from System File Manager to the list to import assets. Drag in the node and drag the node from the Hierarchy panel to a folder in the Assets panel to save the node as a cc.Prefab asset, see the Prefab documentation. Deleting Assets The Delete option is located in the right-click menu, or the shortcut key Delete, which supports batch deletion after multiple selections. After the asset is deleted, it is kept in the system recycle bin, and can be deleted if necessary reduction. Selecting All In The Folder Right-click Select All in the menu to select all sub-assets in the folder. Searching In Folders Right-click Search in Folder in the menu to narrow the search scope. Displaying In The File Manager Right-click Show in File Manager in the menu to locate the system directory where the asset is located. Re-importing Assets Right-click Reimport Resources in the menu to update the corresponding assets in ./library in the project, and these generated data can be recognized by the editor and engine; support multiple selections and batch reimport. Sorting Assets The Sort by button in the top menu has 2 sorting methods: Sort by name and Sort by type. The sorting method has a memory, and the next time you open the editor, the saved sorting method will be preserved. Searching Assets The search function is a combined function that can limit the search type and specify the search field. Limited search type is a major premise. This point requires special attention, which may cause the tree list to be empty. The button is highlighted to indicate that the function is enabled. Multiple selections are possible, select All in the type to return to the normal tree list. There are 3 ways to specify the search field: Search Name or UUID, Search UUID, Search UUID. Among them, UUID and UUID can output data from the last item of the right-click menu. Search box changes instantly. Select the asset in the search results, clear the search, the window will relocate to the asset, to achieve the purpose of finding the asset through search; in addition, double-click the folder in the search result to quickly locate the folder in the tree. Collapsing assets Head menu area All collapse or expand buttons are global. The triangle icon of the tree node, you can press the alt key to expand or collapse all sub-assets. Renaming Assets Select an asset. Shortcut key F2, shortcut key Enter, enter name modification Shortcut key Esc to cancel rename In addition, the initial name of the Typescript asset will be treated as its className, and the className cannot be repeated. Big Picture Preview In addition, it can be used in conjunction with the Assets Preview panel to click on a folder to display the sub-assets of the big picture arranged by type, which is more intuitive for picture assets. "},"editor/inspector/":{"url":"editor/inspector/","title":"Inspector","keywords":"","body":"Inspector panel The Inspector is important for viewing and editing the properties of nodes or assets. You can edit the location of a node, components, pictures, materials, models and other assets of a node. The Inspector features many details and can seem complicated. To get started, aselect the node in Scene panel, Hierarchy panel, or select the asset in Asset panel. Properties can now be displayed or edited. Header area The two arrows on the left are the historical records, click to switch the editing items. The lock icon on the right can lock the panel, fix the edited object, and prevent the panel from changing with the new selected item. Editing a Node Nodes correspond to the nodes in the tree structure in the Hierarchy panel and display the same name. The check box in the upper left corner indicates the activation state of the node. By default, the check box indicates that the node is in an inactive state. The node will be suspended from rendering, and the entire node, including child nodes, will be hidden when running. In the input box is the name of the node. The name can be empty. Next are several general properties of the node: position, rotation, scale, and layer. The node menu on the right, the menu inside can be copied, paste the value of the node attribute, or you can paste a new component. Use the Add component button, after clicking, a list of components will appear, including components provided by the system and custom script components. The list of added components has a search box that supports the up and down arrows on the keyboard, or Enter can be used to confirm the selection. Editing Node Components This panel can display node components and component properties. Like the general properties of nodes, each component has a foldable or expandable header. When multiple components are attached to a node, the scrolling range can be reduced by folding components that are not frequently modified, and improve editing efficiency. To the right of the component name is a help document and a component menu button. The help document button can jump to the API document of the component. The component menu can be operated on: removed, moved up, moved down, copied, pasted as a value, or pasted as a new component. The component created by the user through a script, when editing a node, can be directly dragged into the Inspector panel to generate a component. The different properties in the script component are declared by the user in the script code. When the different types of properties are edited, the editor will automatically recognize the appropriate UI component. The definition of properties is explained, in detail, in the Declaring Properties documentation. How to use UI components Properties are divided into value types and reference types. Value type properties Value type includes simple variable types that take up very little memory, such as numbers, strings, booleans, and enumerations: Number: the keyboard is used to enter digits. The up and down arrows next to the input box can gradually increase or decrease the attributes value. Vector (Vec2): The vector control is a combination of two numeric inputs, and the input box will identify the sub-property name corresponding to each numeric value with x and y. String: the keyboard is used to input strings directly in a text box. The string input control is divided into single line and multi-line. The multi-line text box can be changed by pressing Enter. Boolean: edited in the form of a check box. The selected state indicates that the attribute value is true, and the non-selected state indicates false. Enum: edited in the form of a pull-down menu. Click the enumeration menu, and then select an item from the pop-up menu list to complete the modification of the enumeration value. Color: click the color attribute preview box, and a color picker window will pop up. In this window, you can directly click the desired color with the mouse, or directly enter the designation in the RGBA color input box below s color. Click Color Picker anywhere outside the window to close the window and use the last selected color as the attribute value. For example, the color picker component: Reference type properties Reference types include objects, such as nodes, components, or assets. You can select and assign values ​​by dragging or popping up the asset panel. Batch operationas Multi-selectable nodes, inconsistent properties cannot be modified, and - in the input component indicates that they cannot be modified. Batch assign materials, pictures, animations and other assets, which can be dragged multiple times. Editing Prefab Nodes When editing a Prefab Node, the header area buttons are: disassociate, associate, locate assets, restore from assets, and update to assets. Disassociation refers to disconnecting the prefab node from the asset and turning it into a normal node, the color is no longer green. Association means that a Prefab asset is selected first and then associated with the current Prefab node. The new association between common nodes and Prefab assets can be found in the top menu of the editor Edit: Locating assets refers to locating the Prefab asset on the assets panel and making it flash. Restore from asset means to return an edited Prefab node, along with its child nodes, to the initial state. Update to asset refers to updating the Prefab node data that has been edited to the Prefab asset. Editing Assets When editing assets, please pay attention to the last click to save, the green tick icon in the figure below is the save button. "},"editor/console/":{"url":"editor/console/","title":"Console","keywords":"","body":"Console Console outputs editor or engine information, including log, warnings, and errors. Different types of information will be displayed in different colors. The colors displayed are as follows: console.log(): output log, gray text, the content that developers in the editor and plug-in feel necessary to print to the console. console.warn(): output warning, yellow text, the abnormal situation encountered by the program that does not affect the result. console.error(): output error, red text, the exception encountered during operation that will affect the result, the severity is the highest. Panel operation The functions of the top toolbar are: Clear all logs in the current console. Enter text fuzzy search. Whether to convert the input text to regular search. Select the type of log to display. Open the log file backed up on the disk, and the file data will be reset every time the editor starts. Parameter Settings Some parameters of the console are configured in Preferences. Please refer to the extended settings in the Preferences documentation. Content Output Rules In order to facilitate the location of files, nodes or resources, and provide a quick step to the help document, some recognition of the content and adding actions is required. Specific requirements are as follows: Redirect links according to url. Display pictures according to url. Locate Asset resource according to url or uuid. Locate the Node node according to uuid. Locate the script file according to the disk file path path. Output text in the corresponding language. Data Format {type[text](url)} {type(text | url | uuid | path)} Data format description Match the characters in {} as a whole. [text] is optional for expansion input. When type exists, it is not case sensitive. When type does not exist, the original data is output. types has: link: external redirect link. Image: display picture. Asset: locates resources. node: locates the node. I18n: multilingual translation. Example console.log('Open {link[the help doc url](https://docs.cocos.com/creator/manual/en/editor/console/)}'); console.log('Locate {link[ the file in library](D:/cocos-creator/a/library/36/36b55a90-1547-4695-8105-abd89f8a0e5f.js)}'); console.log('Locate Node UUID {node(f6zHdGKiZDhqbDizUsp8mK)}'); console.warn('Locate Asset UUID {asset(17185449-5194-4d6c-83dc-1e785375acdb)}'); console.error('Locate Asset URL {asset(db://assets/animation.anim)}'); console.log('The URL is {asset[{asset(db://assets/animation.anim)}](db://assets/animation.anim)}'); console.log('Show image {image(https://forum.cocos.org/images/logo.png)}'); console.log('Translate: {i18n(console.description)}'); Which looks like this in the Console window: "},"editor/animation/":{"url":"editor/animation/","title":"Animation","keywords":"","body":"The Animation system This chapter will introduce the Animation System of Cocos Creator. In addition to standard displacement, rotation, zoom animation and sequence frame animation, this Animation System also supports arbitrary component properties and user-defined properties. Plus the time of arbitrary editing curves and innovative mobile trajectory editing functions enable content producers to create delicate, yet, dynamic effects without writing a line of code. Note: Cocos Creator's built-in Animation Editor is suitable for making less complex animations that need to be linked with logic, such as UI animations. About Animation Familiar with animation editor Create Animation components and animation clips Edit Animation Sequence Creating A Frame Animation Edit Animation Curve Animation event "},"editor/preferences/":{"url":"editor/preferences/","title":"Preferences","keywords":"","body":"Preferences The personalized settings of the editor are provided in the Preferences window. You can click the Preferences menu to open the Preferences window. Preferences is divided into the following pages: General General page are mainly configured for some basic data related to the editor. Language: Can choose 中文 or English. IP Address: Case the user may have multiple IP addresses on this computer. Manually select one and two-dimensional code as a default when previewing address. This will list all native IP, editor will picked one for you automatically. Spin step: In the Properties, all numeric property has a set of UP and DOWN arrows next to the input box, values that can be used to step Input: When hovering close to the value of the property name, the cursor will turn into such a shape, then Drag the mouse, can also according to a continuous increase or decrease the value of step amplitude. The above two ways to modify the value, the default step is 0.1, spin step says each time you click the step button or drag the mouse to change the step amplitude. For example, if you mainly use numbers to integers in the script, you can take the step size is set to 1, can be adjusted more easily. Native Develop This page is used to set the path of the development environment required when the game is published to the native platform (iOS, Android, Mac, Windows). Use Builtin JS Engine: Whether to use the engine path that comes with the Cocos Creator installation path as the JavaScript engine path.This engine is used for scene rendering in the scene panel of editor, declaration of built-in components, and engine modules in other Web environments such as preview or publish. Custom JS Engine: In addition to using the built-in engine, you can also go to engine repository to clone or fork a copy of the engine to the local anywhere, then uncheck Use Builtin JS Engine, then set the JavaScript engine path to your customized engine path. Use the editor to customize your engine. WeChatGame APP Path: Set the WechatGame App Path, See WeChat Mini Games. Android NDK Path: Set the NDK Path, See Setup Native Development Environment. Android SDK Path: Set Android SDK Path, See Setup Native Development Environment. Data Editor This category is used to set the default open mode for assets. Script Editor: Use the executable file of any external text editing tool as the opening method when you double-click the script file in Assets. Picture Editor: Similar to the above option, used here to set when Assets, double-click the picture file, open the picture with the default application path. Extension The plugin allows directly registering configuration items into preferences. The configuration items registered in the preferences will be displayed here. For details, please refer to the documentation of each plug-in. Laboratory About Laboratory: The laboratory provides some new technical solutions or experimental features, you can turn each feature on with the on/off switch. Non-backward compatible changes or removal may occur in any future release. Use of the feature in production environments should be well tested and pay attention to the publish notes of future versions. We welcome users to try out and give us your feed backs via our forum, you can make those features more powerful and easier to use in your own projects. Use The Search Pop To Add Components Many users feedback that components can not be searched when add components make they inconvenient. In the face of massive custom scripts component of many projects, find their own scripting components is very difficult.But use the search pop means multi-step operation. Of course, you can turn this option back to the original use. In order to make user more convenient, we also add some auxiliary editing design: The focus will be in the search box when the pop-up window is opened, and you can directly search for related keywords without mouse click to expand; When searching for related components, you can directly use the shortcut keys ↑ ↓ to quickly switch component options, and press the enter key to add the component; For this feature, if you have more awesome suggestions, welcome to tell us in the forum. Turn on terrain For more details can refer to Terrain system documentation. "},"editor/project/":{"url":"editor/project/","title":"Project Settings","keywords":"","body":"Project Settings The Project Settings windows are available from Cocos Creator’s main menu (Project > Project Settings) which includes all the settings related to your project. These settings will be saved in the project's settings / packages folder. If you need to synchronize project settings between different developers, this folder should be added in your source control system. General Default Canvas settings The default Canvas settings include design resolution and adapted screen width/height, which are used to specify the default design resolution value in Canvas when creating a new scene or Canvas component, as well as the Fit Height, Fit Width options. For more information, please refer to the Multi-resolution adaptation scheme documentation. Engine Modules The setting here is to crop the modules used in the engine to reduce the size of the released engine. Modules not selected in the panel will be cropped when they are packaged and previewed. It is recommended to perform a complete test after released to avoid using cropped modules in scenes and scripts. Macro Config For more information and code of the engine macro module, please refer to the Engine macro documentation. This panel here provide the convenience to modify the macro configuration. The Macro Config will take effect during preview and build. At the same time, the default value of the current macro configuration will be updated with the configuration of the custom engine. Texture Compress In Cocos Creator 3.0, the editor has modified the use of compressed texture configuration to configure presets in project settings and select presets for image asset's inspector. After the old version of the project is upgraded, the editor will automatically scan all the compressed texture configurations in the project and sort out as several presets. Used to add compressed texture preset configuration, you can directly select the compressed texture preset to quickly add in the inspector of image asset. At the same time, after adding presets, you can also directly modify the presets to update batch texture compress configuration. Project settings allow users to add multiple compressed texture configurations, and each compressed texture configuration allows to add different format for different platform categories. Platform is rough devised as following: Web: refers to the two platforms Web-Mobile and Web-Desktop Mac & Windows iOS Mini Game: Refers to the mini-games of various manufacturers' platforms, such as WeChat Mini Games and Huawei Quick Game Waiting; Android For the detail of the texture compression support of the platforms, please refer to the Compressed Texture Chapter documentation. Add / remove texture compression presets Enter the name of the compressed texture preset in the input box and press Enter or the plus button on the left to add it. After adding the compressed texture preset, if you need to delete it, you can directly move the mouse to the preset name and click the delete button on the right. Add / remove texture compression format Click the Add Format button, select the desired texture format, and configure the corresponding quality level. Currently, only one image format of the same type can be added at the same time. To delete, move the mouse over the texture format and click the red delete button. Modify compressed texture preset name The name of the compressed texture is only used for display. When adding a compressed texture preset, uuid will be randomly generated as the ID of the preset, so directly modifying the preset name will not affect the reference to the preset in the image asset. Export / import compressed texture presets The compressed texture configuration page allows developers to import and export compressed texture presets for better cross-project reuse. It is also possible to edit the compressed texture presets externally and import them into the editor. In most cases, importing and exporting directly works well. If, however, the configuration needs to be customized, please refer to the following interface definitions and examples: type IConfigGroups = Record; type ITextureCompressPlatform = 'miniGame' | 'web' | 'ios' | 'android' | 'pc'; type ITextureCompressType = | 'jpg' | 'png' | 'webp' | 'pvrtc_4bits_rgb' | 'pvrtc_4bits_rgba' | 'pvrtc_4bits_rgb_a' | 'pvrtc_2bits_rgb' | 'pvrtc_2bits_rgba' | 'pvrtc_2bits_rgb_a' | 'etc1_rgb' | 'etc1_rgb_a' | 'etc2_rgb' | 'etc2_rgba' | 'astc_4x4' | 'astc_5x5' | 'astc_6x6' | 'astc_8x8' | 'astc_10x5' | 'astc_10x10' | 'astc_12x12'; type IConfigGroupsInfo = Record interface ICompressPresetItem { name: string; options: IConfigGroups; } Example: { \"default\": { \"name\": \"default\", \"options\": { \"miniGame\": { \"etc1_rgb\": \"fast\", \"pvrtc_4bits_rgb\": \"fast\" }, \"android\": { \"astc_8x8\": \"-medium\", \"etc1_rgb\": \"fast\" }, \"ios\": { \"astc_8x8\": \"-medium\", \"pvrtc_4bits_rgb\": \"fast\" }, \"web\": { \"astc_8x8\": \"-medium\", \"etc1_rgb\": \"fast\", \"pvrtc_4bits_rgb\": \"fast\" }, } }, \"transparent\": { \"name\": \"transparent\", \"options\": { \"miniGame\": { \"etc1_rgb_a\": \"fast\", \"pvrtc_4bits_rgb_a\": \"fast\" }, \"android\": { \"astc_8x8\": \"-medium\", \"etc1_rgb_a\": \"fast\" }, \"ios\": { \"astc_8x8\": \"-medium\", \"pvrtc_4bits_rgb_a\": \"fast\" }, \"web\": { \"astc_8x8\": \"-medium\", \"etc1_rgb_a\": \"fast\", \"pvrtc_4bits_rgb_a\": \"fast\" }, } } } Layers Layers allows the camera to render part of the scene and let the light illuminate part of the scene. You can customize 0 to 19 Layers, and the original settings will be deleted when you clear the input box. The last 12 Layers are built-in in the engine and cannot be modified. The layers of node matches the visibility option of the camera, the camera can only see nodes whose layer is included in the camera's visibility. For more instructions, please refer to Camera Component introduction; Physics Used to configure the parameters of the physics environment. For details, please refer to the Physics Configs documentation. Bone map layout settings Explicitly specify the bone texture layout to assist the instancing of the skinning models. For details, please refer to the Joints Texture Layout documentation. "},"editor/project/physics-configs.html":{"url":"editor/project/physics-configs.html","title":"Physics Configs","keywords":"","body":"Physics Configs Physical configuration is used to configure various commonly used properties. Property description gravity Gravity direction vector, the sign means the positive or negative direction on the axis. Default: { x: 0, y: -10, z: 0 }. allowSleep Whether to allow rigid bodies to enter sleep state. Default: true. sleepThreshold The maximum speed threshold for entering sleep. Default: 0.1，Min: 0. autoSimulation Whether to enable automatic simulation. fixedTimeStep Fixed time step between each simulation. Default: 1/60, Min: 0. maxSubSteps Maximum number of substeps per simulation step. Default: 1, Min: 0. friction Coefficient of friction. Default: 0.5. rollingFriction Rolling friction coefficient. Default: 0.1. spinningFriction Spin friction coefficient. Default: 0.1. restitution Coefficient of elasticity. Default: 0.1. collisionMatrix The collision matrix, used only for initialization. Collision Matrix The collision matrix is used to initialize groups and masks of physical elements. Grouping concept In the editor, the grouping format of the collision matrix is {index, name}, index is the number of bits from 0 to 31, and name is the name of the group. The new project will have a default grouping: {index: 0, name: 'DEFAULT'}. By clicking the + button you can add a new group. Note: both index and name cannot be empty and cannot be repeated with existing items; after adding, the group cannot be deleted, only the name of the group can be modified. How to configure Take a new water group as an example: This table lists all the groups, and you can check it to determine which two groups will do the collision detection. As shown in the figure above, whether DEFAULT and water will perform collision detection will be determined by whether the corresponding check box is checked. According to the above rules, the collision pairs generated in this table are: DEFAULT - water DEFAULT - DEFAULT And the grouping pairs that do not perform collision detection include: water - water Configure groups of physical components In addition, the Group property on the RigidBody component needs to be configured into the corresponding physical element: "},"editor/preview/":{"url":"editor/preview/","title":"Preview a Game","keywords":"","body":"Previewing The Game After we use the editor to manage assets, build scenes and tweaking components, it's time to preview the game to run on your target platform. Preview In Browser Introduction To Preview Process And Common Error Handling "},"editor/preview/browser.html":{"url":"editor/preview/browser.html","title":"Previewing in Browser","keywords":"","body":"Preview In Browser How To Preview Click the Preview button on top of editor window to see the game in action. After clicking, editor will launch the game in your default browser. We recommend Chrome as the browser of choice, since the developer tools in Chrome are most advanced in web debugging and inspecting. There are a number of control in Preview page: On the left are viewport size presets to simulate how your game look on mobile devices. Rotate button to toggle between landscape and portrait view. Debug Mode let you control the severe level of logs to be shown. Show FPS toggle framerate and draw call stats display. FPS framerate cap. Pause to pause game. Refresh Preview Page If we want to refresh the preview page after some modified, just refresh in browser or click the refresh button in editor. The difference is that click refresh button in editor will refresh all preview pages.If you want the preview page to refresh automatically, just save the scene.The settings for saving scene auto-refresh can be enable in Project Settings -> Project Preview. Scene of Preview The editor will use the current scene as start-scene of preview, we can modified it in Project Settings-> Project Preview. For more information, please refer to the Project Settings documentation. Preview In Mobile There are the following ways to debug the preview page on the mobile phone: Use the mobile browser preview mode of Browser Developer Tools Scan preview QR code Move the mouse to the ip preview address on the left side of the editor toolbar, and a preview QR code will be displayed, which can be scanned with your mobile phone. Directly Enter the preview address in the mobile browser Note: make sure the mobile phone and the computer is on the same network segment.Since there will be multiple networks on the computer, if the IP address of the preview URL in the editor is incorrectly, you can modify it in Preferences-> General Settings-> Select Local Preview Address. Please refer to the description of the preference settings documentation. Custom Preview Template We can add custom preview template to change the preview result, just put your template in preview-template folder in the project dictionary. Editor also use template to render to index.html. If there is a file named index.ejs in this dictionary, editor will use it as the template that render to index.html. You can click the menu in editor Project —> Generate Preview Template to get the latest template used in editor. project-folder |--assets |--build |--preview-template |--index.ejs Note: there are some preview menu items and preview debugging tools in the preview template, We recommended you keep all the content and just add what you need or modified code carefully to avoid some unexpected errors.. In addition, if index.html and index.ejs coexist, index.html will replace index.ejs as the render-template for preview page. Examples of Use Code of this example is stored in the test-case-3d repository. Get lasted preview template Click the menu Project-> Generate Preview Template to generate a preview template, and the address generated by the preview template will be printed in the console. Add script in folder Add the scripts you need to use in folder, such as test.js, where contains the default logic for starting the game. test.js in the example below will be loaded after the game starts. Modify index.ejs Open index.ejs and modify as follows: ... ... // Game start processing logic // New script Place test.js in the preview-template folder like blow |--preview-template |--index.ejs |--test.js Preview Now, you can refresh your preview game to see changes. Add Custom Devices Info Open Project —> Project Preview. Custom device info can be modified on this page, and changes will work after refreshing the preview page. Debugging with browser Developer Tools Take Chrome for example, open menu and choose Developer/Developer Tools to open the Developer Tools. It is possible to debug source code, add breakpoints, check the call stack and use step control during debugging. To learn more about using DevTools, please read the Chrome Dev Tools User Guide documentation, or other browser's developer documentation. Browser compatibility The desktop browsers tested during Cocos Creator development include: Chrome, Firefox (Firefox). Other browsers can be used as long as the kernel version is high enough, for some browsers do not enable IE6 compatibility mode. Browsers tested on mobile devices include: Safari (iOS), Chrome, QQ browser, UC browser, and WeChat built-in Webview. "},"editor/preview/preview-guid.html":{"url":"editor/preview/preview-guid.html","title":"Introduction To Preview Process And Common Error Handling","keywords":"","body":"Introduction to the Preview Process And Common Error Handling Introduction to the Preview Process When opening Cocos Creator, the editor will open a web server (we use Express). When clicking the preview button, the user's default browser will open and access the preview URL. The Editor uses preview templates to write some simple logic for loading the engine, initializing the game, loading game assets. The loading of game assets mainly depends on the generation of setting.js, as setting.js records the url of assets, scripts, and some project settings. The setting.js is generated by calling the interface of the build plugin. If setting.js is not generated correctly, you can open the build debugging tool to inspect. Common Error Handling Ensure that all error are solved before previewing. Loading setting.js Fails You can open Developer -> Build Debugging Tools to see if there are any error messages. Under normal circumstances, if generating settings.js fails, there will be error messages in console. Most common is a script error, because when generating settings.js, all scripts in the project are loaded in the build process. If any script contains illegal writing, an unexpected error will be thrown during the loading process and setting.js will fail to be generated. For specific error message information, you can refer to the hint in the error message. Usually the error content here is the uuid of the asset. The corresponding uuid can be copied to the Assets panel to search and locate the script. Please refer to the Introduction To The Build Process documentation for additional details about how settings.js is generated. Assets Loading with a 404 Usually, this is caused by asset loss or import failure. Please use the missing asset uuid to search in the editor's assets panel. If no assets are found, usually the asset is lost. You need to modify the scene or asset using the assets. If assets are found, you can try to re-import. "},"particle-system/editor/":{"url":"particle-system/editor/","title":"Particle Editor","keywords":"","body":"Particle System Editor The particle system editor mainly includes an introduction to the interface for editing particle properties and how to view and edit the status of selected particles. It mainly consists of the following parts: Curve Editor Gradient Editor Particle Control Panel "},"particle-system/editor/curve-editor.html":{"url":"particle-system/editor/curve-editor.html","title":"Curve Editor","keywords":"","body":"Curve Editor The curve editor can set the curve of a certain property in the particle system with time. The interface of the curve editor is as follows: The curve editor can perform the following operations: The abscissa represents the unitized life cycle of a particle. For example, the life cycle of a particle is 5s, then 0.5 represents 2.5s. The ordinate represents the attribute value, and the ordinate interval can be adjusted through the upper edit bar. The default interval is [-1,1]. Right-click a point on the curve to add a keyframe. Drag the key frame to change its coordinates. You can change the slope of this point by turning the line segment next to the key frame. There is a built-in curve template below the editor. Click a template to apply it directly to the current curve. "},"particle-system/editor/gradient-editor.html":{"url":"particle-system/editor/gradient-editor.html","title":"Gradient Editor","keywords":"","body":"Gradient Editor The gradient editor can set the color of a certain property in the particle system that changes with time. The interface of the gradient editor is as follows: The gradient editor can perform the following operations: Mode has two possible choices: Blend mode will be interpolated according to the two adjacent keyframes at the current time to get the color of the current frame. Fixed mode will directly use the color of the previous keyframe at the current time. Click an empty space above the ribbon to insert an alpha key frame, click an empty space below the ribbon to insert an rgb key frame. Drag the key frame to move left and right to adjust the key frame position, and drag the key frame to move up and down to delete the key frame. The corresponding rgb or alpha value can be edited in the Color / Alpha edit box. Location can edit the position of the selected key frame. "},"particle-system/editor/particle-effect-panel.html":{"url":"particle-system/editor/particle-effect-panel.html","title":"Particle Effects","keywords":"","body":"Particle Control Panel The particle control panel can perform some operations on the particles selected in the editor. The interface is as follows: The following operations are possible: : Play / Pause particle : Replay particle : Stop playing particle Playback Speed: Adjust particle playback speed Playback Time: Show particle duration Particles: Display the current number of particles "},"editor/animation/animation.html":{"url":"editor/animation/animation.html","title":"About Animation","keywords":"","body":"About Animations Before creating an Animation, you must first add an Animation Component to the node, and mount the clip file for the component before editing. Before that, it is necessary to first understand the related concepts of an Animation Clip and Animation Component. Animation Component Cocos Creator is a component structure, and Animation is no exception. It is also a component on the node. Only after adding an Animation Component to the node can the node be given the ability to participate in the animation. Therefore, after clicking on the relevant node, if the node does not have an Animation Component, the Add Animation Component button will be displayed on the interface of the Animation Editor, click to add. To use Animation, please refer to the Animation API. Clip Animation clip An Animation Clip is a piece of declaration data for an animation. If we mount it on an Animation Component, we can apply this animation data to a node. An Animation Component can mount multiple Animation Clips. It is not possible to edit animations on nodes without clips. After clicking on the relevant nodes, if the node has only Animation Components, but no clip files, the Animation Editor will display the Create Clip File button, click to create and assign to the component. In the animation editing mode, you can also switch to edit different Animation Clips through the clip option in the lower left corner of the Animation Editor. Animation editing mode Animations are not allowed to be edited in normal mode. Only in animation editing mode can animation files be edited. However, in animation editing mode, you cannot add, delete, or rename nodes. There are two ways to open edit mode: Select the node that contains the Animation Component and contains more than one clip file, and then click the Enter animation editing mode button in the Animation panel. Press, Ctrl/Cmd + E There are three ways to exit edit mode: Click the exit button in the upper right corner of the Animation Editor Click the close button in the upper left corner of the Scene panel Press, Ctrl/Cmd + E For more details, refer to the Animation System Design and the Script Control.md) documentation. "},"editor/animation/animation-editor.html":{"url":"editor/animation/animation-editor.html","title":"Familiar with animation editor","keywords":"","body":"Animation Editor Introduction to the main panel of the editor The Animation Editor can be divided into 6 main parts. Toolbar Timeline and Events Node List Keyframe preview in node Property List Property track keyframe preview Toolbar The Toolbar is responsible for displaying some commonly used functions that are triggered by buttons. Function Icon Shortcut Key Remarks Move to the first frame Ctrl/Cmd + Left n/a *Move to previous frame Left n/a Play/Pause Ctrl/Cmd + P n/a Move to next frame Right n/a Move to the last frame Ctrl/Cmd + Right Move to the last frame in the effective range Stop animation Ctrl/Cmd + S Click to stop the current animation, it will move to the first frame after stopping Add event keyframe - Clicking will add an event keyframe at the current time control line position Exit animation editing mode Ctrl + Q Click to exit animation editing mode Switch the scale of time axis display - The default is 00-00 mode, click to switch toframe (in keyframe number) display mode. For details about the time axis scale, please refer to the Time axis scale unit representation documentation. Display the current time and jump to the corresponding time - The specific time of the current time control line is displayed. You can also manually enter it to adjust the current time control line to the corresponding time. You can directly input the frame of frame or00-00. Adjust the default keyframe interval - The number of keyframe intervals filled in will be taken as the number of intervals when multiple keyframes are generated at the same time (for example: when creating a frame animation and dragging multiple pictures at once, the interval between the multiple keyframes added at this time will be taken as value) Arrange selected keyframes - The selected keyframes will be arranged based on the first frame and the values in the input box as intervals. Open the shortcut panel - - Timeline and Events The timeline, along with the added custom event frames will mainly be displayed here. Right-clicking will move the event control to the corresponding position. The right-click menu can be used to add/remove, or copy/paste keyframes of the event. The effective length of the animation will also have a corresponding display effect. Timeline scale representation The default notation for ticks on the time axis is 01-05. The value consists of two parts. The preceding number indicates the current second, and the following number indicates the number of frames in the current second. 01-05 means that the scale is located on the time axis at the time that 1 second and 5 frames have passed since the start of the animation. Because the frame rate (sample) can be adjusted at any time, the time indicated by the same scale will also vary with the frame rate. When the frame rate is 30, 01-05 means 1 + 5/30 = 1.1667 seconds after the animation starts. When the frame rate is 10, 01-05 means 1 + 5/10 = 1.5 seconds after the animation starts. Although the time indicated by the current scale will change with the frame rate, once a keyframe is added at a position, the total number of frames where the keyframe is located will not change. If we change the frame rate to 01-05 when the frame rate is 30. A keyframe has been added to the scale, and this keyframe is located at the 35th frame after the animation starts. Then change the frame rate to 10, the keyframe is still at the 35th frame after the animation starts, and the scale reading of the keyframe position at this time is 03-05. After conversion to time, it is exactly 3 times as before. Click the button You can change the scale to frame and toggle back and forth. Key frame events Right-click on the timeline position or click the timeline button to add event key frames. Click the event __key frame mail menu to align for removal, copy and other operations. At the same time, after selection, it also supports a series of copy and paste, delete shortcut keys. Node list The index node in the animation data is based on the relative path of the node where the Animation component is attached. Therefore, a node with the same name under the same parent node can only generate one copy of animation data, and can only be applied to the first node with the same name. The nodes here and the nodes of the Hierarchy panel are mapped one by one. Using this relationship, when the number of nodes in the node list is too large to be consulted, use the search function of the Hierarchy panel to locate the nodes. Click on the node in the Hierarchy panel, and it will also jump to the corresponding node position in the Animation Editor to achieve a reasonable display effect. Selected node icon Since the node list of the Animation Editor is merged with the data in the clip. There may be more node information than the original node, but this part of the extra nodes is the lost node, which cannot be edited and used. The interface, which will be displayed as yellow is also grayed out at the key frame track. At this time, you can transfer the lost node to other nodes through the migration data in the right-click menu. Keyframe preview within the node This is mainly to display a preview of all frames on each node. Here, you can delete the key frame by right-clicking the key frame position menu, and you can also move the key frame position. Clicking the key frames of different nodes at the same time will select the corresponding node. Double-click the key frame to move the time control line to this position. Without the selected property, Ctrl/Cmd + Shift + Left/Right can Move the time control line up/down to the next key frame position. Property list Mainly displays the property list of the currently selected node participating in the animation. Each property display item has a key frame icon, corresponding to the current property track and the key frame status of the current time control line position. Click to add/remove the corresponding key frame. The right-click menu can remove the current track or clear data. Click on the plus button at the top to add an property track for the currently selected node. Like the node, the property track may also be lost. The property recorded in the animation clip does not exist on the current node. This property is the property lost under the current node. The missing Properties are also displayed in yellow. In this case, you can add the relevant Properties to the corresponding node or directly remove the missing property track after exiting the editing mode. Property track keyframe preview It mainly displays the specific key frame settings on each property track, and is also the main area for key frame editing. You can right-click directly on the track to add key frames, or you can drag the time control line to the corresponding position and press enter to add. At the same time, it also supports frame selection and key frame selection to move, copy, paste and other operations in this area. Basic Operation Guide Switch between different animation clips for editing Click the clip option in the lower left corner of the Animation Editor and select the clip to be edited: Change the keyframe display area Change the timeline zoom What should I do if I feel that the range displayed by the animation editor is too small during operation, and it needs to be scaled down to allow more key frames to be displayed in the editor? You can zoom in or zoom out the display scale of the time axis by scrolling the mouse wheel in areas b, d, and f in the figure. Navigate the display area If you want to see the key frame on the right side of the Animation Editor that is hidden beyond the editor or the key frame on the left side, you need to move the display area: Press the middle/right mouse button and drag in the areas b, d and f in the figure. c. Drag to change the layout of the animation editor The dividing line between the node list and the time, and the dividing line between the Property List and the time axis can be used to drag and change the layout, and can be freely adjusted to the layout effect suitable for editing by dragging. Change the currently selected time You can change the current time node by clicking anywhere or dragging the time control line in the time axis (Figure B area) area. Drag and drop time control line. Click the button that controls the time control line in the toolbar. Double-click the key frame to jump the current time to the corresponding position. Use the shortcut keys to control the current time position s. Play/pause animations Click the play button in the area of ​​Figure A, the button will automatically change to pause, click again to play. In the playback state, operations such as saving the scene will terminate the playback. Shortcut key Ctrl/Cmd + P control For more information about keyframe operations, please review the Edit Animation Sequence documentation. Shortcuts Modify shortcut keys Click the shortcut button in the menu bar to open the shortcuts windows, then you can directly modify the shortcut keys of the animation editor Here. Shortcut key summary Function Shortcut key Description Enter/exit animation editor Ctrl/Cmd + E - Save animation data Ctrl/Cmd + S - Move forward one frame Left (←) If it is already at frame 0, the current operation is ignored. When the key frame is not selected, the small red line moves, and after the node is selected, the key frame is moved; Move one frame backward Right (→) When the key frame is not selected, the small red line is moved, and after the node is selected, the key frame is moved; Move to the first frame Ctrl/Cmd + Left (←) - Move to the last frame Ctrl/Cmd + Left (←) The number of effective frames in the current clip Delete the currently selected keyframe Delete/Cmd + Backspace - Play/Pause Animation P - Stop animation Alt + S Current time will become 0 Add key frame I After selecting the property track, the key frame will be added at the position of the time control line, if it is not selected, it will be ignored Skip to the previous key frame Ctrl/Cmd + Shift + Left (←) Move to the nearest key frame to the left of the time control line (select the property track or select the node) Skip to the next key frame Ctrl/Cmd + Shift + Right (→) Move to the nearest key frame on the right of the time control line (selected on the property track or selected node) Select multiple keyframes Ctrl Hold down Ctrl and click on keyframes to select multiple keyframes Select all keyframes of the track Ctrl/Cmd + A Select all keyframes of the selected property track Copy selected animation data Ctrl/Cmd + C Support copying selected key frames, property tracks, node data Paste the animation data of the last copy Ctrl/Cmd + V Support pasting selected key frames, property tracks, node data Unselected key frame or event frame or property track Esc - Most shortcut keys are invalid only when the animation editor is focused, except for the shortcut keys of Enter and Exit Animation Editor and Save Animation. "},"editor/animation/animation-create.html":{"url":"editor/animation/animation-create.html","title":"Create Animation components and animation clips","keywords":"","body":"Create Animation components and animation clips Creating Animation Components On each Node, we can add different components. If we want to create an animation on this node, we must also create a new Animation component for it. There are two ways to create a new Animation component: Select the corresponding node, click Add Component below in the Inspector panel, and select Animation Component in Components. Open the animation editor, then select the node in which to add then animation in the Hierarchy panel, and click the Add Animation component button in the animation editor. Specifics about Animation component parameters can be found in the Animation Component Reference documentation. Creating and attaching animation clips Even though there is an Animation component on the Node, there is no corresponding animation clip data. There are two ways to create animation clips: Click the + on the upper left in the Assets panel, or right-click the blank area and select Animation Clip. Now, a clip file named NewAnimationClip will be created in the Assets panel. It is not enough to just create it. We need to click on the node, in the Hierachy manager and find Animation in the Inspector panel. At this time, Clips shows 0, and it needs to be changed to 1. Next, drag the NewAnimationClip that was just created in the Assets panel, and drag it into the animation-clip selection box that just appeared. If you have not added an animation clip file in the Animation component, you can directly click the NewAnimationClip button in the animation editor to create a new animation clip file. The newly created animation clip will be automatically attached to the animation component. Note: if you choose to overwrite the existing clip file, the content of the overwritten file will be cleared. "},"editor/animation/animation-clip.html":{"url":"editor/animation/animation-clip.html","title":"Edit Animation Sequence","keywords":"","body":"Editing a animation sequence After the animation clip is attached to the Node, click Enter Animation Edit Mode to enter the animation editing mode, and then you can create some animation frame data in the animation clip. First, it is important to understand about animation properties. Animation properties include a Node's own position, rotation and other properties, as well as the properties in a Component. The component contains the component's name and other properties, such as Sprite.spriteFrame. The corresponding blue prism on the property track is the key frame. Animation components can animate the node and component properties on the node and child nodes, including Properties in user-defined scripts. This means that various animation requirements can be flexibly implemented. The specific animation implementation depends on different animation needs and different steps. For an example case, please refer to the official example-3d. This repository mainly introduces some common editing operations and facilitates rapid editing to achieve these effects. Modify a clip's common properties sample: define the frame rate of the current animation data per second, the default is 60, this parameter will affect the number of frames between every two integer seconds scale on the time axis (that is, how many divisions within one seconds). speed: the current playback speed of the animation, the default is 1. duration: when the animation playback speed is 1, the duration of the animation. real time: the actual duration of the animation from the beginning to the end of the animation, corresponding to the number in the parenthesis in the lower right corner of the editor. wrap mode: Loop mode, please refer to the Cycle Mode documentation for specific configuration effects. Changes to properties take effect after the focus leaves the control. Common operations of node panel The animation clip defines the position of the data by the name of the node, ignoring the root node itself, and the remaining child nodes find their corresponding data through the relative path index of the root node. Clear node data: right-click the node item of the animation editor, select Empty Data, and select Clear after the pop-up window prompts Copy and paste node data:right-click the node item of the animation editor, select Copy Node Data, and then right-click the target node item, select Paste Node Data. Note: when using shortcut keys to copy and paste node data, please make sure that no attribute track or keyframe is currently selected. Because when there is a selected attribute track or key frame, the animation data will be copied first. If the paste target node does not exist when the attribute track in the animation data is copied, it will not be created automatically. Please create the required components in advance. Migrating node data: sometimes we will rename the node after the animation is completed, which will cause problems with the animation data, as shown below: Next, right-click on Migrate Data on the missing node, and then click on other nodes to migrate the data. If you do not want to migrate after clicking Migrate Data, click directly in the timeline area or click Cancel in the pop-up window after clicking other nodes. Note: by default, node data migration will overwrite the data on the target node Common operations of property track data An animation clip may contain multiple nodes, and multiple animation properties are bound to each node. The data in each property is the actual key frame. The key frame operation in the property has been mentioned above. This section mainly introduces some operations for the entire property track: Add an property track: click the + small button next to the property list, after the pop-up property menu pops up, click on the property that needs to be added. Example: Remove property track: right-click the property list item and select Remove property track. Example: Clear track data: right-click the property list item and select Clear property track. Example: Copy and paste track data: right-click the property list item, select copy track data or press Ctrl + C, then click the same type of track as the copied track, right-click will see the paste option, click or press Ctrl + V to paste. Example: Common Key Frame Operations In the process of producing animations, there are often some manipulation of key frames. There are a variety of key frame processing methods in the animation editor.. Knowing these methods and techniques can help to edit animation clips faster. Selecting a key frame After clicking the key frame, the key frame will be selected. At this time, the key frame changes from blue to white. Currently, there are the following ways to select the key frame: Right-click a key frame to select it, press Ctrl and right-click to select multiple key frames. Drag the frame directly in the key frame area to select the key frame. Press down the mouse in the empty area of the key frame panel and drag to form a selection area to select all key frames inside. Add key frame To add a key frame: Right-click on the corresponding property track position and select Add Key Frame. The current number of key frame frames will also appear on the right-click menu. Select the corresponding node and the corresponding property, move the time cursor to the position where the key frame needs to be added, and press the I (inset) key Move the time cursor to the position where the key frame needs to be added. In the corresponding property list item, click . After selecting the corresponding node and the corresponding property track, the editor control for the corresponding property will appear in the middle of the animation editor, and the key frame can be marked by modification. After adding the property track, move the time cursor to desired position of the Inspector panel or perform scene operations to automatically generate key frames. Removing key frames Select the key frames you want to delete and press delete/Cmd + backspace on MacOS and delete/Ctrl + backspace on Windows. At the position of the key frame to be deleted right-click, select Remove Key Frame. Drag the time cursor to the position where the key frame needs to be removed and double-click the key frame, in the corresponding property list item, click Modifying key frame data On the timeline double-click the key frame that needs to be modified. The time cursor will move to that position. You can also directly drag the time cursor to the corresponding position, and modify the corresponding properties directly in the Inspector panel. Make sure the animation editor is in edit mode. For example, there are three property tracks in the property list: position, scale, and rotation. After the key frame is selected, you can modify the position, scale, and rotation properties in the Inspector panel. In animation editing mode, move the time control line to a position where there are no key frames on the timeline, and then modify the corresponding properties in the Inspector panel, and a frame will also be inserted automatically. Moving a key frame After selecting a key frame, right-click and hold on the selected key frame to drag, and release it to complete the movement. There will be prompts for the distance and the number of frames in the final position during the movement. Zooming a keyframe After selecting multiple key frames, the left and right control levers will be displayed. Drag any one of the joysticks to move and perform zooming of the key frames. Arranging key frames at specific intervals After selecting multiple key frames, adjust the number of interval key frames. After pressing the button for arranging intervals, the selected key frames will be arranged in sequence according to the set number of intervals. Copying/pasting keyframes A. After selecting the key frame, follow the normal shortcut key C/V to copy and paste. Note that the location of the shortcut key paste will start from the current key frame(The red line position). B. After selecting the key frame, right-click on the selected key frame, select Copy Key Frame, and then right-click elsewhere, select Paste Key Frame. The copy and paste of key frame data supports cross-node and cross-clip use. Note: there is a difference between A and B. When using the shortcut key to paste the keyframe data, it will be pasted one by one in the order of the copied track data, while right-clicking on the target property track and selecting paste will only pasted on the target property track.Please be sure to copy the correct data to produce unexpected results. For more about the design of animation sequences and the content of scripting animations, you can refer to the Animation Clip documentation. "},"editor/animation/sprite-animation.html":{"url":"editor/animation/sprite-animation.html","title":"Creating A Frame Animation","keywords":"","body":"Creating a frame animation Previous chapters wrote about the operation of Attribute Frames, now how to create a Frame Animation. Adding a Sprite component to a node First, we need to allow the node to display the texture normally, so we need to add a Sprite component to the node. After selecting the node, use the Add Component button in the Inspector panel and select UI-> Render-> Sprite. Add a Sprite.spriteFrame to the attribute list After the node can display the texture normally, an Attribute Track needs to be created for the texture. Click the + next to the Property List of the Animation Editor. Select Sprite-> spriteFrame. Adding a Frame First, from the Asset panel, drag the texture to the Attribute Frame area and place it on the Sprite.spriteFrame track. Next, drag the texture to be displayed in the next frame to the specified position, and then click Play to preview the animation that was just created. If you drag multiple textures to the Attribute Track at the same time, the button textures are selected in the order on the track, and they are arranged in sequence according to the number of intervals displayed on the toolbar to generate key frames. Arranging and modifying key frame intervals The interval frame number of frame animation is usually fixed. Sometimes after adding multiple textures, if you want to adjust the interval number, you can fill in the desired interval frame number at the top of the toolbar Then select the key frame to be arranged, click Arrange button on the toolbar or right-click on the selected key frame and select Arrange selected key frames. "},"editor/animation/animation-curve.html":{"url":"editor/animation/animation-curve.html","title":"Edit Animation Curve","keywords":"","body":"Editing Animation Curves We have created a basic animation in previous sections of this documentation. However, sometimes we need to implement easing effects, such as EaseInOut between two key frames. How is this achieved in the animation editor? First, two unequal key frames need to be created on a track, such as two key frames on position, from 0,0 to 100,100. Next, a connecting line will appear between the two key frames (the blue line segment connecting the key frames). Double-click the connecting line to open the Curve Editor. When the Curve Editor is open, if the current animation curve data is in a preset, the corresponding item on the left of the preset will have a golden border to show it's selected effect. The modification of the animation curve is real-time, there is no need to click save. After modifications, click the close button in the upper right corner. Using preset curves Presets can be selected on the left side of the Curve Editor. For example, Ease In, can be applied to the current animation curve by clicking the corresponding curve. Custom curves Sometimes, when the preset curve can not meet the needs of the animation, we can also modify the curve ourselves. In the preview curve of the Curve Editor, there are two gray control points. Drag the control point to change the curve's trajectory. If the control point needs to be dragged out of view, the mouse wheel can be used to zoom the preview. The curve data during the modification process will be displayed in the input box in the upper left corner of the curve area in real time, and the input box also supports manual input of curve data to generate a curve, of course, the format of the curve data must be four numbers in CSV format (commas separated value format) with, otherwise it cannot be applied normally. Save custom curve Sometimes some custom curve data required by the project needs to be reused, it can be saved in the preset library of User. Specifically, after editing the curve data to be saved, select the User option in the preset menu at the upper left and enter the name of the curve data to be saved in the input box at the lower left, and click add to add. Note: the curve with the same name will be overwritten, and the custom curve is saved without undo processing, so if it is overwritten, it needs to be added again. The custom curve saved in the preset is the same as the preset curve of other libraries, click to apply. At the same time, when the mouse moves over the curve, a delete icon will appear. Click to delete the corresponding curve data. For more about the design of animation curve and script control code, please refer to the Animation Curve documentation. "},"editor/animation/animation-event.html":{"url":"editor/animation/animation-event.html","title":"Animation event","keywords":"","body":"Animation Events In games, it is often necessary to execute some function at the end of an animation or at a specific moment in a certain frame. At this time, it can be achieved by adding Animation Events. After adding an event function on to a key frame, the animation system will match the corresponding function methods on the animation root node and execute them when the animation reaches the key frame. Please refer to the frame events documentation before continuing. Adding an event frame First, move the time control line to the position where the event needs to be added, and then click the button in the toolbar area. The same golden icon , this is the event we added. Deleting an event frame At the added time frame position, right-click and select Delete. Deleting here will delete all time frame functions at that time position. Add an event frame function Click the + button on the upper left of the Event Function Editor to add a new event frame function Delete time frame function To delete a frame function at the corresponding time position separately, you can click the delete button next to the function name in the Event Function Editor. Editing a specified event trigger function Double-click the event frame just added to open the Event Editor. In the editor, we can manually enter the name of the function that needs to be triggered. When the event is triggered, animation system will execute all corresponding method with the same name in each component of the animation root node. If you need to add the incoming parameters, click + or - next to Params. Currently, only three types of parameters are supported: Boolean, String, and Number. After the modification occurs, a red asterisk will appear next to the title of the Event Function Editor. The modification of the event function needs to be manually saved. After the modification, click the save button above to save. If not saved, there will be a pop-up box prompting to save when closing the Event Editor. "},"editor/terrain/":{"url":"editor/terrain/","title":"Terrain System","keywords":"","body":"Terrain system The terrain system displays the mountainous landscape of nature in an efficient way. Developers can easily use a brush to sculpt basins, mountains, valleys, plains and other landforms. Creating a terrain Two steps are required to create a terrain: Click the right mouse button in Hierarchy panel and click Create -> Terrain to create a terrain node. Terrain nodes can be moved, but rotation and zoom are not yet supported. Click the right mouse button in the Assets panel and click Create -> Terrain in the pop-up menu to create the necessary terrain assets. Terrain component properties Parameter Description Asset Terrain asset EffectAsset Terrain effect asset ReceiveShadow Accept the shadow UseNormalMap Use normal map UsePBR Use physical materials Using a terrain Click on the created terrain node. There is a terrain component (cc.Terrain) in the Inspector panel, and the created terrain assets are assigned to the Asset in the terrain component. Editing a terrain After assigning the terrain assets, the editing panel can be accessed from the Scene panel. The terrain editing system includes three major functions: Manage, Sculpt, and Paint. These three functions can be switched between by clicking on the corresponding tabs. It is also possible to switch functions via the tools in the upper left corner of the Scene panel: 1 -- Corresponds to the Manage function. 2 -- Corresponds to the Bulge BrushMode in the Sculpt function. 3 -- Corresponds to the Sunken BrushMode in the Sculpt function. 4 -- Corresponds to the Smooth BrushMode in the Sculpt function. 5 -- Corresponds to the Paint function. Management of terrains Management is adjusting various parameters of a terrain. Tile is the smallest unit of terrain. Tile constitutes one 32x32 block of tiles with each terrain needing to consist of at least one tile block. Parameter Description TileSize The size of the terrain tile. Currently, a terrain block consists of 32 x 32 tiles, so the side length of a terrain block is 32 x TileSize. BlockCount Number of terrain blocks in two dimensions WeightMapSize Weight map size LightMapSize Lightmap size Sculpting a terrain Sculpting is changing the shape of a terrain. Parameter Description BrushSize The size of the brush BrushStrength The strength of the brush BrushMode The type of the brush, including Bulge、Sunken and Smooth Brush Custom brush style, by selecting a style picture to generate a custom brush. To control the bulging/depression of the terrain, use the left mouse button and the Shift + left mouse button, respectively. The bulge and depression operation often makes the terrain look sharp, use the smoothing function to overdo it. Painting a terrain Painting is the texture used to depict the appearance of a terrain. Parameter Description TileLayer Set the Layer of the terrain, as described in section Layer editing below. BrushSize The size of the brush BrushStrength The strength of the brush BrushFalloff Brush falloff, this value determines the sharpness of the brush edge.0.0 means that the brush has full effect in the whole range (all covered by the current layer texture), with sharp edges.1.0 means that the brush has full effect only in its center, and the influence will be attenuated when reaching the edge. Brush Custom brush style. by selecting a style picture to generate a custom brush. Layer editing Click the + or - button at the top right to add or delete layers (up to 4 layers are supported). Once a Layer is selected, you can edit the Layer and its texture. Parameter Description TerrainLayer Current Layer texture NormalMap To set the normal map of the current Layer, check the UseNormalMap property for the terrain component Metallic Set the metal properties of the current Layer Roughness Sets the roughness of the current Layer TileSize The tile size of the texture. The smaller the value, the more tiles will be used in the same size area "},"editor/lightmap/":{"url":"editor/lightmap/","title":"Lightmap","keywords":"","body":"Lightmap The baking system is the process of finally generating light maps and applying them in the scene by calculating the influence of all light sources on the object in the engine scene. The purpose of this system is to reduce the calculation of real-time light sources, thereby improving the efficiency of the scene. Creating The following three steps are required to turn on the baking system: Click the menu button in the top menu bar Project (Project), click the Lightmap (light map) button in the pop-up menu bar to pop up the lightmap panel. Before baking, you need to set bakeable to true in the static light attribute of the light source component in the editor. Note: currently only one main direction light source is supported. Bakeable: When checked, enable bake lighting CastShaow: When checked, enable cast static shadow EditorOnly: When checked, only takes effect in the editor In the lightmap panel that pops up, after setting the corresponding parameters, click the Lightmap Generate button and select the corresponding storage folder to generate the lightmap Note: the storage folder must be under Effective Assets. Using During the process of generating baked maps, there will be a generated progress prompt. After the generation, you can view it in the Baked tab in the lightmap panel. Among them, Baked result (baked result display panel) shows the lightmap texture after baking, Lightmap clear (clear button) can delete the generated result of baking, and information output panel shows the information of each baked image (file name, size, etc.). Note: before the lightmap is enabled, the model needs to include two sets of uv, the second set of uv is used to access the lightmap, and Materials also need to check the lightmap option to apply the shadow information after the model is baked. Editing The baking process is to calculate the generated results according to the parameters set on the panel, as shown below: The following table describes the specific meaning of each parameter: Parameter Description MSAA Multisampling. Has the following values: 1, 2, 4, 8 Resolution Baking map size. Has the following values: 128, 256, 512, 1024, 2048 Gamma Gamma correction value GIScale Global illumination scaling factor GISamples Global illumination sampling coefficient AOLevel AO Level AOStrength AO Strength AORadius AO Radius AOColor AO Color "},"editor/publish/":{"url":"editor/publish/","title":"Build and Publish","keywords":"","body":"Cross-platform Game Publish Cocos Creator supports all major platforms in depth, games can be quickly published to Web, iOS, Android, Windows, Mac, and various mini-game platforms, truly realizing one development and running on all platforms. Preparation Work The game project can be published when it is developed normally and the preview results meet the requirements. The preparation work that need to be done before publishing includes: About the Build Panel Build Options Publishing Platform Currently, Cocos Creator supports publishing to the following platforms: Publish to Web Platforms Publish to Native Platforms Setup Native Development Environment Debugging JavaScript on Native Platforms Publish to Mini Game Platforms Publish to HUAWEI AppGallery Connect Publish to Alipay Mini Games Publish to ByteDance Mini Games Publish to QTT Mini Games Publish to Cocos Play Publish to Huawei Quick Games Publish to OPPO Mini Games Publish to vivo Mini Games Publish to Xiaomi Quick Games Publish to LinkSure Mini Games Publish to Baidu Mini Games Publish to WeChat Mini Games WeChat Engine Plugin Access to the WeChat PC Mini Games Access to Open Data Context Developers can also publish game projects via the command line, see Publish from the Command Line for details. Advanced Topics If you have some degree of familiarity and understanding of the build process, you can customize the build templates, extend the build process, etc. For more details, please refer to the following documentation: Build Process Introduction & FAQ Custom Project Build Process Extend the Build Process "},"editor/publish/build-panel.html":{"url":"editor/publish/build-panel.html","title":"About the Build Panel","keywords":"","body":"About the Build Panel Click Project -> Build in the main menu or use the shortcut Ctrl / Cmd + Shift + B to open the Build panel. If multiple build tasks are added at the same time, the editor will automatically start building the next task after the current platform's build task is completed in the order in which it was added. Platform Plugin Each platform's build will be embedded in the Build panel as a separate plugin, with platform related options placed in a collapsible section (e.g. the Web Desktop in the figure below). New Build Task Click the New Build Task button at the top right of the Build panel to open the build options configuration panel. After the options are configured, click Build. Make sure the content in the Scene panel is saved before you build. If it is not saved, when you click on the Build button, a prompt will pop up asking: Do you want to save the current data before build?. You can choose Save, Ignore or Unbuild. If Save / Ignore is selected, the build will continue, and if Unbuild is selected, a record of cancelled builds will be generated. Note: there is no point in executing a build if there is no scene in the project, so projects without a scene are not allowed to add build tasks. Build Task Name Build Task Name is the name of the release folder generated after the build. It is not modified by default. If the same platform performs multiple builds, the suffix -001, -002, -003 and so on will be added to the original Build Task Name. If you want to overwrite an old release package, simply manually change the Build Task Name back to its original name. Note: Cocos Creator uses the Platform name as the name for the release package generated after the build, and overwrites the original package with each build. Note: Cocos Creator uses the Build Task Name as the name of the release package that is generated after the build, and a new release package is generated with each build. If you want to overwrite the original release package, you can manually modify the Build Task Name to match the original release package name. Build Progress After clicking Build, you can monitor the current build task progress in the Build panel. If the build is successful, the progress bar is shown in green, and the time of the actual build is output. Sometimes, especially a first build, the engine will be slow to compile, please be patient. If the build fails, the progress bar is shown in red. Run Currently, most platforms can directly click the Run button in the Build panel to preview the effect of the project after the build is complete. If there is no Run button, it means that the current platform does not support run in the editor, please refer to the release document of the relevant platform for details. Build Log Because the build process generates so many log messages, by default only error log are printed to the editor's Console panel. There are several ways to view all log information: Open Build DevTools Click Developer -> Open Build DevTools in the menu bar to see all the log information printed during the build, including the call stack. Log Level Click Preferences -> Extension in the menu bar, set Package to builder, and then set the log type to output to the Console panel in Log Level. Log File The editor will record the error log generated during each build, which can be viewed by clicking the button under build task in the Build panel. The log file is stored in the project's temp/build-log directory and can be attached when you send feedback to the forum on build related issues. Adjust the build options configuration The Build panel has a button below the build task, which can be clicked to see or adjust the configuration of the previous build options. Click the Recompile button after the adjustment is complete, the generated release package will directly overwrite the original. The information about the completed build task will be saved in the profiles/packages/build.json file of the project. As long as the source file of the corresponding build task is not deleted, either in the Build panel or directly deleted in the project directory, you can view the build options configuration of the previous build after reopening the editor, as well as to run and preview again. Note: the button is for developers to recompile after adjusting the build options of the current build task, while the New Build Task button is for creating a new build task, please don't confuse the two. Export/Import Export The Export option at the top right of the Build panel exports the current configuration of build options to a JSON file. This mainly facilitates building from the command-line and sharing the configuration of build options within the same project. The exported configuration of build options are platform-specific. For developers who use the command line to build, you can directly use the JSON configuration file as the configPath of the command-line build options. Import The Import option reads JSON configuration file into the Build panel for developers to share build options configuration. Recompile If you want to adjust the configuration of build options after the project is built, or if you want to recompile the project after a bug fix. There are following two ways: Option 1: use the Recompile button at the bottom right of the build task, in the Build panel. This option will directly recompile using the previous configuration of build options. Option 2: use the button at the bottom of the build task in the Build panel. Click the button to enter the Build panel and you can see a Recompile button. For details, see Adjust the build options configuration in the upper part of the documentation. "},"editor/publish/build-options.html":{"url":"editor/publish/build-options.html","title":"General Build Options","keywords":"","body":"Build Options General Build Options For the general build options in the Build panel are as follows: Build Path You can designate a release path for the game by inputting a path in the Build Path input field or choosing one via the search icon button. The following cross-platform release will create assets or projects in child folders of this release path. The default release path is in the build under the project folder. If you use version control systems like git and svn, you can ignore the build folder in version control. Included Scenes There are usually multiple game scenes in the project, this option allows you to choose the scenes you want to package. During the build process, all assets that depended on these selected scene assets in deep will be packaged. Just select the game scenes that are actually needed can reduce the size of game package after build. Start Scene The first scene after entering the game can be set directly in the Start Scene. You can also choose other scenes, that are part of your game, in Included Scenes. Move the mouse to the scene, a move up icon button will appear after the scene, then click the button to set it. MD5 Cache Append MD5 hash to the exported assets for resolving CDN or browser cache issue. After being enabled, if any asset fails to load, it is because the renamed new file can not be found. It is usually because some third-party assets were not loaded by assetManager. If this happens, you can convert the url before loading, to fix the loading problem. Example: const uuid = assetManager.utils.getUuidFromURL(url); url = assetManager.utils.getUrlWithUuid(uuid); Note: when MD5 Cache is enabled on the native platform, if any asset fails to load, it is usually because some third-party assets used in C++ were not loaded by assetManager. This can also be solved by converting the URL with the following code: auto cx = ScriptingCore::getInstance()->getGlobalContext(); JS::RootedValue returnParam(cx); ScriptingCore::getInstance()->evalString(\"cc.assetManager.utils.getUrlWithUuid(cc.assetManager.utils.getUuidFromURL('url'))\", &returnParam); string url; jsval_to_string(cx, returnParam, &url); Main Bundle Compression Type Set the compression type of the main package, please refer to the Asset Bundle -- Compression Type documentation for details. Main Bundle Is Remote This option is optional and needs to be used with the Resource Server Address option. If set, the main package is configured as a remote package, and along with its related dependent resources are built into a built-in Asset Bundle — main under the remote folder of the release package directory. You need to upload the entire remote folder to the remote server. Resource Server Address This option is optional and used to fill in the address of the remote server where the resources are stored. If this option is left blank, the remote folder in the release package directory will be packaged into the built game package. If this option is filled in, the remote folder will not be packaged into the built game package. You need to manually upload the remote folder to the filled in resource server address after build. Debug If this option is not checked, release mode will be built and the editor will compress and obfuscate the uuid of the asset, the engine script and project script generated by the build, and subpackage the json of the same type asset, reducing the times of asset loading. If this option is checked, debug mode will be built, allowing you to debug the project and easily locate problems. Source Maps The build will compress engine files and project scripts by default, if you want to generate a sourcemap, you need to check this box. A source map is a file that maps from the transformed source to the original source, enabling the browser to reconstruct the original source and present the reconstructed original in the debugger. For more details on source maps, please refer to the Use a source map documentation. Replace Splash Screen Mouse over this option and an Edit icon button will appear. Click this button and the panel will open. The first time you use this feature you need to fill out a questionnaire before opening the Replace Splash Screen panel. There will be some project-based information in the questionnaire, and we hope to gather more information on games developed using Cocos Creator, as well as more support programs in the future that developers will hopefully be able to fill out truthfully. Compress Texture Some compression options can be added to spriteFrame type image assets in the editor. Once enabled, the corresponding image assets are generated based on these compression options during build. If disabled, the compression texture will not take effect at build time even if configured. Please refer to the Compress Texture documentation for details. PackAutoAtlas The Auto Atlas is the editor's built-in texture merge. If this is disabled, even if you configure the Auto Atlas, it will not take effect at build time. When the Auto Atlas is configured in the resources folder, both the clarge and small image resources and the corresponding serialization information will be packaged, which will increase the package size, So please do not use it like that unless necessary. Please refer to the Auto Atlas documentation for details. Earse module structure (experimental) If this option is checked, importing scripts will be faster, but you will not be able to use module characteristics, such as import.meta, import(), etc. Build options related to each platform Currently, due to the adjustment of the build mechanism, the processing of different platforms are injected into the Build panel as plugins. After you select the platform you want to build in the Platform of the Build panel, you will see the expanded options for the corresponding platform, and the name of the expanded options is the platform plugin name. You can see each platform plugin in Extension -> Extension Manager -> Internal of the main menu of the editor. Custom build plugins are handled in the same way as platform plugins, see Extend the Build Process for details. Configuration of other parameters involved in the build The configuration in the editor menu bar Project -> Project Settings will affect the result of the project build, please refer to Project Settings for details. "},"editor/publish/publish-web.html":{"url":"editor/publish/publish-web.html","title":"Publish to Web Platforms","keywords":"","body":"Publish to Web Platforms Open main menu's Project -> Build to open the Build panel. Cocos Creator provides page templates for two kinds of Web platforms. From the pop up menu of Platform, you can choose Web Mobile or Web Desktop. The major difference is that in Web Mobile, the image will cover the whole browser window by default, while in Web Desktop, you are allowed to designate the resolution of image, which doesn't change when you zoom on the browser window. Build Options For some general build options of platforms, please refer to the General Build Options documentation. Web Desktop Option Explanation Field Name Resource Server Address The server address used to download remote resources, see General Build Options for details. remoteServerAddress Preview Resolution Resolution width and height of the game view, default is (1280, 960). resolution Polyfills In Creator 3.0, the Build supports some new feature of polyfills, mainly when the script is packaged, and the corresponding processing will be done. developer can choose polyfills according to their needs. This option currently only supports Async Functions, and more functions will be opened in the future. polyfills Web Mobile Option Explanation Field Name Resource Server Address The server address used to download remote resources, see General Build Options for details. remoteServerAddress Orientation Device orientation, including Auto, Landscape, Portrait. orientation Polyfills In Creator 3.0, the Build supports some new feature of polyfills, mainly when the script is packaged, and the corresponding processing will be done. This option currently supports Async Functions and coreJs, the developer can choose according to their needs. polyfills VConsole Whether to use vConsole. vConsole is similar to the mini version of DevTools and is used to aid debugging. embedWebDebugger Preview QRCode For scanning previews, see the description below for details. - Preview URL The link for the preview, see the description below for details. - Preview URL Multiple Web projects can be previewed at the same time, so instead of a uniform Preview URL for the build, each build task will have a separate Preview URL that does not interfere with each other. Clicking on the URL will automatically open the browser for previewing, and the specific preview URL splicing rule is ${The Preview IP in Preferences panel}:${Editor preview port number}/${Build platform}/${Build task name}/index.html. Build and Preview After configuring the build options, click the Build button, then a progress bar will appear on the top of the panel. When the progress bar reaches 100%, the build is finished. The image above shows the preview of Web Mobile, you can see that the game view covers the whole browser window, while the game view of Web Desktop is fixed resolution and does not cover the screen. Browser Compatibility The desktop browsers tested during the Cocos Creator development process include: Chrome, Firefox and QQ browser. Other browsers as long as the kernel version is high enough to work properly, for some browsers do not open IE compatibility mode. Browsers tested on mobile devices include: Safari (iOS), Chrome (Android), QQ browser (Android) and UC browser (Android). Retina Setting You can use view.enableRetina(true) to set the high resolution in the script, and the Retina display will be turned on by default when you build to the Web platform. Refer to the API enableRetina for details. Release a game on Web server Click the folder icon button in the bottom left corner of the build task window, If you want to release or share your games on the Internet, click the folder icon button in the bottom left corner of the Build Task window. After opening the release path, according to the current build task name, copy the entire contents of the corresponding folder generated by the build to your Web server. Then you can see the game later there. For information on setting up a Web server, please search for solutions, such as: Apache, Nginx, IIS and Express. "},"editor/publish/native-options.html":{"url":"editor/publish/native-options.html","title":"Publish to Native Platforms","keywords":"","body":"Publish to Native Platforms Click Project -> Build in the main menu of the editor to open the Build panel. Cocos Creator supports four native platforms, which include Android, iOS, Mac and Windows. The options to release games on iOS, Mac and Windows will only appear on those operating systems. This means it isn't possible to publish, for example, a game to iOS from a Windows computer. Environment Configuration To publish to the native platforms you need to install and configure some necessary development environments. Please refer to the Setup Native Development Environment for details. Build Options For the general build options for all platforms, see General Build Options for details. General build options for native platforms Due to the adjustments made to the build mechanism, the processing of different platforms are injected into the Build panel as plugins. When you select the native platform you want to build in the Platform option of the Build panel, you will see that there is a native expand option in addition to the specific native platform expand option (e.g., android, ios). The build options in native are the same for all native platforms. Template Currently, the engine template available in Template is Link. The Link template does not copy the Cocos2d-x source-code to the build directory. Instead, the shared Cocos2d-x source-code is used. This can effectively reduce the footprint of the build directory, and modifications to the Cocos2d-x source-code can also be shared. About Source Engine The Cocos2d-x engine includes the source code engine. The scope of application is: The first time the source code engine builds and compiles a project, it takes a long time to compile C++ code, depending on the configuration of the computer, which may take 5~20 minutes. After the same project has been compiled once, the time required for the next recompile is greatly shortened. The projects built by the source code engine, compiled and run using native development environment (such as Android Studio, Xcode, etc. IDE), and also can be debugged and error trapped. Currently, the Cocos Creator installation directory already includes Cocos2d-x source code engine in the resources\\3d\\cocos2d-x-lite folder. Polyfills Polyfills is a new feature option supported by the script system. If this option is checked at build time, the resulting release package will have the corresponding polyfills in it, which means it will increase the size of the package. Developers can choose polyfills on demand, but only Async Functions are currently available, and more will be opened later. Make after build immediately If this option is checked, the Make step will be executed automatically after the build is completed, without manual operation. Encrypt JS This option is used to encrypt the published script. After build, the JSC file is generated in the assets/ directory, which is encrypted. And the JS file will be backed up in the script-backup directory for debugging, and will not enter the APP when packaged. JS Encryption Key: This secret key will be used to encrypt JS files. The project will generate the key randomly when created. Zip Compress: If this option is checked, you can reduce the size of your scripts. Build Options for the Android Platform The build options for the Android platform are as follows: Render BackEnd Currently, VULKAN, GLES3 and GLES3 are supported, and GLES3 is checked by default. If more than one is checked at the same time, the rendering backend will be selected based on the actual support of the device at runtime. Game Package Name The Game Package Name is usually arranged in the reverse order of the product's website URL, such as: com.mycompany.myproduct. Note: only numbers, letters and underscores can be included in the package name. Besides, the last section of package name should start with a letter, but not an underscore or a number. Target API Level Set up the Target API Level required for compiling the Android platform. Click the Set Android SDK button next to it to quickly jump to the configuration page. Refer to the Setup Native Development Environment documentation for specific configuration rules. APP ABI Set up the CPU types that Android needs to support, including armeabi-v7a、arm64-v8a and x86. You can choose one or more options. Notes: When you select an ABI to build and then build another ABI without Clean, both ABI's so will be packaged into the APK, which is the default behavior of Android Studio. If you import a project with Android Studio, after selecting an ABI to build, run Build -> Clean Project, then build another ABI, only the latter ABI will be packaged into the APK. After the project is imported with Android Studio, it is an independent existence and does not depend on the Build panel. If you need to modify the ABI, you can directly modify the PROP_APP_ABI property in gradle.properties file as shown below: Use Debug Keystore Android requires that all APKs be digitally signed with a certificate before they can be installed. A default keystore is provided, check the Use Debug Keystore to use the default keystore. If you need to customize the keystore, you can remove the Use Debug Keystore checkbox. Please refer to the official Android Documentation for details. Android requires that all APKs must be digitally signed with a certificate before they can be installed. Cocos Creator provides a default keystore by checking Use Debug Keystore to use it. If you need to customize the keystore, you can remove the Use Debug Keystore checkbox, refer to the Official Documentation for details. Screen Orientation The screen orientation currently includes Portrait, Landscape Left and Landscape Right. Portrait: the screen is placed vertically with the Home button on the bottom. Landscape Left: the screen is placed horizontally, with the Home button on the left side of the screen. Landscape Right: the screen is placed horizontally, with the Home button on the right side of the screen. Google Play Instant If this option is enabled, the game can be packaged and published to Google Play Instant. Google Play Instant relies on Google Play, and it is not a new distribution channel, but closer to a game micro-end solution. It can realize the game to be played without installing, which is useful for game's trial play, sharing and conversion. The following notes are required when using: The Android Studio should be v4.0 and above. The Android Phone should be v6.0 and above. Devices with Android SDK version between 6.0 and 7.0 need to install Google Service Framework, while those with SDK version 8.0 or higher do not need it and can install it directly. If you compile for the first time, you need to open the built project with Android Studio to download Google Play Instant Development SDK (Windows) or Instant Apps Development SDK（Mac） support package. If the download fails, it is recommended to set up an HTTP proxy for Android Studio. App Bundle (Google Play) If this option is enabled, the game can be packaged into App Bundle format for uploading to Google Play store. Please refer to Official Documentation for details. Build Options for the Windows Platform The build options for the Windows platform currently have only one Render BackEnd, which includes VULKAN, GLES3 and GLES3, with GLES3 checked by default. If more than one is checked at the same time, the rendering backend will be selected based on the actual support of the device at runtime. Build Options for the iOS Platform The build options for the iOS platform include Bundle Identifier, Orientation and Render BackEnd. The setting of Orientation is the same as the Android platform. The build options for the iOS platform include x, y, and z. The setting of x is the same as Screen Orientation for the Android platform. Bundle Identifier The package name, usually arranged in the reverse order of the product's website URL, such as: com.mycompany.myproduct. Note: only numbers, letters and underscores can be included in the package name. Besides, the last section of package name should start with a letter, but not an underscore or a number. Render BackEnd Currently, METAL and GLES3 are supported, and GLES3 is checked by default. If more than one is checked at the same time, the rendering backend will be selected based on the actual support of the device at runtime. Build Options for the Mac Platform The build options for the Mac platform include Bundle Identifier and Render BackEnd, and the setup method is the same as the iOS platform. Build a Native Project After the build options are set, you can begin the build. Click the Build button in the bottom right corner of the Build panel to start the build process. When compiling scripts and zipping resources, a blue progress bar will display on the Build Task window. When the build completes, the progress bar reaches 100% and turns green. After the build, we get a standard Cocos2d-x project, with the same structure as a new project created using Cocos Console. Taking the Windows platform as an example, the directory structure of the exported native project package windows is shown below: assets: places project resources. proj: places the currently built native platform project, which can be used by the IDE of the corresponding platform to perform compilation tasks. cocos.compile.config.json: place the compile option json for current build. For more information, please refer to Build Directory -- Native. Next, you can continue to Make and run desktop previews through the Cocos Creator editor, or manually open the built native project in the IDE of the corresponding platform for further previewing, debugging, and publishing. Make and Run Cocos Creator supports Make and Run Preview steps via the editor or the corresponding IDE for each platform (e.g. Xcode, Android Studio, Visual Studio). By the Editor Click the Make button on the Build Task window to enter the compile process. When the compilation is successful, it will prompt: make package YourProjectBuildPath success! Note: after the first compilation of the Android platform or version upgrade, it is recommended to open the project via Android Studio, download the missing tools according to the prompts, and then perform the Make and Run. Once the Make process is complete, continue to click the Run button next to it. Some compilation work may continue, so please wait patiently or check the progress through the log file. The results of the Run for each platform are as follows: Mac/Windows platform: run the preview directly on the desktop. Android platform: must connect to physical device via USB and the preview can be run after the USB debugging is enabled on the physical device. IOS platform: will call the simulator to run the preview. But it is recommended to connect to the physical device via Xcode to execute Make and Run, as described below. By the IDE Click the folder icon button in the bottom left corner of the build task window, the release path will be opened in the file manager of the operating system. The build-win32-link or build-win32-default (depending on the selected platform and template) under the build directory in this path contains the native platform project of the current build. Except for the Android platform, the Android platform project is generated in the proj directory of the release path. Next, open these generated native projects using the IDE corresponding to the native platform (e.g. Xcode, Android Studio, Visual Studio) and you can make further operations like compilation, preview and release. Android Windows Mac 和 iOS For the usage instructions for native platform's IDE, please search related information on your own, which will not be discussed in detail here. To learn how to debug on a native platform, please refer to Debugging JavaScript on Native Platforms. Precautions Projects that run debug mode builds on MIUI 10 systems may pop up a \"Detected problems with API compatibility\" prompt box, which is a problem introduced by the MIUI 10 system itself, you can use release mode build to solve the problem. When building for iOS, if you don't use WebView related features in your project, please ensure that the WebView module is removed from the Project -> Project Settings -> Feature crop to help your game approval go as smoothly as possible on iOS App Store. If you really needs to use WebView (or the added third-party SDK comes with WebView), and therefore the game rejected by App Store, you can still try to appeal through email. The result of compiling the Android through the editor and Android Studio has the following differences. After executing the Make step via the editor, the build directory will be created under the release path, and the .apk will be generated in the app\\build\\outputs\\apk directory of the build directory. After compiling with Android Studio, the .apk is generated in the proj\\app\\build\\outputs\\apk directory. In Cocos Creator 3.0, Android and Android Instant use the same build template, and the built native projects are in the build\\android\\proj directory. Please note for this directory: For code and third-party library used separately by the Android, place them in the app\\src and app\\libs directories, respectively (If you don't have these two directories, you can create them yourself). For code and third-party library used separately by the Android Instant, place them in the instantapp\\src and instantapp\\libs directories, respectively. For code and third-party library used in common by the Android and Android Instant, place them in the src and libs directories, respectively. When compiling Android in Build panel, assembleRelease/Debug is executed by default. When compiling Android Instant, instantapp:assembleRelease/Debug is executed by default. "},"editor/publish/setup-native-development.html":{"url":"editor/publish/setup-native-development.html","title":"Setup Native Development","keywords":"","body":"Setup Native Development Environment Apart from Publish games to the Web, Cocos Creator uses JSB technology based on the Cocos2d-x engine for the cross-platform release of native games. Before using Cocos Creator to build and publish games to native platforms, you need to configure related Cocos2d-x development environment first. Android platform dependencies To publish to the Android platform, you need to install all of the following development environments. If you do not have a plan to publish to the Android platform, or if your operating system already has a full Android development environment, you can skip this section. Download the Java SDK (JDK) Compile the Android project requires a complete Java SDK tool on your local computer, download it at the following address: Java SE Development Kit 8 Downloads Download and pay attention to select the machine and the operating system and architecture, download the installation can be completed after the installation process. After the installation is complete, please confirm that the java command is valid on the command line. Input the following code into Mac terminal or Windows command line tool for check: java -version If JAVA SE displays, there is no problem. If JRE displays, then you need to install JAVA SE running environment). On Windows platform, please confirm if JAVA_HOME is included in your environmental variables. By right clicking Computer on your computer, choosing Property -> Advanced system setting -> Environment Variables to check and modify environmental variables. For effective running on Windows platform, you might need to restart the computer. For details, please refer to the document: How do I set or change the PATH system variable?. Download and install Android Studio Cocos Creator does not support Eclipse's ANT build, we need to use Android Studio v4.1 and above as an Android platform's build tool and you should download the required SDK and NDK packages in Android Studio. First, install Android Studio. Download the SDK and NDK required to publish the Android platform After installing Android Studio, refer to the official documentation and open the SDK Manager: SDK Manager Instructions. In the SDK Platforms tab page, check the API level you want to install, and it is recommended to select the required mainstream API Level such as API Level 23 (6.0), API Level 26 (8.0) and API Level 28 (9.0), etc. In the SDK Tools tab page, first check the lower right corner of the Show Package Details, show the version of the tool selection. In the Android SDK Build-Tools, select the latest build Tools version. Check the Android SDK Platform-Tools and CMake. If you need to install the Android Support Library, please refer to the official Support Library Setup. Check the NDK and the recommended version is r20. Take note of the path of Android SDK Location on top of the SDK Manager window. Later we need to fill in the location of the SDK in Cocos Creator. Click OK and follow the prompts to complete the installation. Install C++ compiling environment Please install the following running environment: Python 2.7.5+, download page. Pay attention! Don't download Python 3.x version. In Windows, the installation of Visual Studio 2017/2019 Community Edition is needed. When installing Visual Studio, please check Desktop development with C++ and Game development with C++ two modules. Note: there is a Cocos option in the Game development with C++ module. Do NOT check it. In Mac, the installation of Xcode and command line tool is needed. Configure Native Develop environments path Next, go back to Cocos Creator to configure the environmental path of the native platform. Choose Cocos Creator -> Preferences in the main menu, and open the Preferences panel. We need to configure the following two paths here: Android NDK: choose the ndk-bundle folder in Android SDK Location path we just noted in Android Studio SDK Manager window. You can skip this if you don't need to compile on Android platform. Android SDK: choose the Android SDK Location path we just noted in Android Studio SDK Manager window (the directory of Android SDK should include folders like build-tools, platforms, etc.). You can skip this if you don't need to compile the Android platform. Close the window after configuration is completed. Note: the configuration will work when build native project. If the configuration not work, please try to set these settings to System Environment manually: COCOS_CONSOLE_ROOT, NDK_ROOT, ANDROID_SDK_ROOT. Notes We have received lots of feedback about native packing in the public beta, and some possible reasons are supplemented here: Package name issue Check the Game Package Name in the Build panel, including blank space, -, etc. are all illegal. Android built successfully, but prompt dlopen failed: cannot locate symbol \"xxxx\" referenced by \"libcocos2djs.so\"... in runtime. Please check if the architecture and version of NDK and Android SDK correspond to the phone's Android system. In addition you can try to use the NDK and Android SDK version used in this article to test. In the end, if building still fails, please send a question to the Forum with the Creator version, the build log file in the Build panel, and a demo that reproduces the problem. "},"editor/publish/debug-jsb.html":{"url":"editor/publish/debug-jsb.html","title":"Debugging JavaScript on Native Platforms","keywords":"","body":"Debugging JavaScript on Native Platforms After a game is released on the native platform, because the runtime environment is different, there may be some bugs that cannot be reproduced in the browser preview. This means we must debug it directly on the native platform. Cocos Creator makes it easy to debug JavaScript remotely in the native platforms. Debugging on Android / iOS If a game can only run on a physical device, then the packaged game must be debugged on a physical device. Debugging steps are as follows: Make sure that the Android / iOS device is on the same LAN as Windows or Mac. Select the Android/iOS platform and Debug mode in the Build panel to build, compile and run a project (The iOS platform recommends connecting to the physical device via Xcode to compile and run). Open address with Chrome browser: devtools://devtools/bundled/js_app.html?v8only=true&ws={IP}:6086/00010002-0003-4004-8005-000600070008, where {IP} is the local IP of the Android/iOS device, then you can debug it. Debugging on Windows / Mac The steps for debugging a game on the Windows / Mac platform are similar to the Android / iOS, just compile the project and run it in the IDE. Compile and run the packaged project with the IDE (Visual Studio for Windows and Xcode for Mac). Open Chrome while the game is running and enter the address: devtools://devtools/bundled/js_app.html?v8only=true&ws=127.0.0.1:6086/00010002-0003-4004-8005-000600070008 to debug it. Other Platform Debugging If you need to debug in Release mode, or if you need to debug a custom native engine, please refer to the JSB 2.0 Use Guide: Remote Debugging and Profile documentation. "},"editor/publish/publish-mini-game.html":{"url":"editor/publish/publish-mini-game.html","title":"Publish to Mini Game Platforms","keywords":"","body":"Publish to Mini Game Platforms Publish to HUAWEI AppGallery Connect Publish to Alipay Mini Games Publish to ByteDance Mini Games Publish to QTT Mini Games Publish to Cocos Play Publish to Huawei Quick Games Publish to OPPO Mini Games Publish to vivo Mini Games Publish to Xiaomi Quick Games Publish to LinkSure Mini Games Publish to Baidu Mini Games Publish to WeChat Mini Games WeChat Engine Plugin Access to the WeChat PC Mini Games Open Data Context "},"editor/publish/publish-huawei-agc.html":{"url":"editor/publish/publish-huawei-agc.html","title":"Publish to HUAWEI AppGallery Connect","keywords":"","body":"Publish to HUAWEI AppGallery Connect Cocos Creator supports creating games for HUAWEI AppGallery Connect, which helps developers access the HUAWEI AppGallery. Preparation Work Login to the AppGallery Connect, you need to complete the Developer Registration before you can create an app. When creating an app, select APK for the Package type. You can access the required HUAWEI AppGallery Connect related services via the Cocos Service panel. Currently the SDK only supports the Android platform, please refer to the document HUAWEI HMS Core for the detailed operation steps. Release Process Use Cocos Creator to open the project that needs to be released. Open the Build panel from the Menu bar -> Project, select HUAWEI AppGallery Connect in the Platform dropdown of the Build panel. For the settings of the general options, please refer to the Build Options document. agconnect-services Config：Used to configure Huawei parameter file agconnect-services.json. Please refer to the Configs HUAWEI Parameter File for the specific configuration method. Cocos SDKHub Config Set: This option is used to help the game quickly intergrate the channel SDK. Please select the SDKHub service that you have previously enabled in the Cocos Services panel. Build and Compile After the relevant options of the Build panel are set, click Build. After the build is complete, click the folder icon button in the bottom left corner of the Build Task to open the release package directory. You can see that the huawei-agc folder is generated under the default release path build directory, which has been automatically integrated with HUAWEI AppGallery Connect related services. Then click Make, or use Android Studio to open the project to compile. After compiling, HUAWEI AppGallery Connect APK will be generated in the release package directory. Upload the APK to AppGallery Connect There are two ways to upload the APK to AppGallery Connect. 1. Upload by the Build panel Click the Upload button in the bottom right of the Build Task panel to open the Upload panel, then fill in the relevant information. APP ID: Fill in the APP ID for your app. Login to the AppGallery Connect and click My apps -> App information to get the APP ID. Version: Fill in as required. APK Path: Select the APK generated after compilation. Login Type: Includes both OAuth and API Client. OAuth The OAuth login type only requires you follow the prompts to login to your HUAWEI account (Need to have sufficient permissions) when you click Confirm, then check the box of the required permissions, the window will automatically close and the APK will be uploaded automatically. API Client If the API Client login type is used for the first time, you need to login to AppGallery Connect to get the relevant configuration information. Select Users and permission -> Connect API -> Create to create an API client, and select role permissions as needed, then click Confirm. Fill the Client ID and Key of the API client into the corresponding input boxs in the Upload panel of the Creator. Click Confirm when you are done configuring. Detailed descriptions of the two login types can be found in document AppGallery Connect API Getting Started. 2. Upload by AppGallery Connect Sign in to AppGallery Connect, click My apps and select the app. Then switch to the Distribute column at the top left, click on Version information -> Draft in the left column, find the Upload APK package, click on Software packages, and then click on Upload. Submit Your App for Review Sign in to AppGallery Connect, click My apps and select the app. Then switch to the Distribute column at the top left, click on Version information -> Draft in the left column, find the Upload APK package, click on Software packages, and then click on Select. For other configuration information, please refer to the document Releasing an App. After you have completed and confirmed all the information is in order, you can directly click the Submit button at the top right of the page. HUAWEI AppGallery will complete the review in 3~5 working days. Related Reference Links AppGallery Connect AppGallery Connect Operation Guide "},"editor/publish/publish-alipay-mini-game.html":{"url":"editor/publish/publish-alipay-mini-game.html","title":"Publish to Alipay Mini Games","keywords":"","body":"Publish to Alipay Mini Games Note: some platforms only have Chinese documentation available when visiting the platform's website. It may be necessary to use Google Translate in-order to review the documentation. Cocos Creator officially supports the release of games to the Alipay Mini Games. Environment Configuration Download Alipay Mini Program Studio on the PC and install it. Download Alipay and install it on your phone. The minimum supported version of Alipay on Android is 10.1.75, on iOS is 10.1.78. Release Process First, use Cocos Creator 3.0 to open the project that needs to be released. Select Alipay Mini Game in the Platform dropdown of the Build panel, and then click Build. The specific filling rules for the relevant parameter configuration are as follows: Polyfills - Polyfills are optional. If this option is checked at build time, the resulting release package will have the corresponding polyfills in it, and will also increase the size of the package. Developers can choose polyfills on demand, but only Async Functions are currently available. Remote URL - Remote URL is optional. For details, please refer to the Resource Management for Alipay Mini Game Environment section below. Second, after the build is completed, click the folder icon button below the alipay-mini-game build task to open the build release path. If the Build Task Name is alipay-mini-game, you can see that the Alipay Mini Game's project folder alipay-mini-game is generated in the build directory, which has included Alipay Mini Game environment configuration file game.json. Third, use Alipay Mini Program Studio to open alipay-mini-game directory. Next, you can open alipay mini game project to preview and debug game content. Resource Management for Alipay Mini Game Environment Alipay Mini Game is similar to WeChat Mini Game. There are restrictions on the package size. Assets more than 4MB must be downloaded via a network request. It is recommended to only save script files in the mini-game packages, while other assets are uploaded to the remote server, and downloaded from the remote server as needed. The download, cache, and version management of remote assets, Cocos Creator has already done it for you. The specific implementation logic is similar to the WeChat Mini Game. Please refer to the Resource Management for WeChat Mini Game Environment documentation for details. Specifically, developers need to: Set the Remote URL in the Build panel. And then click Build. When the build is complete, upload the build/alipay-mini-game/res folder to the server. Delete the res folder under the local release package directory. Alipay Mini Games Known issues Currently, our adaptation of Alipay Mini Games has not been completely completed, and the following modules are still not supported: WebView VideoPlayer Subpackage Loading Custom Font The above functions are expected to be gradually supported in future updates. "},"editor/publish/publish-bytedance-mini-game.html":{"url":"editor/publish/publish-bytedance-mini-game.html","title":"Publish to ByteDance Mini Games","keywords":"","body":"Publish to ByteDance Mini Games Note: some platforms only have Chinese documentation available when visiting the platform's website. It may be necessary to use Google Translate in-order to review the documentation. ByteDance Mini Games are developed based on ByteDance full products, which do not require users to download. This is a brand-new game type that can be played on tap. The game submission, review and release process of a mini-game needs to comply with the requirements and standard processes of the Byte official specification. For specific information, please refer to the links at the end of this document. Publish to ByteDance with Cocos Creator Download the ByteDance DevTools on ByteDance Official Website [cn]. Log in to Developer Platform [cn]to find your mini game appid. For details, please refer to the official Access Guide [cn] documentation. Select the ByteDance Mini Game in the Platform in the Build panel, fill in the mini game appid, and then click Build Preview game Following this process, a bytedance-mini-game folder will be generated in the project's build directory (the name of the folder is based on the Build Task Name), then you can open your game with the ByteDance DevTools. Build Options Options Optional or not Default Explanation appid Required testId The appid of the ByteDance Mini Games, it will be written to project.config.json file. Remote server address Optional Empty The remote server address. Resources will then be obtained from this address. Open data context root Optional Empty If an Open Data Context exists, use this root to specify the relative path of the Open Data Context folder in the build directory so that the directory is not overwritten or modified during the build. Orientation Required landscape Device orientation, it will be written to game.json file. Asset Management for ByteDance Mini Game Environment In a ByteDance Mini Game environment, asset management is the most special part. It differs from the browser in the following four points: The size of the ByteDance Mini Game package cannot exceed 4MB, including all the code and assets. Additional assets must be downloaded via web request. For files downloaded from a remote server, the ByteDance Mini Game environment does not have the browser's caching and outdated update mechanism. For the assets in the ByteDance Mini Game package, they are not loaded on demand in the mini game environment, but rather all the assets in the package are loaded at once, and then the game page is launched. You cannot download script files from a remote server. This brings up two key issues, home page loading speed and remote asset caching and version management. For the home page loading speed, we recommend that developers only save the script file in the ByteDance Mini Game package, and all other assets are downloaded from the remote server. As for downloading, caching and version management of remote assets, Cocos Creator has done the job for developers. Specifically, developers need to do the following: When building, enable the MD5 Cache in the Build config panel. Set the Remote service address, and then click Build. When the build is complete, upload the res folder in the mini game release package to the server. Delete the res folder inside the local release package. For the test phase, you may not be able to deploy to the official server, you need to use the local server to test, then open the details page in the WeChat DevTools, check the Does not verify valid domain names, web-view (business domain names), TLS versions and HTTPS certificates option in the Local Settings. Subpackage Loading The ByteDance Mini Game requires a specific version to support the subpackage feature, and the version requirements for the ByteDance product are as follows: Product Android iOS TikTok v13.6.0 v13.7.0 TouTiao v7.9.9 v7.9.8 For ByteDance DevTools, please use v2.0.6 or above, but below v3.0.0. After updating the DevTools, don't forget to modify the Debug Base library to 1.88.0 or above in the ByteDance DevTools. Note: if the product version does not support subpackage loading, the engine will load the subpackage as a normal asset bundle. Currently, the size of the ByteDance Mini Game subpackage has following restrictions: The size of all subpackages of the entire mini game cannot exceed 16 M The size of a single subpackage/main package cannot exceed 4 M For details, please refer to the ByteDance Subpackage Loading Official Documentation [zh] Reference documentation Note: some platforms only have Chinese documentation available when visiting the platforms website. It may be necessary to use Google Translate in-order to review the documentation. ByteDance Mini Game Developer Document Guide [cn] ByteDance Developer Platform [cn] ByteDance Mini Game API Documentation [cn] ByteDance DevTools Download [cn] ByteDance DevTools Documentation [cn] "},"editor/publish/publish-qtt.html":{"url":"editor/publish/publish-qtt.html","title":"Publish to QTT Mini Games","keywords":"","body":"Publish to QTT Mini Games Note: some platforms only have Chinese documentation available when visiting the platform's website. It may be necessary to use Google Translate in-order to review the documentation. Environment Configuration Download QTT APP and install it on your Android device (Android Phone 6.0 or above is recommended). Release Process Use Cocos Creator to open the project that needs to be released. Open the Build panel from the Menu bar -> Project, select QTT Mini Game in the Platform dropdown. Configuration Options The specific filling rules for the relevant parameter configuration are as follows: Main Bundle Compression Type Set the compression type of the main package, please refer to the built-in Asset Bundle — main documentation for details. Main Bundle Is Remote This option is optional and needs to be used with the Resource Server Address option. If set, the main package is configured as a remote package, and along with its related dependent resources are built into a built-in Asset Bundle — main under the remote folder of the release package directory. You need to upload the entire remote folder to the remote server. Start Scene Asset Bundle This option is optional. If set, the start scene and its related dependent resources are built into the built-in Asset Bundle — start-scene to speed up the resource loading of the start scene. Please refer to the Start Scene Loading for details. Game Package Name Game Package Name is filled in according to the user's needs. It's required. Desktop Icon Desktop Icon is required. Click the ... button at the back of the input box to select the icon you want. When building, the Desktop Icon will be built into the QTT Mini Game project. Desktop Icon suggest using PNG pictures. Game Version Name This item is required. Game Version Name is the real version, such as: 1.0.0. Game Version Number This item is required. Game Version Number is different from the Game Version Name, and the Game Version Number is mainly used to distinguish the version update. Each time when you submit audit, the Game Version Number is at least 1 higher than the value of the last submitted audit. It must not be equal to or less than the value of the last submitted audit, and it is recommended that the Game Version Number be recursively incremented by 1 each time when the audit is submitted. Note: the Game Version Number must be a positive integer. Resource Server Address This option is optional and used to fill in the address of the remote server where the resources are stored. If this option is left blank, the build/qtt-game/remote folder in the release package directory will be packaged into the cpk package. If this option is filled in, the remote folder will not be packaged into the built cpk package. You need to manually upload the remote folder to the filled in Resource Server Address after build. Refer to the Resource Management section at the bottom of the document for more details. Build After the relevant options of the Build panel are set, click Build. After the build is complete, click the Open button behind the Build Path to open the build release package. You can see that the qtt-game directory is generated under the default release path build directory, which is the exported QTT Mini Game project directory and cpk, the cpk package is in the /build/qtt-game directory. Run the built cpk to the phone Open the QTT APP that has been installed before on your Android device, click 我的 in the bottom navigation bar. Then drag the page down to the bottom and click 设置 to enter the Settings page. Click the blank area on the right side of the navigation bar of the Settings page for 6 consecutive times to enter the 趣实验 page. Find Cocos 实验室 on the 趣实验 page and click to enter the Cocos 实验室 page. Open game 包本地化开关 in the Cocos 实验室 page, and you can see a file path displayed below. Then rename the cpk package generated by the build to game_debug.cpk, and place it under the file path of the Android device. debug 开关 and vconsole 开关 can be turned on or off as required. Fill in the applied appid and game 版本号 appid is the applied game ID, which can be filled in at will in the debug environment. game 版本号 is the version characteristic value of the game package, normally generated by the platform. Here used for debugging purposes, and it is generally a random string of letters and numbers. Note: A new value is re-entered for each replacement package. After setting, click the 打开游戏 button below to open the game. Note: If you want to open the game again, you need to re-place the cpk package in the file path described above. Resource Management for QTT Mini Game Environment QTT Mini Game is similar to WeChat Mini Game. There are restrictions on the package size. The main package size limit for QTT Mini Game is 4MB, more than that must be downloaded via a network request. Cocos Creator already helps developers with downloading, caching and version management of remote resources. The specific implementation logic and operation steps are similar to the WeChat Mini Game. Please refer to the Resource Management for WeChat Mini Game documentation for details. Related reference links QTT Game Center QTT Mini Games Official Documentation QTT Mini Games Debugging Documentation QTT Mini Games API Documentation "},"editor/publish/publish-cocos-play.html":{"url":"editor/publish/publish-cocos-play.html","title":"Publish to Cocos Play","keywords":"","body":"Publish to Cocos Play Note: some platforms only have Chinese documentation available when visiting the platform's website. It may be necessary to use Google Translate in-order to review the documentation. Cocos Creator officially supports the release of games to the Cocos Play. Publish Cocos Play with Cocos Creator Prerequisites Download and install the Cocos Play Self-test Tools on your Android device (recommended Android Phone 6.0 or above). Build Use Cocos Creator 3.0 to open a project. Select Cocos Play in the Platform dropdown of the Build panel, and then click Build. The specific filling rules for the relevant parameter configuration are as follows: tinyPacketMode This item is optional. The in-package volume of the game contains code and assets that cannot exceed 10M, and assets can be loaded via network requests. tinyPacketMode is to help developers keep the script files in the game package, other assets are uploaded to the remote server, and downloaded from the remote server as needed. Cocos Creator has already helped the developer with the download, cache, and version management of remote assets. The developer needs to do is the following steps: When building, check the tinyPacketMode and fill in the tinyPacketModeServer. First game asset package into the game package, this item is optional. In the tinyPacketMode, due to too many assets on the launch scene, downloading and loading assets for a long time may result in a short black screen when entering the game for the first time. If First game asset package into the game package is checked, you can reduce the black screen time when you first enter the game. However, it should be noted that the res/import asset does not support split asset downloading at this time, and the entire import directory is also packaged into the first package. Developers can choose whether to check this item according to their needs. Then click on Build. After the build is complete, click the Open button after the Build Path to upload the res directory under the release path to the server. For example, if the default release path is build, the Build Task Name is cocos-play, you need to upload the /build/cocos-play/res directory. At this point, the res directory will no longer be included in the built-up cpk, and the assets in the res directory will be downloaded from the filled tinyPacketMode Server Path through the network request. The build parameters when Publish from the command line: tinyPackageMode: false, tinyPackageServer: '', packFirstScreenRes: false, After the build is completed, click the folder icon button below the cocos-play build task to open the build release path. If the Build Task Name is cocos-play, you can see that a cocos-play folder is generated in the build directory. This folder is the exported Cocos Play game project and cpk, the cpk package is in the build/cocos-play directory. Access testing Developers must use the Cocos Play Self-test Tools to test access without problems before submitting to the platform for review. The size of the package is not required for the self-test, but if it is to be submitted for review, the package size cannot exceed 10M. The Self-test Tools can launch the game and provide features such as game login, payment, etc. By reading the game configuration parameters, you can determine the type of game to start and how the game will start. For details, please refer to the Self-test Tools documentation. Open the previously installed Self-test Tools, then click the Configure Game button at the top left of the Self-test Tools to enter the game configuration page. Configure parameters as required and click Save. Parameters Parameters Function Explanation gameId Game ID, which can be obtained from the background. gameKey Game key, which can be obtained from the background. gameSecret Game secret key, which can be obtained from the background. gameType Game type, including Versus and non-Versus. You can see how to use it in the Start Game section below. gameMode Game mode, please select Runtime. lodeType Game load type, which is how the game starts. Includes both File and Url. Please refer to the Start Game section below. path Game load address, needs to be used with lodeType. Please refer to the Start Game section below. Start Game There are two ways to start the game through the Self-test Tools. Load the game package as a file from the specified location (The game lodeType is File). Copy the .cpk file generated after the build to the device directory, if it is copied to the sdcard directory of device, you need to create a new folder (named cocosplay) in the sdcard directory and copy the .cpk to the cocosplay folder. Select File in the lodeType of the game configuration page. Fill in the path to the cocosplay folder where the .cpk file is placed in the path option. Such as /cocosplay/game.cpk. Click on Save after the configuration is complete, then click on Start Game to open the game. Open the game as a web page from the specified URL (The game lodeType is Url). Upload the .cpk file to the server. Select Url in the lodeType of the game configuration page. Fill in path, such as: http://192.168.0.1:8080/game.cpk. Click on Save after the configuration is complete, then click on Start Game to open the game. Reference documentation Note: some platforms only have Chinese documentation available when visiting the platforms website. It may be necessary to use Google Translate in-order to review the documentation. Cocos Play Center Cocos Play Documentation Center Cocos Play API Documentation Cocos Play Self-test Tools Cocos Play Self-test Tools Download "},"editor/publish/publish-huawei-mini-game.html":{"url":"editor/publish/publish-huawei-mini-game.html","title":"Publish to Huawei Quick Games","keywords":"","body":"Publish to Huawei Quick Games Note: some platforms only have Chinese documentation available when visiting the platform's website. It may be necessary to use Google Translate in-order to review the documentation. Cocos Creator officially supports the release of games to the Huawei Quick Games. Environment Configuration Download the Huawei Quick APP Loader and install it on your Android device (Android Phone 6.0 or above is recommended) Install nodejs-8.1.4 or above, globally. Release Process Use Cocos Creator 3.0 to open the project that needs to be released. Select Huawei Quick Game in the Platform dropdown of the Build panel. Click on the huawei-mini-game below to expand the parameter configuration of Huawei Quick Game. The specific filling rules for the relevant parameter configuration are as follows: Game Package Name Game Package Name is filled in according to the developer's needs. It's required. Desktop Icon Desktop Icon is required. Click the search icon button at the back of the input box to select the icon you want. When building, the Desktop Icon will be built into the Huawei Quick Game project. It is suggested that the Desktop Icon is a .png image. Game Version Name This item is required. Game Version Name is the real version, such as: 1.0.0. Game Version Number This item is required. Game Version Number is different from the Game Version Name, and the Game Version Number is mainly used to distinguish the version update. Each time when you submit audit, the game version number is at least 1 higher than the value of the last submitted audit. It must not be equal to or less than the value of the last submitted audit, and it is recommended that the Game Version Number be recursively incremented by 1 each time when the audit is submitted Note: the Game Version Number must be a positive integer. Supported Minimum Platform Version Number This item is required. According to the requirements of Huawei Quick Games, this value must be greater than or equal to 1035. Custom manifest file path (optional) This is an optional item, which is the expansion function of Huawei Quick Game. When used, you need to select a JSON file, and the data type in the file is required to be in JSON format. Note: the JSON data is not available when the key value are package, appType, name, versionName, versionCode, icon, minPlatformVersion, config, display, otherwise it will be overwritten by data such as Game Package Name, Game Name, Desktop Icon, Game Version Name, Game Version Number during the build. Small Packet Mode This item is optional. The in-package volume of the mini-game contains code and assets that cannot exceed 10M, and assets can be loaded via network requests. Small Packet Mode is to help developers keep the script files in the mini game package, other assets are uploaded to the remote server, and downloaded from the remote server as needed. Cocos Creator has already helped the developer with the download, cache, and version management of remote assets. The developer needs to do is the following steps: When building, check the Small Packet Mode and fill in the Small Packet Mode Server Path. First game asset package into the game package, this item is optional. In the Small Packet Mode, due to too many assets on the launch scene, downloading and loading assets for a long time may result in a short black screen when entering the game for the first time. If First game asset package into the game package is checked, you can reduce the black screen time when you first enter the game. However, it should be noted that the res/import asset does not support split asset downloading at this time, and the entire import directory is also packaged into the first package. Developers can choose whether to check this item according to their needs. Then click on Build. After the build is complete, click the Open button after the Build Path to upload the res directory under the release path to the small packet mode server. For example, if the default release path is build, the Build Task Name is huawei-mini-game, you need to upload the /build/huawei-mini-game/res directory. At this point, the res directory will no longer be included in the built-up rpk, and the assets in the res directory will be downloaded from the filled Small Packet Mode Server Path through the network request. Keystore When you check the Keystore, the default is to build the rpk package with a certificate that comes with Creator. This certificate is used only for debugging. Note: when the rpk package is to be used to submit an audit, do not check the Keystore to build it. If you don't check the Keystore, you need to configure the signature files certificate.pem path and private.pem path, where you build a rpk package that you can publish directly. The user can configure two signature files by using the search icon button to the right of the input box. There are two ways to generate a signature files: Generated by the New button after the certificate.pem path in the Build panel. Generated by the command line. The user needs to generate the signature file private.pem, certificate.pem through tools such as openssl. # Generate a signature file with the openssl command tool openssl req -newkey rsa:2048 -nodes -keyout private.pem -x509 -days 3650 -out certificate.pem Note: openssl can be used directly in the terminal in Linux or Mac environment, and in the Windows environment you need to install openssl and configure system environment variables. Restart Cocos Creator after the configuration is complete. 2. Build After the relevant parameters of the Build panel are set, click Build. When the build is complete, click the folder icon button below the corresponding build task to open the build release path, you can see that a directory with the same name as the Build Task Name is generated in the default release path build directory, which is the exported Huawei Quick Game project directory and rpk, rpk package are in the dist directory. 3. Run the built rpk to the phone Copy the rpk package generated by the build to the sdcard directory of the Android device. Open the Huawei Quick APP Loader that has been installed before, clicking the back button on the Android device will bring up a list, select the Local Install, select the path of place rpk, and then you can run the rpk on the Android device. 4. Subpackage rpk Subpackage rpk can be used according to your needs. Subpackage loading, which is, splitting the game content into several packages according to certain rules, only downloading the necessary packages when starting up for the first time. This necessary package is called main package. The developer can trigger in the main package to download other sub-packages, which can effectively reduce the time spent on the first boot. To use this function, set the Bundle Configuration in Cocos Creator, and the package will be automatically subpackaged when the setting is completed. After the build is complete, the generated subpackages and main package are merged into one rpk, which is in the build/huawei-mini-game/dist directory. Note: currently, Huawei Quick Game does not support downloading multiple subpackages at the same time, please download them in order if you need to download multiple subpackages. Reference documentation Huawei Quick Game Development Guide "},"editor/publish/publish-oppo-mini-game.html":{"url":"editor/publish/publish-oppo-mini-game.html","title":"Publish to OPPO Mini Games","keywords":"","body":"Publish to OPPO Mini Games Note: some platforms only have Chinese documentation available when visiting the platform's website. It may be necessary to use Google Translate in-order to review the documentation. Cocos Creator officially supports the release of games to the OPPO Mini Games. Environment Configuration Download OPPO Mini Game Debugger [cn] and install it on your OPPO phone (Android 6.0 or above is recommended) Install nodejs-8.1.4 or above, globally Release Process Use Cocos Creator 3.0 to open the project that needs to be released. Select OPPO Mini Game in the Platform dropdown of the Build panel. Click on the oppo-mini-game below to expand the build options configuration of OPPO Mini Game. For the general build options for each platform, please refer to General Build Options for details. OPPO Mini Game related build options filling rules are as follows: Start Scene Asset Bundle This option is optional. If set, the start scene and its related dependent resources are built into the built-in Asset Bundle - start-scene to speed up the resource loading of the start scene. Resource Server Address This option is optional and used to fill in the address of the remote server where the resources are stored. If this option is left blank, the remote folder in the release package directory will be packaged into the rpk package. If this option is filled in, the remote folder will not be packaged into the built rpk package. You need to manually upload the remote folder to the filled in Resource Server Address after build. Refer to the Resource Management section at the bottom of the document for more details. Game Package Name: is filled in according to the user's needs. It's required. Desktop Icon: is required. Click the search icon button at the back of the input box to select the icon you want. When building, the Desktop Icon will be built into the OPPO Mini Game project. It is suggested to use PNG images for the Desktop Icon. Game Version Name: is required. Game Version Name is the real version, such as: 1.0.0. Game Version Number: is required. Game Version Number is different from the Game Version Name, and the Game Version Number is mainly used to distinguish the version update. Each time when you submit audit, the game version number is at least 1 higher than the value of the last submitted audit. It must not be equal to or less than the value of the last submitted audit, and it is recommended that the Game Version Number be recursively incremented by 1 each time when the audit is submitted. Note: the Game Version Number must be a positive integer. Supported Minimum Platform Version Number: is required. According to the requirements for OPPO Mini Games, this value must be greater than or equal to 1031, and 1060 is recommended. Refer to the Instructions [cn] for details. Keystore: when you check the Keystore, the default is to build the rpk package with a certificate that comes with Creator, which is used only for debugging. Note: when the rpk package is to be used to submit an audit, do not check the Keystore to build it. If you don't check the Keystore, you need to configure the signature files certificate.pem path and private.pem path, where you build a rpk package that you can publish directly. The user can configure two signature files by using the search icon button to the right of the input box. There are two ways to generate a signature files: Generated by the New button after the certificate.pem path in the Build panel. Generated by the command line. The user needs to generate the signature file private.pem, certificate.pem through tools such as openssl. # Generate a signature file with the openssl command tool openssl req -newkey rsa:2048 -nodes -keyout private.pem -x509 -days 3650 -out certificate.pem Note: openssl can be used directly in the terminal in Linux or Mac environment, and in the Windows environment you need to install openssl and configure system environment variables. Restart Cocos Creator after the configuration is complete. 2. Build After the relevant parameters of the Build panel are set, click Build. When the build is complete, click the folder icon button below the corresponding build task to open the build release path, you can see that a directory with the same name as the Build Task Name is generated in the default release path build directory, which is the exported OPPO Mini Game project directory and rpk, rpk package is in the dist directory. 3. Run the built rpk to the phone Copy the generated mini-game rpk file to the /sdcard/games directory on your phone's SD card. Then open the Mini Game Debugger that has been installed before on the OPPO phone, click the OPPO Mini Game section, and then find the icon corresponding to the game name. If not found, click on the More -> Refresh button in the upper right corner to refresh. Note: if the OPPO Mini Game Debugger version is v3.2.0 and above, you need to copy the mini-game rpk file to the /sdcard/Android/data/com.nearme.instant.platform/files/games directory on your OPPO phone. If there is no games directory, you need to create a new one. Please refer to the Instructions -- New Directory [cn] for details. Subpackage rpk Subpackage rpk can be used according to your needs. Subpackage loading, which is, splitting the game content into several packages according to certain rules, only downloading the necessary packages when starting up for the first time. This necessary package is called main package, The developer can trigger in the main package to download other sub-packages, which can effectively reduce the time spent on the first boot. To use this function, set the Bundle Configuration in Cocos Creator, and the package will be automatically subpackaged when the setting is completed. After the build is complete, the subpackage directory is in the dist directory. In this case, you need to create a new subPkg directory in the sdcard directory of the OPPO phone, and then copy the .rpk file in the dist directory to the subPkg directory. Then switch to the Package Load section of OPPO Mini Game Debugger, click Refresh at the top right to see the game name of the subpackage, click Second Open to use the same as the normal packaged rpk. Subpackage rpk needs to be copied to the /sdcard/subPkg directory of OPPO phones, and non-subpackaged rpk needs to be copied to the /sdcard/games directory of OPPO phones, both of which cannot be mixed. Note: if the OPPO Mini Game Debugger version is v3.2.0 and above, you need to copy the mini game subpackaged rpk file to the /sdcard/Android/data/com.nearme.instant.platform/files/subPkg directory on your OPPO phone, or create a new one if there is no subPkg directory. The non-subpackaged rpk is copied to the /sdcard/Android/data/com.nearme.instant.platform/files/games directory on your OPPO phone, and the two cannot be mixed. Resource Management for OPPO Mini Game Environment OPPO Mini Game is similar to WeChat Mini Game. There are restrictions on the package size. The main package size limit for OPPO Mini Game is 10MB, more than that must be downloaded via a network request. Cocos Creator already helps developers with downloading, caching and version management of remote resources. Please refer to the Cache Manager documentation for details. Reference documentation OPPO Developer Guides OPPO Mini Game Tutorial [cn] OPPO Mini Game API Documentation [cn] OPPO Mini Game Tool Download [cn] OPPO Mini Game Instructions -- New Directory [cn] "},"editor/publish/publish-vivo-mini-game.html":{"url":"editor/publish/publish-vivo-mini-game.html","title":"Publish to vivo Mini Games","keywords":"","body":"Publish to vivo Mini Games Note: some platforms only have Chinese documentation available when visiting the platform's website. It may be necessary to use Google Translate in-order to review the documentation. Environment Configuration Download the Quick App & vivo Mini Game Debugger and vivo Mini Game Engine and install it on your Android device (recommended Android Phone 6.0 or above) Install nodejs-8.9.0 or above, globally: Note: after installing nodejs, you need to note whether the npm source address is https://registry.npmjs.org/ # View current npm source address npm config get registry # If not, reset the npm source address npm config set registry https://registry.npmjs.org/ Install vivo-minigame/cli globally: npm install -g @vivo-minigame/cli If vivo-minigame/cli installation fails, it may be caused by too low version of nodejs. Please check the version of node and upgrade. Build Options For some general build options of platforms, please refer to the General Build Options documentation for details. Name Optional Default value Description Field name Start Scene Asset Bundle Optional false If set, the start scene and its related dependent resources are built into the built-in Asset Bundle — start-scene to speed up the resource loading of the start scene. startSceneAssetBundle Remote server address Optional Empty This option is optional and used to fill in the address of the remote server where the resources are stored.If this option is left blank, the build/vivo-mini-game/remote folder in the release package directory will be packaged into the rpk package.Refer to the Resource Management section for more details. remoteServerAddress Game Package Name required (Project Name) such as com.example.demo package Desktop Icon required (Cocos Logo) Click the search icon button at the back of the input box to select the icon you want. When building, the Desktop Icon will be built into the vivo Mini Game project. It is suggested to use PNG images for the Desktop Icon. icon Game Version Name required (Cocos version) Game Version Name is the real version, such as: 1.0.0. versionName Game Version Number required 1201 Game Version Number is different from the Game Version Name, and the Game Version Number is mainly used to distinguish the version update. Each time when you submit audit, the game version number is at least 1 higher than the value of the last submitted audit. It must not be equal to or less than the value of the last submitted audit, and it is recommended that the Game Version Number be recursively incremented by 1 each time when the audit is submitted. versionCode Supported Minimum Platform Version Number required 1035 Please refer to Official Documentation [cn] to check the latest version number of vivo engine. minPlatformVersion Orientation - landscape Device direction, it will be written in manifest.json. deviceOrientation Use debug keystore - true When you check Use Debug Keystore, it means that the rpk package built with the certificate that comes with Creator is used by default, and it is only used for debugging. when the rpk package is to be used to submit an audit, do not check the Use Debug Keystore to build it. useDebugKey Key certification path - - The key store certificate, the quick game on the Huawei App Market, must be signed with the release version certificate, and the certificate fingerprint must be configured in the background of the Huawei Developers Alliance. For details, please refer to the following Generate Signature File privatePemPath、certificatePemPath Generate signature file If you don't check the Keystore, you need to configure the signature files certificate.pem path and private.pem path, where you build a rpk package that you can publish directly. The developer can configure two signature files by using the search icon button to the right of the input box. There are two ways to generate a signature files: Generated by the New button after the certificate.pem path in the Build panel. Generated by the command line. The developer needs to generate the signature file private.pem, certificate.pem through tools such as openssl. # Generate a signature file with the openssl command tool openssl req -newkey rsa:2048 -nodes -keyout private.pem -x509 -days 3650 -out certificate.pem Note: openssl can be used directly in the terminal in Linux or Mac environment, and in the Windows environment you need to install openssl and configure system environment variables. Restart Creator after the configuration is complete. Run the rpk There are three ways to run rpk on your phone: Method One Click the Run button at the bottom right of the vivo-mini-game build task in the Build panel and wait for the QR Code interface to be generated: Then open the Quick App & vivo Mini Game Debugger that was installed before on your Android device. Click the Scan code install button to scan the QR Code to open the rpk. Method Two Copy the generated mini game rpk file (located in the dist directory) to the sdcard directory of the mobile phone. Open the Quick App & vivo Mini Game Debugger that has been installed before on your Android device, click Local Install, then find the rpk file from the sdcard directory of your mobile phone and select Open. Method Three Specify to the editor installation directory resources/tools/vivo-pack-tools in the command line, and execute the command npm run server to generate URL and QR code using the vivo Mini Game Packer Commands. # Specify to the editor installation directory. cd F:/CocosCreator/resources/tools/vivo-pack-tools # Generate URL and QR code npm run server Then open the Quick App & vivo Mini Game Debugger that was installed before on your Android device. Finally, click the Scan code install button to copy the URL generated in the first step to the browser, and then directly scan the QR code on the web page to open the rpk. Subpackage Loading The subpackage loading of vivo Mini Games is similar to WeChat Mini Games. Please refer to the Mini Game Subpackage documentation for details. vivo Mini Game Environment Resource Management The part of vivo mini games that exceed the package size limit must be downloaded through the network. Cocos Creator helps developers to download, cache and manage remote resources. For details, please refer to Resource Management. Reference documentation vivo Mini Games Development Documentation [cn] vivo Mini Games API Documentation [cn] Quick App & vivo Mini Game Debugger Download [cn] "},"editor/publish/publish-xiaomi-quick-game.html":{"url":"editor/publish/publish-xiaomi-quick-game.html","title":"Publish to Xiaomi Quick Games","keywords":"","body":"Publish to Xiaomi Quick Games Note: some platforms only have Chinese documentation available when visiting the platform's website. It may be necessary to use Google Translate in-order to review the documentation. Cocos Creator officially supports the release of games to the Xiaomi Quick Games. Environment Configuration Install Node.js 8.1.4 or above, globally. Make sure the npm version that Node.js comes with is 5.2.0 minimum. Upgrade the npm command as follows: # View the npm version npm -v # If the lowest version of npm is below 5.2.0, you can upgrade npm using the following command. npm install npm@latest -g Download Xiaomi Quick Game Debugger and Xiaomi Quick Game Runtime Environment, and install it on your Xiaomi device (recommended MIUI 8.5.0 or above). Release Process Use Cocos Creator to open the project that needs to be released. Select Xiaomi Quick Game in the Platform dropdown of the Build panel. Click on the xiaomi-quick-game below to expand the parameter configuration of Xiaomi Quick Game. The specific filling rules for the relevant parameter configuration are as follows: App Package Name: the format of the App Package Name is com.yourcompany.projectname. This option is required and will be filled in according to the developer's needs. Note: starting from the platform version number 1062, Xiaomi Quick Game needs to use the official App Package Name, otherwise the error of Data loading exception, please click retry will be reported during debugging. You can refer to the Xiaomi Quick Game App Package Name Application documentation for details. Desktop Icon: is required. Click the search icon button at the back of the input box to select the icon you want. When building, the Desktop Icon will be built into the Xiaomi Quick Game project. It is suggested to use a PNG image for the Desktop Icon. App Version Name: is required. App Version Name is the real version, such as: 1.0.0. App Version Number: is required. App Version Number is different from the App Version Name, and the App Version Number is mainly used to distinguish the version update. Each time when you submit audit, the App Version Number is at least 1 higher than the value of the last submitted audit. It must not be equal to or less than the value of the last submitted audit, and it is recommended that the App Version Number be recursively incremented by 1 each time when the audit is submitted. Note: the App Version Number must be a positive integer. Supported Minimum Platform Version Number: is required. According to the requirements of Xiaomi Quick Games, this value must be greater than or equal to 1050. Small Packet Mode: is optional. The in-package volume of the quick-game contains code and assets that cannot exceed 10M, and assets can be loaded via network requests. Small Packet Mode is to help developers keep the script files in the quick game package, other assets are uploaded to the remote server, and downloaded from the remote server as needed. Cocos Creator has already helped the developer with the download, cache, and version management of remote assets. The developer needs to do is the following steps: When building, check the Small Packet Mode and fill in the Small Packet Mode Server Path. First game asset package into the game package, this item is optional. In the Small Packet Mode, due to too many assets on the launch scene, downloading and loading assets for a long time may result in a short black screen when entering the game for the first time. If First game asset package into the game package is checked, you can reduce the black screen time when you first enter the game. However, it should be noted that the res/import asset does not support split asset downloading at this time, and the entire import directory is also packaged into the first package. Developers can choose whether to check this item according to their needs. Then click on Build. After the build is complete, click the Open button after the Build Path to upload the res directory under the release path to the small packet mode server. For example, if the default release path is build, the Build Task Name is xiaomi-quick-game, you need to upload the /build/xiaomi-quick-game/res directory. Note: if you are using the command line to compile small packet mode, remember to backup the build/xiaomi-pack-tools/res directory, then delete the build/xiaomi-pack-tools/res directory, and then perform command line compilation (npm run build). At this point, the res directory will no longer be included in the built-up rpk, and the assets in the res directory will be downloaded from the filled Small Packet Mode Server Path through the network request. Keystore: when you check the Keystore, the default is to build the rpk package with a certificate that comes with Cocos Creator, which is used only for debugging. Note: when the rpk package is to be used to submit an audit, do not check the Keystore to build it. If you don't check the Keystore, you need to configure the signature files certificate.pem path and private.pem path, where you build a rpk package that you can publish directly. The developer can configure two signature files by using the search icon button to the right of the input box. Note: these two signature files are not recommended to be placed in the build/xiaomi-quick-game directory of the release package, otherwise the build directory will be emptied each time when it is built, resulting in file loss. There are two ways to generate a signature file: Generated by the New button after the certificate.pem path in the Build panel. After clicking the New button, fill in the information in the Packages panel that pops up. After the information is filled in, click Generate button, the log Generate certificate is complete! will be output in the Console panel, indicating that the signature file is generated. Generated by the command line. The developer needs to generate the signature file private.pem, certificate.pem through tools such as openssl. # Generate a signature file with the openssl command tool openssl req -newkey rsa:2048 -nodes -keyout private.pem -x509 -days 3650 -out certificate.pem Note: openssl can be used directly in the terminal in Linux or Mac environment, and in the Windows environment you need to install openssl and configure system environment variables. Restart Cocos Creator after the configuration is complete. 2. Build After the relevant parameters of the Build panel are set, click Build. When the build is complete, click the folder icon button below the corresponding build task to open the build release path, you can see that a directory with the same name as the Build Task Name (e.g xiaomi-quick-game) is generated in the default release path build directory, which is the exported Xiaomi Quick Game project directory and rpk, rpk package are in the /build/xiaomi-quick-game/dist directory. 3. Run the built rpk to the phone There are three ways to run rpk on your phone: Method One Click the Run button at the bottom right of the xiaomi-quick-game build task in the Build panel and wait for the QR Code interface to be generated: Then open the Xiaomi Quick Game Debugger that was installed before on your Xiaomi device. Click the Scan code install button to scan the QR Code to open the rpk. Method Two First open Settings-> Additional settings-> Developer options on Xiaomi device, turn on Developer options and USB debugging. Use a USB cable to connect your computer to your Xiaomi device. Copy the generated quick game rpk file (located in the build/xiaomi-quick-game/dist directory) to the sdcard directory of the Xiaomi device. Open the Xiaomi Quick Game Debugger that has been installed before on your Xiaomi device, click Local Install, then find the rpk file from the sdcard directory of your Xiaomi device and select Open. Debugging The debugging must be based on the physical device and must follow the strict run the game first and start the debugging function sequence. After starting the game, leave Xiaomi device in the interface where the game is open to run. Then use the USB cable to connect your computer to the Xiaomi device, and the Xiaomi device needs to enable Developer options and USB Debugging. Debugging can currently be initiated from the command line. Specify to the editor installation directory resources/tools/xiaomi-pack-tools in the command line, and execute the command npm run debug. And the debugging interface will start automatically in Chrome. If you want to open the debug interface manually, execute the command npm run debug -- --print-only and copy the generated URL address into Chrome to enable the debugging interface. # Specify to the editor installation directory. cd ${CocosCreator}/resources/tools/xiaomi-pack-tools # Automatically opens the debug interface on Chrome. npm run debug # manually opens the debug interface on Chrome. npm run debug -- --print-only 4. Subpackage rpk Subpackage rpk can be used according to your needs. Subpackage loading, which is, splitting the game content into several packages according to certain rules, only downloading the necessary packages when starting up for the first time. This necessary package is called main package. The developer can trigger in the main package to download other sub-packages, which can effectively reduce the time spent on the first boot. To use this function, set the Bundle Configuration in Cocos Creator, and the package will be automatically subpackaged when the setting is completed. When the build is complete, an .rpk file is generated in the build/xiaomi-quick-game/dist directory. The package size limitations for single subpackage/main package, please refer to the Xiaomi Quick Game Subpackage Rules [cn] documentation for details. Reference documentation Xiaomi Quick Game Reference documentation [cn] "},"editor/publish/publish-link-sure.html":{"url":"editor/publish/publish-link-sure.html","title":"Publish to LinkSure Mini Games","keywords":"","body":"Publish to LinkSure Mini Games Note: some platforms only have Chinese documentation available when visiting the platform's website. It may be necessary to use Google Translate in-order to review the documentation. LinkSure Mini Game is a mini game application platform of WiFi Master Key, which is convenient, lightweight and without installation. The LinkSure Mini Game runs as a cpk game package in the mini game environment, which is similar to the WeChat Mini Game. The game package is hosted in the cloud, put and run in the APP, safe, reliable and experience smooth, users can tap to play, without installation. Environment Configuration Download and install LinkSure Mini Game Debugger on your Android device (Recommended Android Phone 6.0 or above). Release Process Use Cocos Creator to open the project that needs to be released. Open the Build panel from the Menu bar -> Project, select LinkSure Mini Game in the Platform dropdown of the Build panel. Configuration Options The specific filling rules for the relevant options configuration are as follows: Main Bundle Compression Type Set the compression type of the main package, please refer to the built-in Asset Bundle — main documentation for details. Main Bundle Is Remote This option is optional and needs to be used with the Resource Server Address option. If set, the main package is configured as a remote package, and along with its related dependent resources are built into a built-in Asset Bundle — main under the remote folder of the release package directory. You need to upload the entire remote folder to the remote server, so that the main package is not packaged into the cpk. Start Scene Asset Bundle This option is optional. If set, the start scene and its related dependent resources are built into the built-in Asset Bundle — start-scene to speed up the resource loading of the start scene. Please refer to the Start Scene Loading for details. Resource Server Address This option is optional and used to fill in the address of the remote server where the resources are stored. If this option is left blank, the build/link-sure/remote folder in the release package directory will be packaged into the cpk package. If this option is filled in, the remote folder will not be packaged into the built cpk package. You need to manually upload the remote folder to the filled in Resource Server Address after build. Refer to the Resource Management section at the bottom of the document for more details. Build After the relevant options of the Build panel are set, click Build. After the build is complete, click the Open button behind the Build Path to open the release package directory. You can see that the link-sure/dist folder is generated under the default release path build directory, which is the exported LinkSure Mini Game project directory and cpk. Run the built cpk to the phone You need to first contact the LinkSure Mini Game business [cn] to become a mini game developer. Enter LinkSure Mini Program Management Platform, click Mini Program Management -> My Mini Program -> Create Mini Program, fill in the relevant information, submit and wait for review. After the review is approved, click the Version Management on the back of the mini program. Then click Upload Developer Version to upload the built cpk, which will only save the latest upload. The cpk that is uploaded later will overwrite the version that was uploaded earlier. Click the View QR Code after uploaded, then open the LinkSure Mini Game Debugger already installed on your phone to scan the code. You can now preview the game on the physical device. If you need to debug the game, refer to the official documentation LinkSure Mini Game debugging [cn]. For more information, please refer to the LinkSure Mini Game Development Process [cn] documentation. Resource Management for the LinkSure Mini Game LinkSure Mini Game is similar to the WeChat Mini Game. There are restrictions on the package size. The main package size limit for LinkSure Mini Game is 10MB, more than that must be downloaded via a network request. Cocos Creator already helps developers with downloading, caching and version management of remote resources. The specific implementation logic and operation steps are similar to the WeChat Mini Game. Please refer to the Resource Management for the WeChat Mini Game documentation for details. Related Reference Links LinkSure Mini Game Guide [cn] LinkSure Mini Game Development Process [cn] LinkSure Mini Game Debugging Documentation [cn] LinkSure Mini Game API Documentation [cn] LinkSure Mini Game Debugger Download [cn] "},"editor/publish/publish-baidu-mini-game.html":{"url":"editor/publish/publish-baidu-mini-game.html","title":"Publish to Baidu Mini Games","keywords":"","body":"Publish to Baidu Mini Games Note: some platforms only have Chinese documentation available when visiting the platform's website. It may be necessary to use Google Translate in-order to review the documentation. Cocos Creator officially supports the release of games to the Baidu Mini Games. The runtime environment of the Baidu Mini Game is an extension of the Baidu Smart Mini Program. This provides a WebGL interface encapsulation based on the mini program environment. This greatly improves the rendering capabilities and performance. However, since these interfaces are encapsulated by the Baidu team, they are not equivalent to the browser environment. On the engine side, in order to make the developers' workload as easy as possible, our main tasks for developers include the following: The engine framework adapts to the Baidu Mini Game API, pure game logic level, developers do not need any additional modifications. The Cocos Creator editor provides a fast packaging process, released directly as a Baidu Mini Game, and automatically evokes the Baidu DevTools. Automatically load remote assets, cache assets, and cache asset version control. Please refer to the Baidu Mini Game Developer Documentation [cn] documentation to review the game submission, the review, and the release process for a Baidu Mini Game. Publish Baidu Mini Games with Cocos Creator Prerequisites Download and install Baidu DevTools in the Baidu DevTools [cn] documentation. Download and install the Baidu App in the app store of your phone. Log in to the Baidu Smart Mini Program Platform [cn] and find App ID. Release process Select the Baidu Mini Game in the Platform of the Build panel, fill in the appid, and then click Build. After a build is completed, a baidu-mini-game folder will be generated in the project's build directory (the name of the folder is based on the Build Task Name), which already contains the configuration files game.json and project.swan.json of the Baidu Mini Games environment. Use the Baidu DevTools to open the baidu-mini-game folder to preview and debug the game. Please refer to the Baidu DevTools documentation for details. About how ​​to use Baidu DevTools, please refer to Baidu DevTools Documentation for details. Note: when previewing and debugging, if a prompt appears stating: The current version of the developer tool can't publish mini program, please update to the latest devtools. This means the appid filled in the Build panel is the appid of the Baidu Smart Mini Program, not the appid of the Baidu Mini Game, please re-apply for the appid of the Baidu Mini Game. asset Management for Baidu Mini Game Environment Baidu Mini Game is similar to WeChat Mini Game. There are restrictions on the package size. Assets more than 4MB must be downloaded via a network request. It is recommended to only save script files in the mini-game packages, while other assets are uploaded to the remote server, and downloaded from the remote server as needed. The download, cache, and version management of remote assets, Cocos Creator has already done it for you. The specific implementation logic is similar to the WeChat Mini Game. Please refer to the asset Management for WeChat Mini Game Environment documentation for details. When the MD5 Cache feature of the engine is enabled, the URL of the file will change as the content of the file changes. When the game releases a new version, the assets of the old version will naturally become invalid in the cache, and only the new assets can be requested from the server, which achieves the effect of version control. Specifically, developers need to do the following: When building, check the MD5 Cache in the Build panel. Set Remote server address in the Build panel and then click Build. After the build is complete, upload the build/baidu-mini-game/res folder to the server. Delete the res folder under the local release package directory. Note: when Baidu loads the assets on the remote server on the physical device, it only supports access via HTTPS, so the asset file must be placed on HTTPS, otherwise the loading of the asset will fail. Note: if the cache asset exceeds the environment limit of Baidu, you need to manually clear the asset. Use the remoteDownloader.cleanAllCaches() and remoteDownloader.cleanOldCaches() interfaces to clear the cache in Baidu mini game. The former will clear all cache assets in the cache directory, please use it with caution. The latter will clear the cache assets that are not used in the current application in the cache directory. Baidu Mini Game Subpackage Loading The subpackage loading method of Baidu Mini Game is similar to WeChat, with the following package restrictions: The size of all subpackages of the entire Mini Game can not exceed 8MB. The size of a single subpackage/main package can not exceed 4MB. Please refer to the Mini Game Subpackage documentation for details. Platform SDK Access In addition to pure game content, the Baidu Mini Game environment also provides a very powerful native SDK interface. These interfaces only exist in Baidu Mini Game environment, equivalent to the third-party SDK interface of other platforms. The porting of such SDK interfaces still needs to be handled by developers at this stage. Here are some of the powerful SDK capabilities offered by Baidu Mini Game: User interface: login, authorization, user information, etc. Baidu cashier payment Forwarding information File upload and download Other: images, locations, ads, device information, etc. Baidu Mini Games known issues Currently, the adaptation work of Baidu Mini Game is not completely finished, and the following components are not supported for the time being: VideoPlayer WebView If needed, you can directly call Baidu's API [cn] as needed. Reference documentation Baidu Mini Game Registration Guide [cn] Baidu DevTools documentation [cn] Baidu Mini Game API documentation [cn] Baidu Mini Game Subpackage Loading [cn] "},"editor/publish/publish-wechatgame.html":{"url":"editor/publish/publish-wechatgame.html","title":"Publish to WeChat Mini Games","keywords":"","body":"Publish to WeChat Mini Games Note: some platforms only have Chinese documentation available when visiting the platform's website. It may be necessary to use Google Translate in-order to review the documentation. The runtime environment of the WeChat Mini Game is an extension of the WeChat Mini Program, providing a WebGL interface encapsulation based on the mini program environment, greatly improving rendering capabilities and performance. However, since these interfaces are encapsulated by the WeChat team, they are not equivalent to the browser environment. On the engine side, in order to make the developers' workload as easy as possible, our main tasks for developers include the following: The engine framework adapts to the WeChat Mini Game API, pure game logic level, developers do not need any additional modifications. The Cocos Creator editor provides a fast packaging process, released directly as a WeChat Mini Game, and automatically evokes the WeChat DevTools. Automatically load remote assets, cache assets, and cache asset version control. In addition, the game submission, review and release process of the WeChat Mini Game is no different from the WeChat Mini Program. Please refer to the WeChat Mini Game Developer documentation. Publish WeChat Mini Games with Cocos Creator Download the WeChat DevTools on WeChat Official Document Set the WeChatGame App Path in Cocos Creator -> Preferences -> Native Develop. Log in to the WeChat public platform and find the appid Select the WeChat Game in the Platform of the Build panel, fill in the mini game appid, and then click Build Click Play to open the WeChat DevTools Note: the WeChat DevTools, if it has not been run on a Mac before, will show an error that states: Please ensure that the IDE has been properly installed. You need to manually open the WeChat DevTools once, before you can click Run. Preview deployment Following this process, a wechatgame folder will be generated in the project's build directory (the name of the folder is based on the Build Task Name), which already contains the configuration files game.json and project.config.json of the WeChat Mini Games environment. Build Options Options Optional or not Default Explanation appid Required wx6ac3f5090a6b99c5 The appid of the WeChat Mini Games, it will be written to project.config.json file. Start Scene Asset Bundle Optional false If set, the start scene and its related dependent resources are built into the built-in Asset Bundle — start-scene to speed up the resource loading of the start scene. Remote server address Optional Empty The remote server address. assets will then be obtained from this address. Open data context root Optional Empty If an Open Data Context exists, use this root to specify the relative path of the Open Data Context folder in the build directory so that the directory is not overwritten or modified during the build. Orientation Required landscape Device orientation, it will be written to game.json file. Asset Management for WeChat Mini Game Environment In a WeChat Mini Game environment, asset management is the most special part. It differs from the browser in the following four points: The size of the WeChat Mini Game package cannot exceed 4MB, including all the code and assets. Additional assets must be downloaded via web request. For files downloaded from a remote server, the WeChat Mini Game environment does not have the browser's caching and outdated update mechanism. For the assets in the WeChat Mini Game package, they are not loaded on demand in the mini game environment, but rather all the assets in the package are loaded at once, and then the game page is launched. You cannot download script files from a remote server. This brings up two key issues, home page loading speed and remote asset caching and version management. For the home page loading speed, we recommend that developers only save the script file in the WeChat Mini Game package, and all other assets are downloaded from the remote server. As for downloading, caching and version management of remote assets, Cocos Creator has done the job for developers. In the WeChat Mini Game environment, we provide a wxDownloader object, and after setting the REMOTE_SERVER_ROOT property to it, the logic of the engine to download assets becomes: Check that assets are in the mini game package. If not present, query local cache assets. If no local cache assets are available, download from a remote server. Download and save them to the mini game application cache in backstage for re-access. Local cache storage has space limitation, if total space of cache exceeds the limit, there will be no more caching without disturbing game process. It should be noted that once the cache space is full, all the assets that need to be downloaded cannot be saved, only the temporary files for save download assets can be used, and WeChat will automatically clean up all temporary files after the mini game is exited. So the next time you run the mini game again, those assets are downloaded again and the process keeps looping. In addition, the problem of file saving failure due to cache space exceeding the limit does not occur on the WeChat DevTools, because the WeChat DevTools does not limit the cache size, so testing the cache needs to be done in a real WeChat environment. At the same time, when the MD5 Cache feature of the engine is enabled, the URL of the file will change as the content of the file changes, so that when a new version of the game is released, the assets of the old version will naturally become invalid in the cache, and only the new assets can be requested from the server, which achieves the effect of version control. Specifically, developers need to do: When building, check the MD5 Cache in the Build panel. Set the Remote service address, and then click Build. When the build is complete, upload the res folder in the mini game release package to the server. Delete the res folder inside the local release package. For the test phase, you may not be able to deploy to the official server, you need to use the local server to test, then open the details page in the WeChat DevTools, check the Does not verify valid domain names, web-view (business domain names), TLS versions and HTTPS certificates option in the Local Settings. Note: if the cache asset exceeds the WeChat environment limit, you need to manually clear the asset. Use wx.downloader.cleanAllAssets() and wx.downloader.cleanOldAssets() to clear the cache in WeChat Mini Games. The former clears all the cache assets in the cache directory, please use it carefully. While the latter clears cache assets that are currently unused in the cache directory in the application. WeChat Mini Game Subpackage Loading To achieve subpackage loading with WeChat Mini Game, please refer to Mini Game Subpackage documentation. Platform SDK Access In addition to pure game content, the WeChat Mini Game environment actually provides a very powerful native SDK interface, the most important of which are user, social, payment, etc. These interfaces are only available in the WeChat Mini Game environment, equivalent to third-party SDK interfaces for other platforms. The porting of such SDK interfaces still needs to be handled by developers at this stage. Here are some of the powerful SDK capabilities provided by WeChat Mini Games: User interface: login, authorization, user information, etc. WeChat payment Forward and get forwarding information File upload and download Media: pictures, recordings, cameras, etc. Other: location, device information, scan code, NFC, etc. WeChat Mini Games Known issues Cocos Creator's adaptation of WeChat Mini Games has not been completely implemented. The following modules are still not supported: VideoPlayer WebView It is possible to use the missing functionality by calling the WeChat's API directly. WebAssembly Support As of 3.0, the Wasm physics experimental option has been added to the WeChat Mini Game builds. It is a laboratory feature for choosing the usage mode of ammo physics: js: Use js mode, this is consistent with previous versions. fallback: Automatic fallback mode, use wasm in an environment that supports wasm, or revert to js. wasm: Use wasm mode. In fallback, the editor packs all the mode code for the ammo physics. The corresponding code packets for the two modes are 1.2MB and 0.7MB, totaling nearly 2MB, which has a significant impact on the 4MB limit of the main packet. The solution is to reduce the pressure on the main package by configuring the subpackage, taking the ammo-82499473.js file as an example of a subpackage: Modify game.json { //*, \"subpackages\": [{ \"name\": \"ammo\", \"root\": \"cocos-js/ammo-82499473.js\" }] } Modify the init function in game.js window.__globalAdapter.init(function() { fsUtils.loadSubpackage('ammo', null, (err) => { System.import('./cocos-js/ammo-82499473.js').then(() => { return System.import('./application.js').then(({ createApplication }) => { return createApplication({ loadJsListFile: (url) => require(url), loadAmmoJsWasmBinary, }); }).then((application) => { return onApplicationCreated(application); }).catch((err) => { console.error(err); }); }) }); }); Notes: The WeChat Separation Engine plugin currently only supports js mode. WebAssembly required WeChat v7.0.17 and above. The WeChat WebAssembly debugging base library needs to be v2.12.0 and above. Fallback mode is recommended for the most comprehensive device support. Reference documentation WeChat Mini Game Developer Document WeChat Public Platform WeChat Mini Game API Documentation WeChat DevTools WeChat DevTools Download WeChat Cache Space Overflow Case "},"editor/publish/wechatgame-plugin.html":{"url":"editor/publish/wechatgame-plugin.html","title":"WeChat Engine Plugin","keywords":"","body":"WeChat Mini Games Engine Plugin Instructions Note: some platforms only have Chinese documentation available when visiting the platform's website. It may be necessary to use Google Translate in-order to review the documentation. The Game Engine Plugin is a new feature added to WeChat v7.0.7, which has the official version of the Cocos Creator engine built in. If the plugin is enabled in the first game the player experiences, all games that also have the plugin enabled do not need to download the Cocos Creator engine again, just use the same version of the engine directly from the public plugin library, or incremental update the engine. For example, when a player has played an A game developed using Cocos Creator v2.2.0, and the A game already enabled this plugin. Then he played the B Game, also developed by v2.2.0, and would not have needed to redownload the Cocos Creator engine if the B game had also enabled this plugin. Even if the B Game is developed using Cocos Creator v2.2.1, WeChat only needs to incremental update the difference between the two engine versions. This will drastically reduce the download counts of mini games, and improve the startup speed of mini games by 0.5~2s for a better user experience. How to use Simply check the Separate Engine option in the Build panel, and then build and release as normal, without additional manual operation. (This feature is only available when the built-in engine is used and the build is in non-debug mode.) FAQ Q: Does the engine plugin feature support engine customization? A: Not supported. If the version does not match or the engine customization is enabled during the build, the built package will not actually use the engine plugin feature properly, although the editor will continue to build after an error occurs. Q: The project enable the engine module clipping, should I need to disable it when using the engine plugin? A: No, the project can continue to use the engine module clipping as before. The engine plugin provides a complete engine that is compatible with all clipping settings without affecting the original project package. Q: After the engine plugin is enabled, will the engine code still be counted into the first package? A: According to WeChat's rules, it will still be counted. Q: After the engine plugin is enabled, can I remove all modules in Project Setting -> Modules of editor to reduce the package size? A: No, because WeChat only supports engine plugin since v7.0.7, if the engine is clipped randomly, the game may not be able to run on a lower version of WeChat. Q: When the engine plugin is enabled, prompt \"Code package unpacking failed\" or \"Login user is not the developer of the Mini Program\" in the WeChat DevTools, while the physical device previews correctly? A: The default appid in the Build panel is a common test id, and according to WeChat's rules, you need to fill in the appid applied for yourself to test the engine plugin. Q: When the engine plugin is enabled, prompt \"Unauthorized plugin, Add plugin\" in the WeChat DevTools? A: Click the Add plugin in the prompt, then select add CocosCreator plugin and recompile. If prompt \"There are no plugins to add\" when you add the plugin, you can select the Clear Cache -> Clear All option in the WeChat DevTools and try again. Reference documentation Note: some platforms only have Chinese documentation available when visiting the platforms website. It may be necessary to use Google Translate in-order to review the documentation. WeChat Mini Games Engine Plugin Development Documentation "},"editor/publish/publish-pc-wechatgame.html":{"url":"editor/publish/publish-pc-wechatgame.html","title":"Access to the WeChat PC Mini Games","keywords":"","body":"Access to WeChat PC Mini Games Note: some platforms only have Chinese documentation available when visiting the platform's website. It may be necessary to use Google Translate in-order to review the documentation. WeChat PC Mini Game supports running WeChat mini games in WeChat for PC. The WeChat PC Mini Game will have most of the Mobile capabilities, including but not limited to virtual payment, open data context, touch events, etc. (ads are not currently supported). It also provides keyboard events, mouse events, window customization and other features. Cocos Creator supports publishing games to WeChat PC Mini Games, and completes the adaptation of mouse and keyboard related interfaces. Let's see how to publish the game to WeChat PC Mini Games by Cocos Creator. Use Cocos Creator to Access to WeChat PC Mini Games Preparation Download and install the latest version of WeChat for PC and login to it with the WeChat account bound to the WeChat DevTools. Process of Publising Refer to the process of Publish to WeChat Mini Games and publish the game project to the WeChat Mini Game. In the WeChat DevTools, click the Preview button in the upper toolbar, select the Automatic Preview tab, check the Launch PC for auto preview option, and then click the Compile and Remote Debug button to preview and debug the mini game on the WeChat for PC. FAQ Q: How to distinguish the Mobile and PC of WeChat through the engine interface? A: You can determine by sys.isMobile that the PC side returns false and the mobile side returns true. Note: the simulator on the WeChat DevTools simulates a environment on the mobile, so it returns true. Q: Does the WeChat PC Mini Game support Mac? A: Not yet supported. By 2021-01-19, WeChat PC Mini Game has been officially launched, and it only supports Windows currently. Later on, we will actively cooperate with the engineers of WeChat PC Mini Game to adapt the Mac system at the first time. Related Reference Links WeChat PC Mini Game Access Guide [cn] Download WeChat for PC "},"editor/publish/build-open-data-context.html":{"url":"editor/publish/build-open-data-context.html","title":"Access to Open Data Context","keywords":"","body":"Access to Open Data Context Currently, platforms such as WeChat, Baidu, and ByteDance Mini Game have added the concept of Open Data Context, which is a separate game execution environment, in order to protect their social relationship chain data. The resources, engines, and applications in the Open Data Context are completely isolated from the main context, and only in the Open Data Context can developers access the relationship chain data through the open interface provided by the platform to implement some features such as leaderboards. In Cocos Creator 3.0, we deprecate the Canvas Renderer module and replaced it with a lightweight front-end Canvas engine based on XML + CSS designed by WeChat team. The engine is integrated into the Cocos Creator 3.0's built-in Open Data Context project template, which allows developers to implement a leaderboard-like feature based on the template with a few basic front-end skills. SubContextView Component Description Since the Open Data Context can only be rendered on the off-screen canvas called sharedCanvas, you need a node in your project to act as a container for rendering the Open Data Context, and add the SubContextView component to that node, which will render the sharedCanvas to the container node. The SubContextView component contains two main properties, Design Resolution Size and FPS. Design Resolution Size If you set the Design Resolution Size of the SubContextView component to 640 * 960, the size of the sharedCanvas will be set to 640 * 960 during the component's onLoad phase. This means that after the build, the Open Data Context Project is rendered on an off-screen canvas of 640 * 960. Then, when customizing the Open Data Context (see below), the maximum size of the tag style in style.js is 640 * 960, otherwise the rendered content will be off the canvas. Example: // style.js export default { container: { width: 640, // max width height: 960, // max height }, } To avoid this part of the data coupling, setting a percentage adaptation to the size is supported. Example: // style.js export default { container: { width: '100%', height: '100%', }, } In the actual rendering process, the engine will adopt the SHOW ALL adaptation policy to render the sharedCanvas to the SubContextView component node to avoid the UI distortion caused by stretching during rendering. For example, in the following two images, we are using SubContextView component nodes of different sizes, and the Open Data Context texture will not be stretched. Setting FPS The FPS property is primarily used to set how often the main context will update the sharedCanvas on the SubContextView component to avoid performance loss due to frequent updates to the Open Data Context texture. Release Process Open the project and double-click the scene, then add the SubContextView component to the node on which you need to render the Open Data Context. After the scene is set, save the scene, and then open the Build panel in Menu -> Project, select the WeChat / Baidu / ByteDance Mini Game platform you want to release, check Generate Open Data Context Template, and then click Build. After the build is complete, click the Folder Icon button at the end of Buid Path, you'll see an openDataContext folder (e.g. build/wechatgame/openDataContext), which is an Open Data Context project template built into Cocos Creator, in the distribution folder of the corresponding game platform. Developers can customize the required Open Data Context content based on this template, and the customization methods are described below. When built again, if the openDataContext folder exists in the build directory, it will be skipped directly and the developer does not have to worry about the customized Open Data Context Project being overwritten. Open the build distribution (e.g. build/wechatgame) using the DevTools of the corresponding mini game platformer to open the mini-game project to view the Open Data Context content. Note: in the Open Data Context of Baidu platform, since the image can only load player avatars returned from Baidu, the local avatar image may not be loaded in the generated template project. Customization on Open Data Context Project Before customizing an Open Data Context project, developers need to know some basic information: minigame-canvas-engine quick start[cn] doT template engine use With this basic information in mind, let's take a look at the Open Data Context template generated by default after the build, with the following directory structure: render/dataDemo.js: Simulates some random data of the leaderboards, where the developer can request the relational chain data from the platform and pass it to the doT template engine to generate relevant XML text render/style.js: To record CSS style text information, refer to Style documentation [cn] render/template.js: To record XML text information, the project uses the template engine to generate XML text by default. Refer to Tag documentation [cn]. render/avatar.png: Header images for display in Open Data Context project template, can be deleted. engine.js: source code of Canvas engine index.js: Open Data Context Project entry file where the Open Data Context is rendered by passing XML text and CSS styles to the Canvas engine Recommended practices Since the build directory generated after the build of the project is excluded from version control by default by git, if you want to include your custom Open Data Context in version control, you can put the openDataContext folder (e.g. build/wechatgame/openDataContext) into your project's build-templates directory. Please refer to Custom Project Build Process documentation. In an Open Data Context Project, if you need to listen to messages from the main context, you need to first determine whether the message comes from the main context engine, using the WeChat interface as an example: wx.onMessage(res => { if (!(res && res.type === 'engine')) { console.log('do something...'); } }); When the main context sends a message to the open data context, it is recommended to include a type message to avoid handling the wrong message source. For example, the res.type === 'engine' in the above code means that the message comes from the main context engine. Reference documentation WeChat official document -- Canvas engine for mini games [cn] minigame-canvas-engine source code doT template engine "},"editor/publish/publish-in-command-line.html":{"url":"editor/publish/publish-in-command-line.html","title":"Publish from the Command Line","keywords":"","body":"Publish from the Command Line Publish a project from the command line can help us build an auto-publish routine that allows modifying command line parameters to achieve different goals. Command Reference For example: Building Web Desktop with debug mode enabled: Mac /Applications/CocosCreator/Creator/3.0.0/CocosCreator.app/Contents/MacOS/CocosCreator --project projectPath --build \"platform=web-desktop;debug=true\" Windows ...\\CocosCreator.exe --project projectPath --build \"platform=web-desktop;debug=true\" Currently, when using the command line to build, except for the required build options, if no parameter values are uploaded, the default values are used to build. Please refer to the description below and the platform's build options description for specific default values. Exit Codes 332 Build failed —— Invalid build parameters. 334 Build failed —— Some unexpected errors occurred during the build process, please refer to the build log for details. 336 Build success. Publish Parameters --project: Required, specify the project path. --build: Specify the parameters to be used when building the project. When parameters are not specified after --build, then the parameters used in the Build panel, such as platforms, templates, and so on, will be used as default parameters. When additional parameter settings are specified, the default parameters will be overwritten with the specified parameters. The available parameters are: configPath: Parameter file path. If define configPath, then Cocos Creator will load this file as a build parameter in the JSON file format. This parameter can be modified by yourself or exported directly from the Build panel. includedModules: Customize the engine packaged modules, only the required modules are packaged. The corresponding field of each module can be found in the features field in this file of engine repository. outputName: The name of the release folder generated after the build. name: Game name. platform: Required, the platform needs to be built. buildPath: The game's release path, the default release path is in the build under the project folder. startScene: The uuid of the main scene (the participating scene will use the build option parameters in the Build panel from the last build), and the first scene from the Included Scenes will be used if not specified. scenes: Information about the scenes involved in the build, which defaults to all scenes when not specified. debug: Whether or not debug mode, the default is false. packAutoAtlas: Enabled or disabled the Auto Atlas, the default is false. compressTexture: Enabled or disabled the compress texture, the default is false. replaceSplashScreen: Whether to replace the splash screen, the default is false. md5Cache: Enabled or disabled the MD5 Cache, the default is false. mainBundleCompressionType: Main bundle compression type. For specific option values, please refer to the document Asset Bundle — compression type. mainBundleIsRemote: Configure the main package as a remote package. packages: The build configuration parameters supported by each plugin. What needs to be stored is the serialized string for the data object. For details, please refer to the following. Each platform's build will be embedded in the Build panel as a separate plugin, so each platform's build options are in different locations. The build parameters are configured in the packages field, for example, to specify the build options for WeChat Mini Game, the configuration is as follows: { taskName: 'wechatgame', packages: { wechatgame: { appid: '*****', } } } After the build plugin system is opened to the public, the configuration parameters of other plugins are embedded in the Build panel in the same way. Please refer to the documentation of each platform for the specific parameter fields of each platform, it is better to use the Export function of the Build panel to get the configuration parameters. Currently it is still compatible with the old version of the parameters to build, but the compatibility process will be gradually removed later, so please upgrade the configuration parameters as soon as possible. Publish using Jenkins Cocos Creator still needs the GUI environment when running from the command line. If the Jenkins server can not run Cocos Creator from the command line, a solution is running Jenkins in agent mode, so it can interact with the operating systems window server. For more details please review this Stack Overflow post. If the Jenkins server can not compile under Windows, specify a local user for the Jenkins service in the Windows Control Panel -> Administrative Tools -> Services, and then restart the computer. You don't need to set up a master-slave mode separately. "},"editor/publish/build-guide.html":{"url":"editor/publish/build-guide.html","title":"Build Process with FAQ","keywords":"","body":"Build Process Introduction with FAQ The build process is mainly divided into two parts, the General Build Process and the Platform Adaptation Process. The adaptation processing logic for each platform will be embedded in the Build panel as a separate plugin. The build plugin system is then open and developers can dynamically embed some build parameters into the panel for use. General build Process The general build process for Cocos Creator consists of the following: Initialization of build parameters Prepare build data Write the built asset to the file system Organizing the data of settings Compression and writing of settings uuid Initialization of build parameters This step mainly initializes the initial options passed to the build to the internal options of the build, does some parameter formatting, initializes the asset data of the build asset database, loads the latest asset information, and classifies it. Prepare build data The editor will first summarize the scene currently involved in the build and all assets in the resources directory. Each asset is packaged through the engine's deserialization process to find the dependent asset and recursion to pack the assets. The entire project's scripting environment is configured before being deserialized, that is, all non-plugin project scripts are loaded. Because whether the script loads correctly or not directly affects the deserialization, failure to load because the script is not written legally will directly result in build failure. If the dependent asset is lost in the deserialization process, a warning is issued, but the build continues nonetheless. The warning here does not mean that the problem does not need to be resolved, and if the asset loss is not resolved, it is difficult to guarantee that the problem will not occur after the build. This step will also sort out the asset types based on the build's internal division, such as scenes, scripts, texture compression tasks, JSON grouping information, etc., and weed out asset information that is not used. Note: all user scripts are loaded before this step is performed. Write the built asset to the file system After performing the previous steps, then we need to generate the used assets into the file system. After building, the serialized JSON files of all assets are placed in the res/import directory. The original files of all assets are placed in the res/raw-assets directory. The build process can be broken down into the following phases: Build scripts: The scripts in the editor are divided into plugin scripts and non-plugin scripts. The plugin script will copy the source file to the build/src directory, which is generated after the build based on the original directory structure. The plugin script does not support any script that needs to be compiled, such as TS or JS written in ES6. The asset information of the plugin script is written to the jsList array in settings. The non-plugin script will package the source files into project.js (project.dev.js in debug mode) in the corresponding src directory. Checking the sourceMap option will generate a corresponding map file, and the debug option will determine whether the script is compressed or not. Auto Atlas: Query all Auto Altas assets in the project, and then pack SpriteFrame assets within Auto Altas into a big Sprite Atlas assets, serialize assets to JSON according to the configuration of Auto Atlas assets. This step will modify the JSON grouping information, asset asset grouping information and add texture compression task. If the packAutoAtlas option in the Build panel is not checked during the build, no processing is done. Compress Texture: Compress the texture assets according to the organized texture compression tasks and write them to the folder generated after build. If the Compress Texture option in the Build panel is not checked during the build, no processing is done. Build engine: Follow the settings in the menu bar Project -> Project Setting -> Modules to discard the unused engine modules, and package them into the src/cocos3d.js file. Checking the sourceMap option will generate a corresponding map file. Checking the debug option will determine whether the script is compressed or not. The main steps in building the engine are as follows: Get the engine module information in the menu bar Project -> Project Setting -> Modules. Check if the engine version in the cache is the same as the engine version that needs to be compiled, and if it is, copy it without compiling. If compilation is required, perform the task of packaging the engine according to the engine interface. Copy the compiled js file and save the engine's modification time. When compiling the engine, you can view the output log information. Please refer to the log information documentation for the detail log viewing method. The packaged engine file will be placed in the editor's global temporary directory (use Build.globalTempDir to print during the build process).The cache file is stored as the name according to the hash value generated by the parameters that will affect the engine compilation. global-temp-folder |--CocosCreator |--x.xx(3.0.0) |--builder |--engine |--1dc4a547f9...63a43bb8965.watch-files.json |--1dc4a547f9...63a43bb8965 |--1dc4a547f9...63a43bb8965.meta ... As soon as any of the engine's build options change, the engine will recompile. Specifically affecting the engine build are: debug: Whether in debug mode includeModules: Setting engine modules sourceMaps: Whether or not to enable sourceMap platform: Build platform the modification times for the engine files. Whether to check the separation engine (WeChat platform only) build JSON: Serialized JSON is merged based on the JSON grouping and written to the file system (placed in the res/import directory). If in release mode, compression is also performed on the uuid in the serialized JSON. General assets copy: Some of the original assets (rawAssets) in the library are copied directly into the res/raw-assets folder generated after the build. MD5 Cache: Add the MD5 suffix to all the assets in the res folder and organize the data to record in settings. Generate application.js template file: Configure project settings into the application.js folder according to the the developers specified options. Generate them in the build output directory. Organizing the data of settings The main thing is to prepare the necessary configuration information for the game start based on the data of previous asset collation. About the structure of settings: { debug: boolean; // Whether in debug mode designResolution: { // Canvas resolution width: number; // The width of canvas resolution height: number; // The height of canvas resolution policy: number; // Full screen aspect adapted mode }; launchScene: string; // URL of the initial scene platform: string; // Platform rawAssets: { [index: string]: { [uuid: string]: string[] } }; // Store the asset URL and type loaded in assets // Example: \"bba00d3a-2f17-4511-b47c-0d584b21b763@6c48a\": [\"test/right/texture\", \"cc.Texture2D\", \"bba0...@6c48a\"] // \"bba0...@6c48a\": [\"test/right/texture\", 1, 1] scenes: Array; // The array of scenes information involved in the run scriptPackages: Array; // Script message array jsList: string[]; // Script plugin array moduleIds: string[]; // Information on all user script components packedAssets: Record; // json grouping information md5AssetsMap: { [index: string]: Array }; // It is not available until md5Cache is checked, and the array is stored in the format of [uuid_1, md5_1, uuid_2, md5_2, ...]. If uuid_1 is a simple number, it means that the uuid index in the uuids array is stored. uuids: string[]; // Arrays of uuid, only takes effect in release mode assetTypes?: string[]; // Arrays of asset types, only takes effect in release mode subpackages?: Record; // Subpackage asset information renderPipeline: string; // renderPipeline information } The structure here only lists the settings structure under the general build process, and actually adds configurations as needed when packaging for different platforms. Compression and writing of settings uuid During the asset packaging process, the uuid of all assets involved in the build are continuously collected and then organized into setting.js. setting.js will be written to the build/src directory, which isgenerated after the build. The uuid in the file will be compressed or not, depending on whether it is in debug mode or not. Organize all used uuid and store the uuid that appear more than twice in the uuids array, and replaced with indexes. All assetType that appear more than twice are also stored in the assetTypes array, and replaced with indexes. Build assets At this stage, the editor will arrage the scenes assets that selected in Build panel and all assets in the assets directory. All assets will be deserialized by engine to find out the dependent assets in deep. Before deserialization, editor will load all the scripts (expect plugin scripts) in the project, if the script is written illegally and fails to load, it will make this build task stop immediately. If any dependent asset is missing during the deserialization process, a warning info will be print, but editor will continue to build. When warning info is printed, we recommend you to read and try to resolve it, otherwise it may cause some unexpect errors after build. During the packaging process, the assets will be re-compressed and serialized after deserialization to reduce the package size. Also, all serialized files will be sorted into deferent JSON groups to reduce the size of game package. Assets that perform deserialization during the packing process will recompress the serialization to reduce the package size after packing. The serialized files of the texture assets are all packaged into a single JSON file, and the other serialized files are subpackaged according to the build options configuration. Build scripts The scripts in the editor are divided into plugin script and non-plugin script. The plugin script will copy the source file to the build/src directory generated after the build based on the original directory structure, so the plugin script does not support any script that needs to be compiled, such as TS or JS written in ES6. The asset information of the plugin script is written to the jsList array in settings. The non-plugin script will package the source files into project.js (project.dev.js in debug mode) in the corresponding src directory. Platform Adaptation Process The build provides a partial lifecycle hook function that facilitates the developer's involvement in the build during the different processing periods of the build. The build also provides a way for developers to add build options directly, as well as to modify the UI interface of the build panel, data verification, etc. At the moment these features are not open to the public, only briefly described here, but the platform building plugins within the editor have been developed in this way. Frequently asked questions The entire build process is in a separate worker, so if you want to see the log information during the build, please refer to the Build Log documentation. Please make sure that the scenes involved in the build can be previewed properly before the build, some of the scenes asset loss, script compilation failure problems can be exposed in the preview stage. Building on the premise of a normal preview allows for better troubleshooting and saves time. Assets loading with a 404 In this case, please copy the uuid in the lost asset error message to Assets to find the corresponding asset, and then see if all the assets on which the asset depends are normal. Assets loading with a 404 usually occurs in the following situations: Assets that are not in resources are dynamically loaded in the script Reason: Only the assets in the resources directory and those involved in building the scene will be packaged into the final release package. And only the asset url in the resources directory will be written to settings.js, if an asset is used in the script but not in the resources directory, then a 404 will appear when it is loaded. Solution: Move the used assets to the resources directory. The loaded asset had a problem when it was imported, causing the data to not be generated properly into the library Reason: All raw data during the build is obtained by reading the asset file in the library, and if the import fails, the correct corresponding asset information will not be obtained. Solution: Find the corresponding asset through Assets panel, right click it, and select Reimport Asset in the menu. Lost assets Reason: asset builds look for dependencies through engine deserialization, and the most frequent problem is that the dependent asset is accidentally deleted during the project iteration, resulting in the loss of the asset. The loss of these assets may not normally be noticed, but will be exposed once the build is executed. Solution: Use the Code Editor to find out which assets the uuid is referenced by, and then modify the corresponding assets. Script asset load error The scripting environment needs to be configured for the build. If the error message is related to the script, please refer to the error message to modify the script. If it is not clear which script is reporting the error, you can find the uuid of the corresponding script in the error message's call stack, and then look for the location in Assets. Find the image merged from Auto Atlas The Auto Atlas prints the uuid information of the original small image and the merged large image during the build process, the uuid can be found in the Build devTools, then the large image can be found by searching in the res/raw-assets folder generated after the build using the uuid of the found large image. If there are too many images, you can search for uuid directly in the build log. Engine compilation failed If it's a custom engine compilation failure, check your modified code, or custom engine path. "},"editor/publish/custom-project-build-template.html":{"url":"editor/publish/custom-project-build-template.html","title":"Custom Project Build Process","keywords":"","body":"Custom Project Build Process Custom Project Build Template Cocos Creator supports custom build templates for each project. Add a build-templates folder to the project path, divide the sub-folder according to the platform path. Then all the files in this folder will be automatically copied to the build generated project according to the corresponding folder structure after the build. Currently, all platforms except the native platform support this function, the specific platform name can be referred to the following custom build template platform support table. Folder Structure: project-folder |--assets |--build |--build-templates |--web-mobile |--index.html If the current platform is Web-Mobile, then build-templates/web-mobile/index.html will be copied to build/web-mobile/index.html. In addition to this, build templates can be customized in the following ways. ejs type Since the content of the package is not guaranteed to be exactly the same in every version, when the build template within the editor is updated, the developer also needs to update the build template within their project. Now add a new way to use the template, click on Project -> Create preview template in the main menu, and an ejs template file will be generated for the corresponding platform. project-folder |--assets |--build |--build-templates |--web-mobile |--index.ejs Parameters are imported into these templates during the build, and content that is frequently changed during the build is placed in sub-templates of that template. You only need to modify what you want to use, so that the build templates within the project can be updated less frequently. Note: the copy template occurs after the rendered template. For example, if both index.ejs and index.html exist in this directory, the final packaged package will be the index.html file instead of the index.ejs rendered file. JSON Type Many mini games have their own configuration JSON files, like game.json to WeChat Mini Games. Files in the build templates folder will just copy in default, but this configuration JSON will be merged instead of overwrite. Of course, it doesn't mean that all JSON file will be merged, you can check it in the tables below. Custom build template platform supports tables The JSON files corresponding to the data fusion for each mini game are as follows: Platform Actual Name Custom Build Template WeChat Mini Game wechatgame game.ejs, game.json, project.config.json Web Mobile web-mobile index.ejs Web Desktop web-desktop index.ejs Xiaomi Quick Game xiaomi-quick-game manifest.json Huawei Quick Game huawei-mini-game Use the Build Panel's Cocos Play cocos-play game.config.json Baidu Mini Game baidu-mini-game game.json, project.swan.json OPPO Mini Game oppo-mini-game manifest.json vivo Mini Game vivo-mini-game project.config.json Alipay Mini Game alipay-mini-game game.json Native native X (Not recommended) Custom Build Plugins It is currently in the internal testing phase and is not open to the public at this time. "},"editor/publish/custom-build-plugin.html":{"url":"editor/publish/custom-build-plugin.html","title":"Extend the Build Process","keywords":"","body":"Extended Build Process To build a platform plug-in a common editor plug-in format is required. For the basic structure of the plug-in, please refer to the First Extension documentation . To extend the build function, it is necessary to understand the overall process of the build. Please read the Introduction to the build process and FAQ guide documentation. Quick start Click Project -> New Build Extension in the menu bar of the editor, and select Global/Project to create a build extension package. If selecting Global, the build extension will be applied to all Cocos Creator projects. The path of Global is: Windows: %USERPROFILE%\\.CocosCreator\\extensions Mac: $HOME/.CocosCreator/extensions If selecting Project, this will apply the build extension to the specified Cocos Creator project. The path of Project is: $Your project address/extensions After the build extension is created, you will see the generation path of the plugin in the Console. Click on the path to open the build extension package in the file manager of the operating system. Before enabling the build extension, execute npm install in the directory to install some dependent @types modules to compile normally. The interface definition that comes with the editor has been generated under the @types folder in the root directory. Developer -> Export.d.ts from the menu bar of the editor shows the latest interface definitions. Click Extension -> Extension Manager in the menu bar of the editor to open the Extension Manager panel. Then select the Project/Global tab in the Extension Manager, and click the Refresh Icon button to see the build extension you just added. Then click the Enable button on the right to run the plug-in normally. After the build extension is enabled, open the Build panel, notice the expansion bar of the build extension plugin. Click Build to join the build process. If you need to modify the content of the build extension, directly modify the build extension package under the extensions directory, see the readme.md file in the build extension package directory for details. Then find the corresponding build extension in the Extension Manager, and click the Reload icon button. At this time, the extension in the editor will re-run with the latest code and files. Basic configuration process To extend the build function of the plug-in, you need to add the builder field to the contributions in package.json, and the relative path configuration of the corresponding module can be passed to the specified platform in the field. Example package.json: { \"contributions\": { \"builder\": \"./dist/builder\" } } The plugin entry configuration code example is shown below: export const configs: IConfigs = { 'web-mobile': { hooks: './hooks', options: { remoteAddress: { label: 'i18n:xxx', render: { ui: 'ui-input', attributes: { placeholder: 'Enter remote address...', }, }, // Validation rules, there are currently several commonly used validation rules built in, and the rules that need to be customized can be configured in the \"verifyRuleMap\" field verifyRules: ['require', 'http'], }, enterCocos: { label: 'i18n:cocos-build-template.options.enterCocos', description: 'i18n:cocos-build-template.options.enterCocos', default: '', render: { // Please click \"Developer -> UI Components\" in the menu bar of the editor to view a list of all supported UI components. ui: 'ui-input', attributes: { placeholder: 'i18n:cocos-build-template.options.enterCocos', }, }, verifyRules: ['ruleTest'] } }, verifyRuleMap: { ruleTest: { message: 'i18n:cocos-build-template.ruleTest_msg', func(val, option) { if (val === 'cocos') { return true; } return false; } } } }, }; Please pay extra attention to the following points when writing entry scripts: The environment variables in different processes will be different. The entry script will be loaded by the rendering process and the main process at the same time, do not use the editor interface that only exists in a single process in the entry script. There are two ways to configure the key of config: one is for a single platform configuration, and the key is filled in as platform plugin name (available in the editor menu bar Extensions -> Extension Manager -> Internal to view the platform plug-in name); one is the configuration for all platforms, the key is filled in as *. These two configuration methods are mutually exclusive, please do not use them in the same build extension package. The detailed interface definition is described as follows: declare type IConfigs = Record; declare interface IBuildPlugin { hooks?: string; // Storage path of hook function options?: IDisplayOptions; // Platform parameter configuration that needs to be injected verifyRuleMap?: IVerificationRuleMap; // Register parameter verification rule function } declare type IDisplayOptions = Record; declare interface IConfigItem { // The default value, the registered default value will be in the \"options.[platform].xxx\" field in the plugin configuration default?: any; render: ?{ // The rules for rendering UI components are consistent with the unified rules at \"ui-prop\". Only configurations with UI properties specified will be displayed on the Build panel ui?: string; // The configuration parameters passed to the UI component attributes?: IUiOptions; }; // Configure the displayed name, if you need to translate, then pass in \"i18n:${key}\" label?: string; // A brief description of the setting, which will be displayed on the title when the mouse hovers over the configuration name. description?: string; // Type of configuration type?: 'array' | 'object'; // If type is an array, the data will be rendered according to the specified data type and \"itemConfigs\" itemConfigs?: Record | IConfigItem[]; } declare interface IUiOptions extends IOptionsBase { // // Validation rules array, build provides some basic rules, and you can also specify new validation rules through “verifyRuleMap”. Only when pass in “require” will be a valueless checksum, otherwise only when there is a value. verifyRules?: string[]; } declare interface IUiOptions extends IOptionsBase { class?: string | string[]; // The name of the style that needs to be set on the current \"ui-prop\" } For the interface definition of IOptionsBase please refer to ui-prop automatic rendering rule definition. Custom build hook function code configuration In the script module defined by the hooks field in the entry configuration, hook functions can be written that build the life cycle. In different hook functions, the data received will be different. All hook functions run in the build process, and the engine method can be used directly in the build process. If you need to use Editor, adding the code import * as Editor from 'editor'; to manually require. The relationship between the public hook function and the life cycle of the build can be seen in the following figure: The rough interface definition of hook function is as follows: declare interface IHook { throwError?: boolean; // The hook function injected by the plugin, whether to exit the build process directly and show the build failure when the execution fails. // ------------------ hook function -------------------------- onBeforeBuild?: IBaseHooks; onBeforeCompressSettings?: IBaseHooks; onAfterCompressSettings?: IBaseHooks; onAfterBuild?: IBaseHooks; // Compile the generated hook function (only valid if the platform's build process has a \"Make\" step) onBeforeMake?: (root: string, options: IBuildTaskOptions) => void; onAfterMake?: (root: string, options: IBuildTaskOptions) => void; } type IBaseHooks = (options: IBuildTaskOptions, result?: IBuildResult) => void; Note: the result parameter can be accessed only at the beginning of onBeforeCompressSettings, and the options passed to the hook function is a copy of the options used in the actual build process, and only used as a reference for information acquisition, so directly modifying it does not really affect the build process, although it can be modified successfully. To modify the build parameters, please set in the options field of the entry configuration code. Due to the numerous interface definitions, you can refer to the @types/packages/builder folder in the build extension package for detailed interface definitions. A simple example: export function onBeforeBuild(options) { // Todo some thing... } export function onBeforeCompressSettings(options, result) { // Todo some thing... } Build plugin debugging Click Developer --> Open Build DevTools in the menu to debug the plugin script normally. "},"module-map/":{"url":"module-map/","title":"Function Map","keywords":"","body":"Engine Features Map Guide Graphics RenderRendering system, including materials, lighting, particles, etc. UI SystemUI system, including all UI-related content. Animation SystemGeneric animation and skeletal animation system based on animation frame data and skeletal vertex data. AudioControl the playback, pause, etc. of sound clips. Physical SimulationPhysical simulation, mainly including rigidbody and collision, etc. Scripting Guide and Event SystemGuidelines for scripting to implement user-defined behaviors, including triggering mechanisms for events, etc. ComponentsComponents for adding different functions to game objects. AssetsAn introduction to the different resources used by the engine and an overview of the overall resource workflow. Scene and Environment SettingsScene structure and environment related settings. "},"module-map/graphics.html":{"url":"module-map/graphics.html","title":"Graphics Rendering","keywords":"","body":"Graphics Rendering MaterialThe properties of the model surface controlled by the shader. LightLighting, shading control and environment settings. ParticleCreate and use various types of particle effects. "},"concepts/scene/":{"url":"concepts/scene/","title":"Scene Creation Workflow","keywords":"","body":"Scene Creation Workflow A scene is an abstract collection of environmental factors in a game, a local unit for creating a game environment. Game developers represent a part of the game's world content by creating a scene in the editor. Scene Structure Cocos Creator implements a free scene structure using a node tree and a node component system. The Node is responsible for managing the parent-child relationship of the node tree and the spatial matrix transformation Transform, so that all entity nodes can be easily managed and placed in the scene. The component system gives nodes a variety of advanced features, such as MeshRenderer component, Animation component, Light component, Terrain component, and more. One of the necessary elements of the 3D scene is the Camera component, which represents the player's viewpoint in the game, without which nothing can be seen. Therefore, when creating a scene, the Creator will create a node with the Camera component mounted by default. Scene Creation Related Workflow Nodes and Components Coordinate System and Transformations Node Hierarchy and Display Order Building a Scene with the Scene Panel Skybox Global Fog Shadow "},"concepts/scene/node-component.html":{"url":"concepts/scene/node-component.html","title":"Nodes and Components","keywords":"","body":"Nodes and Components The workflow of Cocos Creator 3.0 is centered on component-based development, also known as an Entity-Component System, which simply means that the various elements of the game are built in a combinatorial rather than an inherited manner. In Cocos Creator 3.0, a Node is an entity that hosts a component, and we mount Component with various functions on it to give it a variety of representations and functions. Let's see how to create nodes and add components to a scene. Nodes Nodes are the basic building blocks of a scene. Nodes are organized in a tree-like relationship, and each node can have multiple children: Nodes have the following properties: A node contains a set of base attributes (Position, Rotation, Scale), and nodes are organized together by a set of relative transformation relationships, as described in coordinate systems and node transformation properties. The update order between nodes is cascading. The update of child nodes depends on the parent node, and child nodes follow the parent node transformations. Components can be added to a node to associate multiple components with the node. Create Nodes The quickest way to get a node with a specific function is to use the Create Node button in the top left corner of the Hierarchy panel. Take the simplest example of creating a Sphere node by clicking on the +, creating a Node button in the upper left corner and then selecting Create 3D Object -> Create Sphere. Notice the newly added Sphere node in the Scene and Hierarchy panel. The new node is named Sphere by default, indicating that it is a node whose functionality is primarily provided by the Sphere component. Try clicking the Create Node button again to select another node type and see that they will be named and behave differently. Also, note that creating a UI node automatically creates a Canvas node as the root node of the UI node, as described in the document UI Structure Description. For more information about the operations of single-select, multi-select, copy, delete, etc. of nodes in the Hierarchy panel, please refer to the Hierarchy Panel documentation. To create nodes dynamically in a script, refer to the Create and Destroy Nodes documentation. Components What are components and how do they relate nodes? Select the Sphere node, created above, and notice what the Inspector panel shows: The part of the Inspector panel that starts with the Node title is the node's properties, which include information about the node's Position, Rotation, Scale, and other transformations. This is covered in detail in the Coordinate Systems and Node Transformation Properties documentation. Starting with the cc.MeshRenderer title, is the properties of the Sphere component. In Cocos Creator, the MeshRenderer component is used to draw mesh resources, where the Mesh property is used to specify the mesh resources used for rendering. As the Sphere node was just created the default is sphere.mesh. The Materials property is used to specify the material used for rendering. You can try dragging any material from the Assets into the Materials property of the Inspector panel and you can see that the default material just became the specified material. Note: any resources set on the component, such as sphere.mesh in this case, will be loaded automatically at the same time as the scene loads. Types of resources that need to be set and automatically loaded can also be declared in custom components, refer to the Getting and loading resources documentation. In addition to adding components manually in the editor, they can also be added via scripts, for more details see the Component creation and destruction documentation. Effect of Node Properties on Components Once the node and MeshRenderer component are combined, the rendering of the mesh resources can be controlled by modifying the node properties. The node can also be adjust according to the properties marked by the red line in the figure below, notice that the rotation and scaling of the model have changed. Before adjustment: After adjustment: As previously mentioned, component-based structure is combined to achieve functional extensions. The combination of the node and MeshRenderer component is shown in the following figure: Add Additional Components Multiple components can be added to a node to add more functionality to the node. For example, select the node Sphere in the above example, then click the Add Component button at the bottom of the Inspector panel and select Light -> DirectionalLight to add a Directional Light component. Next, set the properties of the Directional Light component, e.g. adjust the Color property of the directional light to red, and notice that the color of the sphere model has changed, i.e. the DirectionalLight component that was added to the node has taken effect! Note: this is just a brief example of a more obvious effect. It is not recommended to add a DirectionalLight component to a sphere node. For more information about Components as well as other types of Components, please refer to the Components documentation. Note: that only one rendering component can be added to a node. Rendering components include: MeshRenderer, Sprite, Label, Graphics, Mask, RichText, UIStaticBatch, etc. "},"concepts/scene/coord.html":{"url":"concepts/scene/coord.html","title":"Coordinate Systems and Transformations","keywords":"","body":"Coordinate Systems and Node Transformation Properties In the documents, Scene Panel, and Nodes and Components, the ability to change the display behavior of nodes by using the transformation tool Gizmo and editing the properties of nodes in the Inspector panel was introduced. This document will take a deeper look at the coordinate system of the scene space in which the node is located and how the Position, Rotation, and Scale transformation properties of the node work. Coordinate Systems Position properties for nodes can be set, but where will a node with a specific position property be rendered on the screen when the game is running? Just as longitude and latitude specify coordinates for a location on a planet it is necessary to understand the coordinate system of Cocos Creator 3.0 to understand the meaning of node positions. World Coordinate The world coordinate system, also called absolute coordinate system, represents a unified coordinate system in the scene space in Cocos Creator 3.0 game development, and \"world\" is used to represent our game scene. The Creator 3.0 world coordinate system uses a Cartesian right-handed coordinate system with default x to the right, y to the top, z to the outside, and the -z axis for the front. Local Coordinate The local coordinate system, also called the relative coordinate system, is the coordinate system associated with the node. Each node has a separate coordinate system, and when the node moves or changes direction, the coordinate system associated with that node will move or change direction with it. Creator 3.0 has a hierarchy of parent-child relationships between Nodes, and the position of a node set by modifying its Position property is the node's local coordinate system with respect to its parent, not the world coordinate system. Finally when drawing the whole scene, Creator will map the local coordinates of these nodes to world coordinate system coordinates. Suppose there are three nodes in the scene: NodeA, NodeB, and NodeC. The structure of the nodes is shown in the following figure. When the scene contains nodes at different levels, the position of each node under the world coordinate system is determined according to the following steps: Process each node starting from the root level, NodeA in the above figure is a root level node. The first step is to determine the position of the origin of NodeA's local coordinate system (i.e. Position) in the world coordinate system based on NodeA's Position property. Next, process all the direct children of NodeA, which is NodeB in the above figure (as well as other nodes of the same level as NodeB). Based on NodeB's Position property, determine NodeB's position in the world coordinate system in NodeA's local coordinate system. Each node uses the parent's coordinate system and its own position property to determine its position in the world coordinate system. Transformation Properties Nodes include three main transformation properties, Position, Rotation and Scale, which are described below in turn. Position Position consists of the X, Y and Z properties, which specify the coordinates of the node on the X-axis, Y-axis and Z-axis of the current coordinate system, respectively, and default to (0, 0, 0). In the above figure, the world coordinates of NodeA are (50, 50, 50) and the local coordinates of child NodeB are (0, 2, 0). If NodeB is moved to the root of the scene, the world coordinates of NodeB become (50, 52, 50). The Position of the child NodeB is based on the Position of the parent NodeA as the origin of the coordinate system. If the parent NodeA changes its Position, the child NodeB will also change its position (world coordinate system), but the Position property of the child NodeB will not change, because the child NodeB does not change in the local coordinate system with the parent NodeA's Position as the origin. In the Scene panel, use the Move Transform Tool to change the node position. Rotation Rotation consists of the X, Y and Z properties, which default to (0, 0, 0), and is another important property that affects the node's local coordinate system. When the X property is changed, it means that the node will be rotated counterclockwise/clockwise around the x-axis, and so on, and the same applies when the Y or Z property is changed. When the property value is positive, the node rotates counterclockwise. When the property value is negative, the node rotates clockwise. The node hierarchy shown above is the same as the previous figure, except that the Rotation property of NodeA on the z-axis is set to 60 degrees, so you can see that in addition to NodeA itself being counterclockwise rotated by 60 degrees on the z-axis, its child NodeB is also centered on the z-axis. NodeB is also rotated counterclockwise on NodeA's z-axis. This also means that the rotation property affects the child nodes. Note: the rotation property on a node is a quaternion that represents the angle of rotation about any axis. The property corresponding to Rotation in the Inspector is the property EulerAngles. These two properties can be used separately according to your needs. When using the API, make sure to pay attention to the difference between them and the editor panel property names. In the Scene panel, use the rotate transform tool to set the rotation of the node. Scale The Scale property also consists of the X, Y and Z properties, which represent the scaling of the node on the x-axis, y-axis and z-axis, respectively, and defaults to (1, 1, 1). The node hierarchy shown above is the same as when Position was introduced. Setting the scale property of NodeA to (2, 1, 1) means that NodeA is scaled to 2 times its original size in the x-axis direction, while the y-axis and z-axis remain unchanged. You can see that the child node NodeB is also scaled to twice its original size in the x-axis direction, so the scaling property affects all child nodes. The Scale property set on a child node are superimposed on its parent node's scaling, and the child nodes of the child node multiply all the Scale properties at each level to obtain the scaling multiplier displayed in the world coordinate system. This is actually the same as the position and rotation properties, except that the position and rotation properties are additive, while the scaling property is multiplicative, which has a more pronounced effect. The Scale property does not affect the Position and Rotation of the current node, but it does affect the Position of the child nodes. In the Scene panel, use the Scale Transform Tool to modify the node scaling. "},"concepts/scene/node-tree.html":{"url":"concepts/scene/node-tree.html","title":"Node Hierarchy and Rendering Order","keywords":"","body":"Node Hierarchy and Rendering Order Combining Nodes and Components together creates all kinds of images, texts and interactive elements in a scene. When there are more and more elements in the scene, we can use the Hierarchy panel to arrange their hierarchy and rendering order to make things organized. Hierarchy Panel When creating and editing nodes, the Scene panel can display an intuitive visualization of scene elements. The hierarchical relationships between nodes need to be checked and manipulated using the Hierarchy panel. Please refer to the Hierarchy panel documentation first to learn how to use it. Node Trees The complete logical relationship between nodes established by the operations of the Hierarchy panel or runtime scripts is called a node tree. Using a simple game scenario demonstrates what a node tree is. The following picture includes a background image, a main character (the blob), a title, a springboard, diamonds and a button to start the game. Each visual element is a node. Usually all nodes are not laid flat on the scene, but rather, organized into a node tree according to a certain classification and order (e.g. according to our own preferences). Example: The nodes displayed in the upper level are referred to as parent nodes and those displayed in the lower level are referred to as children. In the Hierarchy panel, the node tree in the above figure would look like this: Creator 3.0 UI nodes require any parent node to have at least one UITransform component, if it does not comply with the rules, a Canvas node will be automatically added as its parent, the node tree in the above figure puts all UI nodes under the Canvas node. Next, parent nodes are created according to the category and put nodes of the same category under one parent node to build the node tree. In real game projects, other methods (such as game logic) can be used to organize the node tree as needed. Rendering Order of Nodes The rendering of 3D nodes is related to the Z-coordinate value of the distance between the node and the camera, transparency, etc. The rendering and occlusion relationship of UI nodes, on the other hand, is influenced by the node tree, which is rendered in order of node arrangement from top to bottom in the Hierarchy panel, meaning that nodes displayed above the list are occluded by the nodes below them in the scene. Therefore, the child nodes will always cover the parent nodes. For details, please refer to the UI rendering ordering rules documentation. Other rendering-related references can be found in. Graphics Rendering Particle Renderer Model Group Rendering Performance Considerations Note: although it is said that the parent node can be used to organize logical relationships or even as a container to host child nodes, the scene loading speed will be affected when there are too many nodes, avoid a large number of meaningless nodes when creating a scene and merge nodes with the same function as much as possible. "},"concepts/scene/scene-editing.html":{"url":"concepts/scene/scene-editing.html","title":"Build a Scene Image Using the Scene Panel","keywords":"","body":"Build a Scene Image Using the Scene Panel This document will introduce the workflow and tips of using Scene panel to create and edit scene images. Use the \"Create Node\" Menu to Quickly Add Basic Node Types When we start adding content to the scene, we typically start with the Create Node menu in the Hierarchy panel, which is the menu that pops up when you click the + button in the upper left corner, and select the base node type we need from several simple node categories and add it to the scene. When adding nodes, the node selected in Hierarchy panel will become the parent of the newly created node. If you select a node that is collapsed and then add a new node through the menu, you need to expand the node you just selected to see the newly added node. Empty Node Select Create Empty Node in the Create Node menu to create a node that does not contain any components. Empty nodes can be used as containers for organizing other nodes or for mounting logic and control components written by the developer. Also in the following we will describe how to create controls that meet your specific requirements by combining empty nodes and components. 3D Objects Select Create 3D Object in the Create Node menu to create some of the more basic static model controls that come with the editor, which currently include cub, cylinder, sphere, capsule, cone, torus, plane, and quad. If you need to create other types of models, you can refer to the MeshRenderer component. UI Nodes UI nodes can be created by selecting Create UI from the Create Node menu. UI nodes in Creator 3.0 require that any parent node must have at least one UITransform component. And every UI node itself will also have a UITransform component. So the Canvas node is the root node of UI rendering, and all rendering-related UI nodes are placed under the Canvas, which has the following benefits: Canvas can provide multi-resolution adaptive scaling, and using Canvas as the root node can ensure that our scenes will look good on larger or smaller screens, see Multi-resolution adaptation scheme. Canvas nodes are automatically centered according to the screen size, so UI nodes under Canvas will have the center of the screen as the origin of the coordinate system. In our experience, this simplifies the scene and UI setup (e.g. having the button element's text appear right in the center of the button node by default), and makes it easier to script the UI node position control. 2D Rendering Nodes The Create Node menu allows you to create node types consisting of nodes and base rendering components like ParticleSystem, Sprite, Label, Mask, etc. The base 2D rendering component here cannot be replaced by a combination of other components. Note that only one rendering component can be added to each node, and repeated additions will result in an error. However, complex interface controls can be implemented by combining different rendering nodes, such as the UI control node below. UI Control Node Common UI controls including Button, Widget, Layout, ScrollView, EditBox, etc. nodes can be created from the UI category in the Create Node menu. UI nodes are mostly a combination of rendered nodes, for example, the Button node we created through the menu includes a button background node with a Button component + a Sprite component, and a label node with a Label component: Creating nodes of the base type using the menu is the recommended way to quickly add content to the scene, and then we can edit the nodes created using the menu as needed to create the combinations we need. For more on UI nodes, see UI Structure Description. Attribution of Logical Nodes In addition to nodes with specific rendering and other tasks, it is recommended to have some nodes in the root directory of the scene that are only responsible for mounting scripts and executing game logic, without any rendering and other related content. Usually we place these nodes at the root level of the scene, side by side with Canvas nodes, so that other developers can find the game logic and bind relevant data in the first place when collaborating. Tips to Improve the Efficiency of Scene Creation The Scene panel includes both 3D and 2D views. The 3D view is used for 3D scene editing, and the 2D view is used mainly for editing 2D elements such as UI nodes. The scene view can be switched via the 3D/2D button in the toolbar at the top left of the editor. The following shortcuts work for both views. Select a node in the Hierarchy panel and double-click or press F to focus the node in the Scene panel. Pressing Cmd/Ctrl + D after selecting a node will copy and paste an identical node at the same location as the node, which can be used for efficiency when we need to make multiple similar nodes quickly. In Scene/Hierarchy panel, hold down the Cmd/Ctrl key and click on the node you want in order to select multiple nodes at the same time. The Shift key allows you to select nodes in succession, without selecting them one by one. Align/Evenly Distribute Nodes When the Scene panel is in 2D view, there is a row of buttons in the upper left corner that can be used to align or evenly distribute multiple nodes when they are selected. The specific rules are as follows: Assuming that all three Label nodes are selected, the six alignment buttons from left to right will align these nodes in turn: Top-aligned to the nearest upper border (not the upper border of the topmost node) Vertically centered, aligned to the overall horizontal center line Bottom-aligned, aligned to the nearest lower boundary Left-aligned to its closest left border Horizontally centered, aligned to the overall vertical center line Right-aligned, aligned to the nearest right border The 6 distribution buttons in the second half, from left to right, will align these nodes in turn: Top distribution, evenly distributed along the top boundary of the node Vertically centered distribution, evenly distributed along the horizontal midline of the node Bottom distribution, evenly distributed along the lower boundary of the node Left distribution, evenly distributed along the left border of the node Horizontally centered distribution, evenly distributed along the vertical center line of the node Right distribution, evenly distributed along the right boundary of the node Note: whether the left and right boundaries and the center line are determined at the beginning, or the reference when aligning/evenly distributing each node later, it is the center of the node bounding box or one of the boundaries rather than the position coordinates of the nodes. For example, in the figure below, when we align the three Label nodes with different widths to the right, we get the alignment of the right boundaries of the three node bounding boxes, not the x coordinates of the three node positions becoming the same. Scene Display Effects There is also support for setting the Skybox, Global Fog, and Shadows in the scene to better enrich the scene and render and display the scene environment. For details, please refer to: Skybox Global Fog Shadow "},"concepts/scene/skybox.html":{"url":"concepts/scene/skybox.html","title":"Skybox","keywords":"","body":"Skybox The skybox in a video game is a cube that wraps around the entire scene and can render and display the entire scene environment very well. The Skybox can also contribute very important IBL ambient lighting the in PBR-based workflow. Enable Skybox Check Scene in the Hierarchy panel, then check the Enabled property in the Skybox component of the Inspector panel to enable the skybox. The Skybox component properties are as follows: Property Description Enabled Whether to enable skybox UseIBL Whether to use ambient lighting Envmap Environment map, TextureCube type, see below for details on how to set it. When this property is empty, the skybox uses and displays pixel mapping by default IsRGBE Whether the pixel format of the environment map is RGBE Set the Environment Map of the Skybox After enabling the skybox, you also need to set the skybox's environment map. The environment map asset of the skybox can be a single map of TextureCube type or a CubeMap which is a combination of six texture type maps. So the developer can set the environment map of the skybox in the following two ways: By Setting the Texture Assets of TextureCube Type To import a texture asset, drag and drop it directly into the Assets panel. Select the imported texture asset, set the Type property to texture cube in the Inspector panel on the right, then click the green checkbox in the upper right corner to save the settings. Check Scene in the Hierarchy panel, then drag the set texture asset to the Envmap property box of the Skybox component in the Inspector panel. Then the setup is done. The developer can see the set environment map of the skybox in the Scene panel. If the map is not displayed correctly, you need to check if the value of SkyIllumination parameter is too low, or modify the Clear Flag of Camera. SkyIllumination Property The SkyIllumination property can be found in the Scene component of the Inspector panel by selecting Scene in the Hierarchy panel and then in the Ambient component of the Inspector panel, with a default value of 20000. If the SkyIllumination property is set too low, the environment map of the skybox may not be displayed correctly in the Scene panel. General: When the SkyIllumination property value is less than 300, the environment map of the Skybox will not be displayed properly. When the SkyIllumination property is 5000, the effect is equivalent to the light intensity of a moonlit night. Modify ClearFlags of Camera If the environment map of the skybox is already displayed correctly in the Scene panel but still does not take effect after the project is run, you need to change the ClearFlags of the Camera component to SKYBOX: By Setting the CubeMap To use a CubeMap as the environment map for the skybox, you need to create a CubeMap and drag it into the Envmap property box of the Skybox component. The operation steps are as follows: Select all the six prepared texture assets in the Assets panel, and then set the Type property of these texture assets to texture in the Inspector panel, and click the green checkbox in the upper right corner. Create a new CubeMap asset. Select the folder where you want to store CubeMap in the Assets panel, click the + button in the upper left corner, and then select Cubemap. Or you can right-click the folder where you want to store the CubeMap, and select New -> Cubemap. Drag and drop the six images you just set as texture type into the corresponding property box of the CubeMap, and click the green tick button on the top right then you are done. Notes: The property boxes in CubeMap that do not have a texture asset yet will be populated using the default asset. The six property boxes in CubeMap do not use the same texture, otherwise they will not be displayed properly for some platforms. Finally, drag the finished CubeMap asset into the Envmap property box of the Skybox component, and you are done with the CubeMap application. "},"concepts/scene/fog.html":{"url":"concepts/scene/fog.html","title":"GlobalFog","keywords":"","body":"Global Fog Global fog is used to simulate fog effects in outdoor environments in video games. In addition to fog representation in video games, it can also be used to hide the model outside the camera's far clipping plane to improve rendering performance. Check Scene in the Hierarchy panel, then check the Enabled property in the Fog component of the Inspector panel to enable global fog. Types of Global Fog The type of global fog depend on the result of the calculation of Camera and Model Vertices, which is called the Fog Blend Factor. The fog blend factor determines how the fog colors and model colors are blended, resulting in a different global fog effect. Currently there are four fog types including LINEAR, EXP, EXP_SQUARED, and LAYERED. Linear Property Description Enabled Whether to enable the global fog FogColor The color of the global fog Type The type of the global fog FogStart The starting position of the fog effect FogEnd The end position of the fog effect The fog blend factor of Linear Fog is calculated by the following formula: f = (FogEnd - Cam_dis) / (FogEnd - FogStart) When Cam_dis = FogEnd, i.e., the distance between the camera and the model vertex is equal to FogEnd, the blend factor is calculated as 0, and the object is fully fogged. When Cam_dis = FogStart, i.e. the distance between the camera and the model vertex is equal to FogStart, the blend factor is calculated as 1, and the object is not affected by fogging. To increase the density of Linear Fog when the distance between the camera and the model vertex is fixed, there are two ways: fix the value of FogStart and decrease the value of FogEnd. Decrease the value of FogStart and fix the value of FogEnd. To adjust the fog effect to the right consistency, it is best to adjust both the FogStart and FogEnd properties appropriately. An example effect of Linear Fog is shown below： Exponential and Exponential Squared Property Description Enabled Whether to enable the global fog FogColor The color of the global fog Type The type of the global fog FogDensity The fog density, in the range 0 ~ 1 FogAtten Fog attenuation coefficient The fog blend factor for Exponential Fog is calculated as f = e^(-distance * fogDensity) The fog blend factor for Exponential Squared Fog is calculated as f = e^(-distance * fogDensity)² Developers can use FogDensity and FogAtten to adjust the density of global fog at different locations. An example effect of Exponential Fog is shown below. Layered Layered Fog is parallel to the horizontal plane and has a specific height. The height of the fog can be determined by setting the top of the Layered Fog at any position in the vertical direction of the scene world coordinate system. Property Description Enabled Whether to enable the global fog FogColor The color of the global fog Type The fog type of the global fog FogAtten Fog attenuation coefficient FogTop The position of the model vertices in the vertical direction of the world coordinate system, below which all vertices will be affected by the fog effect FogRange The range of the fog effect The fog calculation of Layered Fog is a bit more complicated than the previous three fog types, as it introduces the concept of FogTop and also requires distance calculation in the x-z plane. Layered Fog is more common in reality, with towering mountains and buildings. If it is used wisely, it is believed to have a good effect on scene presentation, but at the same time, the computation will be increased, developers can decide according to their needs. An example of Layered Fog: "},"concepts/scene/shadow.html":{"url":"concepts/scene/shadow.html","title":"Shadows","keywords":"","body":"Shadow In the 3D world, light and shadow have always been extremely important components that enrich the entire environment. High quality shadows can make the game world look more realistic. Creator 3.0 currently supports both Planar and ShadowMap shadow types. Enable Shadow Effect To enable the shadow effect for an object, proceed as follows: Check Scene in the Hierarchy panel, and then check the Enabled property in the Shadows component of the Inspector panel. Select the 3D node that needs to display shadows in the Hierarchy panel, and then set the ShadowCastingMode property to ON in the MeshRenderer component of the Inspector panel. If the shadow type is ShadowMap, you also need to set the ReceiveShadow property on the MeshRenderer component to ON. Note: if the shadows are not displayed properly, you need to adjust the direction of the directional light. Shadow Type The shadow type can be set in the Type property of the Shadows component. Planar Shadow The Planar shadow type is generally used for simpler scenes. Property Description Enabled Whether to enable shadow effect Type Shadow type ShadowColor Shadow color Normal The normal line perpendicular to the shadow, used to adjust the slope of the shadow Distance The distance of the shadow in the direction of the normal to the origin of the coordinate Adjust the direction of the directional light to adjust the position of the shadow. Note: planar shadows are only cast on planar surfaces, not on objects, which means that the ReceiveShadow property in the MeshRenderer component is invalid. ShadowMap ShadowMap renders the scene with the light source as the viewpoint. From the position of the light source, the places in the scene that are not visible are where the shadows are created. Property Description Enabled Whether to enable the shadow effect Type Shadow type ShadowColor Shadow color Pcf Set the anti-aliasing level of the shadow edge, currently including HARD, FILTER_X5, FILTER_X9, FILTER_X25 Near Set the near clip plane of the main light source camera Far Set the far clip plane of the main light source camera OrthoSize Set the orthogonal viewport size of the main light source camera ShadowMapSize Set the texture size of the shadow Aspect Set the aspect ratio of the orthogonal viewport of the main light source camera ShadowMap receives and displays shadow effects generated by other objects when ReceiveShadow on the object MeshRenderer component is enabled. ShadowMap is generally used for scenes that require more realistic and complex light and shadow effects. The downside is that if the light source is not moved, then the previously generated Shadow Map can be reused, while once the light source is moved, then a new ShadowMap needs to be recalculated. "},"concepts/scene/light.html":{"url":"concepts/scene/light.html","title":"Lighting","keywords":"","body":"Lighting The Light in the game represents an object with luminous ability that can illuminate the surrounding environment. Adding light in the scene can make the scene produce the corresponding light and shadow effects, and get better visual effects. Add Lights There are two ways to add lights: Click on the + button in the upper left corner of the Hierarchy panel, and select Light, then select the light type as needed to create a node containing the corresponding type of light component to the scene. Select the node in the Hierarchy panel where you want to add the lights, then clicking the Add Component button below the Inspector panel and selecting Light. Physically-based Lighting Cocos Creator uses optical measurement units to describe light source parameters. Based on optical measurement units, we can convert all relevant parameters of the light source into physical values in the real world. In this way, the designer can adjust the light intensity, color, range and other parameters according to the industrial standards of parameters and the physical parameters of a real environment. The overall lighting effect is more in line with the real natural environment. For more information about the light and light parameters, please refer to the Physically-based Lighting. Types of Light For more information about light types, please refer to the following documentations: Directional lights Spherical lights Spotlights Ambient lights "},"concepts/scene/light/pbr-lighting.html":{"url":"concepts/scene/light/pbr-lighting.html","title":"Physically-based Lighting","keywords":"","body":"Physically-based Lighting Lights in the real world Physically-based lighting describes the light in the real world. In real environments, the lights we see have their own industrial parameters. First, let's look at a light bulb.💡 From the product packaging, we can understand several important industrial parameters of this bulb: luminous power color temperature size These three important parameters affect the performance of the light in the real world. Let's focus on the physical meaning of these three parameters. Luminous Power Luminous power is what we usually call the lights intensity. Cocos Creator 3.0 uses photometric units to measure light intensity: Luminous Power Unit Lumens (lm). Describes the total amount of light emitted by the light from all directions. Changing the size of the light will not affect the lighting effect of the scene. Luminance Unit Candela per square meter (cd/m2 or nits). Describes the intensity of the light when light is measured from a point on the surface of the light to a point on the receiving surface. Changing the size of the light will affect the lighting effect of the scene. Illuminance Unit lux (lx) Describes the total amount of light from a light measured at the receiving surface. This value is affected by the distance the light travels. In the real world, because the important physical parameters describing lights are different, we usually use luminous power and luminance to describe lights that illuminate areas commonly used in life. Color Temperature Color temperature refers to the color of the absolute black body after it has been heated from absolute zero (-273°C). Color temperature is an important attribute that affects the color of the light. It is an optional attribute. When color temperature is enabled, the color temperature also contributes to the color of the light. In a real world environment, the ambient color temperature at different times of the day also changes dynamically: Please refer to the following table: Light Size Lights in the real world have real physical dimensions. At the same time, the size of the light also affects the intensity of the light. "},"concepts/scene/light/dir-light.html":{"url":"concepts/scene/light/dir-light.html","title":"Directional Lights","keywords":"","body":"Main Directional Lights Directional light is the most common type of lights, and can be understood as the dominant light in a scene. The lighting effect is not affected by the light position and orientation, and is suitable for achieving sunlight. However, rotation affects the direction of directional lights illumination, which in turn affects the range to which the model receives illumination and where the model produces shadows. Note: Cocos Creator currently supports only one main directional light. If more than one is added at the same time, the last one added will prevail. To add the directional light to the scene, refer to the Lighting documentation. For the related interface of the directional light component, please refer to the DirectionalLight API. Main Directional Lights Properties Property Description Color Set the light color UseColorTemperature Whether to enable color temperature ColorTemperature Adjust the color temperature StaticSettings Set up static lighting, see LightMap for details Illumination Illumination, unit lux (lx) "},"concepts/scene/light/sphere-light.html":{"url":"concepts/scene/light/sphere-light.html","title":"Spherical Lights","keywords":"","body":"Spherical Lights Cocos Creator 3.0 uses Spherical Lights instead of Point Light because Point Light ignores volume, but physical light in the real world have a light size property. To add the spherical light to the scene, refer to the Lighting for details. For the related interface of the spherical light component, please refer to the SphereLight API. Spherical Lights Properties Property Description Color Set the light color UseColorTemperature Whether to enable color temperature ColorTemperature Adjust the color temperature Size Set the light source size Range Set the lighting impact range Term Setup the light intensity unit type, including both LUMINOUS_POWER and LUMINANCE. LuminousPower Luminous power in lumens (lm). Takes effect when Term is set to LUMINOUS_POWER. Luminance Brightness in Candela per square meter (cd/m2). Takes effect when Term is set to LUMINANCE. StaticSettings Set up static lighting, see LightMap for details "},"concepts/scene/light/spot-light.html":{"url":"concepts/scene/light/spot-light.html","title":"Spotlights","keywords":"","body":"Spotlights Spotlight is a beam of light emitted from a point in one direction, close to the light produced by a flashlight. Spotlights have an additional SpotAngle property over other types of lighting, which is used to adjust the illumination range of the Spotlight. To add the Spotlight to the scene, refer to the Lighting documentation. For the related interface of the Spotlight component, please refer to the Spotlight API. Spotlights Properties Property Description Color Set the light color UseColorTemperature Whether to enable color temperature ColorTemperature Adjust the color temperature Size Set the light source size Range Set the lighting impact range SpotAngle Adjust the spotlight angle to control the lighting range Term Setup the light intensity unit type, including both LUMINOUS_POWER and LUMINANCE LuminousPower Luminous power in lumens (lm). Takes effect when Term is set to LUMINOUS_POWER Luminance Brightness in Candela per square meter (cd/m2). Takes effect when Term is set to LUMINANCE StaticSettings Set up static lighting, see LightMap for details "},"concepts/scene/ambient.html":{"url":"concepts/scene/ambient.html","title":"Ambient Lights","keywords":"","body":"Ambient Lights In life, intricate lights and uneven surfaces of objects reflect each other, making the whole environment illuminated, as if by a layer of light evenly enveloped, this light is generally called Ambient Light. By adjusting the ambient light, is the most direct way to adjust the overall illumination of the environment, but also an effective way to express the atmosphere of the environment. Select Scene in the Hierarchy panel and set the properties in the ambient component of the Inspector panel. Note: since the ambient light is directionless, it cannot produce shadows. Ambient lights properties Property Explanation SkyColor Set the sky color SkyIllumination Adjust the sky brightness GroundAlbedo Set the ground reflected light Ambient light can be used with a Skybox, see Skybox for details. "},"material-system/overview.html":{"url":"material-system/overview.html","title":"Materials System","keywords":"","body":"Material System Overview The material system plays an essential role in any game engine infrastructure, it controls the way everything is drawn on screen and much more. The general structure of the system is as follows: EffectAsset EffectAsset is a shading procedure description file, written by both engine and game developers. It contains the mathematical calculations and algorithms for calculating the color of each pixel rendered. When the builtin effects are not the best fit for your need, writing your own effect can give you all the capabilities to customize the rendering process. Detailed syntax instructions can be found in the Effect Syntax documentation. Here is the flow that the engine reads EffectAsset resource: when the editor imports EffectAsset, the engine will do a pre-processing on your written content, then replace GL string as constant in the pipeline, extract shader information, convert shader version and so on. Using builtin-unlit.effect as an example, the structure of the compiled output EffectAsset is roughly as follows: { \"name\": \"builtin-unlit\", \"techniques\": [{ \"name\": \"opaque\", \"passes\": [{ \"program\": \"builtin-unlit|unlit-vs:vert|unlit-fs:frag\", \"properties\": { \"mainTexture\": { \"value\": \"grey\", \"type\": 28 }, \"tilingOffset\": { \"value\": [1, 1, 0, 0], \"type\": 16 }, \"mainColor\": { \"value\": [1, 1, 1, 1], \"editor\": { \"type\": \"color\" }, \"type\": 16 }, \"colorScale\": { \"value\": [1, 1, 1], \"type\": 15, \"handleInfo\": [\"colorScaleAndCutoff\", 0, 15] }, \"alphaThreshold\": { \"value\": [0.5], \"editor\": { \"parent\": \"USE_ALPHA_TEST\" }, \"type\": 13, \"handleInfo\": [\"colorScaleAndCutoff\", 3, 13] }, \"color\": { \"editor\": { \"visible\": false }, \"type\": 16, \"handleInfo\": [\"mainColor\", 0, 16] }, \"colorScaleAndCutoff\": { \"type\": 16, \"editor\": { \"visible\": false, \"deprecated\": true }, \"value\": [1, 1, 1, 0.5] } }, \"migrations\": { \"properties\": { \"mainColor\": { \"formerlySerializedAs\": \"color\" } } } }] }], \"shaders\": [{ \"name\": \"builtin-unlit|unlit-vs:vert|unlit-fs:frag\", \"hash\": 2093221684, \"glsl4\": { \"vert\": \"// glsl 460 vert source, omitted here for brevity\", \"frag\": \"// glsl 460 frag source, omitted here for brevity\", }, \"glsl3\": { \"vert\": \"// glsl 300 es vert source, omitted here for brevity\", \"frag\": \"// glsl 300 es frag source, omitted here for brevity\", }, \"glsl1\": { \"vert\": \"// glsl 100 vert source, omitted here for brevity\", \"frag\": \"// glsl 100 frag source, omitted here for brevity\", }, \"attributes\": [ { \"tags\": [\"USE_BATCHING\"], \"name\": \"a_dyn_batch_id\", \"type\": 13, \"count\": 1, \"defines\": [\"USE_BATCHING\"], \"location\": 1 }, { \"name\": \"a_position\", \"type\": 15, \"count\": 1, \"defines\": [], \"location\": 0 }, { \"name\": \"a_weights\", \"type\": 16, \"count\": 1, \"defines\": [\"USE_SKINNING\"], \"location\": 2 }, { \"name\": \"a_joints\", \"type\": 16, \"count\": 1, \"defines\": [\"USE_SKINNING\"], \"location\": 3 }, { \"tags\": [\"USE_VERTEX_COLOR\"], \"name\": \"a_color\", \"type\": 16, \"count\": 1, \"defines\": [\"USE_VERTEX_COLOR\"], \"location\": 4 }, { \"tags\": [\"USE_TEXTURE\"], \"name\": \"a_texCoord\", \"type\": 14, \"count\": 1, \"defines\": [\"USE_TEXTURE\"], \"location\": 5 } ], \"varyings\": [ { \"name\": \"v_color\", \"type\": 16, \"count\": 1, \"defines\": [\"USE_VERTEX_COLOR\"], \"location\": 0 }, { \"name\": \"v_uv\", \"type\": 14, \"count\": 1, \"defines\": [\"USE_TEXTURE\"], \"location\": 1 } ], \"builtins\": { \"globals\": { \"blocks\": [ { \"name\": \"CCGlobal\", \"defines\": [] } ], \"samplers\": [] }, \"locals\": { \"blocks\": [ { \"name\": \"CCLocalBatched\", \"defines\": [\"USE_BATCHING\"] }, { \"name\": \"CCLocal\", \"defines\": [] }, { \"name\": \"CCSkinningTexture\", \"defines\": [\"USE_SKINNING\", \"ANIMATION_BAKED\"] }, { \"name\": \"CCSkinningAnimation\", \"defines\": [\"USE_SKINNING\", \"ANIMATION_BAKED\"] }, { \"name\": \"CCSkinningFlexible\", \"defines\": [\"USE_SKINNING\"] } ], \"samplers\": [ { \"name\": \"cc_jointsTexture\", \"defines\": [\"USE_SKINNING\", \"ANIMATION_BAKED\"] } ] } }, \"defines\": [ { \"name\": \"USE_BATCHING\", \"type\": \"boolean\", \"defines\": [] }, { \"name\": \"USE_SKINNING\", \"type\": \"boolean\", \"defines\": [] }, { \"name\": \"ANIMATION_BAKED\", \"type\": \"boolean\", \"defines\": [\"USE_SKINNING\"] }, { \"name\": \"CC_SUPPORT_FLOAT_TEXTURE\", \"type\": \"boolean\", \"defines\": [\"USE_SKINNING\", \"ANIMATION_BAKED\"] }, { \"name\": \"USE_VERTEX_COLOR\", \"type\": \"boolean\", \"defines\": [] }, { \"name\": \"USE_TEXTURE\", \"type\": \"boolean\", \"defines\": [] }, { \"name\": \"FLIP_UV\", \"type\": \"boolean\", \"defines\": [\"USE_TEXTURE\"] }, { \"name\": \"CC_USE_HDR\", \"type\": \"boolean\", \"defines\": [] }, { \"name\": \"USE_ALPHA_TEST\", \"type\": \"boolean\", \"defines\": [] }, { \"name\": \"ALPHA_TEST_CHANNEL\", \"type\": \"string\", \"defines\": [\"USE_ALPHA_TEST\"], \"options\": [\"a\", \"r\", \"g\", \"b\"] } ], \"blocks\": [ { \"name\": \"TexCoords\", \"defines\": [\"USE_TEXTURE\"], \"binding\": 0, \"members\": [ { \"name\": \"tilingOffset\", \"type\": 16, \"count\": 1 } ] }, { \"name\": \"Constant\", \"defines\": [], \"binding\": 1, \"members\": [ { \"name\": \"mainColor\", \"type\": 16, \"count\": 1 }, { \"name\": \"colorScaleAndCutoff\", \"type\": 16, \"count\": 1 } ] } ], \"samplers\": [ { \"name\": \"mainTexture\", \"type\": 28, \"count\": 1, \"defines\": [\"USE_TEXTURE\"], \"binding\": 30 } ] } ] } There is a lot to unpack here, but for the most part the details won't be of any concern to game deverlopers, and the key insight you need to remember is: All the necessary info for runtime shading procedure setup on any target platform (and even editor support) is here in advance to guarantee portability and performance. Redundant info will be trimmed at build-time to ensure minimum space consumption. Material Material defines how a surface should be rendered, by including references to textures it uses, tiling information, color tints and more. The available options for a Material depend on which EffectAsset it is using. Essential parameters for setting up a Material object are: effectAsset or effectName: Effect reference, specifying which EffectAsset will be used (must specify). technique: Inside the EffectAsset, specifying which technique will be used, default to 0. defines: The list of macros, specify what value the shader macros have (for shader variants), default all to 0 (disabled), or in-shader specified default value. states: If any, specifying which pipeline state to override (defaul to nothing, keep everything the same as how they are specified in effect) const mat = new Material(); mat.initialize({ effectName: 'pipeline/skybox', defines: { USE_RGBE_CUBEMAP: true } }); With this information, the Material can be properly initialized, indicated by the generation of an array of Pass objects for rendering, which can be used for rendering specific models. Knowing which EffectAsset is currently using, we can specify all the shader properties: mat.setProperty('cubeMap', someCubeMap); console.log(mat.getProperty('cubeMap') === someCubeMap); // true These properties are assigned inside the material, which is just an asset by itself, and hasn't connected to any model. To apply the material on a specific model, it needs to be attached to a RenderableComponent. Any component that accepts a material parameter (MeshRenderer, SkinnedMeshRenderer, etc.) is inherited from it. const comp = someNode.getComponent(MeshRenderer); comp.material = mat; comp.setMaterial(mat, 0); // same as last line According to the number of sub-models, RenderableComponent may reference multiple Material: comp.setMaterial(someOtherMaterial, 1); // assign to second sub-model The same Material can be attached to multiple RenderableComponent too: const comp2 = someNode2.getComponent(MeshRenderer); comp2.material = mat; // the same material above When one of the material-sharing models needs to customize some property, you need to get a copied instance of the material asset, aka. MaterialInstance, from the RenderableComponent, by calling: const mat2 = comp2.material; // copy constructor, now 'mat2' is an 'MaterialInstance', and every change made to `mat2` only affect the 'comp2' instance The biggest difference between Material asset and MaterialInstance is: MaterialInstance is definitively attached to one RenderableComponent at the beginning of its life cyle, while Material has no such limit. For an already initialized material, if you need to re-initialize it, just re-invoke the initialize function, to rebuild everything. mat.initialize({ effectName: 'builtin-standard', technique: 1 }); Specifically, if it is only the shader macros or pipeline states that you want to modify, there are more efficient ways: mat2.recompileShaders({ USE_EMISSIVE: true }); mat2.overridePipelineStates({ rasterizerState: { cullMode: GFXCullMode.NONE } }); But remember these can only be called on MaterialInstances, not Material asset itself. Updating shader properties every frame is a common practice, under situations like this, where performance matters, use lower level APIs: // Save these when starting const pass = mat2.passes[0]; const hColor = pass.getHandle('albedo'); const color = new Color('#dadada'); // inside update function color.a = Math.sin(director.getTotalFrames() * 0.01) * 127 + 127; pass.setUniform(hColor, color); Builtins Although the material system itself doesn't make any assumptions on the content, there are some built-in effects written on top of the system, provided for common usage: unlit, physically-based (standard), skybox, particle, sprite, etc. For a quick reference, here is how each shading term in builtin-standard will be assembled from input data: Here are the complete list of properties and macros for it: Property Info tilingOffset tiling and offset of the model UV, xy channel for tiling, zw channel for offset albedo/mainColor albedo color, the main base color of the model albedoMap/mainTexture albedo texture, if present, will be multiplied by the albedo property albedoScale albedo scaling factorweighting the whole albedo factor before the final output alphaThreshold test threshold for discarding pixels, any pixel with target channel value lower than this threshold will be discarded normalMap normal map texture, enhancing surface details normalStrenth strenth of the normal map, the bigger the bumpier pbrMapR (AO)G (Roughness)B (Metallic) PBR parameter all-in-one texture: occlusion, roughness and metallicsample result will be multiplied by the matching constants metallicRoughnessMapG (Roughness)B (Metallic) metallic and roughness texturesample result will be multiplied by the matching constants occlusionMap independent occlusion texturesample result will be multiplied by the matching constants occlusion occlusion constant roughness roughness constant metallic metallic constant emissive emissive color emissiveMap emissive color texture, if present, will be multiplied by the emissive property,so remember to set emissive property more close to white(default black) for this to take effect emissiveScale emissive scaling factorweighting the whole emissive factor before the final output Accordingly, these are the available macros: Macro Info USE_BATCHING Whether to enable dynamic VB-merging-style batching USE_INSTANCING Whether to enable dynamic instancing HAS_SECOND_UV Whether there is a second set of UV ALBEDO_UV Specifies the uv set to use when sampling albedo texture, default to the first set EMISSIVE_UV Specifies the uv set to use when sampling emissive texture, default to the first set ALPHA_TEST_CHANNEL Specifies the source channel for alpha test, default to A channel USE_VERTEX_COLOR If enabled, vertex color will be multiplied to albedo factor USE_ALPHA_TEST Whether to enable alpha test USE_ALBEDO_MAP Whether to enable albedo texture USE_NORMAL_MAP Whether to enable normal map USE_PBR_MAP Whether to enable PBR parameter 3-in-1 textureAs per the glTF spec, the RGB channels must correspond to occlusion, roughness and metallicity respectively USE_METALLIC_ROUGHNESS_MAP Whether to enable metallic-roughness textureAs per the glTF spec, the GB channels must correspond to roughness and metallicity respectively USE_OCCLUSION_MAP Whether to enable occlusion textureOnly the red channel will be used, as per glTF spec USE_EMISSIVE_MAP Whether to enable emissive texture "},"material-system/yaml-101.html":{"url":"material-system/yaml-101.html","title":"YAML 101","keywords":"","body":"YAML 101 Cocos Creator 3.0 uses a parser that conforms to the YAML 1.2 standard, which means that Creator is fully compatible with JSON, and use JSON directly without any problems. \"techniques\": [{ \"passes\": [{ \"vert\": \"skybox-vs\", \"frag\": \"skybox-fs\", \"rasterizerState\": { \"cullMode\": \"none\" } # ... hash sign for comments }] }] But of course it would be cumbersome and error-prone, so what YAML provides is a much simpler representation of the same data: All quotation marks and commas can be omitted key1: 1 key2: unquoted string Note: never omit the space after colon Like Python, indentation is part of the syntax, representing hierarchy of the data1 object1: key1: false object2: key2: 3.14 key3: 0xdeadbeef nestedObject: key4: 'quoted string' Array elements are represented by dash+space prefix - 42 - \"double-quoted string\" - arrayElement3: key1: punctuations? sure. key2: you can even have {}s as long as they are not the first character key3: { nested1: 'but no unquoted string allowed inside brackets', nested2: 'also notice the comma is back too' } With these in mind, the effect manifest at the beginning of this document can be re-write as follows: techniques: - passes: - vert: skybox-vs frag: skybox-fs rasterizerState: cullMode: none # ... Another YAML feature that comes in handy is referencing and inheriting between data. Reference object1: &o1 key1: value1 object2: key2: value2 key3: *o1 This is its corresponding JSON: { \"object1\": { \"key1\": \"value1\" }, \"object2\": { \"key2\": \"value2\", \"key3\": { \"key1\": \"value1\" } } } Inheritance object1: &o1 key1: value1 key2: value2 object2: The corresponding JSON: { \"object1\": { \"key1\": \"value1\", \"key2\": \"value2\" }, \"object2\": { \"key1\": \"value1\", \"key2\": \"value2\", \"key3\": \"value3\" } } For our purposes, like when multiple pass has the same properties, etc. it could be really helpful: techniques: - passes: - # pass 1 specifications... properties: &props # declare once... p1: { value: [ 1, 1, 1, 1 ] } p2: { sampler: { mipFilter: linear } } p3: { inspector: { type: color } } - # pass 2 specifications... properties: *props # reference anywhere Finally, before writing any YAML, wrap it in a CCEffect block first: CCEffect %{ # YAML starts here }% You can always refer to any online YAML JSON converter to play around ideas. Reference Link YAML on Wikipedia YAML.org Spec [1] The YAML standard doesn't support tabs, so the effect compiler will try to replace all the tabs in file with 2 spaces first, to avoid the trivial yet annoying trouble of accidentally inserting tabs somewhere. But overall, please try to avoid doing that completely to make sure the compilation goes smoothly. ↩ "},"material-system/effect-syntax.html":{"url":"material-system/effect-syntax.html","title":"Effect Syntax","keywords":"","body":"Effect Syntax Guide Cocos Effect is a single-source embedded domain-specific language, based on YAML and GLSL. The YAML part declares the general framework, while GLSL part specifies the actual shader. Together they form a complete specification for the rendering process. If you want to implement a custom shading effect in the engine, you need to write your own custom Effect. We recommend editing effect files using Visual Studio Code with the official Cocos Effect plugin from the marketplace. Note: this document is targeted at Technical Artists or Graphics developers. If you are a design artist who needs specific shader customizations, please contact your Technical Artist or Programmer for support. Framework Syntax Using builtin-unlit.effect as an example, it looks something like this: Effect Name Effect name is automatically generated based on the filename and path of the effect, the path is a relative path based on the assets/effects directory, the filename does not include an extension. Effect names can be directly used at runtime to acquire/use the EffectAsset: const effect = cc.EffectAsset.get('builtin-unlit'); // this is the EffectAsset resource instance const mat = new cc.Material(); mat.initialize({ effectName: 'builtin-standard' }); // now `mat` is a valid standard material Note: the builtin effects of the editor are located directly inside the assets/effects folder in the internal database, so the effect names don't contain a path. Select the material in the Assets panel, and then you can see all currently available effect names in the Effect property drop-down list in the Inspector panel. About YAML YAML is a human-readable data-serialization language, with a flexible, minimal syntax and easily configurable, which makes it an ideal choice. However, the syntax maybe somewhat unique, at first for those who are unfamiliar with the language. For an introduction to the most commonly used syntaxes and language features, please refer to the YAML 101 documentation. Configurable Pass Parameters The shader entries are the only required fields, namely vert and frag, in the format of shaderChunkName:entryFunctionName. Normally the main function shouldn't be specified in shader, for version-specific wrappers will be inserted at compile-time. assigning the return value of the specified function to the ouput of current shader stage. (gl_Position or the final output color). You can find all of the optional parameters in the pass parameter list documentation. Shader Chunks Syntactically shader chunks are a superset of GLSL, all the extended features will be processed immediately at resource compile-time. It can either be written inside the CCProgram block in .effect file, or directly in a seperate .chunk file. We recommend limiting the syntax within GLSL version 300 ES range to maintain best portability, although you can always write your own porting using GLSL built-in macro __VERSION__. This section will introduce the 'domain-specific' extended features, all of which will be processed immediately at resource compile-time. Also feel free to look around the built-in effects, which are always excellent concrete examples. On top of GLSL, the following c-style extensions are naturally introduced: Chunk Include Just like the include directive in C/C++, you can include other shader chunks: #include #include \"../headers/my-shading-algorithm.chunk\" Relevant details: The .chunk extension can be omitted; quotation marks and angle brackets means the same. Every included header is guaranteed to be expanded only once; so every module could (and in fact should) include all its dependencies, even if there are overlaps. Dead code elimination is done at compile-time too, so including lots of unused utility functions shouldn't be of concern. There are two ways to reference a external chunk file: using the relative path to current file ('relative path'), or the relative path to assets/chunks folder of current project ('project absolute path'). If the specified file interpreted under both rules are present, the latter is preferred. When including files from other databases (like the internal database), only project absolute path is supported. When there are multiple databases have the same specified file, the priority is: User Project DB > Plugin DB > Internal DB. The built-in chunks are located directly inside assets/chunks in the internal database. Include these without path prefix. All CCProgram blocks in the same effect file can include each other. Pre-processing Macros Currently the effect system tends to take advantage of the language built-in pre-processing macros to create shader variants. The effect compiler will collect the macros that appear in shaders, and declarations will be inserted accordingly at runtime. For the most part, use them without thinking about the effect compiler, while material inspector will automatically integrate both macros and shader properties into a natual editting interface. Relevant details: To type check as many branches as possible at effect compile-time, the strategy currently taken is to set all macros to 1 (or its given default value) before doing the actual check; so make sure this combination works (or if not, maybe you need numerical macros, specified in the next section). All the macros that are not enabled at runtime will be explicitly given a value of 0, so please avoid using #ifdef or #if defined (except the GLSL built-in macros, like extension indicators with GL_ prefix), for they would alway be true. Hash values will be calculated for each macro combination at runtime. For a single shader, the process is the most efficient when there are less than 2^32 combinations (a standard integer range), that means 32 boolean macros switches (or less if there are numerical macros). Try to keep in this range to maintain optimal performance. Macro Tags Although the effect compiler will try to be smart and collect all pre-processing branches, sometimes there are more complicated cases: // macro defined within certain numerical 'range' #if LAYERS == 4 // ... #elif LAYERS == 5 // ... #endif // multiple discrete 'options' float metallic = texture(pbrMap, uv).METALLIC_SOURCE; For these special usages, you'll have to explicitly declare the macro, using macro tags: Tag Description Default Value Usage range A two-element array, specifying minimum and maximum value, both inclusive [0, 3] For macros with bounded range. The bound should be as tight as possible options An arbitrary-length array, specifying every possible options nothing For macros with discrete, explicit choices Declarations for the above case are: #pragma define LAYERS range([4, 5]) #pragma define METALLIC_SOURCE options([r, g, b, a]) The first line declares a macro named LAYERS, with possible range of [4, 5]. The second line declares a macro named METALLIC_SOURCE, with four possible options: 'r', 'g', 'b', 'a'. Note: every tag accepts a single parameter, in the syntax of YAML. Functional Macros Due to lack of native support in WebGL platform, functional macros are provided as an effect compile-time feature, all references will be expanded in the output shader. This is an good match for inlining some simple utility functions, or similar code repeating several times. In fact, many built-in utility functions are functional macros: #define CCDecode(position) \\ position = vec4(a_position, 1.0) #define CCVertInput(position) \\ CCDecode(position); \\ #if CC_USE_SKINNING \\ CCSkin(position); \\ #endif \\ #pragma // empty pragma trick to get rid of trailing semicolons at effect compile time Meanwhile, same as the macro system in C/C++, the mechanism does nothing on checking the Hygienic Macro WikiPedia Entry. Any issues will have to be dealt with by developers manually: // please do be careful with unhygienic macros like this #define INCI(i) do { int a=0; ++i; } while(0) // when invoking int a = 4, b = 8; INCI(b); // correct, b would be 9 after this INCI(a); // wrong! a would still be 4 Vertex Input1 To encapsulate in-shader data pre-processing like data decompression and vertex skinning, utility function CCVertInput is provided. For all shaders used to draw mesh assets, you need something like this: #include vec4 vert () { vec3 position; CCVertInput(position); // ... do your thing with `position` (models space, after skinning) } If normals are required, use the standard version: #include vec4 vert () { StandardVertInput In; CCVertInput(In); // ... now use `In.position`, etc. } This will acquire position, normal and tangent data, all after vertex skinning. Other vertex data (uv, color, etc.) can be declared directly. To support dynamic instancing & batching, use CCGetWorldMatrix: #include vec4 vert () { // ... // unlit version (when normal is not needed) mat4 matWorld; CCGetWorldMatrix(matWorld); // standard version mat4 matWorld, matWorldIT; CCGetWorldMatrixFull(matWorld, matWorldIT); // ... } You can find the complete built-in shader uniform list in this documentation. Fragment Ouput1 To encapsulate render pipeline complexities, use CCFragOutput. For unlit shaders: #include vec4 frag () { vec4 o = vec4(0.0); // ... do the computation return CCFragOutput(o); } The code can work in both the HDR and LDR pipelines. If lighting is involved, combine with CCStandardShading to form a surface shader structure: #include #include // note the header file change void surf (out StandardSurface s) { // fill in your data here } vec4 frag () { StandardSurface s; surf(s); vec4 color = CCStandardShading(s); return CCFragOutput(color); } Under the framework writing your own surface shader or even shading algorithm becomes staightforward. Note: the CCFragOutput function should not be overriden, unless using custom render pipelines. Custom Instancing Attribute Dynamic instancing is a very flexible batching framework, whcih allows user-defined instanced properties on top of the built-in ones. If you want to define them in shader, all the related processing code need to be wrapped inside the agreed upon macro USE_INSTANCING: #if USE_INSTANCING // when instancing is enabled #pragma format(RGBA8) // normalized unsigned byte in vec4 a_instanced_color; #endif Notes: The actual data format can be specified using compiler hint format tag, which accepts a single parameter in the form of GFXFormat enum name2. 32-bytes float type will be assumed if the tag is omitted. All instanced properties are input attributes of the vertex shader, so if some property is needed in fragment shader, you need to pass it as varyings; Make sure the code works for all branches, regardless of the actual state of USE_INSTANCING. The instanced property value will be initialized to all zeros by default. Use the setInstancedAttribute on MeshRenderer to assign new values: const comp = node.getComponent(MeshRenderer); comp.setInstancedAttribute('a_instanced_color', [100, 150, 200, 255]); // should match the specified format Note: the instanced properties will be reset to all zeros whenever creating a new PSO (the most common case is when assigning a new material). WebGL 1 fallback Support The effect compiler provides fallback conversion from GLSL 300 ES to GLSL 100 automatically, for WebGL 1.0 only support GLSL 100 syntax. this should be transparent to developers for the most time. Currently the automatic conversion only supports some basic usage, and if some post-100 features or extensions were used, (texelFetch, textureGrad, etc.) Developers have to do your own porting using the language built-in \\_\\_VERSION__ macro: vec4 fragTextureLod (samplerCube tex, vec3 coord, float lod) { #if __VERSION__ The effect compiler will finally split these compile-time constant branches into different output versions. About UBO Memory Layout First the conclusion, the final rules are, every non-sampler uniform should be specified in UBO blocks, and for every UBO block: There should be no vec3 typed members. For array typed members, size of each element should be no less than a vec4. Any member ordering that introduces a padding will be rejected. These rules will be checked rigorously at effect compile-time and throws detailed, implicit padding related compile error. This might sound overly-strict at first, but it's for a few good reasons: First, UBO is a much better basic unit to efficiently reuse data, so discrete declaration is no longer an option. Second, currently many platforms, including WebGL 2.0 only support one platform-independent memory layout, namely std140, and it has many restrictions3: All vec3 members will be aligned to vec4 uniform ControversialType { vec3 v3_1; // offset 0, length 16 [IMPLICIT PADDING!] }; // total of 16 bytes Any array member with element size less than a vec4 is aligned to vec4 element-wise uniform ProblematicArrays { float f4_1[4]; // offset 0, stride 16, length 64 [IMPLICIT PADDING!] }; // total of 64 bytes All UBO members are aligned to the size of itself4: uniform IncorrectUBOOrder { float f1_1; // offset 0, length 4 (aligned to 4 bytes) vec2 v2; // offset 8, length 8 (aligned to 8 bytes) [IMPLICIT PADDING!] float f1_2; // offset 16, length 4 (aligned to 4 bytes) }; // total of 32 bytes uniform CorrectUBOOrder { float f1_1; // offset 0, length 4 (aligned to 4 bytes) float f1_2; // offset 4, length 4 (aligned to 4 bytes) vec2 v2; // offset 8, length 8 (aligned to 8 bytes) }; // total of 16 bytes This means lots of wasted space, and some driver implementation might not completely conform to the standard5, hence all the strict checking procedure help to clear some pretty insidious bugs. Note: the actual uniform type can differ from the public interfaces the effect exposes to artists and runtime properties. Through the property target system, every single channel can be manipulated independently, without restriction of the original uniform. [1] Shaders for systems with procedurally generated mesh, like particles, sprites, post-effects, etc. may handle things a bit differently ↩ [2] Integer-typed attribute is not supported on WebGL 1.0 platform, so use the default float type if targeting this platform ↩ [3] OpenGL 4.5, Section 7.6.2.2, page 137 ↩ [4] In the example code, UBO IncorrectUBOOrder has a total size 32. Actually this is still a platform-dependent data, due to what it seems like an oversight in the GLSL specification. More discussions can be found here ↩ [5] Interface Block - OpenGL Wiki#Memory_layout) ↩ "},"material-system/pass-parameter-list.html":{"url":"material-system/pass-parameter-list.html","title":"Pass Params","keywords":"","body":"Optional Pass Parameters The parameters in Pass are mainly divided into two parts: the developer-defined effect parameter and the PipelineStates parameter provided by the engine, this document mainly introduces the parameters related to PipelineStates, all the parameters are case-insensitive. Parameter name Description Default value Remark switch Specifies a power switch for the current pass. Could be any valid macro name that's not defined in the shader, the macro name shouldn't collide with any existing macros inside the shader *undefined This property doesn't exist by default, which means the pass is executed unconditionally priority Specifies the rendering priority of the current pass, the bigger the number, the lower the priority 128 Could be any number between max(255) and min(0) stage Specifies which render stage the current pass belongs to. Could be the name of any registered stage in your runtime pipeline default For the built-in forward pipeline, the only available stage is default phase Specifies which phase the current pass belongs to. Could be the name of any registered phase in your runtime pipeline default For the built-in forward pipeline, the available phases are default, forward-add and shadow-caster propertyIndex Specifies the index of the pass to copy runtime property data from. When two passes need to share the same set of properties, propertyIndex can be specified to avoid the need for developers to specify that same set of data multiple times (especially in the material inspector). This could be useful in some cases, e.g. the forward add pass vs. the base pass *undefined Could be any valid pass index. Once specified, all the properties for the current pass will not be visible in the material inspector embeddedMacros Specifies additional macro definitions on top of the current shader, could be an object containing any macro key-value pair *undefined This parameter can be used to multiplex shader resources in multiple passes only if the macros are defined differently. properties Specifies the public interfaces exposed to material instector and runtime API See the Properties section below for details migrations Migrate old material data See the Migrations section below for details primitive Create material vertex data triangle_list Options include: point_list, line_list, line_strip, line_loop,triangle_list, triangle_strip, triangle_fan,line_list_adjacency, line_strip_adjacency,triangle_list_adjacency, triangle_strip_adjacency,triangle_patch_adjacency, quad_patch_list, iso_line_list dynamics 补充说明 [] An array containing any of the following:viewport, scissor, line_width, depth_bias, blend_constants,depth_bounds, stencil_write_mask, stencil_compare_mask RasterizerState 补充说明 See the RasterizerState section below for details DepthStencilState 补充说明 See the DepthStencilState section below for details BlendState Mixed state of the material false See the BlendState section below for details Properties Specifies the public interfaces exposed to material instector and runtime API. It can be a direct mapping to shader uniforms, or specific channels of the uniform: albedo: { value: [1, 1, 1, 1] } # uniform vec4 albedo roughness: { value: 0.8, target: pbrParams.g } # uniform vec4 pbrParams offset: { value: [0, 0], target: tilingOffset.zw } # uniform vec4 tilingOffset # say there is another uniform, vec4 emissive, that doesn't appear here # so it will be assigned a default value of [0, 0, 0, 0] and will not appear in the inspector Runtime reference is straightforward: // as long as it is a real uniform // it doesn't matter whether it is specified in the property list or not mat.setProperty('emissive', cc.Color.GREY); // this works mat.setProperty('albedo', cc.Color.RED); // directly set uniform mat.setProperty('roughness', 0.2); // set certain component const h = mat.passes[0].getHandle('offset'); // or just take the handle, mat.passes[0].setUniform(h, new Vec2(0.5, 0.5)); // and use Pass.setUniform interface instead Shader uniforms that are not in the properties list will be given a default value. For quick setup and experiment, the __metadata__ feature is provided, which will be the 'base class' for all other properties: properties: __metadata__: { editor: { visible: false } } a: { value: [1, 1, 0, 0] } b: { editor: { type: color } } c: { editor: { visible: true } } Here a and b will no longer appear in the inspector, while c stays visible. Property Parameter List The configurable parameters in Property are shown in the table below, and any configurable field can be omitted if it is the same as the default value. Parameter name Default value Options Remark target undefined undefined Any valid uniform components, no random swizzle value See the Default Values section below for details sampler.minFilter linear none, point, linear, anisotropic sampler.magFilter linear none, point, linear, anisotropic sampler.mipFilter none none, point, linear, anisotropic sampler.addressU wrap wrap, mirror, clamp, border sampler.addressV wrap wrap, mirror, clamp, border sampler.addressW wrap wrap, mirror, clamp, border sampler.maxAnisotropy 16 16 sampler.cmpFunc never never, less, equal, less_equal, greater, not_equal, greater_equal, always sampler.borderColor [0, 0, 0, 0] [0, 0, 0, 0] sampler.minLOD 0 0 sampler.maxLOD 0 0 Remember to override this when enabling mip filter sampler.mipLODBias 0 editor.displayName *property name *property name Any string editor.type vector vector, color editor.visible true true, false editor.tooltip *property name *property name Any string editor.range undefined undefined, [ min, max, [step] ] editor.deprecated false true, false For any material using this effect, delete the existing data for this property after next saving Migrations Ideally the public interface of an effect should always be backward-compatible, but occasionally introducing breaking changes might become the only option as the project iterate. A smooth data transition would be much desired during the process, which leads to the migration system. After an effect with migrations is successfully compiled, all the dependent material assets will be immediately updated, new property will be automatically migrated/generated from existing data using specified rules. Note: please remember to backup your project before doing any migration attemps! For a existing effect, declares the following migration rules: migrations: # macros: # macros follows the same rule as properties, without the component-wise features # USE_MIAN_TEXTURE: { formerlySerializedAs: USE_MAIN_TEXTURE } properties: newFloat: { formerlySerializedAs: oldVec4.w } Say we have a dependent material, with the following data: { \"oldVec4\": { \"__type__\": \"cc.Vec4\", \"x\": 1, \"y\": 1, \"z\": 1, \"w\": 0.5 } } After the effect is compiled, the material will be automatically updated to: { \"oldVec4\": { \"__type__\": \"cc.Vec4\", \"x\": 1, \"y\": 1, \"z\": 1, \"w\": 0.5 }, \"newFloat\": 0.5 } And after the next save operation on this material: (say the content is actually not changed) { \"newFloat\": 0.5 } We are just using the w channel here, while in fact arbitrary shuffle is supported too: newColor: { formerlySerializedAs: someOldColor.yxx } Or even based on a target macro: occlusion: { formerlySerializedAs: pbrParams. } This means the new occlusion data will be extracted from pbrParams data, the specific channel depend on the OCCLUSION_CHANNEL macro of current pass, and default to channel z if macro data not present. If newFloat property already exists before migration, nothing will happen, unless in force mode: newFloat: { formerlySerializedAs: oldVec4.w! } Then the migration is guaranteed to execute, regardless of the existing data. Note: migration in force mode will execute in every database event, which is basically every mouse click in editor. So use it as a quick-and-dirty test measure, and be sure not to submit effect files with force mode migrations into version control. Again here are the bottomline rules about preventing potential data losses: Property removal will happen if, and only if, you specify the removeImmediately entry explicitly. Property override will happen if, and only if, you end the formerlySerializedAs entry with ! (force mode) RasterizerState Parameter name Description Default value Options cullMode 补充说明 back front, back, none DepthStencilState Parameter name Description Default value Options depthTest 补充说明 true true, false depthWrite 补充说明 true true, false depthFunc 补充说明 less never, less, equal, less_equal, greater, not_equal, greater_equal, always stencilTest 补充说明 false true, false stencilFunc 补充说明 always never, less, equal, less_equal, greater, not_equal, greater_equal, always stencilReadMask 补充说明 0xffffffff 0xffffffff, [1, 1, 1, 1] stencilWriteMask 补充说明 0xffffffff 0xffffffff, [1, 1, 1, 1] stencilFailOp 补充说明 keep keep, zero, replace, incr, incr_wrap, decr, decr_wrap, invert stencilZFailOp 补充说明 keep keep, zero, replace, incr, incr_wrap, decr, decr_wrap, invert stencilPassOp 补充说明 keep keep, zero, replace, incr, incr_wrap, decr, decr_wrap, invert stencilRef 补充说明 1 1, [0, 0, 0, 1] stencil*Front/Back 补充说明 *set above stencil properties for specific side BlendState Parameter name Description Default value Options BlendColor 补充说明 0 0, [0, 0, 0, 0] Targets 补充说明 false false true, false targets[i].blend 补充说明 false true, false targets[i].blendEq 补充说明 add add, sub, rev_sub targets[i].blendSrc 补充说明 one one, zero, src_alpha_saturate,src_alpha, one_minus_src_alpha,dst_alpha, one_minus_dst_alpha,src_color, one_minus_src_color,dst_color, one_minus_dst_color,constant_color, one_minus_constant_color,constant_alpha, one_minus_constant_alpha targets[i].blendDst 补充说明 zero one, zero, src_alpha_saturate,src_alpha, one_minus_src_alpha,dst_alpha, one_minus_dst_alpha,src_color, one_minus_src_color,dst_color, one_minus_dst_color,constant_color, one_minus_constant_color,constant_alpha, one_minus_constant_alpha targets[i].blendSrcAlpha 补充说明 one one, zero, src_alpha_saturate,src_alpha, one_minus_src_alpha,dst_alpha, one_minus_dst_alpha,src_color, one_minus_src_color,dst_color, one_minus_dst_color,constant_color, one_minus_constant_color,constant_alpha, one_minus_constant_alpha targets[i].blendDstAlpha 补充说明 zero one, zero, src_alpha_saturate,src_alpha, one_minus_src_alpha,dst_alpha, one_minus_dst_alpha,src_color, one_minus_src_color,dst_color, one_minus_dst_color,constant_color, one_minus_constant_color,constant_alpha, one_minus_constant_alpha targets[i].blendAlphaEq 补充说明 add add, sub, rev_sub targets[i].blendColorMask 补充说明 all all, none, r, g, b, a, rg, rb, ra, gb, ga, ba, rgb, rga, rba, gba Default Values Type Default Value Options int 0 ivec2 [0, 0] ivec3 [0, 0, 0] ivec4 [0, 0, 0, 0] float 0 vec2 [0, 0] vec3 [0, 0, 0] vec4 [0, 0, 0, 0] sampler2D default black, grey, white, normal, default samplerCube default-cube black-cube, white-cube, default-cube For defines: The default value for the boolean type is false. The default value for the number type is 0, and the value range is [0, 3]. The default value for the string type is the first element of the options array. "},"material-system/builtin-shader-uniforms.html":{"url":"material-system/builtin-shader-uniforms.html","title":"Builtin Shader Uniforms","keywords":"","body":"Built-in Shader Uniforms To use built-in shader variables, you need to include the corresponding chunks first. All currently available built-in uniforms, grouped by the chunks they are located: cc-local.chunk Name Type Info cc_matWorld mat4 model to world transform matrix cc_matWorldIT mat4 inverse-transpose of model to world transform matrix cc-global.chunk Name Type Info cc_time vec4 x: seconds since engine started cc_screenSize vec4 xy: shading screen sizezw: reciprocal of shading screen size cc_screenScale vec4 xy: screen scalezw: reciprocal of screen scale cc_nativeSize vec4 xy: canvas sizezw: reciprocal of canvas size cc_matView mat4 view transform matrix cc_matViewInv mat4 inverse view matrix cc_matProj mat4 projection transform matrix cc_matProjInv mat4 inverse projection transform matrix cc_matViewProj mat4 view-projection transform matrix cc_matViewProjInv mat4 inverse view-projection transform matrix cc_cameraPos vec4 xyz: camera position cc_exposure vec4 x: camera exposurey: reciprocal of camera exposurez: is HDR enabled w: HDR-LDR scaling factor cc_mainLitDir vec4 xyz: direction of the main directional light cc_mainLitColor vec4 xyz: color of the main directional lightw: intensity cc_ambientSky vec4 xyz: ambient sky colorw: intensity cc_ambientGround vec4 xyz: ambient ground color cc-environment.chunk Name Type Info cc_environment samplerCube IBL environment map cc-forward-light.chunk Name Type Info cc_sphereLitPos[MAX_LIGHTS] vec4 xyz: position of spherical lights cc_sphereLitSizeRange[MAX_LIGHTS] vec4 x: size of spherical lightsy: range of spherical lights cc_sphereLitColor[MAX_LIGHTS] vec4 xyz: color of spherical lightsw: intensity cc_spotLitPos[MAX_LIGHTS] vec4 xyz: position of spotlights cc_spotLitSizeRangeAngle[MAX_LIGHTS] vec4 x: size of spotlightsy: range of spotlightsz: angle of spotlights cc_spotLitDir[MAX_LIGHTS] vec4 xyz: direction of spotlights cc_spotLitColor[MAX_LIGHTS] vec4 xyz: color of spotlightsw: intensity cc-shadow.chunk Name Type Info cc_matLightPlaneProj mat4 planar shadow transform matrix cc_shadowColor vec4 shadow color "},"audio-system/overview.html":{"url":"audio-system/overview.html","title":"Audio System","keywords":"","body":"Overview of sound systems There are two types of sounds available in the audio system: sound effects and music. Sound effects are short bursts of quick sounds that signal the player of the game making progress. A few examples of sound effects are gun noises, bullets firing, a character jumping, physics contact events and many others. Music is longer in length and usually played in a loop. A few examples of music are background music, cut scenes, successfully completing a milestone in the game and many others. All audio assets are imported into the editor in the format of audioClip assets. Music Playing Create an empty node on the Node Tree Select the empty node and click Add Component -> Components -> AudioSource at the bottom of the Properties to add the AudioSource component. Drag the audio resources in Assets to the Clip of the AudioSource component, as follows: Then set the other parameter of the AudioSource component as needed, for the details of parameter can refer Audiosource Component Reference. If you only need to play the audio automatically after the game is loaded, check the PlayOnAwake of the AudioSource component. If you want more flexibility in controlling AudioSource playback, you can get the AudioSource Component in the custom script and then call the appropriate API. As shown below: // AudioController.ts @ccclass(\"AudioController\") export class AudioController extends Component { @property(AudioSource) public audioSource: AudioSource = null!; play () { this.audioSource.play(); } pause () { this.audioSource.pause(); } } Then add the corresponding custom component to the editor's Properties. Selecting the corresponding node and add the custom component by clicking Add Component-> Custom script -> User Script at the bottom of the Properties. Then drag and drop the node with the AudioSource component onto Audio Source in the custom component. As shown below: Effect Playing Compared to long music playback, audio effects playback has the following characteristics: Short playback time A large number of simultaneous playback For such playback requirements, the AudioSource component provides the playOneShot interface to play audio effects. The specific code implementation is as follows: // AudioController.ts @ccclass(\"AudioController\") export class AudioController extends Component { @property(AudioClip) public clip: AudioClip = null!; @property(AudioSource) public audioSource: AudioSource = null!; playOneShot () { this.audioSource.playOneShot(this.clip, 1); } } Note: playOneShot is a one-time play operation, there is no way to pause or stop the audio after it is played, and no way to register the ended event callback. Web Platform Playback Restrictions Audio playback on the Web platform currently requires compliance with the latest Audio Play Police, and even if the AudioSource component is set to playOnAwake it will not start until the first user input is received. An example is as follows: // AudioController.ts @ccclass(\"AudioController\") export class AudioController extends Component { @property(AudioSource) public audioSource: AudioSource = null!; start () { let btnNode = find('BUTTON_NODE_NAME'); btnNode!.on(Node.EventType.TOUCH_START, this.playAudio, this); } playAudio () { this.audioSource.play(); } } Related Links Audio Asset AudioSource Component "},"particle-system/overview.html":{"url":"particle-system/overview.html","title":"Particle System","keywords":"","body":"Particle System Overview The particle system is the basis of the game engine's special effects. It can be used to simulate natural phenomena such as fire, smoke, water, clouds, snow, and fallen leaves. It can also be used to simulate abstract visual effects such as luminous tracks and speed lines. Basic Structure The basic unit of a particle system is a particle. A particle generally has attributes such as position, size, color, velocity, acceleration, and life cycle. In each frame, the particle system generally performs the following steps: Generate new particles and initialize. Delete particles beyond the life cycle. Update the dynamic properties of particles. Render all valid particles. The general particle system will consist of the following parts: Emitter, used to create particles and initialize particle properties. Influencer, used to update the properties of particles. Renderer, render particles. Particle class, which stores the properties of particles. The particle system class manages the above modules. Adding a particle system There are two ways to add a particle system: Select the node in the Hierarchy panel and click the Add Component button on the Inspector panel, as shown below: You can also right-click the Hierarchy panel and select Create -> Effects-> Particle System, as shown below: Particle Modules The Cocos Creator particle system uses modules to organize functions, including the following modules: Module Description ParticleSystem It is used to store all the data displayed in the Inspector, manage the related modules of particle generation, update and destruction, and control the particle playback. ShapeModule Used to control particle emission, including emission direction and speed, and supports predefined emission directions including squares, circles, cones, balls, and hemispheres. AnimatorModule Used to control the state update after particle emission. The supported functions are: size, color, rotation, speed, acceleration, speed limit, texture animation. ParticleSystemRenderer Used to generate the data needed for particle rendering. Including control related to vb, ib, rendering state. "},"particle-system/module.html":{"url":"particle-system/module.html","title":"Particle System Module","keywords":"","body":"Introduction to particle system. ParticleSystem stores the initial state of particle emission. After particle emission, it updates the submodule through the state. Particle System Module ParticleSystem ShapeModule ColorOvertimeModule SizeOvertimeModule RotationOvertimeModule VelocityOvertimeModule LimitVelocityOvertimeModule ForceOvertimeModule TextureAnimationModule Renderer TrailModule Resource Culling The modules of each particle system exist as independent objects, and each module stores some module-related data, so for the modules that are not checked for use, the recorded data is useless data. When developers do not need to dynamically open these unedited modules at runtime, they can check the EnableCulling option at the bottom of the Inspector panel of ParticleSystem to remove these useless data to reduce resource consumption. "},"particle-system/main-module.html":{"url":"particle-system/main-module.html","title":"Main Module","keywords":"","body":"Particle System Component Property Feature Description duration Total running time of particle system. capacity The maximum number of particles that a particle system can generate. loop Whether the particle system loops. playOnAwake Whether the particle system automatically starts playing after loading. prewarm After being selected, the particle system will start playing after one round has been played (only valid when loop playback is enabled). simulationSpace Control the coordinate system where the particle coordinates are calculated. startDelay Delay time of particle emission. startLifetime The life cycle of particle. startColor The initial color of particle. scaleSpace Coordinate system for particle. scalingLocal: Scaling based on local coordinate system. World: Scaling based on world coordinate system.Custom: Custom scaling, which is not affected by the scale of the node. startSize The initial size of particle. startSpeed The initial velocity of particle. startRotation The initial rotation angle of particle. gravityModifier Gravity coefficient. rateOverTime Number of particles emitted per second. rateOverDistance Number of particles emitted per moving unit distance. bursts Emit a given number of particles at a certain point in time, and can be adjusted by several properties:time: How long does the particle play after it starts to emit burst.count: Number of particles emitted.repeatCount: The number of burst triggers.repeatInterval: The time interval of each trigger. To use Particle System, please refer to the Particle System API. "},"particle-system/emitter.html":{"url":"particle-system/emitter.html","title":"Emitter","keywords":"","body":"ShapeModule Public properties Property Features position Relative to the location of the installed node. rotation Rotation relative to the mounted node. scale Relative to the scale of the mounted node. sphericalDirectionAmount Represents the interpolation between the current emission direction and the connection direction from the current position to the center of the node. randomPositionAmount Indicates the offset from the current launch position. Box Property Features shapeType Box emitFrom From which part of the block the particles are emitted.edge: bordershell: surfacevolume: inside Shpere\\Hemisphere Property Features shapeType Shpere\\Hemisphere radius Sphere radius radiusThickness 0 means launch from the surface of the ball 1 means launch from the inside of the sphere0 ~ 1 means launch from the surface to the center of the sphere Circle Property Features shapeType Circle radius Radius of circle radiusThickness 0 means launching from the circle1 means launching from inside the circle0 ~ 1 means launching from the circle to the center of the circle. arc Represents emission in a sector of the circle. mode Represents the emission method of particles in the fan-shaped area, random: random position.loop: cyclic emission in a certain direction, the same direction every timepingPong: cyclic emission, every time On the contraryspread: indicates that the particles are emitted at a certain interval, for example, 0 indicates that they can be emitted at any position, and 0.1 indicates that they are emitted every tenth of the circumference. speed Represents the speed of particles emitted along the circumference. spread It indicates where the particles are emitted in the arc when they are emitted along the circumference. For example, if arc is 120° and spread is 0.1, particles will be emitted every 12° from the arc. Cone Property Features shapeType Cone angle Angle between cone axis and generatrix. radius Radius of the top of the cone. length The axial length of the top section of the cone from the bottom. radiusThickness 0 means launching from the circle1 means launching from inside the circle0 ~ 1 means launching from the circle to the center of the circle. arc Represents emission in a sector of the circle. mode Represents the emission method of particles in the fan-shaped area.random: random positionloop: cyclic emission in a certain direction and the same direction every timepingPong: cyclic emission, every time on the contraryspread: indicates that the particles are emitted at a certain interval, for example, 0 indicates that they can be emitted at any position, and 0.1 indicates that they are emitted every tenth of the circumference. speed Represents the speed of particles emitted along the circumference. spread It indicates where the particles are emitted in the arc when they are emitted along the circumference. For example, if arc is 120° and spread is 0.1, particles will be emitted every 12° from the arc. "},"particle-system/color-module.html":{"url":"particle-system/color-module.html","title":"Color Module","keywords":"","body":"Color Overtime Module Properties Features color For the parameters whose color changes with time, different color change modes can be used. "},"particle-system/size-module.html":{"url":"particle-system/size-module.html","title":"Size Module","keywords":"","body":"Size Overtime Module Property Role separateAxes Whether the three axes are scaled separately. size The curve of the size change with time can be used in different calculation modes. It is valid when separateAxes is false. X Y Z The curve whose size changes with time, different zooms can be set on the three coordinate axes, and different calculation modes can be used. It is effective when separateAxes is true. "},"particle-system/rotation-module.html":{"url":"particle-system/rotation-module.html","title":"Rotation Module","keywords":"","body":"Rotation Overtime Module Property Role separateAxes Whether the three axes rotate separately. X Y Z The curve of the rotation with time can be set to different rotations on the three coordinate axes, and different calculation modes can be used. X and Y are only valid when separateAxes is true. "},"particle-system/velocity-module.html":{"url":"particle-system/velocity-module.html","title":"Velocity Module","keywords":"","body":"Velocity Overtime Module Property Description space In which coordinate system the speed is calculated. x,y,z Different calculation modes can be used for the velocity components in the three directions. speedModifier Speed correction factor. "},"particle-system/limit-velocity-module.html":{"url":"particle-system/limit-velocity-module.html","title":"Limit Velocity Module","keywords":"","body":"Limit Velocity Overtime Module Property Features space In which coordinate system the speed is calculated. limit Lower speed limit. When the speed exceeds this value, the current speed is linearly interpolated with this speed. It is valid when separateAxes is false. dampen Interpolation of current speed and lower speed limit. separateAxes Whether the three axes are restricted separately. limit X,Y,Z The lower speed limits of the three axes are valid when separateAxes is true. "},"particle-system/force-module.html":{"url":"particle-system/force-module.html","title":"Force Module","keywords":"","body":"Force Overtime Module Property Features space In which coordinate system the acceleration is calculated. x,y,z The acceleration components in the three directions, can be calculated in different modes. "},"particle-system/texture-animation-module.html":{"url":"particle-system/texture-animation-module.html","title":"Texture Animation Module","keywords":"","body":"Texture Animation Module Property Role mode A grid texture contains an animation frame for particle playback. numTilesX The number of animation frames in the x direction. numTilesY The number of animation frames in the y direction. animation WholeSheet plays all the frames in the texture, singleRow only plays one row. frameOverTime The frame of animation playing in a cycle and the curve of time change. startFrame Play from the first few frames, the time is the life cycle of the entire particle system. cycleCount The number of playback cycles in a life cycle. "},"particle-system/renderer.html":{"url":"particle-system/renderer.html","title":"Renderer","keywords":"","body":"Particle Renderer The particle rendering part is controlled by ParticleSystemRenderer, which is divided into CPU renderer and GPU renderer. The CPU renderer maintains all particles through an object pool, generates corresponding vb and ib data according to the current state of the particles, holds the materials to be rendered by the particles, and saves the relevant rendering state. The GPU renderer generates particles on the CPU side, and only submits the vb and ib data of initial parameter, but the calculations related to the module are in the form of pre-sampled data. The data is submitted once during initialization, and the subsequent module system extracts and simulates the data on the GPU side to reduce the computing pressure on the CPU side. The subsequent versions will continue to optimize and improve the particle system. The current GPU version does not support TrailModule and LimitVelocityOvertimeModule. Property Description RenderMode Set a particle patch generation method. Billboard particles always face the cameraStretchedBillboard particles always face the camera, but will be stretched according to the relevant parametersHorizontalBillboard particles patches are always in the x-z plane parallelVerticalBillboard particles patch is always parallel to the Y axis, but will face the cameraMesh particles are a model. VelocityScale In stretchedBillboard mode, the particles are stretched according to the speed in the direction of motion. LengthScale In StretchedBillboard mode, the particles are stretched by the size of the particles in the direction of motion. Mesh When RenderMode is set to Mesh, specify the model of particles to be rendered. ParticleMaterial The material used for particle rendering.When use the CPU renderer, that is, when UseGPU option is not selected, the effect used by the material can only be builtin-particle, and other effects are not supported.When use the GPU renderer, that is, when UseGPU option is checked, the effect used by the material can only be builtin-particle-gpu, and other effects are not supported. TrailMaterial The material used for trail rendering. The effect of the material only supports builtin-particle-trail, not other effects. UseGPU Whether to use the GPU renderer for particle rendering, it is not selected by default.When this option is not checked, use the CPU renderer ParticleSystemRendererCPU to render particles.When this option is checked, use the GPU renderer ParticleSystemRendererGPU to render particles. "},"particle-system/trail-module.html":{"url":"particle-system/trail-module.html","title":"Trail Module","keywords":"","body":"Trail Module Property Role mode Particle forms a trailing effect on each particle's trajectory. LifeTime The life cycle of trail. MinParticleDistance The shortest distance traveled by the particle for each trailing node. Space The coordinate system where the tail is located, World runs in the world coordinate system, and Local runs in the local coordinate system. ExistWithParticles Whether the tail disappears with the particles. TextureMode The expanded form of the texture on the tail, the Stretch texture is overlaid on the entire tail, and the Repeat texture is overlaid on the tail. WidthFromParticle The trai width inherited from the particle size. WidthRatio Trail width, if it is inherited from particle, it is the ratio of particle size ColorFromParticle Whether the trail color is inherited from the particles. ColorOverTrail The color of the trail color changes gradually with the length of the trailing itself. ColorOvertime Color gradient of trail color over time. "},"engine/animation/":{"url":"engine/animation/","title":"Animation","keywords":"","body":"Animation overview Cocos Creator has a built-in general animation system to realize animation based on key frames. Animation Clips are assets that contain animation information. Animation Clips can be reused, and their state is saved in an object called an Animation State. Animation State can play, pause, stop, and change the animation. The Animation Component manages Animation Clips and their states in a unified manner, allowing users to implement animation functions at the component level. In the editor, one can easily produce animation clip assets. For example, through the Animation Editor, or using external assets already containing Animation Clip assets. The Animation Components documentation describes how to use Animation Components and Animation Clips to control the playback of animations. The Animation Clip documentation describes the composition of Animation Clips_ or creating _Animation Clips programmatically. The Animation State provides a low-level control of animation playback. The Skeletal Animation documentation describes how to use this common but special type of animation. "},"engine/animation/animation-component.html":{"url":"engine/animation/animation-component.html","title":"Animation Components","keywords":"","body":"Animation component Animation components control the playback of animations. Animation components are added to nodes in exactly the same way as other components: import { Animation, Node } from \"cc\"; function (node: Node) { const animationComponent = node.addComponent(Animation); } The animation component manages a set of animation clips. Before the animation component begins, it creates a corresponding animation state object for each animation clip. The animation state controls the playback process of an animation clip at a node, and an animation clip can be used by multiple animation states at the same time. In an animation component, the animation state is identified by name. The default name of each animation state is the name of its animation clip. Playing and switching animations play() causes the animation component to start playing the specified animation: animationComponent.play('idle'); // play animation state 'idle' When playing, the old animation will be stopped immediately, this switch is very abrupt. In some cases, we want this switch to fade in and out. The crossFade() method can be used to achieve this. crossFade() will complete the switch smoothly within the specified period: animationComponent.play('walk'); /* ... */ // When you need to switch to running animation animationComponent.crossFade('run', 0.3); // Smoothly switch from walking animation to running animation in 0.3 seconds The crossFade() fade-in and fade-out mechanism makes it possible for more than one animation state to play at the same time. Therefore, the animation component has no concept of the current animation. The animation component still provides pause(), resume() and stop() methods. These calls pause, continue, and stop all animation states that are playing, however, they also pause, resume, and stop switching animations. Animation State Sometimes it is necessary to perform other operations on the animation state, for example, to set its speed. You can get the animation state through getState(): const animationComponent = node.getComponent(Animation); animationComponent.clips = [ idleClip, runClip ]; // Get the status of `idleClip` const idleState = animationComponent.getState(idleClip.name); You can set the speed of the animation playback: animationComponent.getState('idle').speed = 2.0; // Play standby animation at double speed The animation state also provides play(), pause(), resume() and stop(). These control common playback functions. When these common playback controls cannot meet your requirements, it is also possible to manipulate the playback of the animation state in a custom way. Default animation When the animation component's playOnLoad is true, it will automatically play the default animation clip, defaultClip, the first time it runs. Frame events You can add events for each time point of the animation. The events of an AnimationClip contains all event descriptions for the animation, and each event description has the following properties: { frame: number; func: string; params: any[]; } frame represents the time point at which the event was triggered, in seconds. For example, 0.618 means that the event will be triggered when the animation reaches 0.618 seconds. func represents the method name that is called back when the event is triggered. When the event is triggered, a search for a method named func on all components of the current node, once found, it is called with params passed to it. Example: import { Animation, Component } from \"cc\"; class MyScript extends Component { constructor() { } public start() { const animationComponent = this.node.getComponent(Animation); if (animationComponent && animationComponent.defaultClip) { const { defaultClip } = animationComponent; defaultClip.events.push({ frame: 0.5, // trigger event on the 0.5 second func: 'onTriggered', // name of event to be called params: [0], // parameters passed to `func` }); defaultClip.updateEventDatas(); } } public onTriggered(arg: number) { console.log('I am triggered!'); } } The above code indicates that the default animation clip of the animation component at the node where the MyScript component is located. At the 0.5th second, it will call the test() method of the MyScript component and pass the parameter 0. "},"engine/animation/animation-clip.html":{"url":"engine/animation/animation-clip.html","title":"Animation Clips","keywords":"","body":"Animation clip An Animation Clip is a set of Animation Curves that contains all animation data. Animation Curve The Animation Curve describes the change of a certain attribute value on an object with time. Internally, the Animation Curve stores a series of time points, and each time point corresponds to a (curve) value, called a frame, or key frame. When the animation system is operating, the Animation Component calculates the (result) value at the specified time point according to the current animation state and assigns it to the object to complete the attribute change; this calculation process is called sampling. The following code snippet demonstrates how to create Animation Clips programmatically: import { AnimationClip, animation, js } from \"cc\"; const animationClip = new AnimationClip(); animationClip.duration = 1.0; // The cycle of the entire animation clip, no frame time should be greater than this attribute. animationClip.keys = [ [ 0.3, 0.6, 0.9 ] ]; // Frame time shared by all curves of this animation clip animationClip.curves = [{ // The property curve on the component modifiers: [ // The target is the current node // \"Body\" child node new animation.HierarchyPath('Body'), // 'MyComponent' new animation.ComponentPath(js.getClassName(MyComponent)), // 'value' attribute 'value', ], data: { keys: 0, // Index to 'AnimationClip.keys', ie [0.3, 0.6, 0.9] values: [ 0.0, 0.5, 1.0 ], }, }]; The above Animation Clip contains a curve to control the value property of the MyComponent component of the Body sub-node. The curve has three frames, so that the value property becomes 0.5 at 0.3 seconds and 0.5 at 0.6 seconds and then becomes 1.0 at 0.9 seconds. Note: the frame time of the curve is indexed into the AnimationClip.keys array by reference. Multiple curves can share the frame time. This will bring additional performance optimizations. Target The target of the Animation Curve can be any JavaScript object. The modifiers field specifies how runtime addresses the current node object to the target object. modifiers is an array, each element of it expresses how to address from the object at the upper level to another object. The object addressed by the last element is the target object of the curve. This behavior is like a file system path, so each element is called a target path. When the target path is string/number, this indicates the attribute addressed to the upper-level object, which itself specifies the attribute name. Otherwise, the target path must be an object that implements the interface animation.TargetPath. Cocos Creator has the following built-in classes that implement the self-interface animation.TargetPath: animation.HierarchyPath treats the upper-level object as a node and addresses it to one of its child nodes; animation.ComponentPath treats the upper-level object as a node and addresses it to one of its components. Target paths can be combined arbitrarily, as long as they have the correct meaning: // The target object is modifiers: [ // \"nested_1\" child node \"nested_2\" child node \"nested_3\" child node new animation.HierarchyPath('nested_1/nested_2/nested_3'), // 'BlahBlahComponent' component new animation.ComponentPath(js.getClassName(BlahBlahComponent)), // of the 'names' attribute 'names', // The first element 0, ] When your target object is not a property, but must be returned from a method, custom target path is useful: class BlahBlahComponent extends Component { public getName(index: number) { return _names[index]; } private _names: string[] = []; } // The target object is modifiers: [ // \"nested_1\" child node \"nested_2\" child node \"nested_3\" child node new animation.HierarchyPath('nested_1/nested_2/nested_3'), // 'BlahBlahComponent' component new animation.ComponentPath(js.getClassName(BlahBlahComponent)), // of the 'names' attribute { get: (target: BlahBlahComponent) => target.getName(0), }, ] If you want your custom target paths to be serializable, declare them as classes: @ccclass class MyPath implements animation.TargetPath { @property public index = 0; constructor(index: number) { this.index = index; } get (target: BlahBlahComponent) { return target.getName(this.index); } } // Target modifiers: [ \"nested_1\" child node \"nested_2\" child node \"nested_3\" child node new animation.HierarchyPath('nested_1/nested_2/nested_3'), // 'BlahBlahComponent' component new animation.ComponentPath(js.getClassName(BlahBlahComponent)), // of the 'names' attribute new MyPath(0), ] The addressing of the target object is done at runtime, this feature allows Animation Clips to be reused on multiple objects. Assignment When the value is sampled, the assignment operator = will be used to set the value to the target object by default. Sometimes, however, it is not possible use the assignment operator to set values. For example, when the uniform of a Material object needs to be set, it cannot be performed through the assignment operator. This is because the Material object only provides setUniform(uniformName, value) method to change the uniform. For this case, the curve field valueAdapter provides a mechanism for you to customize how the value to the target object is set. Examples are as follows: class BlahBlahComponent { public setUniform(index: number, value: number) { /* */ } } { // Curve valueAdapter: { // Called when the curve is instantiated forTarget(target: BlahBlahComponent) { // do something useful here return { // Called every time the value of the target // object is set set(value: number) { target.setUniform(0, value); } }; } }, }; If you want your custom assignments to be serializable, declare them as classes: @ccclass class MyValueProxy implements animation.ValueProxyFactory { @property public index: number = 0; constructor(index: number) { this.index = index; } // Called when the curve is instantiated public forTarget(target: BlahBlahComponent) { // do something useful here return { // Called every time the value of the target object // is set set(value: number) { target.setUniform(0, value); } }; } } animation.UniformProxyFactory is one such example of a custom assignment class, that implements the uniform value of setting the material: { // the target object modifiers: [ // 'MeshRenderer' Component new animation.ComponentPath(js.getClassName(MeshRenderer)), // 'sharedMaterials' attribute 'sharedMaterials', // The first material 0, ], valueAdapter: new animation.UniformProxyFactory( 0, // Pass index 'albedo', // Uniform name ), }; Sampling If the sampling time point is exactly equal to the time point of a key frame, the animation data on the key frame is used. Otherwise, when the sampling time is between two frames, the resulting value should be affected by the two frames of data at the same time. The ratio of the sampling time point to the time interval of two key frames ([0,1]) reflects the degree of influence. Cocos Creator allows this ratio to be mapped to another ratio to achieve different gradient effects. These mapping methods are called gradient methods. After the ratio is determined, the final result value is calculated according to the specified interpolation method. Both the gradient and interpolation methods affect the smoothness of the animation. Gradient method You can specify the gradient method for each frame, or you can specify a uniform gradient method for all frames. The gradient method can be the name of the built-in gradient method or the Bezier control point. The following lists several commonly used gradient methods. linear keeps the original ratio, that is, linear gradient; this method is used by default when no gradient method is specified. constant always uses a scale of 0, i.e. no gradient; similar to the interpolation method Step; The gradient of quadIn changes from slow to fast. The gradient of quadOut changes from fast to slow. The gradient of quadInOut changes from slow to fast to slow again. The gradient of quadOutIn changes from fast to slow to fast. IBezierControlPoints Expand comparison Curve value and interpolation method Some interpolation algorithms require additional data to be stored in the curve value of each frame. Therefore, the value type of the curve value and the target attribute are not necessarily the same. For numeric types or value types, Cocos Creator provides several general interpolation methods. Also, custom interpolation method can be defined. When the interpolate property of the curve data is true, the curve will try to use the interpolation function: If the type of curve value is number, Number, linear interpolation will be applied; If the curve value inherits from ValueType, the lerp function of ValueType will be called to complete the interpolation. Most of the value types built into Cocos Creator implement its lerp as linear interpolation. If the curve value is interpolable, the curve value's lerp function will be called to complete the interpolation 2. If the curve value does not satisfy any of the above conditions, or when the interpolate property of the curve data is false, there will be no interpolation operation. Always use the curve value of the previous frame as the result. import { AnimationClip, color, IPropertyCurveData, SpriteFrame, Vec3 } from \"cc\"; const animationClip = new AnimationClip(); const keys = [ 0, 0.5, 1.0, 2.0 ]; animationClip.duration = keys.length === 0 ? 0 : keys[keys.length - 1]; animationClip.keys = [ keys ]; // All curves share a list of frame times // Linear interpolation using values const numberCurve: IPropertyCurveData = { keys: 0, values: [ 0, 1, 2, 3 ], // The interpolate property is turned on by default /* interpolate: true, */ }; // Use lerp() of value type Vec3 const vec3Curve: IPropertyCurveData = { keys: 0, values: [ new Vec3(0), new Vec3(2), new Vec3(4), new Vec3(6) ], interpolate: true, }; // No interpolation (because interpolation is explicitly disabled) const colorCuve: IPropertyCurveData = { keys: 0, values: [ color(255), color(128), color(61), color(0) ], interpolate: false, // No interpolation }; // No interpolation (because SpriteFrame cannot interpolate) const spriteCurve: IPropertyCurveData = { keys: 0, values: [ new SpriteFrame(), new SpriteFrame(), new SpriteFrame(), new SpriteFrame() ], }; The following code shows how to customize the interpolation algorithm: import { ILerpable, IPropertyCurveData, Quat, quat, Vec3, vmath } from \"cc\"; class MyCurveValue implements ILerpable { public position: Vec3; public rotation: Quat; constructor(position: Vec3, rotation: Quat) { this.position = position; this.rotation = rotation; } /** this method will be called for interpolation * @param this starting curve value * @param to target curve value * @param t to target curve value * @param dt he frame time interval between the start curve value and the target curve value */ lerp (to: MyCurveValue, t: number, dt: number) { return new MyCurveValue( // The position attribute is not interpolated this.position.clone(), // Rotate property uses Quat's lerp() method this.rotation.lerp(to.rotation, t), ); } /** This method is called without interpolation. * It is optional, if this method is not defined, the curve value itself (ie `this`) is used as the result value. */ getNoLerp () { return this; } } /** * A curve is created, which realizes a smooth rotation but a sudden change of position throughout the cycle. */ function createMyCurve (): IPropertyCurveData { const rotation1 = quat(); const rotation2 = quat(); const rotation3 = quat(); vmath.quat.rotateY(rotation1, rotation1, 0); vmath.quat.rotateY(rotation2, rotation2, Math.PI); vmath.quat.rotateY(rotation3, rotation3, 0); return { keys: 0 /* frame time */, values: [ new MyCurveValue(new Vec3(0), rotation1), new MyCurveValue(new Vec3(10), rotation2), new MyCurveValue(new Vec3(0), rotation3), ], }; } Loop Mode You can set different loop modes for Animation Clips by setting AnimationClip.wrapMode(). The table below represents several commonly used looping modes: AnimationClip.wrapMode Description WrapMode.Normal Stop after playing to the end. WrapMode.Loop Loop playback. WrapMode.PingPong After playing from the beginning to the end of the animation, play backwards from the end to the beginning, and so on For more looping modes, see WrapMode. 1The node of the Animation Clip is the node attached to the Animation Component that guides the use of the Animation State object of the Animation Clip. ↩ 2 For numerical values, quaternions, and various vectors, Cocos Creator provides corresponding interpolable classes to implement cubic spline interpolation. ↩ "},"engine/animation/animation-state.html":{"url":"engine/animation/animation-state.html","title":"Animation State","keywords":"","body":"Animation State Animation clips describes animation data for specific kinds of objects and do not bind to individual target object. When the animation got to be played, target object is bound to the animation clip, the playback state is so called animation state. Animation states are somewhat similar to a player, which for example pause and alter the speed of animation. Animation states are represented by class AnimationState. Playback Time An animation state traces the accumulated playback time of an animation. The initial accumulated playback time is 0 and it's self accumulated while playing automatically. In the case of a looping playback, the accumulated playback time would be duration * 2 when the second pass done. At arbitrary time, the playback location of the animation is called as progress time. Obviously process time is always in the range [0, duration]. The accumulated playback time and progress time can be accessed through time and current fields, whereas accumulated playback time can be manually set but progress time is read only. The loop mode and loop count decide the correspondence of playback location and accumulated playback time. The progress time varies accordingly no matter the accumulated playback time is automatically accumulated or is changed manually. Loop Mode and Loop Count The animation can be stopped once it had been played to the end or can be loop forever, or, can be played to the end and replay to the begin so forth. These are called loop modes, denoted by enumeration AnimationClip.WrapMode: Loop Mode Description AnimationClip.WrapMode.Normal Play to the end and then stop. AnimationClip.WrapMode.Loop Play to the end continuously. AnimationClip.WrapMode.PingPong Play to the end, and replay to the beginning from the end, back and forth. Besides, each loop mode in above table have a reversing edition: Loop Mode Description AnimationClip.WrapMode.Reverse Play to the beginning from the end and then stop. AnimationClip.WrapMode.LoopReverse Play to the beginning from the end continuously. AnimationClip.WrapMode.PingPongReverse Play to the beginning from the end, and replay to the end from the beginning, back and forth. The initial loop mode is read from the animation clip. Assign to wrapMode would alter the loop mode. NOTE: the accumulated playback time is reset after change the loop mode. Except for the AnimationClip.WrapMode.Normal and its responding AnimationClip.WrapMode.Reverse(thought they loop only once), other loop modes loop infinitely. You can retrieve and limit the loop count through repeatCount field of AnimationState. NOTE: you should set loop count after you set loop mode since the loop count is reset after you set loop mode. AnimationClip.WrapMode.Normal and its responding AnimationClip.WrapMode.Reverse would reset the loop count as 1. The others reset the loop count as Infinity(infinite count). Playback Control Animation state provides the following methods to control the playing, pausing, resuming and stopping of a animation: Method Description play() Reset playback time as 0 and start to play the animation. pause() Pause the animation. resume() Continue to play the animation starting from current playback time. stop() Stop the animation playing. The following fields can be used to query the playback status: Field(readonly) Description isPlaying Whether the animation is in playing status. isPaused Whether the animation is in paused status. isMotionless Whether the animation is paused or stopped. The playback status and playback control is formatted as the following graph: "},"engine/animation/skeletal-animation.html":{"url":"engine/animation/skeletal-animation.html","title":"Skeletal Animation","keywords":"","body":"Skeletal animation Skeletal Animation is a common but special type of animation. Two different systems are provided and each is optimized for different purposes. Seamless switching between these two systems can be as simple as toggle the useBakedAnimation switch on SkeletalAnimation, even at runtime. when enabled, the pre-baked system will be used, or the real-time calculated system if otherwise. To use SkeletalAnimation, please refer to the SkeletalAnimation API. Pre-baked Skeletal Animation System The dominant purpose of this system is performance, and some sacrifices in expressiveness are also considered acceptable. Cocos Creator has made many low-level optimizations in a targeted manner. The current runtime process is roughly as follows: All animation data will be pre-sampled in advance according to the specified frame rate and baked onto a global-managed joint texture atlas. Depending on whether the operating platform supports floating-point textures, the corresponding texture format will be RGBA32F, or automatically fallback to RGBA8 if not available (The rendering results should be identical, it is only the fail-safe approach for really low-end devices, and shouldn't be of any concern for game developers). Each Skeletal Animation Component (SkeletalAnimation) is responsible for maintaining the current playback progress, stored in the form of UBO (a vec4). Each skinning model component (SkinnedMeshRenderer) holds a pre-baked skinning model class (BakedSkinningModel). Based on the bounding box information pre-baked in the same way to do frustum culling, update the UBO, and get the current data from the texture atlas on the GPU to complete the skinning. Real-time calculated Skeletal Animation System The dominant purpose of this system is expressiveness, ensuring the correct display of all details, and complete program control capabilities. The current runtime process is roughly as follows: All animation data are calculated dynamically according to the current global time. Animation data will be output to the skeleton node tree of the scene. Users and any other system can affect the skin effect by manipulating this node tree. Each Skinning Model Component (SkinnedMeshRenderer) holds a common Skinning Model class (SkinningModel). Extract the transformation data from joint node tree, do frustum culling, upload the complete joint transformation information of the current frame to UBO, and complete the skinning in the GPU. This provides the fundamental support for all the following functions: Blendshape support Mixing and masking of any number of Animation Clips Inverse kinematics, secondary physics Explicit procedural control over any joint tranformations Selection and best practice of two systems After importing all model assets, all prefabs use the pre-baked system by default to achieve the best performance. It is recommended that you only use the real-time calculated system if you clearly feel that the performance of the pre-baked system cannot reach the standard. Although the two systems can be switched seamlessly at runtime, try to do this as less frequent as possible, because each switch involves the reconstruction of the underlying rendering data. Skinning algorithm We have two built-in common standard skinning algorithms, which have similar performance and only affect the rendering results: LBS (Linear Blend Skinning): joint information is stored in the form of a 3x4 matrix, and the matrix is ​​interpolated directly to achieve skinning, and there are well-known problems such as volume loss, etc. DQS (Dual Quaternion Skinning): The joint information is interpolated in the form of dual quaternions, which is more accurate and natural for the skeleton animation without scaling transformation, but for performance reasons, there are pragmatic approximation measures for scaling animations. The engine uses LBS by default. You can switch the skinning algorithm by modifying the updateJointData function reference of the engine skeletal-animation-utils.ts and the header file reference in cc-skinning.chunk. It is recommended that projects with higher pursuit of skin animation quality can try to enable DQS, but since there is no fma instruction before GLSL 400, operations such as cross cannot bypass floating-point cancellation on some GPUs, and the error is relatively high. This may introduce some visible defects. Socket system If you need to attach some external nodes to the specified joint joints, you need to use the Socket system of the Skeleton Animation Component: Create a new child node directly under the node of SkeletalAnimation to be attached to. Add an array element in the sockets list of the SkeletalAnimation. Select the path of the joint to be attached to from the drop-down list (note that the defaultClip property of the SkeletalAnimation must be a valid clip, the content of the drop-down list depend on this), and specify the target as the child node just created. This child node becomes a socket node, you can put any node under and it will follow the transformations of the specified joint. FBX or glTF assets will be automatically adapted to use this socket system at import time, without any manual interference. About Dynamic Instancing Based on the framework of the pre-baked skeletal animation system, the instancing of the skin model has also become a function within reach, but to ensure correctness, you need to collect some relatively low-level information. The fundamental problem here is that the joint texture atlass used by each model in the same drawcall must be the same. If they are not the same, the display effect will be completely messy. The way to distribute all the animation data used at runtime to each joint texture atlases becomes a project-specific information, thus needs developer's input. See the joint texture layout panel documentation for more details on how to configure this. Note: instancing is only supported under the pre-baked system. Although we do not strictly prohibit instancing under the real-time calculated system (will only trigger some warnings in the editor), there will be problems with the rendering results. Depending on the asset allocation situation at the time, all the instances could be playing the same clip at best, or more often, completely mad rendering results. Note: for models with instancing turned on in the material, the planar shadow system will also automatically draw using instancing. In particular, the shadow of the skin model has a higher requirement for the layout of the joint texture atlas, because the pipeline state of the shadow is unified, all the animation of the skin model with the shadow turned on needs to be put into the same texture (Compared to when drawing the model itself, only the instances in the same drawcall need to be put into the same texture). Batched Skinning Model Component The joint texture uploaded by the GPU on the bottom layer has been globally automatically batched and reused. The upper layer data can currently be combined with all the sub-skin models controlled by the same joint animation component by using the BatchedSkinningModelComponent: The batch version of the effect is relatively complicated to write, but it can basically be based on the common effects used by the sub-materials, adding some relatively direct preprocessing and interface changes. The built-in assets in the editor (util/batched-unlit) provide a The integrated version of builtin-unlit can be referenced. Note: only using the Batched Skinning Model Component under the pre-baked system can guarantee the correctness. Although it can also be used under the real-time calculated system, there will be rendering problems when the number of joints after the merger exceeds 30 (the maximum number of Uniform arrays). "},"tween/":{"url":"tween/","title":"Tween","keywords":"","body":"Tweening In order to be fully compatible with and maintain the experience of the Cocos Creator v2.x easing system, all the Cocos Creator v2.x functions are transplanted in Cocos Creator 3.0. Note: action has been abandoned, please use tween. Note: there is no longer a dependency on tween.js. If you use the relevant features of tween.js, please adapt. Note: the onStart, onUpdate, onComplete callbacks were added to the optional attributes of to and by. The difference from the previous tween.js is mainly optional attributes, explained as follows: The value definition of easing has been changed (compatibility is done here). In addition to easing, onStart, onUpdate, onComplete, other properties are not supported yet (checked here, the console will have a corresponding warning). Example import { _decorator, Component, Vec3, tween } from \"cc\"; @ccclass(\"tween-test\") export class tweentest extends Component { private _pos: Vec3 = new Vec3(0, 0, 0); start () { /** Easing _pos */ tween(this._pos) .to(3, new Vec3(10, 10, 10), { easing: 'bounceInOut' }) .to(3, new Vec3(0, 0, 0), { easing: 'elasticOut' }) .union() .repeat(2) // 执行 2 次 .start(); /** Easing Node, here will ease the Node's position property */ tween(this.node) .to(3, { position: new Vec3(10, 10, 10) }, { easing: 'bounceInOut' }) .to(3, { position: new Vec3(0, 0, 0) }, { easing: 'elasticOut' }) .union() .repeat(2) // execute 2 times .start(); } } Precautions repeat semantics Previously, the semantics of repeat was repeated several times. In order to fully maintain the design of Cocos Creator 2D, repeat is executed several times, that is, repeat(1) stands for one execution. Restrictions In-order to reduce the frequency of updating the Node Transform information, Node maintains a dirty state. Only when an interface that may change the Node Transform information is called, will dirty be set to the state that needs to be updated. Note: the current interface has certain restrictions, for example position obtained through this.node.position is a generic Vec3. When this code this.node.position.x = 1 is executed, only the getter of position is executed, and the setter of position is not executed. Since dirty is not updated, it will cause the Transform information of the nodes used during rendering not to be updated. Such calls are not supported, but the use of setPosition or position is encouraged. Example: let _pos = new Vec3(0, 1, 0); this.node.position = _pos; // here will pass the position setter this.node.setPosition(_pos); // here will setPosition through interface The right way of easing In the new Tween module, you can obtain properties with getter and setter, such as the position property of node (in the simple example above). During the easing process, the corresponding interface will be carried out, making setting changes to ensure that dirty is updated normally. Note: pay attention to stop the corresponding slow motion when switching scenes. Tween interface introduction Interface Explanation to Add an interval action that calculates the absolute value of the attribute by Add an interval action to calculate the relative value of the attribute set Add a momentary action that sets the target property directly delay Add an instant action of delay time call Add an instant action of call callback target Add a instant action to directly set the slow-motion target union Package the easing action of the context into one then Insert a Tween into the easing queue repeat Execution several times (previously repeated several times, if using, please adapt) repeatForever Always repeat execution sequence Add a sequential slow motion parallel Add a simultaneous easing start Start slow motion stop Stop slow motion clone Clone Easing show To enable rendering on the node chain, the slowing target needs to be Node hide Disable rendering on the node chain, the slowing target needs to be Node removeSelf Move the node out of the scene tree, the slowing target needs to be Node Optional attributes of to and by The definition is as follows: interface ITweenOption { easing?: TweenEasing | ((k: number) => number); progress?: (start: number, end: number, current: number, ratio: number) => number; onStart?: (target: object) => {}; onUpdate?: (target: object, ratio: number) => {}; onComplete?: (target: object) => {}; } The difference with Cocos Creator 2D is the addition of properties such as onStart, onUpdate, and onComplete. These properties are callback functions, which will be passed into the easing target when called. In addition, an additional value of the current easing will be passed in when onUpdate is called, and the range is (0-1). Example of using callback Taking onUpdate as an example, the following code eases a position, and then setting it to multiple objects in onUpdate, this demonstrates batch easing. import { Node, tween, Vec3 } from \"cc\"; const nodeArray: Node[] = []; // Replace here with your node array const tweenTargetVec3 = new Vec3(); tween(tweenTargetVec3) .by(1, new Vec3(1, 1, 1), { 'onUpdate': (target: Vec3, ratio: number) => { for (let i = 0; i Automatic destruction In Cocos Creator 3.0, when the easing target is Node, it will listen to its destruction event for automatic destruction of the easing. This calls the target method and also automatically updates the listener. Note: related test cases are located on GitHub. Note: please refer to Using the Tween System documentation. "},"physics/physics.html":{"url":"physics/physics.html","title":"Physics","keywords":"","body":"Physics Introduction Cocos Creator currently supports the lightweight collision detection system builtin and the physics engine cannon.js with physical simulation, and the asm.js/wasm version ammo.js of the powerful physics engine bullet, also we provides users with efficient and unified component-based workflow and convenient methods of use. Physics World And Elements Elements in the physics world can be divided into rigid body. We can adding physics elements by adding a collider (Collider) or rigid body (RigidBody) component to the game object. The physics system will perform calculations on these elements to make their behaviors the same with the real world. Note: the rigid body here doesn't refer to the RigidBody component. The RigidBody component is used to control the properties related to the physical behavior of the rigid body. Adding a Physical Element Adding a physical element to the world can be divided int the following steps: Create a new shape Cube; Click Add Component on the Inspector panel witch is on the right of editor; Select BoxCollider under the Physics menu, and adjust the parameters; add a RigidBody component in order to make it have physical behavior. In this way we get a physical element that has both a collider and a physical behavior. Perfecting The Physics World We can add a ground to the world. Following the steps 1,2,and 3, you can add another Plane with collider only. Then, adjust the view of the camera (select the camera and press the shortcut Ctrl + Shift + F to align the camera view to screen). Finally, click the run button, you can see the changes of physical elements in the scene. The final scene is shown in the following figure: Composition Of Physical Elements A physical element can be composed of the following ways: A RigidBody component One or more Collider components One RigidBody component plus one or more collider components More Detailed Modules Additional physics system will be introduced in more detail through the following modules: Module Description Physics Options Introduces the optional options of low-level physics engine in Cocos Creator Physics System Introduces the physics system and a series of properties and interfaces of the physics system. Physics Component Introduces some physics components and a series of properties on the panel. Physics Usage Further introduces the use of physics, events, group masks, etc. "},"physics/physics-item.html":{"url":"physics/physics-item.html","title":"Physics Options","keywords":"","body":"Choosing The Physics System Suitable For Your Project In the panel Project -> Project Settings -> Module Options of the Editor, you can choose a physics engine suitable for the needs of the project for development. Notes: The default is ammo.js physics engine. The physics engine can be switched at will during development. Collision Detection: builtin builtin only has the function of collision detection. Compared with other physics engines, it has no complicated physical simulation calculations. If your project does not require the physical simulation of this part, you can consider using builtin, which will make the size of game's package smaller. If you use builtin for development, please note the following: builtin only has events of type trigger. isTrigger in Collider component is a trigger regardless of whether the value is true or false. Physics Engine: cannon.js cannon.js is an open source physics engine, which uses js language to develop and implement more comprehensive physics functions, if your project needs more complex physical functions, then you can consider using cannon.js. The size of the cannon.js module is 141KB. Physics Engine: ammo.js ammo.js is the asm.js/wasm Version of the bullet physics engine, it is compiled by emscripten tool. Bullet has perfect physical functions, and we will put more work here in the future. It should be noted that currently the ammo.js module has a size of about 1.5MB. Do Not Use Physics If you don't need to use any physics related components and interfaces, you can uncheck the yellow box, so that you can get a smaller package when publishing. Note: if it is unchecked, the project will not be able to use physics related components and interfaces, otherwise an error will be reported during runtime. "},"physics/physics-system.html":{"url":"physics/physics-system.html","title":"Physics System","keywords":"","body":"Physics System The physics system is used to manage all physics related functions. Currently, it is responsible for synchronizing physical elements, triggering physics events and scheduling iterations of the physical world. Physics World When the physics world iterates, physical calculations will be made on physical elements, such as calculating whether each object collides and the force of the object. When the calculation is completed, the physics system will update the physics world to the scene world, so that the game objects will generate corresponding physical behaviors. Note: there is only a single physical world, and the functional support of the multi-physics world will be discussed later. Scene World and Physics World: Properties The properties of the physics system can only be set through the code for the time being. A setting panel will be added in the future, please pay attention to the update announcement. Note: gets the instance of physics system using: PhysicsSystem.instance Property Description enable Whether to enable the physics system, the default is true gravity The gravity value of the physics world, the default is (0, -10, 0) allowSleep Whether to allow the physics system to automatically sleep, the default is true maxSubSteps The maximum number of physics simulation sub-steps per frame, the default is 2 fixedTimeStep The time spent in each step of physics simulation, the default is 1/60, note that is not every frame sleepThreshold The default speed threshold for going to sleep, the default is 0.1 autoSimulation Automatic simulation, the default is true defaultMaterial Get the default physics material (read only) raycastResults Gets the raycast test results (read only) raycastClosestResult Gets the raycastClosest test result (read only) collisionMatrix Gets the collision matrix (It`s used only for initialization) Interfaces Property Signature Description resetAccumulator (time=0)=>void Reset the accumulator of time to given value "},"physics/physics-component.html":{"url":"physics/physics-component.html","title":"Physics Component","keywords":"","body":"Physics Component Cocos Creator currently provides users with a variety of collider components, common rigid body components, as well as tool-type constant force components. Collider Component The collider component is used to represent the shape of the collision body of a rigid body. Different geometric shapes have different properties. Note: the following property names are all lowercase in the actual code. Note: currently only box, sphere and capsule are supported in builtin. BoxCollider Properties Description material The physics material referenced by the collider (the default physics material was referenced when it is empty) isTrigger Whether it is a trigger, the trigger will not generate physical feedback center The origin of the shape in the local coordinate system size The size of the box, ie length, width, height To use BoxCollider, please refer to the BoxCollider API. SphereCollider Properties Description (Other reference box colliders) radius Radius of the sphere To use SphereCollider, please refer to the SphereCollider API. CylinderCollider Properties Description (Other reference box colliders) direction The reference axis of the cylinder's extended direction height The total height of the cylinder radius The radius of the circular surfaces at both ends of the cylinder To use CylinderCollider, please refer to the CylinderCollider API. CapsuleCollider Properties Description (Other reference cylinders and box colliders) cylinderHeight The height of the cylinder in the capsule radius The radius of the sphere in the capsule To use CapsuleCollider, please refer to the CapsuleCollider API. Note: cannon.js does not support capsule components. It is recommended to use two spheres and cylinders and piece them together. ConeCollider Properties Description (Other reference cylinders and box colliders) radius The radius of the circle of the underside of the cone height The height of the cone To use ConeCollider, please refer to the ConeCollider API. PlaneCollider Properties Description (Other reference box colliders) normal The normal vector to the plane constant The distance that the plane moves along the normal vector To use PlaneCollider, please refer to the PlaneCollider API. MeshCollider Properties Description (Other reference box colliders) mesh The mesh asset referenced by the mesh collider, used to initialize the mesh collision volume convex Whether used the convex hull of the mesh is approximated, the number of vertices of the mesh should be less than 255 (through which any convex collider and dynamic rigid body can be supported). To use MeshCollider, please refer to the MeshCollider API. Note: cannon.js has poor support for the mesh collider component, and only allows detection with the sphere\\plane collider. Note: currently only ammo.js backend supports convex functionality. SimplexCollider Properties Description (Other reference box colliders) shapeType There are four types of simplex: point, line, triangular face and tetrahedron vertex0 Vertex 0 of the simplex, point (consisting of 0) vertex1 Vertex 1 of the simplex, line (consisting of 0,1) vertex2 Vertex 2 of the simplex, triangular face (consisting of 0,1,2) vertex3 Vertex 3 of the simplex, tetrahedron (consisting of 0,1,2,3) Note: cannon.js has imperfect support for line and triangular face. To use SimplexCollider, please refer to the SimplexCollider API. RigidBody In order to more easily simulate physical behavior, Cocos Creator provides users with rigid body components. Properties Description (The property values ​​in the above picture are all default values) group The group of the physics element mass The mass of the object type The type of the rigid body linearDamping Linear damping, used to reduce the linear velocity of an object angularDamping Angular damping, used to reduce the rotation rate of objects useGravity Whether the rigid body is affected by gravity linerFactor Linear factor, which can affect the change of linear velocity in each axis angularFactor Rotation factor, which can affect the change of the rotation speed of each axis To use RigidBody, please refer to the RigidBody API. ConstantForce This is a tool component that depends on a RigidBody and will apply a given force and torque to a rigid body every frame. Properties Description force The force applied to the rigid body in the world coordinate system localForce The force applied to the rigid body in the local coordinate system torque Torque applied to the rigid body in the world coordinate system localTorque Torque applied to the rigid body in the local coordinate system To use ConstantForce, please refer to the ConstantForce API. "},"physics/physics-use.html":{"url":"physics/physics-use.html","title":"Using Physics","keywords":"","body":"Using Physics In order to introduce how to use physics better, the following modules will be introduced: Module Description Collision Component Introduces the design of the Collider component and its relationship with the RigidBody component Physics Material Introduced physics material assets in Cocos Creator Rigid Body Component Introduces some code usage examples of the RigidBody component Physics Event Introduced the physics events in Cocos Creator Group Mask Introduces the use of group and mask in physics filter detection Raycast Detection Introduces the ray detection function of the physics collider "},"physics/physics-collider.html":{"url":"physics/physics-collider.html","title":"Physics Collider","keywords":"","body":"Collision Component Getting the Collider Component The following code works in both JavaScript and TypeScript: this.getComponent('cc.BoxCollider') // Or import { BoxCollider } from 'cc' this.getComponent(BoxCollider) Collider and Trigger The Collider component has an isTrigger attribute. When isTrigger is true, it is represented as a trigger, otherwise it is a collider. Note: to learn more about he differences between colliders and triggers please review the Physics Event documentation. The relationship between Collider and RigidBody The Collider and RigidBody components are meant to serve physical elements, and control a part of the attributes on the physical elements respectively. This also means that to understand the relationship between them, you need to first understand how the physical elements in Cocos Creator are composed. How Elements Are Composed In the Introduction to Physics documentation, it is introduced that a physical element is composed of a Collider and RigidBody components. This indicates that there can only be one or zero physical elements RigidBody components, and there can be multiple Collider components. It is easy to see if there is a physical element for a single node, but if we consider the node chain as a single unit, it will be difficult to see which nodes and which components the physical element is composed of. There are two ways to consider viewing the the node chain: As long as each node has a physics component, it is an element, which means that the components of the parent and child nodes have no dependencies and require multiple shapes. Add the corresponding Collider component to the node. Start searching from the own node to the parent chain node. If the RigidBody component is found, bind its own Collider component to the node, otherwise the Collider component on the entire chain will share a RigidBody component, the node corresponding to the element is the node corresponding to the topmost Collider component. These two ideas have their pros and cons: Idea 1 is not intuitive enough. Multiple shapes can only be added to one node. To display the shape, you need to add a child node model. When adjusting the parameters in Idea 1, two places need to be adjusted, namely the position information of the child node and the data information of the corresponding Collider component on the parent node. Idea 2 adds the coupling of node. When a node is updated, the corresponding dependent node needs to be updated. When the node chain is destroyed, more content needs to be maintained, and the node chain needs to deal with complex logic when it is repeatedly destroyed in Idea 2. Note: the physics engine in Cocos Creator is currently using idea 1, which may be adjusted in the future. attachedRigidbody property of Collider The Collider component has an attachedRigidbody property. This property can get the RigidBody component bound to the current Collider component, but please note the following points: When there is no RigidBody component in its own node, this property is returned as null. attachedRigidbody is a read-only property. Auto-Scaling Each component is bound to a node, some components dynamically update their data based on the bound node. collider components update their data based on the node The information automatically updates the corresponding shape data, allowing collision bodies to more easily fit the rendered model. Updating data to model components as an example. The model component automatically updates the model's world matrix according to the bound nodes, thus changing the node's position, scaling, rotation, etc. , which allows the rendered model to have a corresponding affine transformation. However, some properties of collider shape lead to a different treatment of scaling. Collider shape are generally described by their geometry structure. Most of the collider shape are of the convex hull type. These properties restrict transformations such as tangential, non-uniform scaling, etc., taking the sphere collider as an example. Assume that the scaling information of the bound nodes is (1,2,1) (non-uniform scaling), since the structure described by the model and the collider is not same, the sphere model is represented using multiple primitives (e.g., triangles) that, when scaled, model shape into a pebble-like shape; however, the sphere collider is described by the size of the radius, which is scaled in the dimension with the largest value (to ensure that the collision body can be as large as possible of the enclosing model), but scaled it is still a sphere. Realize the shape of goose soft stone In this case, the mesh collider can be used instead of the primitive collider. Note: You must turn on the convex if you want to support the dynamic rigid body. PhysicsMaterial The collision body has physics material properties. Related content is described in detail in the physics material documentation. The difference between shared and non-shared interfaces is mainly introduced. The Collider component provides two properties to get and set. These are material and sharedMaterial, and their differences are as follows: Setting sharedMaterial or material has the same effect. It is in a shared state before calling these interfaces. When it is found that the set and the current reference are not the same instance, obtaining a material later will not generate a new material instance. At this time, it is a non-shared state. Under the premise of shared state, obtaining material will generate a new material instance to ensure that only the current collision body references the material, so that the modification will not affect other collision bodies, and then it will be in the non-shared state. Obtaining sharedMaterial does not generate a new one, but directly returns a reference. Continue to the physics material documentation. "},"physics/physics-material.html":{"url":"physics/physics-material.html","title":"Materials","keywords":"","body":"Physics Material In Cocos Creator, the physics material is a asset, which records the surface information of the object. This is used to calculate the friction and elastic force of the colliding object. Properties of Materials The properties of Physics Materials are shown below: Properties Description friction Coefficient of friction restitution Coefficient of restitution When in contact with other surfaces, these coefficients are used to calculate the corresponding friction and elastic forces. Creating Physics Materials Physics Materials can be created in two ways: Create in editor Code instantiation The way to create with the editor is shown below: Instantiated in the code: let newPmtl = new PhysicMaterial(); newPmtl.friction = 0.1; newPmtl.restitution = 0.1; Application of materials The physics material is set in units of collision bodies, and each Collider has a material property (when not set, Collider will refer to the default physics material in the physics system). The application to Collider is also divided into editor operation and code operation. To operate in the editor, just drag the asset into the cc.PhysicsMaterial property box, as shown in the following figure: Operation in the code: const collider = this.node.getComponent(ColliderComponent); collider.material = newPmtl; Because of the design of Material Sharing, you can actually do this directly in the code (because an instance will be created when you get material) collider.material.friction = 0.1; collider.material.restitution = 0.1; "},"physics/physics-rigidbody.html":{"url":"physics/physics-rigidbody.html","title":"Rigid Body","keywords":"","body":"RigidBody Component RigidBody is the basic object that make up a physics world, and it can make a node physically affected and react. The RigidBody component is used to control the properties associated with the simulation. Click the Add Component -> Physics Component -> RigidBody button at the bottom of the Inspector panel to add the RigidBody component to the node. RigidBody Properties Properties Function explanation Type The type of the rigid body, including DYNAMIC, STATIC and KINEMATIC, See below for details. Mass The mass of the rigid body. AllowSleep Whether to allow the rigid body to enter sleep state. Linear Damping Used to reduce the linear rate of rigid body. The larger the value, the slower the rigid body moves. Angular Damping Used to reduce the rotation rate of rigid body. The larger the value, the slower the rigid body rotates. Use Gravity If enabled, the rigid body is affected by gravity. Linear Factor It can affect the linear velocity change of the rigid body in each axis. The larger the value, the faster the rigid body moves. Angular Factor It can affect the rotation speed change of the rigid body in each axis. The larger the value, the faster the rigid body rotates. For more information, please refer to the RigidBody API. Obtaining a RigidBody // TypeScript const rigidBody = this.getComponent(RigidBody); Rigid Body Types Rigid bodies are generally divided into three types, STATIC, DYNAMIC, and KINEMATIC. STATIC, which means a static rigid body, Used to describe a building at rest. If the object needs to keep moving, it should be set to KINEMATIC type. DYNAMIC, which means that a dynamic rigid body can be subjected to forces. Move the object through the laws of physics, and make sure the mass is greater than 0. KINEMATIC, which means kinematic rigid body, Usually used to express the motion of the object such as the elevator platform, please control the motion of the object through the Transform. Center Of Mass Currently the center of mass is fixed to the node to which the RigidBody component is bound, and the center of mass is relative to the collider shape. By adjusting the collider shape offset (center), the center of mass can be shifted in shape. Note: in order to make it easier to fit collider shape to the model, methods for changing mass centers may be added in the future, as well as methods for dynamically calculating mass centers mechanism. Sleeping or Waking the Rigid Body Sleeping the Rigid Body If a rigid body is sleeping, all the force and velocity of the rigid body are cleared, and the rigid body freezed. // asleep if (rigidBody.isAwake) { rigidBody.sleep(); } Waking the Rigid Body // awake if (rigidBody.isSleeping) { rigidBody.wakeUp(); } Allowing The Rigid Body To Move To move a rigid body, you need to change the speed of the rigid body. Currently, there are several ways to change the speed of the rigid body. By Gravity The RigidBody component provides the useGravity property, set it to true and the rigid body will be affected by gravity. By Applying Force The RigidBody component provides an applyForce interface with the signature: applyForce (force: Vec3, relativePoint?: Vec3) According to Newton's second law F = m * a, a force is applied to a certain point of the rigid body, so that there is acceleration, and the speed will change with the acceleration with time, which will cause the rigid body to move. Example: rigidBody.applyForce(new Vec3(200, 0, 0));` By Applying Torsional Force The RigidBody component provides the applyTorque interface with the signature: applyTorque (torque: Vec3) Through this interface, you can apply torque to the rigid body, because it only affects the rotation axis, so no longer need to specify the point of action. By Applying Impulse The RigidBody component provides the applyImpulse interface, with the signature: applyImpulse (impulse: Vec3, relativePoint?: Vec3) According to the equation of conservation of momentum F Δt = m Δv, impulse is applied to a certain point of the rigid body. Since the mass of the object is constant, the speed will change immediately and the rigid body will move. Example: rigidBody.applyImpulse(new Vec3(5, 0, 0));` By Directly Changing The Speed Linear speed The RigidBody component provides the setLinearVelocity interface, which can be used to change the linear velocity. The signature is: setLinearVelocity (value: Vec3) Example: rigidBody.setLinearVelocity(new Vec3(5, 0, 0)); Spinning speed The RigidBody component provides the setAngularVelocity interface, which can be used to change the rotation speed. The signature is: setAngularVelocity (value: Vec3) Example: rigidBody.setAngularVelocity(new Vec3(5, 0, 0)); Limit Movement Of Rigid Body By Sleeping When sleeping the rigid body, all the force and speed of the rigid body will be emptied, which will stop the rigid body. Note: currently application of force or impulse, and changing the speed will wake up the rigid body again, and subsequent adjustments may be made, please pay attention to the version update announcement. By Damping The RigidBody component provides linearDamping and angularDamping properties: The linearDamping property is used to set the linear damping. The angularDamping property is used to set the angular damping. The range of the damping parameter is from 0 to infinity, where 0 means no damping and infinity means full damping. Generally, the value of damping is between 0 ~ 0.1. By Factor The RigidBody component provides the linearFactor and angularFactor properties: The linearFactor property is used to set the linear factor. The angularFactor property is used to set the angular factor. The factor is the type of Vec3. The value of the corresponding component is used to scale the speed change of the corresponding axis. The default value is 1, which means that the scaling is 1 times, that is, no effect. Notes: Set a certain component value of the factor to 0, you can fix a certain axis of movement or rotation. In the physics engines cannon.js and ammo.js, the factors act on different physical quantities, in cannon.js on speed and in ammo.js on force. "},"physics/physics-event.html":{"url":"physics/physics-event.html","title":"Physics Events","keywords":"","body":"Physics Events The physics event system in Cocos Creator 3.0 are divided into trigger events and collision events, which are generated by Trigger and Collider respectively. Trigger and Collider When colliding, the collider will produce physical a behavior, however the trigger will not. Therefore, the trigger only performs collision detection. The collider performs both collision detection and physical simulation. The difference between them: A Trigger is a Collider component whose Is Trigger property is true. When a collision occurs, the Trigger does not produce collision effect, so the Trigger is only used for collision detection. The differences between Trigger and Collider are as follows: Trigger do not perform finer detection with other triggers or colliders. Collider do more detailed detection with other colliders, and will provide some additional data due to collisions, such as collision points, normals and so on. Trigger Events and Collision Events The differences between Trigger events and Collision events are as follows: Trigger events are generated by triggers, and collision events are generated based on collision data. The trigger event can be generated by the trigger with another trigger or another collider. Collision events need to be generated by two colliders and at least one dynamic rigid body. Trigger Events There are three types of Trigger Events: Events Description onTriggerEnter Trigger start onTriggerStay Trigger stay onTriggerExit Trigger end Where the collision pairs that can generate trigger events are: Type Static rigid body Kinematic rigid body Dynamic rigid body Static rigid body ✔ ✔ Kinematic rigid body ✔ ✔ ✔ Dynamic rigid body ✔ ✔ ✔ Note: the prerequisite is that both must come with a collision component and at least one of them must be a trigger type. Listen to trigger events In order to add listeners to the trigger event, you need to add the corresponding callback by registering the event: Get Collider through this.getComponent(Collider) Register the callback of the corresponding event through the on or once method of Collider Code example: public start () { let collider = this.getComponent(Collider); collider.on('onTriggerStay', this.onTrigger, this); } private onTrigger (event: ITriggerEvent) { console.log(event.type, event); } Collision Events Collision events are generated based on collision data. Collision data is not generated between rigid bodies of static types. Collision events are divided into three types: Events Description onCollisionEnter Start of the collision onCollisionStay Collision hold onCollisionExit end of the collision Where the collision pairs that can generate collision events are: Type Static rigid body Kinematic rigid body Dynamic rigid body Static rigid body ✔ ✔ Kinematic rigid body ✔ ✔ ✔ Dynamic rigid body ✔ ✔ ✔ Note: the prerequisite is that both must come with a collision component and both must be of the collider type. Listen to collision events In order to add a listener to the collision event, you need to add the corresponding callback by registering the event: Get Collider through this.getComponent(Collider) Register the callback of the corresponding event through the on or once method of Collider Code example: public start () { let collider = this.getComponent(Collider); collider.on('onCollisionStay', this.onCollision, this); } private onCollision (event: ICollisionEvent) { console.log(event.type, event); } Notes: Collider is the parent class of all collision components. Collision events are in physical elements, and all collider components on this element will receive collision events. "},"physics/physics-group-mask.html":{"url":"physics/physics-group-mask.html","title":"Group Masks","keywords":"","body":"Groups And Masks In Cocos Creator, some physics components (there are currently rigid body components and collider components) provide interfaces for Groups and Masks. How does it work? Physics elements and nodes are currently in a one-to-one relationship. The group and mask belong to the physics elements. The physics components on a single node modify the group and mask of the physics elements corresponding to the nodes. As long as the following conditions are true, it will be detected (GroupA & MaskB) && (GroupB & MaskA) For example: two physical elements A and B. The group value of A is 1 and the mask value is 3 The group value of B is 2, and the mask value is 2 The formula (1 & 2) && (2 & 3) is false, so here A will not be detected with B. Here according to the mask value of B is 2, we can know that the detectable group of B is 1, and the group of A is 0, so it is not detected. Note: the expression depends on bit operation, the bit operation of JavaScript is limited to 32 bits, and the last bit is the sign bit. To avoid exceeding the operation range, it is recommended that the range of the group is [0, 31 ). Groups Setting a Group Value The following group value is 3, and the binary value is 11, which means it is in the 0, 1 group (starting from 0) const group = (1 Obtaining a Group Value Use getGroup(). Collider.getGroup(); Adding a Group Based on the above code, after the following code, the grouping value is 7, and the binary value is 111, so it means that it is in the 0, 1, and 2 groups. const group = 1 Removing a Group Based on the above code, after the following code, the grouping value is 3, so in the 0, 1 group. const group = 1 Note: it is recommended to fix in a group. Note: the receiving parameters of the above methods are all decimal numbers. For easy understanding, binary explanation is used here. Developers can also directly input decimal numbers for group operation after they are familiar**. Masks Setting a Mask Value The value of the following mask is 3, the binary value is 11, indicating that the detectable group is 0, 1. const mask = (1 Obtaining a Mask Value Use getMask() console.log(Collider.getMask()); Adding a Mask On the basis of the above code, after the following code, a detectable group 3 was added. const mask = 1 Removing a Mask The following code removes a detectable group 3. const mask = 1 Note: the addition and subtraction operation have higher priority than the shift operation. Note: flexible use of group and mask can reduce the cost of additional detecting. Examples Here is a simple example of usage: Defining a Group Method 1: Defined in an object export const PHY_GROUP = { Group0: 1 Method 2: Defined in an enum (TypeScript only) enum PHY_GROUP { Group0 = 1 In order to be able to set up groups on the panel, you need to register the defined groups to the editor Enum(PHY_GROUP) through the Enum function exported by the cc module. Note: for historical reasons, the Enum function has special treatment for -1. If you are not familiar with it, do not define an attribute with a value of -1. Using a Mask The mask can be defined according to grouping, for example: Define a mask(const maskForGroup1 = PHY_GROUP.Group1;) that only detects Group1 Define a mask(const maskForGroup01 = PHY_GROUP.Group0 + PHY_GROUP.Group1;) that can detect Group0 and Group1 Define a mask(const maskForNone = 0;) that is not detected by all groups Define a mask(const maskForAll = -1;) for all groups to detect View Binary By executing (value >>> 0).toString(2) in the running environment of JavaScript, you can see the binary string representation. Collision Matrix The collision matrix is a further encapsulation of the packet mask configuration, which provides a more unified management and makes it easier to initialize the packet mask configuration without writing any code, and can be configured directly in the editor's project Settings. For details, please refer to the collision matrix Settings documentation. "},"physics/physics-raycast.html":{"url":"physics/physics-raycast.html","title":"Raycast","keywords":"","body":"Raycast Detection Raycast detection is a very important function and is often used to judge various situations. The essence is to make a intersection judgment between a ray and another shape, as shown in the figure below. Constructing a Ray The ray is under the geometry namespace of the cc module, so in order to access to ray, we need to import geometry: import { geometry } from \"cc\"; The ray is composed of start point and direction. There are the following common methods to construct a ray: Via start point + direction, such as ray constructor or static interface create: import { geometry } from \"cc\"; const { ray } = geometry; // Construct a ray starting from (0, -1, 0) and pointing to the Y axis // The first three parameters are the starting point, the last three parameters are the direction const outRay = new ray(0, -1, 0, 0, 1, 0); // Or through the static method create const outRay2 = ray.create(0, -1, 0, 0, 1, 0); Via start point + another point on the ray, for example the static interface fromPoints in the ray: import { geometry, Vec3 } from \"cc\"; // Construct a ray starting from the origin and pointing to the Z axis const outRay = new geometry.ray(); geometry.ray.fromPoints(outRay, Vec3.ZERO, Vec3.UNIT_Z); Use the camera to construct a ray emitted from the origin of the camera to a point on the screen (or the near plane of the camera): import { geometry, Camera } from \"cc\"; const { ray } = geometry; // It is assumed here that there is already a reference to cameraCom const cameraCom: Camera; const cameraCom: Camera; // Get a ray emitted by the screen coordinates (0, 0) const outRay = new ray(); cameraCom.screenPointToRay(0, 0, outRay); Notes: You need to get a reference to a camera component or camera instance. The order of the interface parameters exposed by both the camera component and the camera instance is not the same. Interface Introduction Cocos Creator provides a set of ray detection functions. However, it should be noted that the detected object is a physics collider, and the corresponding collider component on the inspector panel, such as BoxCollider. Currently, the interface is provided by PhysicsSystem, which has the following two categories: raycastAll: Detect all colliders and return a Boolean value to indicate whether the detection was successful. raycastClosest: Detect all colliders and return Boolean value as well. Parameter description: worldRay: Rays in world space mask: Mask for filtering, you can pass in the packets to be detected maxDistance: Maximum detection distance, please do not pass Infinity or Number.MAX_VALUE queryTrigger: Whether to detect triggers Getting Results To get the detection results of the above interfaces, you need to use the following methods separately: Gets the detection result of raycastAll: PhysicsSystem.instance.raycastResults Gets the detection result of raycastClosest: PhysicsSystem.instance.raycastClosestResult Note: the returned object is read-only and reused, and the corresponding result will be updated after each call to the detection interface. Information Stored By Results The information is stored by PhysicsRayResult, which mainly has the following information: collider: Collider that is hit distance: The distance between the hit point and the starting point of the ray hitPoint: Hit point (in world coordinate system) hitNormal: The normal of the hit point's face (in the world coordinate system) Related test cases can be found in the GitHub repo. "},"physics-2d/physics-2d.html":{"url":"physics-2d/physics-2d.html","title":"2D Physics","keywords":"","body":"Introduction to Physics 2D Cocos Creator 3.0 supports the built-in lightweight builtin physics system and the powerful Box2D physics system. For simpler physics calculations, we recommend that users use the built-in physics module, which avoids the runtime overhead of loading large Box2D physics modules and building physics worlds. The Box2D physics module provides a more complete interaction with the interface and pre-defined components such as rigid bodies and joints. Choose the physics module that suits your needs, and switch the physics module you use through the Project Setting/Engine Module settings. Details Physics System Rigid Body Collision Components Contact Callback Physics Joints Physics 2D Examples Examples are available on GitHub. "},"physics-2d/physics-2d-system.html":{"url":"physics-2d/physics-2d-system.html","title":"2D Physics System","keywords":"","body":"Physics Manager The physics system hides most of the implementation details of the physics modules (Box2D and Builtin modules) (e.g. creating rigid bodies, synchronizing rigid body information to nodes, etc.). Use the physics system to access some of the common functions of the physics module, such as click testing, ray testing, and setting up test messages. Physics system related settings Enabling the Physics Manager The Physics Manager is disabled by default. To use the physics system-related functions, first, enable the Physics Manager, otherwise, all the physics objects setup in the editor will not produce any effect. PhysicsSystem2D.instance.enable = true; Draw physics debugging information To enable draw debugging information, use the debugDrawFlags. The physics system provides a variety of debugging information, you can combine the information to draw the relevant content. PhysicsSystem2D.instance.debugDrawFlags = EPhysics2DDrawFlags.Aabb | EPhysics2DDrawFlags.Pair | EPhysics2DDrawFlags.CenterOfMass | EPhysics2DDrawFlags.Joint | EPhysics2DDrawFlags.Shape; Set the drawing flag to EPhysics2DDrawFlags.None to disable drawing. PhysicsSystem2D.instance.debugDrawFlags = EPhysics2DDrawFlags.None; Converting physics units to the world coordinate system units General physics modules (Box2D) uses Metre-Kilogramme-Second (MKS) unit system, it has the best performance operating under such a unit system. But we use the world coordinate system units (short for world units) as the unit of length in 2D games, so we need a ratio to convert the physics units to the world units. In general, set this ratio to 32, which can be obtained by cc.PhysicsManager.PTM_RATIO, and this value is read-only. Usually the user does not need to care about this value, the physics system will automatically convert the physics units and world units to each other. User can use the familiar world units for all the calculations. Set physics gravity Gravity is a very important thing in physics operations, and most physics games use the gravity as a important feature. The default gravity is (0, -320) world units per second^2, according to the conversion rules described above, that's (0, -10) m/s^2 in physics unit. Gravity can be set to 0. Example: PhysicsSystem2D.instance.gravity = cc.v2(); It is possible to change the acceleration of gravity to something else, such as a 20 m/s. Example: PhysicsSystem2D.instance.gravity = cc.v2(0, -20 * PHYSICS_2D_PTM_RATIO); Set physics timestep The Physics System updates the physics world according to a fixed timestep, the default timestep is 1/60. But some games may not want to follow such a high frequency to update the physics world, after all, this operation is more time consuming, then you can reduce the timestep to achieve this effect. const system = PhysicsSystem2D.instance; // Physics timestep, default fixedTimeStep is 1/60 system.fixedTimeStep = 1/30; // The number of iterations per update of the Physics System processing speed is 10 by default system.velocityIterations = 8; // The number of iterations per update of the Physics processing location is 10 by default system.positionIterations = 8; Note: reducing the fixed timestep and the number of iterations for each property will reduce the physics detection frequency. Therefore, it is more likely to occur rigid body penetration, which needs to be taken into account when using. Querying physics object Often, knowing which physics objects are in a given scene is beneficial. For example, if a bomb explodes, objects in its range will be damaged; or in a strategy game, you may want to let the user drag to move a unit from a certain range. The physics system provides several ways to efficiently and quickly look for objects in a region, each of which uses different ways to query objects that fit the needs of the game. Point test The point test will test if there's a collider contains a specific point under the world coordinate system. If the test is successful, it will return the collider. If there're multiple collider that contains the point, a random one will be returned. const collider = PhysicsSystem2D.instance.testPoint(point); Rectangle test The rectangle test will test a specified rectangle in the world coordinate system, and if the bounding box of a collision body overlaps with this rectangle, then the collision body will be added to the return list. const colliderList = PhysicsSystem2D.instance.testAABB(rect); Ray test The Box2D physics module (not available in the Builtin module) also provides ray detection to detect which collision bodies a given line segment passes through. We can also obtain the normal vector at the point where the given line passes through and other useful information. const results = PhysicsSystem2D.instance.rayCast(p1, p2, type, mask); for (const i = 0; i The third parameter of the rayCast function specifies the type of detection, and the ray detection supports four types. This is because the ray detection of Box2D is not detected from the nearest object of the ray starting point, so the result of the test can not guarantee that the result is sorted by the distance from the object near the start of the ray. Cocos Creator's physics system will determine whether the Box2d test results are sorted based on the type of detection. This type will affect the result return to user. ERaycast2DType.Any Detect any collider on the ray path. Once it detects any collider, it will immediately end the detection process and will no longer detect other objects. ERaycast2DType.Closest Detect the nearest collider on the ray path, which is the default for the rayCast detection, slightly slower than above method. ERaycast2DType.All Detect all colliders on the ray path, the order of the detected results is not fixed. In this type of detection, a collider may return multiple results because Box2D run the detection by testing the fixture, and a collider may consist of multiple fixtures. This is a more costly method and will be slower than above methods. ERaycast2DType.AllClosest All colliders on the ray path are detected, but the return result is filtered and only the relevant information about the nearest point of each collider is returned, the slowest method of all. The result of ray detection The results of ray detection contain a lot of useful information, you can utilize these info according to the actual need. collider Specifies which collider the ray passes through. point Specifies the point at which the ray intersects the collider. normal Specifies the normal vector of the surface of the collider at the intersection. fraction Specifies the score of the intersection point at the ray. The following figure helps to better understand the result of ray detection. "},"physics-2d/physics-2d-rigid-body.html":{"url":"physics-2d/physics-2d-rigid-body.html","title":"2D Rigid Body","keywords":"","body":"Rigidbody Rigidbody is the basic object that composite the physics world. The built-in 2D physics system only has collision detection capabilities, the rigid body is not available to the built-in 2D physics system. This setting is available only for other 2D physics systems. Rigidbody properties Mass The mass of a Rigidbody is automatically calculated by the density and size of the PhysicsCollider Component. This property may be needed when calculating how much force the object should be subjected to. // Get the mass of the rigidbody const mass = rigidbody.getMass(); Velocity // Get the velocity of the move const velocity = rigidbody.linearVelocity; // Set the velocity of the move rigidbody.linearVelocity = velocity; Linear Damping is used to simulate the air friction and other damping effects, it will make the current velocity decrease over time. // Get the moving speed attenuation factor const damping = rigidbody.linearDamping; // Set the moving speed attenuation factor rigidbody.linearDamping = damping; To get the velocity of a point on a rigidbody, such as a box that rotates forward and touches the wall. It may be desirable to get the velocity of the box at the point of the collision. You can get it by getLinearVelocityFromWorldPoint. const velocity = rigidbody.getLinearVelocityFromWorldPoint(worldPoint); Or, pass in a cc.Vec2 object as the second argument to get the return value in order to use the cached object to store this value. This avoids creating too many objects to improve performance. Note: the get method of rigidbody provides an out parameter to receive the function return value. const velocity = cc.v2(); rigidbody.getLinearVelocityFromWorldPoint(worldPoint, velocity); Angular Velocity // Get the angular velocity const velocity = rigidbody.angularVelocity; // Set the angular velocity rigidbody.angularVelocity = velocity; Travel speed decay coefficient, the larger the value the slower the object moves, and can be used to simulate effects such as air friction. // Get the angular damping const damping = rigidbody.angularDamping; // Set the angular damping rigidbody.angularDamping = damping; Rotation, position and scaling Rotation, position and scaling are the most commonly used transform in game development, and almost every node has these properties set. In the physics system, the system will automatically synchronize these properties of the node to Box2D corresponding properties. Notes: There is only rotation and position in Box2D and there is no scaling, so if you set the scale properties of the node, all the colliders of the Rigidbody are reconstructed. One way to avoid this is to take the renderer node as a child node of the Rigidbody node, and to scale only the renderer node, to avoid scaling the Rigidbody nodes as much as possible. At the end of each update of the physics system (which is updated in postUpdate), all rigid body information is synchronized to the corresponding node. all Rigidbody information is synchronized to the corresponding node. In the performance considerations, the node information will be synchronized to the rigid body only if the developer sets the display properties of the node where the rigid body is located, and the rigid body will only monitor the node where it is located, i.e. if the rotation shift of the node's parent node is modified, the information will not be synchronized. Fixed rotation When making a platform action game usually we do not want the player character to rotate due to physics forces. Since it will lead to the player character to lean and even fall in the process of moving around, then the fixedRotation of the rigid body can be set to true to fix the rotation. rigidbody.fixedRotation = true; Enable Contact Listener Only when the Rigidbody's contact listener is enabled, it will send callback to component attach to the node when collision happens. Rigidbody.enabledContactListener = true; Rigidbody type There are three types of Box2d's native Rigidbody: Static, Dynamic, Kinematic. We added a forth type in Cocos Creator's physics system: Animated。 Animated is derived from the Kinematic type, the general Rigidbody type changes rotate or position by setting the properties directly, but Animated type will lerp the property values between current property and target property, and assign it to the corresponding property. Animated type is invented mainly to prevent the weird behavior such as penetration when making movement animation on Rigidbody node. cc.RigidBodyType.Static Static Rigidbody, zero mass, zero velocity, that is not affected by gravity or force, but can set its position to move. cc.RigidBodyType.Dynamic Dynamic Rigidbody, with mass, its velocity can be set, will be affected by gravity. cc.RigidBodyType.Kinematic Kinematic Rigidbody, zero mass, its velocity can be set, will not be affected by gravity, but can move by setting the velocity. cc.RigidBodyType.Animated Animated Rigidbody, previously mentioned above, is derived from Kinematic type, mainly used for Rigidbody and animation in combination. Rigidbody API Get or convert the rotation and position property Using these api to get the rotation and position in the world coordinate system will be faster than getting the relevant properties through the node, because the nodes also need to get the results through the matrix operation, and these api gives you the direct result. Local coordinates and world coordinate transformation // world coordinates to local coordinates const localPoint = rigidbody.getLocalPoint(worldPoint); // or localPoint = cc.v2(); rigidbody.getLocalPoint(worldPoint, localPoint); // local coordinates to world coordinates const worldPoint = rigidbody.getWorldPoint(localPoint); // or worldPoint = cc.v2(); rigidbody.getLocalPoint(localPoint, worldPoint); // local vector to world vector const worldVector = rigidbody.getWorldVector(localVector); // or worldVector = cc.v2(); rigidbody.getWorldVector(localVector, worldVector); const localVector = rigidbody.getLocalVector(worldVector); // or localVector = cc.v2(); rigidbody.getLocalVector(worldVector, localVector); Get the rigidbody mass center When force is applied to a Rigidbody, the mass center of the Rigidbody is generally chosen as the point of application of the force, which ensures that the force does not affect the rotation value. // Get the mass center in the local coordinate system const localCenter = rigidbody.getLocalCenter(); // or through the parameters to receive the return value localCenter = cc.v2(); rigidbody.getLocalCenter(localCenter); // Get the mass center in the world coordinate system const worldCenter = rigidbody.getWorldCenter(); // or through the parameters to receive the return value worldCenter = cc.v2(); rigidbody.getWorldCenter(worldCenter); Force and impulse There are two ways to move an object: Apply a force or impulse to the object. The force will slowly change the velocity of the object over time, and the impulse will immediately modify the velocity of the object. It is possible to directly modify the location of the object, but this does not give you the real physics simulation, you should try to use force or impulse to move a Rigidbody to make the physics world more consistent. // Apply a force to the point specified on the rigidbody, this point is a point in the world coordinate system rigidbody.applyForce(force, point); // or apply force directly to the mass of the rigid body rigidbody.applyForceToCenter(force); // Apply a punch to the point specified on the rigid body, this point is a point in the world coordinate system rigidbody.applyLinearImpulse(impulse, point); Force and impulse can also affect the rotation only, this kind of force is called torque. // Apply torque to rigidbody. because it only affects the rotation, so no longer need to specify a point rigidbody.applyTorque(torque); // Apply the impulse on the rotating shaft to the rigidbody rigidbody.applyAngularImpulse(impulse); Other Information Sometimes you need to get the velocity of a Rigidbody at a certain point, you can get by getLinearVelocityFromWorldPoint API, such as when the object collides with a platform, we need to determine whether the object is colliding from top or bottom of the platform according to the velocity of the collision point relative to the platform. rigidbody.getLinearVelocityFromWorldPoint(worldPoint); "},"physics-2d/physics-2d-collider.html":{"url":"physics-2d/physics-2d-collider.html","title":"2D Physics Collider","keywords":"","body":"Physics Collision Components Physics Collision Component Properties sensor - specifies whether the collider is a sensor type. A sensor type collider will produce collision callbacks, but no physics collision effects will occur. density - density of colliding bodies. Mass calculation for rigid bodies. friction - friction of colliding bodies. The movement of colliding bodies is influenced by friction when they touch. restitution - restitution of colliding bodies. Indicates whether the colliding body is affected by the elasticity of the collision. Box2D Physics Collision Component Interior Details The Box2D physics collision component is composed of the Box2D b2Fixture internally. Due to some limitations within Box2D, a polygon physics collision component may be composed of multiple b2Fixtures objects. A few examples: When the vertices of a polygonal physics collision component form a concave shape, the physics system automatically divides these vertices into convex edges. When the polygon physics collision component has more vertices than b2.maxPolygonVertices (typically 8), the physics system automatically splits these vertices into multiple polygons. Normally these details are of no concern, but when using ray detection and the detection type is ERaycast2DType.All, a collision body may detect multiple collision points because multiple b2Fixtures are detected. Edit Collider Component Click the editing checkbox of a collider component to edit collider shape freely. Polygon Collider For editing Polygon Collider all green points of the collider can be moved freely by dragging. All changes to the points can be seen in Points property of Polygon Collider. Moving the mouse over the line between two points, the mouse pointer changes to Add style. Then clicking the mouse to add a new point to the Polygon Collider. The polygon collision component also has a Regenerate Points function. This function automatically generates the vertices of the contour based on the pixels of the Sprite component's texture on the node to which the component is attached. Threshold specifies the minimum distance between the vertices of the generated map contour, the larger the value the fewer points are generated, and can be adjusted as desired. Circle Collider Enable editing for a Circle Collider will show the circle editing area like below: Left mouse button dragging the displayed dots modifies the radius of circular collision components. Dragging an area inside a circle can drag a circular area. Box Collider Enable editing for a Box Collider will show the box editing area like below: When the mouse is hovering over the points of the box collider, clicking the left mouse button and drag to modify the length and width of the box collider component. When the mouse is hovering over the rectangular collision area, clicking and dragging will modify the offset of the rectangular collision component. While holding down Alt, the rectangular center point position will remain unchanged during dragging. Modifying the Collision Component Offset In the editing mode of all kinds of Colliders you can drag the center of the collider to move it off the center of the node. The Offset property of the collider will change as well. "},"physics-2d/physics-2d-contact-callback.html":{"url":"physics-2d/physics-2d-contact-callback.html","title":"2D Contact Callback","keywords":"","body":"Contact Callback When a physics object moves in the scene and collides with other objects, Box2D will handle most of the necessary collision detection and behavior. But the main point of making a physics game is what would happen when an object collides with something: such as a character encounters a monster should lead to damage taken, or when the ball hits the ground it should produce a sound. Besides the engine tells us when a collision happens, we also need a way to get these collision information. The physics engine provides contact callback when the collision happens. In the callback we can get the information from callback argument that we can determine what happened and what action needs to be done next. Notes: First, set Enable contact listener in the Rigidbody component properties. The corresponding callback will be generated. The information in the argument of callback function is fetched from the cache of the physics engine, so the information is only accessible in the current callback. Do not store the reference to those parameters in your script, but rather copy the data to local variables for later use. If creating a physics object (rigidbody, joint or collider) in the callback function, the corresponding Box2D objects will not be created immediately along these objects. The creation of physics object will be done after a physics time step completes. Define a callback function There are two ways to register a collision callback function, either through the specified collider or through a global callback function registered with the 2D physics system. Note: the built-in 2D physics module will only send BEGIN_CONTACT and END_CONTACT callback messages. @ccclass('TestContactCallBack') export class TestContactCallBack extends Component { start () { // Registering callback functions for a single collider let collider = this.getComponent(Collider2D); if (collider) { collider.on(Contact2DType.BEGIN_CONTACT, this.onBeginContact, this); collider.on(Contact2DType.END_CONTACT, this.onEndContact, this); collider.on(Contact2DType.PRE_SOLVE, this.onPreSolve, this); collider.on(Contact2DType.POST_SOLVE, this.onPostSolve, this); } // Registering global contact callback functions if (PhysicsSystem2D.instance) { PhysicsSystem2D.instance.on(Contact2DType.BEGIN_CONTACT, this.onBeginContact, this); PhysicsSystem2D.instance.on(Contact2DType.END_CONTACT, this.onEndContact, this); PhysicsSystem2D.instance.on(Contact2DType.PRE_SOLVE, this.onPreSolve, this); PhysicsSystem2D.instance.on(Contact2DType.POST_SOLVE, this.onPostSolve, this); } } onBeginContact (selfCollider: Collider2D, otherCollider: Collider2D, contact: : IPhysics2DContact | null) { // will be called once when two colliders begin to contact console.log('onBeginContact'); } onEndContact (selfCollider: Collider2D, otherCollider: Collider2D, contact: : IPhysics2DContact | null) { // will be called once when the contact between two colliders just about to end. console.log('onEndContact'); } onPreSolve (selfCollider: Collider2D, otherCollider: Collider2D, contact: : IPhysics2DContact | null) { // will be called every time collider contact should be resolved console.log('onPreSolve'); } onPostSolve (selfCollider: Collider2D, otherCollider: Collider2D, contact: : IPhysics2DContact | null) { // will be called every time collider contact should be resolved console.log('onPostSolve'); } } The above code example demonstrates how to add all the collision callback functions to a script. There are four types of callbacks, each callback function has three parameters, see Callback parameters below for details. The role of each callback function is shown in the comments, and developers can implement their own callback functions according to their needs. Callback Order The callback order and timing of a collision callback function can be viewed by splitting a simple example collision. Assume that two rigid bodies are moving towards each other, the triangle to the right and the box to the left, and are about to collide. Collision Procedure Collision 1 Collision 2 Collision 3 When two colliders intersect with each other, Box2D's default behavior is to give them an impulse so that they can get away with each other. But the behavior may not be complete in a single physics cycle. As shown here, the colliders in the example will cover each other for three physics cycles until the \"bounce\" is complete and they are separated from each other. In this time we can customize the behavior we want. onPreSolve will call back each time before the physics engine processes a collision. You can modify the crash information in this callback. onPostSolve will call back after the collision is processed. In this callback we can get information about the impulse of the collision as calculated by the physics engine. The below output log shows the exact callback order of the example. ... Step Step BeginContact PreSolve PostSolve Step PreSolve PostSolve Step PreSolve PostSolve Step EndContact Step Step ... Callback parameters The callback parameters contain all the collision contact information, and each callback function provides three parameters: selfCollider: refers to the collider on the node of the callback script. otherCollider: refers to the other collider. contact: it's an interface of the class PhysicsContact. Contains the most important information about the collision. Some useful information in contact object are location of the collision and the normal vector. contact store location information according to rigidbody's local coordinate system. What we need however is information from world coordinate system. We can use contact.getWorldManifold to get these information. Note that the builtin physics module parameter is null. worldManifold Obtaining the worldManifold: const worldManifold = contact.getWorldManifold(); const points = worldManifold.points; const normal = worldManifold.normal; worldManifold has the following: points The array of contact points, they are not necessarily at the exact place where the collision happens as shown below (unless you set the rigidbody to use the bullet type, but will be more performance costing). By for general usage these points are accurate enough for us to write game logic upon. Note: not every collision will have two contact points, in more simulation cases only one contact point will be produced. The following lists some other examples of the collision. normal The normal vector on the contact point is from selfCollider to otherCollider, indicating the quickest direction to resolve the collision. The lines shown in the figure is the normal vectors on the contact point. In this collision, the quickest way to solve the collision is to add the impulse to push the triangle to the top and push the box down to the right. The normal vector here is only about the direction, not with the location properties, nor with connection to any of these contact points. It is also necessary to understand that the collision normal vector is not the same as the angle in which two object collides. It will only be able to point the direction which can solve the two colliders intersecting with each other. For example, in the above example, if the triangle moves a little faster, the intersection will be shown below: Then the quickest way would be to push the triangle to the right, so using the normal vector as the direction of collision is not a good idea. To know the true direction of the collision, use the following to get the relative velocities of two colliding bodies at the point of collision when they collide with each other. const vel1 = triangleBody.getLinearVelocityFromWorldPoint(worldManifold.points[0]); const vel2 = squareBody.getLinearVelocityFromWorldPoint(worldManifold.points[0]); const relativeVelocity = vel1.sub(vel2); Disabling contact contact.disabled = true; Disabling the contact will cause the physics engine to ignore the contact when calculating the collision. Disabling will continue until the collision is completely resolved unless the contact is enabled in other callbacks. To disable contact in the current time step, use disabledOnce。 contact.disabledOnce = true; Modify contact information To modify the contact information in onPreSolve because onPreSolve is called before the physics engine handles the contact information. Changes to the contact information will affect the subsequent collision calculations. // Modify the friction between the collision bodies contact.setFriction(friction); // Modify the elasticity of the collision body contact.setRestitution(restitution); Note: these changes will only take effect within the current time step. "},"physics-2d/physics-2d-joint.html":{"url":"physics-2d/physics-2d-joint.html","title":"2D Physical Joints","keywords":"","body":"Joint The physics system contains a series of Joint components for linking two rigidbodies. Joint components can be used to simulate the interaction between real objects, such as hinges, pistons, ropes, wheels, pulleys, motor vehicles, chains and so on. Learning how to use joint components can effectively help create a truly interesting scene. Note: joint components are invalid in the Builtin 2D physics module. The following joints are available in the physics system: Distance Joint - The anchors of two rigidbodies at both ends of the joint will keep a certain distance. Fixed Joint - Hold two points on two objects together according to their initial angles of view. Hinge Joint - Think of it as a hinge or a nail, where the rigid body rotates around a common point. Relative Joint - Control the relative motion between two rigid bodies Slider Joint - The angle between two rigid body positions is fixed, and they can only slide in one specified axis. Spring Joint - Connects objects at both ends of the joint like a spring. Wheel Joint - Consist of Revolute and Prismatic joint, used to simulate motor vehicle wheels. Common properties of joints Although each joint has a different behavior, they have some common properties. connectedBody - the rigidbody connected on the other end of the joint. anchor - the anchor of the rigidbody on the same node of the joint. connectedAnchor - the anchor of the rigidbody connected at the other end of the joint collideConnected - whether the rigidbody at both ends of the joint can collide with each other Each joint need to link two rigidbodies to work. The one on the same node of the joint and the one on another node, which will be assigned to connectedBody property. Usually, each rigid body chooses a location around itself as an anchor point. Depending on the type of joint component, the anchor point determines the center of rotation of the object, or a coordinate point to hold a certain distance, etc. collideConnected property is used to determine if the rigid bodies at both ends of the joint need to continue to follow the normal collision rules. For example, when ready to make a ragdoll, you may want the upper and lower leg can be partially intersected, and then linked at the knee joint. You will need to set collideConnected property to false. If you are making a lift, you may want the lift platform and floor to collide, then you need to set the collideConnected property to true. "},"ui-system/components/engine/":{"url":"ui-system/components/engine/","title":"UI","keywords":"","body":"UI Architecture The UI rendering is based on a tree structure. The Canvas node (a node with Canvas component) is the root of UI. All ui nodes must be under the Canvas node to be rendered. The UITransform is the necessary condition that each UI node must have for a click or alignment strategy, etc. to take effect. The UI supports 2D & 3D camera hybrid sorting. Control the sorting by switching the rendering mode and adjusting the priority property on the component. The UI also supports model rendering, the only condition being that a node with the model components (such as MeshRenderer/SkinnedMeshRenderer) must add UI/Model component before it can be rendered on the same pipeline as the UI. The UI rendering process as follows: Get Started with UI The UI is a necessary interaction part of game development. The buttons, labels, backgrounds and so on in the game are usually made through the UI. When you start making a UI, the first thing you need to confirm is the size of the display area (Design resolution) of the current design, which can be set in the Project -> Project Setting -> General panel of the menu bar: Now that your design resolution is setup, you can start creating the UI elements. All UI elements are contained under the Canvas node, you can create a Canvas node by clicking the + button at the top left of the Hierarchy panel, and then select the UI -> Canvas. There is a Canvas component on the Canvas node, which automatically creates a camera inside. You can achieve true interspersed rendering between 3D camera and 2D camera by adjusting the RenderMode property on Canvas. And then adjust the display priority between multiple camera with the priority property on the component of Canvas/Camera. Note: there can be more than one Canvas node in a scene, but the Canvas should not be nested under another Canvas or its child nodes. Next, you can create the UI nodes under the Canvas nodes. There are several UI nodes that come with the editor are as follow: You can view UI components by checking the node and then clicking on the Add Component in the Inspector panel. The components in UI -> Render belong to the UI renderer component and the others are UI functional components. The UI renderer component uses Breadth-First Sorting scheme, that is, the order of child nodes under the Canvas already determines the subsequent Rendering Order, but you can modify the rendering order with priority property of the renderer component. For nodes without renderer component, you can add a component with only sorting function to sort by selecting Add Component -> UI -> Reorder in the Inspector panel. In general game development, the necessary UI elements are usually Sprite, Label, Mask, Layout, Widget, etc. Sprite and Label are used for rendering image and text. Mask is mainly used to limit the display content, some commonly used places are chat boxes and backpacks, and so on. Layout is mainly used for layout, generally used for single arrangement of buttons, neat arrangement of props in backpacks, etc. The last more important is the Widget, which is mainly used for display alignment. This may involve the multi-resolution adaptation function. When we design the UI and publish it to different platforms, the actual device resolution of the platform will inevitably be different from our design resolution. In order to adapt, we need to do Some trade-offs. For example, the headshot frame cannot be scaled, but we also hope that it will not be greatly affected by the device. Then you can add a Widget component and always ensure that it is aligned at the upper left of our design resolution. Please refer to the Widget Alignment and Widget Component documentation for details. When our interface is finished, you may find out how the display effects of iPhone7 and iPhoneX are different. This is actually a problem with the device resolution, as previously mentioned. When you design at the design resolution and publish at the device resolution, because the device resolution of different mobile phones may be different, the problem of pixel deviation may occur. Therefore, you also need to do screen adaptation. As you can see on the Project -> Project Setting -> General -> Default canvas setting page of the menu bar, there are two other options, Fit Width and Fit Height. According to the screen adaptation rules provided by Cocos Creator, and combined with the Widget component, you can easily adapt to different devices. Please refer to the Multi-Resolution Adaptation documentation for details. UI Rules Introduction Rendering Order Multi-Resolution Adaption Widget Alignment Label Layout Auto Layout Container List with data Stretchable UI Sprite UI Static Batching UI Custom Material "},"ui-system/components/engine/priority.html":{"url":"ui-system/components/engine/priority.html","title":"Rendering Order","keywords":"","body":"Rendering Order 1. UI node ordering The rendering order of the UI uses the Breadth-First Sorting scheme, and each UITransform component has a priority property. Adjust the order of nodes according to the value of priority. Sorting starts from the child nodes under the root node, and determines the overall rendering structure according to the priority of the child nodes, that is, the rendering order of the child nodes under the root node has determined the final rendering order. The priority property of all child nodes under each node is used to determine the rendering order under the current node. For example: Therefore, the overall rendering order in the figure above is B -> b1 -> C -> A -> a1 -> a2, and the rendering state on the screen is a2 -> a1 -> A -> C -> b1 -> B. 2. Mixed camera sorting The UI camera has the highest priority when it was originally designed, that is, the UI camera content is only drawn after all 3D content is drawn. However, this will cause a problem. Once the UI camera has a background or large icon, it will block the 3D content. Therefore, a mixed sorting function between cameras is essential. The key factor of the mixed sorting of the UI camera and the 3D camera is here in the UI camera. Therefore, the Canvas on the root node of the UI, which is the Canvas node, provides a property called RenderMode to distinguish the sorting method.Next, talk about the role of the RenderMode option: When the selection mode is OVERLAY, it means that the UI camera will always be behind the 3D camera, which means will always cover the rendering content of the 3D camera. Multiple UI cameras select this mode, and use the attribute Priority to sort between UI cameras. When the selection mode is INTERSPERSE, it is possible to mix and sort with the 3D camera. The sorting method between UI camera and the 3D camera is done by setting Priority on the Canvas\\Camera component. Detailed Explanation Sorting is a very simple function, but the final rendering is based on the rendering capabilities provided by different platforms. Therefore, explain here. If you encounter an error in UI rendering, such as flickering or unwanted artifacts or other please consider the following. The first thing to check is the ClearFlag of all cameras (Camera and Canvas) in the scene, and make sure that the lowest Canvas or Camera's ClearFlag property is set to SOLID_COLOR in each scene. To set the ClearFlag property, please refer to the following situations: If there is only one 2D Canvas or 3D Camera in the scene, then the ClearFlag property is set to Solid_Color. If the scene contains 2D background layer, 3D scene layer, 2D UI layer, then: 2D background layer: ClearFlag property is set to Solid_Color. 3D scene layer: ClearFlag property is set to Depth_Only. 2D UI layer: If the model is included, the ClearFlag property is set to Depth_Only to avoid a model splash screen. If no model is present, the ClearFlag property can be set to Dont_Clear/Depth_Only. "},"ui-system/components/engine/ui-batch.html":{"url":"ui-system/components/engine/ui-batch.html","title":"UI Batch","keywords":"","body":"UI Batch Rules The rules for UI batching are the same hash material and image and sampler for batching. The same hash means that even if the same material is used, if their hash values ​​are different, the batch will be interrupted. For example, two materials involve the modification of Uniform, resulting in failure to batch. Sprite and text are the same because their images are different. Of course, it can be done under strict control, but this is another story. UI rendering data collection is based on the Hierarchy, so in the process of recursive Hierarchy, if you encounter the three components UIMeshRenderer, Mask, Graphics and the above situation, the batch will be interrupted. Therefore, we recommend that the images of different modules be batched separately to reduce DrawCall. However, if you want to batch a large amount of data, you need to strictly layout the nodes. "},"ui-system/components/engine/multi-resolution.html":{"url":"ui-system/components/engine/multi-resolution.html","title":"Multi-Resolution Adaption","keywords":"","body":"Auto fit for multi-resolution Cocos Creator still provides the solution to adapting to screens with various resolutions with one set of assets. Generally speaking, we realize the adaptation scheme for multi-resolution through the following technology: Canvas component immediately obtains the actual resolution of the device screen and appropriately adjusts the size of all the render elements in the scene. Widget component add to UI nodes. It can align the element with different referential positions of the target node(e.g. The default is the parent node) according to different needs. Label component has a built-in function that provides various dynamic layout modes. When the bounding box of labels change because of the alignment requirement of the Widget, labels will present the perfect layout effect according to your needs. Sliced Sprite provides images whose size can be arbitrarily designated. Simultaneously, it can meet various alignment requirements and display images with high definition on screens of any resolution. Next, start off by getting to know the concepts of design resolution and screen resolution, then we will go on to learn the zooming in/out function of the Canvas component. Design resolution and screen resolution Design resolution is the resolution sample used by content creators when creating the scene. But screen resolution is the actual resolution of the device that the game is running on. Normally, design resolution will use the screen resolution of the device that is being used the most by the targeted group on the market, such as: screen resolutions of 800x480 and 1280x720 that are being used by Android devices currently, or screen resolutions of 1136x640 and 960x640 that are being used by iOS devices. Therefore, after designers or directors set up the scene by using design resolution, the game will automatically adapt to the device used by the major targeted group. Then when the design resolution is different from the screen resolution, how could Cocos Creator adapt to the device? Supposing the design resolution is 800x480, designers will create a background image of the same resolution. When design resolution and screen resolution have the same aspect ratio When design resolution and screen resolution have the same aspect ratio, supposing the screen resolution is 1600x960, enlarging the background image to 1600/800 = 2 times will perfectly fit the screen. This is the simplest situation, which will not be discussed in detail here. When the aspect ratio of design resolution is more than that of screen resolution, the height should be adjusted to avoid black borders Supposing the screen resolution is 1024x768, a red frame is used in the following picture to indicate the visible area of the device screen. We use Fit Height mode provided by the Canvas component to make the height of the design resolution automatically cover the height of the screen, i.e., enlarging the scene image to 768/480 = 1.6 times. This is a fairly good adaptation mode when the aspect ratio of the design resolution is more than that of the screen resolution. As illustrated above, although some parts of the background image will be cut down on the two sides of the screen, it can be ensured that no goof or black borders will appear in the visible area of the screen. Then the position of UI elements can be adjusted by the Widget, which makes sure that the UI elements will appear in the visible area of the screen. We will introduce this in detail in the next section, theWidget Align documentation. When the aspect ratio of the design resolution is less than that of screen resolution, the width should be adjusted to avoid black borders Supposing the screen resolution is 1920x960, a red frame is also used in the following picture to indicate the visible area of the device screen. We use Fit Width mode provided by the Canvas component to make the width of the design resolution automatically cover the width of the screen, i.e., enlarging the scene to 1920/800 = 2.4 times When the aspect ratio of the design resolution is relatively small, the use of this mode will cut down some parts of the background image on the upper/lower sides of the screen. No matter how much the aspect ratio of the screen is, all the contents of design resolution will be completely displayed, and black borders are permitted In the last example, supposing the screen has a resolution of 640 x 960. If you want to make sure the background image is completely displayed on the screen, you need to simultaneously open Fit Height and Fit Width in the Canvas component. The zooming in/out proportion of the scene image is calculated according to the smaller dimension in the screen resolution. In the example in the following picture, because the aspect ratio of the screen is less than 1, the zoom ratio will be calculated based on the width, that is, 640/800 = 0.8 times. Under such a displaying mode, there might be black borders on the screen or scene image that exceed the design resolution (goof). Although developers try their best to avoid black borders in general, if you want to make sure all the contents within the scale of design resolution are displayed on the screen, use this mode too. According to the screen aspect ratio, 'Fit Width' or 'Fit Height' will be automatically selected If there is no strict requirement for the content that may be cropped down on the four sides of the screen, you can not enabled any adaptation mode in the Canvas component. At this time, Fit Width or Fix Height will be automatically selected according to the screen aspect ratio to avoid black border. In other words, when the aspect ratio of the design resolution is more than the screen resolution, Fit Height will be automatically opened (as in the first picture above); when the aspect ratio of the design resolution is less than the screen resolution, Fit Width will be automatically opened (as in the second picture above). Canvas component doesn't provide a fit mode that can respectively zoom in/out of the x axis and the y axis, which will distort the image In the Cocos engine, there is a fit mode called ExactFit, which doesn't have black borders, or cut down the image within the scale of design resolution. But the price is the zooming in/out ratio of the scene image to the direction of the x/y axis is different, which will distort the image. Design resolution can only be configured in the project settings The current design mode does not allow multi-resolution coexistence, so the design resolution of multiple Canvas in the project still uses the same set of design resolution and adaptation scheme, and you can configure it in Project -> Project Setting -> General -> Default canvas setting. "},"ui-system/components/engine/widget-align.html":{"url":"ui-system/components/engine/widget-align.html","title":"Widget Alignment","keywords":"","body":"Alignment Strategy To achieve a perfect multi-resolution fit effect, presenting UI elements according to the positions stipulated in the design resolution is not enough. When the width and height of the screen change, UI elements must be able to intelligently sense the positions of the borders of the screen to make sure that they are presenting themselves in the visible area of the screen and being distributed in suitable positions. We can do this with the Widget component. Next, we categorize different alignment workflows according to the categories of elements that need to be aligned: Aligning Buttons and Small Elements with the Border For elements with relatively small areas like a pause menu, gold coins in the game, etc., normally, aligning them by the borders of the screen would be enough. Only a few simple steps are needed: Set these elements as child nodes of the Canvas node in Hierarchy Add the Widget component to element nodes To align something with the bottom left corner of the screen for example, check the Left and Bottom tick boxes in the Widget component. Then set up the distance between the node and the borders of the screen. In the picture below, the left margin is set as 40px, the bottom margin is set as 30px. After setting up the Widget component like this, no matter what the actual screen resolution is, this node element will remain at the bottom left corner of the screen. The distance between the left side of the node's bounding box and left border of the screen remains at 40px. The distance between the bottom of the node's bounding box and the bottom of the screen remains at 30px. Note: the alignment distance provided by the Widget component refers to the border of the bounding box that is located in the same direction as the child node and parent node. For example, Left is ticked on in the above example to align the element with the left border, then the distance between the left border of the child node's bounding box and the left border of the parent node's (i.e., Canvas node, whose bounding box is constantly the same size as the screen) bounding box is the set value 40px. Nest Alignment Elements We just showed how to align something with the border of the screen in the example above. Because the default alignment reference of Widget is the parent node, we can add different node hierarchies and make the nodes on every hierarchy use the auto alignment function. Here is a simple example to explain it. Suppose we have a node hierarchy as follows: In the example above, parent is a panel, and button is a button. We can add Widget component to both of these nodes, and respectively set their alignment distance. For the parent node, the distance of aligning the top left corner of the Canvas node remains at 80px: For the button node, the distance of aligning the top left corner of the parent node remains at 50px: With a workflow like this, we can group UI elements according to their display areas or functions, and elements of a different hierarchy can be aligned according to design. Automatically zooming in/out the size of a node according to alignment requirements In the above example, two borders that simultaneously align on one axis in opposite directions don't exist. If we want to make a panel that fully covers the width of the whole screen, we can simultaneously tick off the alignment switches Left and Right: When simultaneously ticking off the alignment switches in opposite directions, Widget obtains the ability of modifying the Size of the node according to alignment requirements. In the picture above, we ticked off the left and right directions and set up margins, then Widget can dynamically set up the Width property of the node according to the width of the parent node. As a result, no matter how wide the screen is, the distance between the panel and the left & right borders of the screen remains at 100px permanently. Create a node whose size is in accordance with the size of screen Making use of the features of a node that can automatically zoom in/out, we can make the size of the node the same with that of the screen by setting up the Widget component of the node. To make such a node, we should first make sure that the size of the parent node of this node remains the same with that of the screen. The Canvas node is the best choice. Next, set up the Widget component of this node according to the following method: Therefore the size of the node will remain constantly the same with that of the Canvas node when running, i.e., the same as the size of the screen. After being set up like this, the child node of this node can transmit the same screen size by the same settings. What needs to be noted is that because the Canvas node itself has the function of remaining the same size as that of the screen, there is no need to add the Widget component to the Canvas node. Set up percentage alignment distance After the alignment in a certain direction is enabled on the Widget component, in addition to specifying the margin in pixels, we can also input a percentage value (For example: by clicking the symbol circled in the box), therefore, Widget will multiply the width or height of the parent node on the corresponding axis by the input percentage to get the value of the actual margin. Let's take a look at a real example. Take a child node that has been directly put under Canvas as an example. We hope this node panel remains on the right side of the screen and constantly covers 60% of the total height of screen. Therefore, setting up the Widget component according to the following picture will realize this effect: When inputting the margin value when opening alignment direction, Widget can use the pixel unit together with percentage unit according to various needs. For example, input 50% on the Left direction that needs to align with the center of screen and input 20px on the Right direction that needs to align with the right of screen; when calculating the position and size of the child node at last, all the margins will be positioned after being converted to pixel distance according to the size of the parent node. Making use of the percentage alignment distance, we can create UI elements that can zoom in/out infinitely according to the size of the screen. Exerting your imagination, fitting a thousand types of phones with one set of resources will be a piece of cake! Update alignment and optimization strategies for every frame at runtime Widget component is generally used to locate the position of each element when the scene is initialized on the target device, but once the scene is initialized, we often do not need to use the Widget component for alignment. The alignOnce property is used to ensure that the Widget component only performs alignment and positioning at initialization, and no longer consumes time for alignment at runtime. If the alignment mode alignOnce is selected, and the alignment is performed once when the component is initialized, the engine will automatically set the enabled property of the Widget component to false to disable the automatically update for subsequent every frame. If you need to change at runtime, you need to manually set the alignment mode to always. Or when you need to update and align each frame at runtime, manually traverse the Widget that need to be aligned and set their enabled property to true. For scene with many UI elements, ensuring that the alignOnce option of the Widget component is enabled can greatly improve the running performance of the scene. Limitation on the position and size of node When the Widget component enables one or more alignment settings, the position, width and height properties of the node may be restricted and cannot be freely modified through the API or Animation panel. If you need to modify the position or size of the alignment node at runtime, please refer to the Widget Component: Limitation on node position control for details. "},"ui-system/components/engine/label-layout.html":{"url":"ui-system/components/engine/label-layout.html","title":"Label Layout","keywords":"","body":"Label Layout The Label component is one of the key rendering components. You need to learn about how to set up label layout in order to have a perfect display when the UI system adapts to various resolutions and sets up alignment. Alignment of labels in the bounding box Like other renderer components, the layout of the Label component is also based on the size information (contentSize) possessed by the UITransform component, that is, the range specified by the Bounding Box. What is shown in the picture above is the display effect of labels rendered by Label in the blue bounding box. The following properties in Label determines the position of labels in the bounding box: Horizontal Align: the horizontal alignment of labels in the bounding box, which can be chosen from 3 positions: Left, Right, Center. Vertical Align: the vertical alignment of labels in the bounding box, which can be chosen from 3 positions: Top, Bottom, Center. In the figure above, the horizontal alignment position is set to Right, and the vertical alignment position is set to Bottom. It can be seen that the label appears at the bottom of the Bounding Box and is aligned to the right. The developer can modify the two properties above to make other combinations, labels will appear on the corresponding position of the blue bounding box according to the settings. Label Size and Line Height Font Size determines the display size of labels. Its unit is Point (it can also be called 'pound'), which is the size unit for fonts commonly used in most image editing softwares and font editing softwares. For dynamic fonts, Font Size can be zoomed in losslessly. But the display of bitmap fonts will be more and more vague when the set value of Font Size exceeds the font size stipulated by the font. Line Height determines the height occupied by each line when multiple lines of labels display, the unit of which is also Point. The displaying of multiple lines of labels can be carried out by using two methods: When inputting labels in the String property, manually input \\r or \\n Open the Enable Wrap Text property, which will be introduced in detail later Relation of label size and line height: If the values of Font Size and Line Height are the same, labels will occupy the height of the most part of one line. If the value of Font Size is less than that of Line Height, space between multiple lines of labels will be enlarged If the value of Font Size is larger than that of Line Height, space between multiple lines of labels will be narrowed between multiple lines of labels. Overlapping of labels may appear. Overflow The Overflow property determines the array of labels in the bounding box when the content of labels is increased. There are four modes: NONE, CLAMP, SHRINK, and RESIZE_HEIGHT. Only in the latter three modes can the size of the bounding box be adjusted through the Rectangle Transform Tool (or click the keyboard button T) in the upper left corner of the editor or modifying the Size in the Inspector panel or add the Widget component. NONE mode will automatically fix the size of the bounding box according to the text size, line height, etc. Clamp When in Clamp mode, labels will firstly be rendered according to the requirements of alignment type and size, but the parts exceeding the bounding box will be concealed (clamped). Auto Shrink When in auto shrink mode, if labels exceed the bounding box when being rendered according to the original size, the size of the labels will be automatically shrink to display all the labels. Attention! Auto shrink mode will not zoom in on labels to adapt to bounding box. Resize Height Resize height mode will make sure the bounding box of the labels fits the height of the labels, no matter the quantity of the labels' lines. This mode is suitable for displaying paragraphs of labels that don't have the same amount of content. An infinite amount of label content can be displayed in the arbitrary UI field when using this mode together with the ScrollView component. Enable Wrap Text The Enable Wrap Text property of the Label component can switch the auto wrap switch of labels. When Enable Wrap Text is opened, labels will automatically wrap acccording to the width of the bounding box without manual input of \\r or \\n when inputting labels. Note: the Enable Wrap Text property is only available in the CLAMP and SHRINK modes of the label layout mode. In RESIZE_HEIGHT mode, the Enable Wrap Text property is compulsorily opened. Auto Wrap in Clamp Mode When clamp mode opens auto wrap, labels will be wrapped in the allowable scale of the bounding box in priority. Only when not all the words can be displayed after being wrapped will clamp mode function. The following two pictures are taken when Clamp + Enable Wrap Text are opened, the difference of which is the different width of the bounding boxes of the labels; When the width of the bounding box is changing from the left picture to the right picture, labels will be continuously adjusted and wrapped. In the end, the clamped display will appear due to the insufficient height of the bounding box. Auto Wrap in Auto shrink mode Similar to clamp mode, labels will be wrapped in priority when labels exceed the width of the bounding box in auto shrink mode. Only when the width and length of the bounding box are exceeded will the labels be automatically shrink to adapt to the bounding box. Enable Wrap Text of Chinese The auto wrap behavior of Chinese is different from that of English. English is wrapped by the unit of words. Blank space is the smallest unit of wrap adjustment. Chinese is wrapped by the unit of characters. Every character can be wrapped alone. Anchor point of label node The anchor point of a label node and the alignment mode of labels in the bounding box are two concepts that need to be differentiated. In a layout type that needs labels to enlarge the bounding box (e.g., Resize Height), only correct setting up of anchor points can make the bounding box be extended to the expected direction. For example, if you want the bounding box to extend downward, you need to set the y property of Anchor as 1. As shown below: Widget Add a Widget component to the node with the Label component, then you can make various layouts for label nodes relative to their parent nodes. In the above picture, two Label child nodes are added to the background node. After respectively adding the Widget component to them, set the Right property of the Widget for the labels on the left side as 50%, and set the Left property of the Widget for the labels on the right side as 60%, then the multi-column layout of labels in the picture above can be realized. And by setting margins on the Widget, plus the layout type of labels, a flexible and beautiful layout for labels can be easily realized without concrete and minor adjustments to the bounding box. Reference for checking components For properties of the Label component, you can also check Label Component document. "},"ui-system/components/engine/auto-layout.html":{"url":"ui-system/components/engine/auto-layout.html","title":"Auto Layout Container","keywords":"","body":"Auto Layout Container The Layout component can be mounted to any Node, making the node into a container with the auto layout function. The so-called auto layout container can automatically array the child nodes according to certain rules and adjust the container type nodes of its own size according to the sum total of bounding boxes of the node content. For the next layout types, the node structure is as follows: Layout Type Auto layout components have several basic layout types. These can be set up by the Layout Type property, which includes the following types. Horizontal Layout When Layout Type is set to Horizontal, all child nodes will be automatically aligned horizontally and the component will modify the position or height of the node on the y-axis by default. If the child node needs to be placed outside the height range of the Layout node's bounding box, you can uncheck AutoAlignment (as shown above). The situation that the content exceeds the container easily under horizontal sorting, the following measures can be taken as needed. If the container is to adapt to the size of the content, you can set the ResizeMode to Container, which will set the width of the Layout node based on the sum of the widths of the child nodes (Width) (left in the figure below). If the content object is always to remain inside the container, you can set ResizeMode to Children, which will limit the size of the content object to the container (right in the figure below). If you want the child nodes to be aligned upwards on the y-axis, you can add a widget component to the child node and turn on the Top or Bottom alignment mode. Horizontal Direction In the horizontal layout, you can set the horizontal orientation with HorizontalDirection. There are two types of orientation: LEFT_TO_RIGHT and RIGHT_TO_LEFT. The former will arrange the nodes from left to right according to their display order in Hierarchy. The latter will arrange the nodes from right to left according to their display order. Vertical Layout The layout and orientation of vertical layout is almost the same as horizontal layout, only the orientation is different. Grid Layout Layout Type set to Grid will start the grid layout. The grid layout will determine the starting point of the layout based on the combination of HorizontalDirection and VerticalDirection within a fixed container size, and the layout direction based on the StartAxis property. Grid Direction Layout arranges the child nodes in the order in which they are displayed in the Hierarchy, plus the start point and the alignment direction set by the StartAxis property. Start axis Set to either HORIZONTAL or VERTICAL orientation. The former will be aligned horizontally, the latter vertically. Start point The start point is created by combining HorizontalDirection and VerticalDirection. Suppose HorizontalDirection is LEFT_TO_RIGHT and VerticalDirection is TOP_TO_BOTTOM, then the start point is top left. Suppose HorizontalDirection is RIGHT_TO_LEFT and VerticalDirection is BOTTOM_TO_TOP, then the start point is bottom right. Two examples are given in conjunction with alignment directions: If the HorizontalDirection is set to LEFT_TO_RIGHT, VerticalDirection is TOP_TO_BOTTOM and StartAxis is HORIZONTAL. This tells the component to be sorted horizontally starting from the top left of the container (below left). If the currently set HorizontalDirection is RIGHT_TO_LEFT, VerticalDirection is BOTTOM_TO_TOP and StartAxis is VERTICAL, it is telling the component to be sorted vertically starting from the BOTTOM RIGHT of the container (right in the figure below). Grid sorting may also cause the content to exceed the container, which can also be solved by using the Children and Container modes of ResizeMode mentioned in Horizontal Layout. For more information, please refer to the Layout component documentation. "},"ui-system/components/engine/list-with-data.html":{"url":"ui-system/components/engine/list-with-data.html","title":"List with data","keywords":"","body":"Create a list of dynamically generated content We can build and edit static UI interfaces with Scene panel easily, but in real world game project it's not enough. We'll need dynamically generated UI elements with data, such as character selection, inventory and level selection. Prepare data Let's take an inventory interface as example, we need following data structure to generate an item dynamically: Item id Icon id, we can put up a icon id to spriteFrame reference dictionary or array Item name Item price We will introduce how to define a data class and generate those data in Inspector panel. If you're not familiar with component system of Cocos Creator, please start with Workflow of script development documentation. Custom data class For most game project, you can get inventory data from game server. For the simplicity let's define a data class for data structure and input. Let's add a new script ItemList.js and add the following properties: @ccclass('Item') export class Item { @property id = 0; @property itemName = ''; @property itemPrice = 0; @property(SpriteFrame) iconSF: SpriteFrame | null = null; } @ccclass export class ItemList extends Component { @property([Item]) items: Item[] = []; @property(Prefab) itemPrefab: Prefab | null = null; onLoad () { for (let i = 0; i We defined an Item class at the top of the script for storing and easily updating data needed by item. Please notice this class does not extends Component, so it can be defined as a property type for any component. Please refer to the Declare class documentation for additional details. After the Item class definition, we defined a component class. Each script file can only contains one component definition and the component name will be the same as the file name. So the component we define is ItemList. In this component we have a list property which type is Item. This way we can populate the list with data input in Inspector panel. Now let's create an empty node and add ItemList component. We can find Items property in Inspector panel. To populate data, let's give the list a length. Type 3 in the field and you can input data like these: We have our data ready for now, you can also type in more data entries as you wish. If you're making a game with lots of data, please consider using more specialized data source like Excel and database. It's easy to convert such data sources to JSON for Cocos Creator. Make the view for data: Prefab as template Now move on to the view to visualize data, we also need a template resource that can be used to instantiate each item at runtime. We can use Prefab to do this job. Let's create a prefab that looks like this: The child nodes icon, name, price will be used to display icon, item name and price from data. Data binding You can freely customize the prefab as you need, the picture above only shows an example. Now we need a component script to bind the data to the components that show them. Create a new script ItemTemplate.js and add it to the prefab root node. The script contains: @ccclass export class ItemTemplate extends Component { @property public id = 0; @property(Sprite) public icon: Sprite | null = null; @property(Label) public itemName: Label | null = null; @property(Label) public itemPrice: Label | null = null; } Drag all those nodes onto the property fields of ItemTemplate component. Note: we will assign value for id property through script, no data binding needed. Update template display with script Modify ItemTemplate.js script to add function to update the renderer components with input data. Let's add the following to the end of script: // data: { id, iconSF, itemName, itemPrice } init(data: Item) { this.id = data.id; this.icon.spriteFrame = data.iconSF; this.itemName.string = data.itemName; this.itemPrice.string = data.itemPrice; } init method takes a data object and use the data to update each renderer component on bound nodes. Now we can save Item node as a Prefab asset and use it as the template of our item entries. Instantiate template with data Go back to ItemList.js script, and add reference to our Prefab and then instantiate it with data. //... @property(Prefab) itemPrefab: Prefab | null = null; onLoad () { for (let i = 0; i In the onLoad callback method, we traverse each data stored in items in turn, instantiate itemPrefab to generate a new node and add it to the node where ItemList.js is. Then call the init method in ItemTemplate.js to update its display. Now we can add a Layout component to the node that holds ItemList.js through Add Component -> Add UI Component -> Layout under the Inspector panel, and set the following properties: Type: HORIZONTAL Resize Mode: CONTAINER Don't forget to drag and drop item Prefab to itemPrefab property field of ItemList component. You can also add a Sprite component to the node as the background. All steps have been completed. Now itemList node should look like this: Preview Running preview of the scene will get the result like this (the actual look depends on how your template was setup and your data): The Layout component added in previous step is not necessary. We can use it to help putting multiple items in a container in order but you can also use the script program to do that. You can also add a ScrollView component together to display a large amount of content in a limited space. For details of layout methods please read the Auto Layout Container and the ScrollView Component documentation. "},"ui-system/components/engine/sliced-sprite.html":{"url":"ui-system/components/engine/sliced-sprite.html","title":"Stretchable UI Sprite","keywords":"","body":"Use a Sliced Sprite to make a UI image The core design principle of the UI system is to automatically adapt to different device screen sizes. When developing the UI, we need to correctly set the each node's size, and which can be automatically stretched and adapted according to the screen size of the device. To achieve this, we usually use 9-sliced format images to render these nodes. In this way, even if small original images can be used to generate background images that can cover the entire screen. On the one hand, the game package is reduced, and on the other hand, it can be flexibly adapted to different layout requirements. The right side of the picture above displays the texture of original size. The left side displays the effect of choosing Sliced mode and enlarging the size property. Setting up your SpriteFrame for 9-slicing To use a 9-sliced image effect that can be infinitely enlarged, we need to cut the image asset into a 9-slicing at first. First open the Sprite Editor, select the image asset in Assets, then click the Edit button on the bottom of Inspector. If the height of your window is not large enough, you might need to scroll Inspector downward to see the button at the bottom. After opening Sprite Editor, you will see there is a green line around the image, which indicates the position of the current 9-sliced split line. Drag the mouse to the split line, you will see the shape of the cursor change, then you can press down and drag the mouse to modify the position of the split line. We click and drag the four split lines at the top, bottom, and sides respectively and cut the image into a 9-slicing. The nine areas will apply different zooming in/out strategies when the Sprite size changes, which is as illustrated below: And the following picture illustrates the state of zooming in/out in different areas (the picture comes from Yannick Loriot's Blog): After cutting, don't forget to click the green check mark on the upper right corner of Sprite Editor to save modifications to the asset. Set the Sprite component to use Sliced mode After you have prepared the 9-sliced asset, you can modify the draw mode of the Sprite and modify the size to make a UI element that can specify any size. First, select the Sprite node in the Scene/Hierarchy, set the Type property of the Sprite as Sliced in the Inspector. Then drag the control point with the Rect Transform Tool to enlarge the size property of the node. You can also modify the size property value directly in the Inspector. Because the image asset has been set to 9-slicing, no matter how much the Sprite zooms in, there will be no vagueness or distortion. Precautions When using tools or directly modifying the size attribute of Sliced ​​Sprite, note that the size property value cannot be negative, otherwise it cannot be displayed normally in Sliced ​​mode. "},"ui-system/components/engine/ui-material.html":{"url":"ui-system/components/engine/ui-material.html","title":"UI Custom Material","keywords":"","body":"UI Custom Material UI custom material is the best practice to expand UI performance and enhance UI's own capabilities. Cool UI effects such as dissolving and external glow can be achieved through custom materials Sprite component supports UI Custom Material. The user interface is as follows: Using a UI built-in material works the same as custom materials. However, there are few items to take into consideration: When the number of custom materials is set to 0 or empty, the default material will be used. Please refer to the Sprite documentation. UI does not support multiple materials, the number of custom materials is at most one. When the ui custom material is used, the Grayscale function on the panel will be invalid. Users can choose to implement this function in the material. For custom materials, the cc-sprite-texture header file must be introduced in the shader to obtain the uploaded texture. The cc_spriteTexture in it corresponds to the SpriteFrame image resource set on the UI rendering component property panel. For example, a simple fragment shader that uses the panel setting SpriteFrame to sample textures should look like the following: CCProgram sprite-fs %{ precision highp float; #include in vec4 v_color; uniform ARGS{ float time; }; in vec2 uv0; uniform sampler2D u_normalMap; vec4 frag () { vec4 color = vec4(1, 1, 1, 1); color *= v_color; float value = 1.0; vec4 o = texture(u_normalMap, uv0); value *= o.r; if (value To perform uniform assignment operations to custom materials, they can operate by obtaining the material on the Sprite. We provide different interfaces to deal with different operating conditions, as shown in the following code: (Please pay attention to the difference Notes on the interface!) let spriteCom = this.node.getComponent(Sprite); // What is obtained through the sharedMaterial method is a shared material resource, and operations on material will affect all rendering objects that use this material let material = spriteCom.sharedMaterial; // The material trial used by the current rendering component obtained through the material method, the operation for material Instance will only affect the current component let materialInstance = spriteCom.material; "},"editor/components/":{"url":"editor/components/","title":"Components","keywords":"","body":"Components Cocos Creator includes the following Components: AudioSource MeshRenderer SkinnedMeshRenderer Camera DirectionalLight SphereLight SpotLight Animation Billboard Line ParticleSystem BoxCollider SphereCollider RigidBody UI Components "},"audio-system/audiosource.html":{"url":"audio-system/audiosource.html","title":"AudioSource","keywords":"","body":"AudioSource Component Properties |Property | Description | |:-- | :-- | |Clip | The audio resource object to be played | |Loop | Whether to loop | |PlayOnAwake | Whether to play audio automatically after the component is activated | |Volume | Audio volume, ranging from 0 to 1 | For more script interfaces for AudioSource, please refer to AudioSource API.For specific playback controls, please refer to Audio System Overview. "},"engine/renderable/model-component.html":{"url":"engine/renderable/model-component.html","title":"MeshRenderer","keywords":"","body":"Model Component The ModelComponent is used to display a static 3D model. Set the model grid through a mesh, and change the appearance of the model through material. To use MeshRenderer, please refer to the MeshRenderer API. MeshRenderer Properties Property Functions mesh 3D model assets for rendering. materials The material used to render the model, one material corresponds to one submesh in the mesh. shadowCastingMode Whether the model casts shadows. The planar shadow system in the scene should be enabled beforehand. visibility Used for which camera the model will be rendered, only the camera with the same visibility as the model will render the model. Model group rendering The group rendering function is determined by the Visibility property of the camera component and the Layer property of the node. Users can set the Visibility value through code to complete the group rendering. All nodes belong to the DEFAULT layer by default and are visible on all cameras. Note: please review the Camera Component documentation for additional information, if required. Static batching The current static batching scheme is static batching at run time. Static batching can be performed by calling BatchingUtility.batchStaticModel. This function receives a node, and then merges all Mesh in MeshRenderer under that node into one, and hangs it under another node. After batching, the original transform of MeshRenderer cannot be changed, but the transform of the root node after batching can be changed. Only nodes that meet the following conditions can be statically batched: The child node can only contain MeshRenderer. The vertex data structure of Mesh of MeshRenderer under child nodes must be consistent. The material of MeshRenderer under child nodes must be the same. About dynamic batching The engine currently provides two sets of dynamic batching systems, instancing batching and VB-merging batching. The two methods cannot coexist, and the priority of instancing is greater than that of dynamic merging VB. To enable batching, simply check the USE_INSTANCING or USE_BATCHING switch in the material used in the model. Note: batching can participate in the frustum culling process normally, but transparents model cannot be sorted, which will lead to incorrect blending results. The engine does not explicitly prohibit the approval of transparent objects, and developers can control the trade-offs. Instancing batching The batch through instancing is suitable for drawing a large number of dynamic models with the same vertex data. When enabled, drawing will be grouped according to the material and vertex data, and the instanced attributes information will be organized in each group, and then complete the drawing at one time. Note: for the support and related settings of the skinning model, refer to the Skeletal Animation Component documentation. In addition, inside each group, the instanced attributes supports custom additional instanced attributes, which can pass more per-instance data between different instances (such as the difference in appearance of a diffuse color between different characters, or the influence of wind in a large grass field). This requires the support of custom effects. For more detailed instructions, please refer to the Syntax Guide documentation. VB-merging batching VB-merging batching is suitable for drawing a large number of non-skinned dynamic models with low number of faces and different vertex data. When enabled, drawing will be grouped according to the material, and then the vertex and world transformation information will be merged in each frame of each group, and then completed in batches 1. Operations such as merging vertices per frame introduce a portion of CPU overhead, which is particularly expensive in JavaScript. In addition, it is necessary to remind that the number of draw calls is not as low as possible. Although, it is important to note, minimizing the number of draw calls to the extreme doesn't necessarily lead to the best (or even good) performance 2. Optimal performance is often the result of CPU and GPU load balancing, so when using batch functions, be sure to do more tests to identify performance bottlenecks and do targeted optimization. Batch best practices Generally speaking, the priority of the batch system is: static batching -> instancing batching -> VB-merging batching. The material must be insured that it is consistent, under this premise: If you are certain that certain models will remain completely static during the game cycle, use static batching. If there are a large number of the same model repeated drawing, there is only a relatively controllable small difference between each other, use instancing batching. If there are a large number of models with very low number of triangles but different vertex data, consider trying VB-merging batching. Notes: [1] Currently use uniforms to upload the batched world transformation matrix, taking into account the WebGL standard uniform quantity limit, the current batch draws up to 10 models, so for a large number of same For the material model, the number of drawcalls is expected to be reduced by up to 10 times after enabling VB-merging batching. ↩ [2] There have been many discussions in the industry on the topic of batching and performance, you can refer to this nVidia slide. ↩ "},"editor/components/camera-component.html":{"url":"editor/components/camera-component.html","title":"Camera","keywords":"","body":"Camera The Camera in a game is the main tool used to capture Scenes. The visible range of the Camera is controlled by adjusting camera-related parameters. The Camera is represented as follows in the Cocos Creator editor: The Camera's visual range is composed of 6 planes forming a Frustum, a Near Plane, and a Far Plane to control the visible distance and range of near and far distance, at the same time, they also constitute the size of the viewport. To use Camera, please refer to the Camera API. Camera components The Camera Component is an important functional component that we use to present a Scene. Parameter Description ClearFlags Camera clear logo. Contains: DONT_CLEAR: not clear; DEPTH_ONLY: only clear the depth; SLOD_COLOR: clear the color, depth and template buffer Color Clear the specified color Depth Clear the specified depth Stencil Clear the specified template buffer Far Far cutting distance Near Near cutting distance Fov Angle of view OrthoHeight The height of the orthogonal Camera Priority Priority. High-priority Cameras will be rendered first in the rendering process Projection Projection mode. Divided into perspective projection (PERSPECTIVE) and orthogonal projection (ORTHO) Rect Viewport size of Camera Visibility The visibility of the Camera. Used to control the visibility of different models in the same Camera. Camera group rendering The Camera's group rendering function works with the Model Component through the Visibility property of the Camera Component. The user can set the Visibility value through code to complete the group rendering. It should be noted that the Visibility value is bitwise comparison, and the user can manipulate the top 20 bits of Visibility through bit operations to complete the grouping. The Camera and models provided by default are all rendered without grouping. You do not need to change this value if the game has no special requirements to do so. "},"particle-system/billboard-component.html":{"url":"particle-system/billboard-component.html","title":"Billboard","keywords":"","body":"Billboard Component The Billboard component is used to render a box that always faces the camera. Property Description Texture The texture displayed on the billboard. Height The height of billboard. Width The width of billboard. Rotation The angle of rotation of the billboard around the center point. To use Billboard, please refer to the Billboard API. "},"particle-system/line-component.html":{"url":"particle-system/line-component.html","title":"Line","keywords":"","body":"Line Component The Line component is used to render a line segment connected by a given point in a 3D scene. The line segment rendered by the Line component is wide and always faces the camera, which is similar to the billboard component. Properties Features texture The map displayed in the line segment. worldSpace Which coordinate system is used for the coordinates of each point in the line segment, check Use world coordinate system, and deselect use local coordinate system. positions The coordinates of the end points of each line segment. wdith The width of the line segment, if a curve is used, it means the change of the curve along the direction of the line segment. tile Number of texture tiles. offset The offset of the texture coordinates. color The color of the line segment. If a gradient color is used, it indicates the color gradient along the direction of the line segment. To use Line, please refer to the Line API. "},"ui-system/components/editor/":{"url":"ui-system/components/editor/","title":"UI Component Reference","keywords":"","body":"Common UI Controls This document describes commonly used control components in the UI system, the core rendering components, and alignment and layout strategy components. These controls will constitute the most interactive part of our game UI. Some commonly used UI controls can be created by adding nodes. In the upper left corner of the Hierarchy, select UI in the + create node menu to create a UI node, and the corresponding UI component will be automatically mounted on the node: For other UI components, you can manually select the node in the Hierarchy, and then click Add Component -> UI in the Inspector to add: Component Catalog UI components are mainly divided into the following two types: UI Renderer Components UI Basic Components "},"ui-system/components/editor/render-component.html":{"url":"ui-system/components/editor/render-component.html","title":"UI Renderer Component","keywords":"","body":"UI Renderer Components Sprite Component Reference Label Component Reference Mask Component Reference Graphics Component Reference RichText Component Reference UIStaticBatch Component Reference "},"ui-system/components/editor/sprite.html":{"url":"ui-system/components/editor/sprite.html","title":"Sprite Reference","keywords":"","body":"Sprite Component Reference Using Sprite is the most common way to display images in 2D/3D games. By adding the Sprite component to a Node, you can display SpriteFrame assets from project assets. Add a Sprite component to the node by clicking the Add Component button below the Inspector panel and selecting UI -> Render -> Sprite. To use Sprite, please refer to the Sprite API documentation and the sprite scene of the test-cases-3d project. Sprite Properties Property Function Explanation Type Rendering mode, currently includes SIMPLE, SLICED, TILED, FILLED four rendering modes. Materials Custom Material, please refer to UI Custom Material Src Blend Factor The source image blend mode. Dst Blend Factor The destination image blend mode. Together with the above properties, you can mix the foreground Sprite and background in different ways to render, and you can refer to glBlendFunc Tool for an effect preview. Color Image color. Size Mode Specify the size of the Sprite.TRIMMED automatically fit to the size of the sprite croppedRAW automatic fit for sprite original size.CUSTOM use the node preset size. When the developer manually modifies Size properties, Size Mode will be automatically set to Custom. Atlas Auto Atlas which the Sprite display image asset belongs to. Sprite Frame Sprite Frame Assets which is used to render the Sprite. (The Edit button behind Sprite Frame is used to edit the 9-sliced cutting of the image asset, please refer to the Use a Sliced Sprite to make a UI image documentation. Trim Whether the transparent pixel area is included in the node bounding box. Please refer to the Auto Trim for SpriteFrame documentation. Grayscale If enabled, Sprite will be rendered in gray scale mode. After adding the Sprite component, drag the SpriteFrame type asset from the Assets to the Sprite Frame property reference. Then, the asset image can be displayed through the Sprite component. If this SpriteFrame asset is contained within an Atlas asset, then the Atlas property of the Sprite will be set up along with it. Note: to dynamically replace SpriteFrame, you need to dynamically load the image asset before you replace it, please refer to the Acquire and load asset: how to dynamically load documentation. Rendering mode Currently, the Sprite component supports the following rendering modes: Simple mode: rendering the Sprite according to the original image asset. It is normally used along with Use Original Size to guarantee the image shown in the scene is in full accordance with the image designed by the graphic designer. Sliced mode: the image is cut up into a 9-slicing and according to certain rules is scaled to fit freely set dimensions (size). It is usually used in UI elements or to make images that can be enlarged infinitely without influencing the image quality. It will cut up the original image into a grid to save game asset space. Please read Use a Sliced Sprite to make a UI image for details. Tiled mode: The image will be repeated to fit the size of the Sprite. If the SpriteFrame is 9-sliced, the corners will also remain unscaled while the other areas will be repeated. Filled mode: draws a portion of the original image in a certain direction and scale, based on the origin and fill mode settings. Often used for dynamic display of progress bars. Filled mode When the Type property selects FILLED, a new set of properties appears to be configured. So let's explain their roles in turn. Property Function Explanation Fill Type Fill type selection, including HORIZONTAL, VERTICAL, and RADIAL. Fill Start Normalized values for filling starting position (from 0 ~ 1, denoting the percentage of total population), when you select a horizontal fill, the Fill Start is set to 0, and it is populated from the leftmost edge of the image. Fill Range Normalized values for padding ranges (same from 0 ~ 1). When set to 1, it fills up the entire range of the original image. Fill Center Fill center point, this property can only be modified if the RADIAL fill type is selected. Determines which point on the Sprite is used as pivot when the FillType is set to RADIAL. Fill Range Supplemental description Under both the HORIZONTAL and VERTICAL fill types, the values set by Fill Start affect the total number of fills, if Fill Start is set to 0.5, even if Fill Range is set to 1.0, the actual padding is still only half the total size of the Sprite. The Fill Start in the RADIAL type only determines the orientation of the starting fill, when Fill Start is set to 0, start filling from the x axis positive direction. Fill Range determines the total amount of padding, which fills the entire circle when Fill Range is set to 1. A counter anticlockwise fill when Fill Range is positive, and is filled clockwise when negative. "},"ui-system/components/editor/label.html":{"url":"ui-system/components/editor/label.html","title":"Label Reference","keywords":"","body":"Label Component Reference The Label component is used to display texts, the text can use System Font, TrueType Font, or Bitmap Font. In addition, Label also has some basic layout functionalities like alignment, line wrap, auto fit etc. Select a node in the Hierarchy panel, then click the Add Component button at the bottom of the Inspector panel and select Label from UI -> Render to add the Label component to the node. To use Label, please refer to the Label API documentation and the label scene of the test-cases-3d project. Label Properties Property Function Explanation Color Label color. String Text content string. HorizontalAlign Horizontal alignment of the text, including LEFT, CENTER and RIGHT. VerticalAlign Vertical alignment of the text, including TOP, CENTER and BOTTOM. FontSize Font size of the text. FontFamily Font family name (Takes effect when using System Font). LineHeight Line height of the text. Overflow Layout of the text. Currently supports CLAMP, SHRINK and RESIZE_HEIGHT. For details, see Label Layout below or Label Layout document. EnableWrapText Enable or disable the text line wrap (which takes effect when the Overflow is set to CLAMP or SHRINK). Font Specify the font asset used for text rendering. If the System Font is used, then this property can be set to null. UseSystemFont If enabled, the given FontFamily will be used for rendering. CacheMode Text cache mode, including NONE, BITMAP and CHAR. Takes effect only for System Font or TTF Font, BMFont does not require this optimization. See Cache Mode below for details. IsBold If enabled, bold effect will be added to the text. (Takes effect when using System Font or some TTF Font). IsItalic If enabled, italic effect will be added to the text. (Takes effect when using System Font or some TTF Font). IsUnderline If enabled, underline effect will be added to the text. (Takes effect when using System Font or TTF Font). SrcBlendFactor The source blend mode for text rendering. DstBlendFactor The destination blend mode for text rendering. Together with the above properties, you can mix the foreground and background content in different ways, and you can refer to glBlendFunc Tool for the effect. Label Layout Options Function Explanation CLAMP The text size won't zoom in/out as the UITransform contentSize changes.When Wrap Text is disabled, texts exceeding the width will be clipped according to the normal character layout.When Wrap Text is enabled, it will try to wrap the text exceeding the boundaries to the next line. If the vertical space is not enough, any text out of bounds will also be hidden. SHRINK The text size could be scaled down as the UITransform contentSize changes (it won't be scale up automatically, the maximum size that will show is specified by FontSize).When EnableWrapText is enabled, if the width is not enough, it will try to wrap the text to the next line first.Then no matter whether the text is wrapped, if the text still exceed the contentSize of UITransform, it will be scaled down automatically to fit the boundaries.Note: this mode may consumes more CPU resources when the label is refreshed. RESIZE_HEIGHT The UITransform contentSize will be adapted to make sure the text is completely shown in its boundary. The developer cannot manually change the height of text in UITransform, it is automatically calculated by the internal algorithm. Cache Mode Options Function Explanation NONE Defaults, the entire text in label will generate a bitmap. BITMAP Currently it behaves in the same way as NONE CHAR The principle of this mode is similar to BMFont, Label will cache text to a global shared bitmap in characters, each character of the same font style and font size will share the same cache globally. This mode is the most friendly to performance and memory if the characters is limited in a small set. However, there are currently restrictions on this mode, which we will optimize in subsequent releases:1. This mode can only be used for font style and fixed font size (by recording the fontSize, fontFamily, color, and outline of the font as key information for repetitive use of characters, other users who use special custom text formats need to be aware). And will not frequently appear with a huge amount of unused characters of Label. This is to save the cache, because the global shared bitmap size is 1024 * 1024, it will only be cleared when the scene is switched. Once the bitmap is full, the newly appearing characters will not be rendered. 2. Overflow does not support SHRINK. Note: Cache Mode has an optimized effect for all platforms. Use font assets By dragging the TTF font asset and BMFont font asset into the Font property in the Inspector panel, the Label component can alter the rendering font type. If you want to stop using a font file, use the system font again by checking UseSystemFont. "},"ui-system/components/editor/mask.html":{"url":"ui-system/components/editor/mask.html","title":"Mask Reference","keywords":"","body":"Mask Component Reference Mask is used to specify the range which clip the render results of the children. A node with a Mask component will use a bounding box (which is specified by the contentSize of the UITransform component in the Inspector) to create a rectangular rendered mask. All child nodes of this node will only appear inside the mask's boundary. Select a node in the Hierarchy panel, then click the Add Component button at the bottom of the Inspector panel and select Mask from UI -> Render. Then you can add the Mask component to the node. Note: the Mask component cannot be added to a node with other renderer components such as Sprite, Label, etc. To use Mask, please refer to the Mask API documentation and the mask scene of the test-cases-3d project. Mask Properties Property Function Explanation Type Mask type, including RECT, ELLIPSE, GRAPHICS_STENCIL, IMAGE_STENCIL. Segments The segments for ellipse mask, which takes effect only when the Mask type is set to ELLIPSE. Inverted The Reverse mask. SpriteFrame Image used for the type is IMAGE_STENCIL Type RECT ELLIPSE It can also be set by code at runtime. Example: const mask = this.getComponent(Mask); mask.type = Mask.Type.ELLIPSE; mask.segments = 32; GRAPHICS_STENCIL It can also be set by code at runtime. Example: const mask = this.getComponent(Mask); mask.type = Mask.Type.GRAPHICS_STENCIL; const g = mask.graphics; g.lineWidth = 10; g.fillColor.fromHEX('#ff0000'); g.moveTo(-40, 0); g.lineTo(0, -80); g.lineTo(40, 0); g.lineTo(0, 80); g.close(); g.stroke(); g.fill(); IMAGE_STENCIL It can also be set by code at runtime. Example: const mask = this.getComponent(Mask); mask.type = Mask.Type.IMAGE_STENCIL; mask.spriteFrame = this.spriteFrame; mask.alphaThreshold = 0.1; Notes: After adding the Mask component to a node, all nodes in the sub tree of this node will be affected by Mask during rendering. The GRAPHICS_STENCIL simply provides the graphics component, which developers can use graphics property in the mask component to draw custom graphics. But the node click events are still calculated based on the size of the node. The IMAGE_STENCIL type requires a picture resource by default. If it is not set, it is equivalent to no mask. In the current version and previous versions, due to the underlying rendering architecture, the rendering content of all sub-nodes of Mask in the editor is invisible. The solution is to adjust the layer of the Mask node in the editor to default, which will not affect the runtime data. "},"ui-system/components/editor/graphics.html":{"url":"ui-system/components/editor/graphics.html","title":"Graphics Reference","keywords":"","body":"Graphics Component Reference The Graphics component provides a series of drawing functions that reference the Web canvas's drawing APIs. Select a node in the Hierarchy panel, then click the Add Component button at the bottom of the Inspector panel and select Graphics from UI -> Render. Then you can add the Graphics component to the node. To use graphics, please refer to the graphics API documentation and the graphics scene of the test-cases-3d project. Graphic Properties Property Function Explanation FillColor Sets or returns the color used for the fill function. LineCap LineCap determines how the end points of every line are drawn. LineJoin LineJoin determines how two connecting segments (of lines, arcs or curves) with non-zero lengths in a shape are joined together. MiterLimit Sets or returns the maximum miter length. StrokeColor Stroke color. Sets or returns the color used for the stroke. LineWidth Current line width. Graphics API Path Function Function Explanation moveTo (x, y) Move the render cursor to a specified point in the canvas without creating lines. lineTo (x, y) Adds a straight line to the path. bezierCurveTo (c1x, c1y, c2x, c2y, x, y) Adds a cubic Bézier curve to the path. quadraticCurveTo (cx, cy, x, y) Adds a quadratic Bézier curve to the path. arc (cx, cy, r, a0, a1, counterclockwise) Adds an arc to the path which is centered at (cx, cy) position with radius r starting at startAngle and ending at endAngle going in the given direction by counterclockwise (defaulting to false). ellipse (cx, cy, rx, ry) Adds an ellipse to the path. circle (cx, cy, r) Adds a circle to the path. rect (x, y, w, h) Adds a rectangle to the path. close () Close the previous path by connecting the last point and the beginning point. stroke () Stroke the path as lines fill () Close and fill a path's inner surface clear () Erase any previously drawn content. Modify the drawing pattern through script code import { _decorator, Component, Graphics } from 'cc'; const { ccclass, property } = _decorator; @ccclass('Example') export class Example extends Component { start () { const g = this.getComponent(Graphics); g.lineWidth = 10; g.fillColor.fromHEX('#ff0000'); g.moveTo(-40, 0); g.lineTo(0, -80); g.lineTo(40, 0); g.lineTo(0, 80); g.close(); g.stroke(); g.fill(); } } "},"ui-system/components/editor/richtext.html":{"url":"ui-system/components/editor/richtext.html","title":"RichText Reference","keywords":"","body":"RichText Component Reference RichText component could be used for displaying a string with multiple styles. You could customize the text style of each text segment with a few simple BBCode. The currently supported tags are: color, size, outline, b, i, u, br, img and on, these tags could also be nested within each other. For more information about BBCode, please refer to the BBCode format section below. Click the Add Component button at the bottom of the Inspector panel and select RichText from UI -> Render to add the RichText component to the node. To use RichText, please refer to the RichText API documentation and the richText scene of the test-cases-3d project. RichText Properties Properties Function Explanation Font Custom TTF font of RichText, all the label segments will use the same custom TTF font. FontSize Font size, in points (Note: this field does not affect the font size set in BBCode.) HandleTouchEvent Once checked, the RichText will block all input events (mouse and touch) within the bounding box of the node, preventing the input from penetrating into the underlying node. Horizontal Align Horizontal alignment ImageAtlas The image atlas for the img tag. For each src value in the img tag, there should be a valid spriteFrame in the imageAtlas. Font Family Custom system font of RichText. Use System Font Whether to use the system default font. MaxWidth The maximize width of RichText, set to 0 means the maximize width is not limited. LineHeight Line height, in points. String Text of the RichText, you could use BBcode in the string. BBCode format Basics Currently the supported tag list is: size, color, b, i, u, img and on. There are used for customizing the font size, font color, bold, italic, underline, image and click event. Every tag should has a start tag and an end tag. The name and attribute format of the start tag must meet the requirements and be all lowercase. It will check the start tag name, but the end tag name restrict is loose, it only requires a tag, the end tags name doesn't matter. Here is an example of the size and color tag: Hello, Creator Supported tags Note: all tag names should be lowercase and the attribute assignment should use = sign. Name Description Example Note color Specify the font rendering color, the color value could be a built-in value or a hex value. eg, use #ff0000 for red. Red Text size Specify the font rendering size, the size should be a integer. enlarge me The size assignment should use = sign. outline Specify the font outline, you could customize the outline color and width by using the color and width attribute. A label with outline If you don't specify the color or width of outline, the default color value is #ffffff and the default width is 1. b Render text as bold font This text will be rendered as bold The tag name must be lowercase and cannot be written in bold. i Render text as italic font This text will be rendered as italic The tag name must be lowercase and cannot be written in italic. u Add a underline to the text This text will have a underline The tag name must be lowercase and cannot be written in underline. on Specify a event callback to a text node, when you click the node, the callback will be triggered. click me! Except for on tag, color and size tags can also add click event parameter. eg. click me param When the click event is triggered, the value can be obtained in the second attribute of the callback function. click me! Depends on the click event. br Insert a empty line and are both invalid tags. img Add image and emoji support to your RichText. The emoji name should be a valid sprite frame name in the ImageAtlas. Only is a valid img tag. If you specify a large emoji image, it will scale the sprite height to the line height of the RichText together with the sprite width. Optional attribute of img tag For better typography, additional optional attributes to the img tag have been provided. Developers can use width, height to specify the size of the SpriteFrame. This will allow the image to be larger or smaller than the line height (but it will not change the line height). When the height or width of the SpriteFrame changes, The align attribute may need to be used to adjust the alignment of the image in the line. Attribute Description Example Note height Specify the SpriteFrame height size, the size should be a integer. If you only assign height the SpriteFrame will auto keep aspect-ratio width Specify the SpriteFrame width size, the size should be a integer. Use both Height and Width align Specify the SpriteFrame alignment in line, the value should be bottom, top or center. Default SpriteFrame alignment will be bottom To support custom image layout, the offset attribute can be used to fine-tune the position of the specified SpriteFrame in the RichText component. When setting the offset attribute, keep in mind that the value must be an integer, and it will cause the image to overlap the text if it is not set properly. offset attribute Example Description Note Y Specify the SpriteFrame to offset y + 5 If offset only set one Integer value it's will be offset Y Y Specify the SpriteFrame to offset y - 5 Use minus to decrease Y position X, Y Specify the SpriteFrame to offset x + 6 and y - 5 The offset values should only contains 0-9, - and , characters Nested Tags Tags could be nested, the rules is the same as normal HTML tags. For example, the following settings will render a label with font size 30 and color value green. I'm green is equal to: I'm green Cache Mode Since the RichText component is assembled from multiple Label nodes, the number of drawcalls for complex rich text will also be high. Therefore, the engine provides the CacheMode setting of the Label component for the RichText component to avoid the increase of drawcall. For a detailed description of each cache type, please refer to the Cache Mode of the Label component documentation. Attributes Description NONE By default, for each Label node created by RichText, set its CacheMode to NONE, that is, generate a bitmap of the entire text of each Label and render it separately. BITMAP After selection, for each Label node created by RichText, set its CacheMode to BITMAP type, that is, generate a bitmap of the entire text of each Label, and add the bitmap to the dynamic atlas, and then according to the dynamic atlas to assemble and render. CHAR After selection, each Label node created by RichText has its CacheMode set to CHAR type, that is, the text of each Label is cached in a globally shared bitmap in \"words\". Each of the same font style and size is Characters will share a cache globally. Note: the RenderTexture module in the Project -> Project Settings -> Module Config panel cannot be removed when using the cache mode. Detailed Explanation The RichText component is implemented in the JavaScript layer and uses the Label node as the rendering part. All the layout logic goes also in JavaScript layer. This means if you create a very complex RichText, it will end up with many label node created under the hook. And all these label node are using system font for rendering. So, you should avoid modifying the RichText content frequently in your game's main loop, which can lead to lower performance. Also, try to use the normal Label component instead of the RichText component if you can, and BMFont is the most efficient. "},"ui-system/components/editor/ui-static.html":{"url":"ui-system/components/editor/ui-static.html","title":"UIStaticBatch Reference","keywords":"","body":"UIStaticBatch Component References The UIStaticBatch component is used to improve UI rendering performance. The script will collect all the rendering data under the UI node tree (except Model, Mask, and Graphic) during the initialization of the current frame rendering and store it as a static input assembler(IA) rendering data. And rendering with fixed data in the subsequent rendering process, no longer traversing its node tree, after which the coordinate transformation will no longer take effect. To use UIStaticBatch, please refer to the UIStaticBatch API documentation and the UIStaticBatch scene of the test-cases-3d project. Enable static batching through script code. Example: import { _decorator, Component } from \"cc\"; const { ccclass, property } = _decorator; @ccclass(\"example\") export class example extends Component { start(){ const uiStatic = this.node.getComponent(UIStaticBatch); // Choose the time you want to start static batching, call this interface to start static batching uiStatic.markAsDirty(); } } Detailed Explanation The following points need to be noted when using this component: Do not trigger static batches frequently, as the original stored IA data will be emptied and re-collected, resulting in some performance and memory loss. Not applicable for child node tree which contains Mask, Graphic and Model. For a node that will not have any changes in the node tree (e.g. 2D Map), all child nodes can be deleted after data collection to get the best performance and memory performance. "},"ui-system/components/editor/base-component.html":{"url":"ui-system/components/editor/base-component.html","title":"UI Basic Component","keywords":"","body":"UI Basic Components Canvas Component Reference UITransform Component Reference Widget Component Reference Button Component Reference Layout Component Reference EditBox Component Reference ScrollView Component Reference ScrollBar Component Reference ProgressBar Component Reference LabelOutline Component Reference Toggle Component Reference UIModel Component Reference ToggleGroup Component Reference Slider Component Reference PageView Component Reference PageViewIndicator Component Reference UIOpacity Component Reference BlockInputEvents Component Reference "},"ui-system/components/editor/canvas.html":{"url":"ui-system/components/editor/canvas.html","title":"Canvas Reference","keywords":"","body":"Canvas Component Reference The node where the Canvas component is located is the root of the UI rendering. There can be multiple Canvas in the scene. All UI elements must be placed under a Canvas node so that it can be rendered. UI Elements are rendered by the Canvas node that they are located under. Each Canvas can be presented in a certain order controlled by the priority attribute. In addition to the root node of the UI, Canvas also has a screen adaptation function. Please refer to the Multi-Resolution Adaption documentation to read about this. Canvas also supports multi-resolution adaptation. The design resolution and adaptation scheme are uniformly set in the Project Setting. A Camera is provided inside the Canvas, and the default z-axis direction is -1000 ~ 998, so the z-axis on the UI must be within this range to display properly (without taking the threshold value). In the previous design, Canvas was last rendered, meaning it could mask the rendering of all 3D content, but this was far from sufficient for project development needs, such as a 2D map with a 3D character. The RenderMode property allows developers to sort the rendering order of the 3D Camera and UI Camera. If you want to have canvas and 3D camera content mixed up, only the lowest camera or canvas can have the SOLID_COLOR ClearFlag, otherwise a camera with SOLID_COLOR flag will erase all content rendered before it. Canvas Properties Properties Function Explanation ClearFlag Clean up the flag of the screen buffer.DONT_CLEAR: No cleanup.DEPTH_ONLY: Clear the depth buffer.SOLID_COLOR: Clear the color depth buffer. Color The color used to clear the whole render buffer. Priority Camera sort priority.Only when the Canvas RenderMode is INTERSPERSE, the canvas can be rendered before any camera with lower priority.When RenderMode is OVERLAY, the priority only affect the order among all canvas. RenderMode Render mode of the Canvas.When set to INTERSPERSE, the priority take effect among all canvas and cameras in the Scene. When set to OVERLAY, the canvas will always be rendered after all cameras in the scene.Note: when INTERSPERSE mode is enabled and its priority is lower than other camera, the camera's ClearFlags should be set to DONT_ClEAR, otherwise the content of the beneath canvas will be erased. TargetTexture Rendering texture of the target. Detailed Explanation If you encounter errors in UI rendering, such as flickering, unwanted artifacts or other graphical oddness please refer to the Engine priority documentation. "},"ui-system/components/editor/ui-transform.html":{"url":"ui-system/components/editor/ui-transform.html","title":"UITransform Reference","keywords":"","body":"UITransform Component Reference The UITransform component defines the rectangle information on the UI, including the content size and anchor position of the rectangle. This component allows developers to modify the size and position of the rectangle freely, generally for rendering, calculation of click events, UI layout, screen adaptation, etc. Click the Add Component button at the bottom of the Inspector panel and select UITransform from UI to add the UITransform component to the node. Please refer to the UITransform API. UITransform Properties Property Function Explanation ContentSize The content size of UI rectangle. AnchorPoint The anchor position of UI rectangle. Priority The priority of UI nodes, sorted in the parent node. The order of the Canvas node is not affected by this property. change the size and anchor point in script. Example: ```ts import { _decorator, Component, Node, UITransform } from 'cc'; const { ccclass, property } = _decorator; @ccclass('Example') export class Example extends Component { start () { const uiTransform = this.getComponent(UITransform); // method one uiTransform.setContentSize(200, 120); uiTransform.setAnchorPoint(0, 0.5); // method two uiTransform.width = 200; uiTransform.height = 120; uiTransform.anchorX = 0; uiTransform.anchorY = 0.5; } } "},"ui-system/components/editor/widget.html":{"url":"ui-system/components/editor/widget.html","title":"Widget Reference","keywords":"","body":"Widget Component Reference Widget is a frequently used UI layout component. It can automatically align the current node to any position in the parent node's bounding box, or constrain the size, to make your game easily adaptable to different resolutions. About the alignment scheme, please see Widget Alignment for details. Click the Add Component button at the bottom of the Inspector panel and select UI/Widget to add the Widget component to the node. To use Widget, please refer to the Widget API documentation and the widget scene of the test-cases-3d project. Widget Properties Properties Function Explanation Note Top Upper border alignment Once selected, an input field will appear to set the distance between the upper border of the current node and the upper border of the parent object. Bottom Lower border alignment Once selected, an input field will appear to set the distance between the lower border of the current node and the lower border of the parent object. Left Left border alignment Once selected, an input field will appear to set the distance between the left border of the current node and the left border of the parent object. Right Right border alignment Once selected, an input field will appear to set the distance between the right border of the current node and the right border of the parent object. HorizontalCenter Horizontal center alignment VerticalCenter Vertical center alignment Target Alignment target Specifies an alignment target that can only be one of the parent nodes of the current node. The default value is null, and when null, indicates the current parent.If the parent node is the entire scene, it will be aligned to the visible area of the screen (visibleRect), and can be used to dock UI elements to the edge of the screen. Align Mode Specifies the alignment mode of the Widget, which determines when the widget should refresh at runtime Normally set to ALWAYS, only to be initialized and realigned whenever the window size changes.Set to ONCE, will only make alignment when the component is enabled.Set to ON_WINDOW_RESIZE, will update Widget's alignment every time when the window changes. Border alignment We can create a new Sprite node under the Canvas node, add a Widget component to the Sprite, and do the following test: Left alignment, left border distance 100 px: Bottom alignment, bottom border distance 50%: The percentage will take the width or height of the parent node as a benchmark. Bottom right alignment, border distance 0 px: Center Alignment Horizontal center alignment: Vertical center alignment and right border distance 50%: Limit size If you align the left and right side at the same time, or align the top and bottom at the same time, then the size will be stretched in the corresponding direction. Let us look at a demonstration. Place two rectangular Sprites in the Scene and take the bigger one as the dialog box background and the smaller one as the button on the dialog box. Take the button node as the child node of the dialog box and set the button into SLICED mode so that you can observe the stretch effect. Horizontal stretch, left and right margin 10%: Vertical stretch, no margins on each end and horizontal center alignment: Stretch in the horizontal and vertical directions, margin 50 px: Limitation on node position control If Align Mode property is set to ALWAYS, the Widget will set the alignment for the current node every frame at runtime according to the alignment policy you set. The position and size (width, height) properties of the node where the component is located may be restricted and cannot be freely modified via the API or animation system. This is because the alignment set by the widget is processed at the end of each frame, so if you set the previously set alignment related properties in the Widget component, those settings will eventually be reset by the widget component's own settings. To make sure you can update node's position or size during runtime: Set Align Mode property of Widget to ONCE, so it will only align during onEnable process. Use Widget's API to update node's position and size, for example updating Widget's top, bottom, left, right instead of node's x, y, width, height. Modify the alignment distance in script code. Example: import { _decorator, Component, Widget } from 'cc'; const { ccclass, property } = _decorator; @ccclass('Example') export class Example extends Component { start () { const widget = this.getComponent(Widget); // Set the default alignment unit to px widget!.bottom = 50; widget!.top = 50; // The alignment unit is% widget!.isAbsoluteTop = false; widget!.isAbsoluteBottom = false; widget!.bottom = 0.1; // 10% widget!.top = 0.1; // 10% } } "},"ui-system/components/editor/button.html":{"url":"ui-system/components/editor/button.html","title":"Button Reference","keywords":"","body":"Button Component Reference The Button component responds to a click from the user. When the user clicks a Button, its status will change. In addition, users can assign a custom behavior to buttons' click event. Click the Add Component button at the bottom of the Inspector panel and select UI/Button to add the Button component to the node. To use Button, please refer to the Button API documentation and the button scene of the test-cases-3d project. Button Properties Properties Function Explanation Target Specify the Button background node. When the Button status changes, the Color or Sprite property of the node will be modified. Interactable Boolean type, if set to false then the Button component enters the forbidden state. Transition Enumeration type, including NONE, COLOR, SPRITE and SCALE. Each type corresponds to a different Transition setting. Please see the Button Transition section below for details. ClickEvents List type, default is null. Each event added by the user is composed of the node reference, component name and a response function. Please see the Button Event section below for details. Button Transition Button Transition is used to choose the action of the button when clicked by the user. Currently the types available are NONE, COLOR, SPRITE and SCALE. Color Transition Property Function Explanation Normal Color of Button under Normal status. Pressed Color of Button under Pressed status. Hover Color of Button under Hover status. Disabled Color of Button under Disabled status. Duration Time interval needed for Button status switching. Sprite Transition Properties Function Explanation Normal SpriteFrame of Button under Normal status. Pressed SpriteFrame of Button under Pressed status. Hover SpriteFrame of Button under Hover status. Disabled SpriteFrame of Button under Disabled status. Scale Transition Properties Function Explanation Duration Time interval needed for Button status switching. ZoomScale When the user clicks the button, the button will zoom to a scale. The final scale of the button equals to the button's original scale * zoomScale, and the zoomScale can be a negative value. Button Click Events The Button can additionally add a click event to respond to the player's click action. There are two ways to achieve this. Add a callback using the Properties Property Function Explanation Target Node with the script component. Component Script component name. Handler Assign a callback function from the given component which will be triggered when the user clicks the Button. CustomEventData A user-defined string value passed as the last event argument of the event callback. Add a callback using the script There are two ways to add a callback through the script. The event callback added by this method is the same as the event callback added by the editor, all added by the script. First you need to construct a EventHandler object, and then set the corresponding target, component, handler and customEventData parameters. import { _decorator, Component, Event, Node, Button, EventHandler } from \"cc\"; const { ccclass, property } = _decorator; @ccclass(\"example\") export class example extends Component { onLoad () { const clickEventHandler = new EventHandler(); // This node is the node to which your event handler code component belongs clickEventHandler.target = this.node; // This is the code file name clickEventHandler.component = 'example'; clickEventHandler.handler = 'callback'; clickEventHandler.customEventData = 'foobar'; const button = this.node.getComponent(Button); button.clickEvents.push(clickEventHandler); } callback (event: Event, customEventData: string) { // The event here is a Touch object, and you can get the send node of the event by event.target const node = event.target as Node; const button = node.getComponent(Button); console.log(customEventData); // foobar } } By button.node.on ('click', ...) to add event callback. This is a very simple way, but the way has some limitations, in the event callback the screen coordinate point of the current click button cannot be obtained. // Suppose we add an event handler callback to the onLoad method of a component and handle the event in the callback function: import { _decorator, Component, Button } from \"cc\"; const { ccclass, property } = _decorator; @ccclass(\"example\") export class example ex tends Component { @property(Button) button: Button | null = null; onLoad () { this.button.node.on(Button.EventType.CLICK, this.callback, this); } callback (button: Button) { // Note that events registered this way cannot pass customEventData } } "},"ui-system/components/editor/layout.html":{"url":"ui-system/components/editor/layout.html","title":"Layout Reference","keywords":"","body":"Layout Component Reference Layout is a component for UI container nodes. This component provide to the container various layout functionalities to automatically arrange all the children, so that the developer can make list, page, grid container, etc conveniently. Click the Add Component button at the bottom of the Inspector panel and select UI -> Layout to add the Layout component to the node. To use Layout, please refer to the Layout API documentation and the 05.layout example of the test-cases-3d project. Layout Properties Property Function Explanation Type Layout type, including NONE, HORIZONTAL, VERTICAL and GRID. ResizeMode Resize mode, including NONE, CHILDREN and CONTAINER. PaddingLeft The left padding between the children and the container frame. PaddingRight The right padding between the children and the container frame. PaddingTop The top padding between the children and the container frame. PaddingBottom The bottom padding between the children and the container frame. SpacingX The spacing between children in the horizontal layout. NONE mode doesn't have this property. SpacingY The spacing between children in the vertical layout. NONE mode doesn't have this property. HorizontalDirection When it is designated as horizontal layout, this property determines which side(left or right) does the first child node start in the layout. When the Layout type is set to GRID, this property along with Start Axis property determine the starting horizontal alignment of GRID layout elements. VerticalDirection When it is designated as vertical layout, this property determines which side(top or bottom) does the first child node start in the layout. When the Layout type is set to GRID, this property with Start Axis property determines the starting vertical alignment of GRID layout elements. CellSize This property is only available in GRID layout, CHILDREN resize mode, determines the size of each child node. StartAxis This property is only available in GRID layout, determines the arrangement direction of children. AffectedByScale Whether the scale of the child node affects the layout. AutoAlignment Auto-alignment, in Type type HORIZONTAL or VERTICAL mode, ensures that the other axial value is zero. Constraint Layout constraints that constrain the number of alignments in a given direction, supporting NONE, FIXED_ROW and FIXED_COL. ConstraintNum The layout constraint value, valid in Constraint of type FIXED_ROW or FIXED_COL mode. Detailed Explanation After adding the Layout component, the default layout type is NONE, you can toggle the container alignment type by modifying Type in Inspector. The types are HORIZONTAL, VERTICAL and GRID layouts. Also, ResizeMode is supported for all layout types except NONE. The modes of Resize Mode: When Resize Mode is NONE, the size of the container and children is independent from each other. When Resize Mode is CHILDREN, the size of the children will change with the size of the container to make sure all children fit inside the container's bounding box. When Resize Mode is CONTAINER, the size of the container will change with the size of the children to make sure the container is large enough to contain all children inside its bounding box. All alignments are calculated based on the container size. If the sorting needs to be fixed, set the Type to Grid and then set the Constraint and ConstraintNum to fix the sorting. The modes of Constraint: When Constraint is NONE, the layout is free of Constraint. When Constraint is FIXED_ROW, a fixed number of rows is used with ConstraintNum. When Constraint is FIXED_COL, a fixed number of columns is used with ConstraintNum. Note: if the Layout's configuration is set in runtime, the results need to be updated until the next frame, unless you manually call updateLayout API. For more layout examples, please refer to the Auto Layout documentation for details. "},"ui-system/components/editor/editbox.html":{"url":"ui-system/components/editor/editbox.html","title":"EditBox Reference","keywords":"","body":"EditBox Component Reference EditBox is a text input component, use this component to get user input easily. Click the Add Component button at the bottom of the Inspector panel and select UI/EditBox to add the EditBox component to the node. To use EditBox, please refer to the EditBox API documentation and the editBox scene of the test-cases-3d project. EditBox Properties Properties Function Explanation BackgroundImage The Sprite component attached to the node for EditBox's background FontColor The input text color of EditBox FontSize The input text size of EditBox InputFlag Specify the input flag: password or capitalized word. (Only supports Android platform) InputMode Specify the input mode: multiline or single line LineHeight The input text line height of EditBox MaxLength The maximize input characters of EditBox Placeholder The text content of EditBox placeholder PlaceholderFontColor The text font color of EditBox placeholder PlaceholderFontSize The text font size of EditBox placeholder PlaceholderLabel The Label component attached to the node for EditBox's placeholder text label ReturnType The keyboard return type of EditBox. This is useful for keyboard of mobile device String The initial input text of EditBox, which displays the text of the placeholder if not set TabIndex Set the tabIndex of the DOM input element, only useful on the Web TextLabel The Label component attached to the node for EditBox's input text label EditBox Events For event structure you can refer to the Button documentation. Editing Did Began: This event will be triggered when the user clicks on the EditBox. Editing Did Ended: This event will be triggered when the EditBox loses focus. When in single line input mode, it's triggered after user presses Enter key or clicks the area outside of EditBox. When in multiline input mode, it's triggered only after user clicks the area outside of EditBox. Text Changed: This event will be triggered when the content in EditBox is changed each time. Detailed Explanation If you want to input password, you need set Input Flag to PASSWORD and the Input Mode mustn't be ANY, usually we use Single Line. If you want to enable multiline input support, you can set the Input Mode to Any. The background image of EditBox support 9-slicing sprite frame, you could customize the border as you did in Sprite component. Add a callback through the script code Method one The event callback added by this method is the same as the event callback added by the editor, all added by code. First you need to construct a EventHandler object, and then set the corresponding target, component, handler and customEventData parameters. import { _decorator, Component, EditBoxComponent, EventHandler } from \"cc\"; const { ccclass, property } = _decorator; @ccclass(\"example\") export class example extends Component { onLoad() { const editboxEventHandler = new EventHandler(); // This node is the node to which your event handler code component belongs. editboxEventHandler.target = this.node; editboxEventHandler.component = 'example'; editboxEventHandler.handler = 'onEditDidBegan'; editboxEventHandler.customEventData = 'foobar'; const editbox = this.node.getComponent(EditBoxComponent); editbox.editingDidBegan.push(editboxEventHandler); // You can also register other callback functions in a similar way. // editbox.editingDidEnded.push(editboxEventHandler); // editbox.textChanged.push(editboxEventHandler); // editbox.editingReturn.push(editboxEventHandler); } onEditDidBegan(editbox, customEventData) { // The editbox here is a cc.EditBox object. // The customEventData parameter here is equal to the \"foobar\" you set before. } // Suppose this callback is for the editingDidEnded event. onEditDidEnded(editbox, customEventData) { // The editbox here is a cc.EditBox object. // The customEventData parameter here is equal to the \"foobar\" you set before. } // Suppose this callback is for the textChanged event. onTextChanged(text, editbox, customEventData) { // The text here indicates the text content of the modified EditBox. // The editbox here is a cc.EditBox object. // The customEventData parameter here is equal to the \"foobar\" you set before. } // Suppose this callback is for the editingReturn event. onEditingReturn(editbox, customEventData) { // The editbox here is a cc.EditBox object. // The customEventData parameter here is equal to the \"foobar\" you set before. } } Method two Added with Node's event API editbox.node.on('editing-did-began', ...). // Suppose we add an event handler callback inside a component's onLoad method and event handlers in the callback function. import { _decorator, Component, EditBoxComponent } from \"cc\"; const { ccclass, property } = _decorator; @ccclass(\"example\") export class example extends Component { @property(EditBoxComponent) editbox: EditBoxComponent | null = null; onLoad(){ this.editbox.node.on('editing-did-began', this.callback, this); } callback(editbox: EditBoxComponent){ // The callback parameter is the EditBox component, note that events registered this way cannot pass customEventData. } } Similarly, you can register events such as editing-did-ended, text-changed, editing-return, etc. The parameters of the callback function for these events are consistent with the parameters of editing-did-began. "},"ui-system/components/editor/scrollview.html":{"url":"ui-system/components/editor/scrollview.html","title":"ScrollView Reference","keywords":"","body":"ScrollView Component Reference ScrollView is a container with a scroll function. It provides a way to browse more contents within a limited display area. Generally, ScrollView will be used along with the Mask component and the ScrollBar component can also be added to show the current offset location within the browsing content. Click the Add Component button at the bottom of the Inspector panel and select UI/ScrollView to add the ScrollView component to the node. To use ScrollView, please refer to the ScrollView API documentation and the scrollView scene of the test-cases-3d project. ScrollView Properties Properties Function Explanation BounceDuration Floating point number, the time duration for bounce back. The value range is 0-10 Brake Floating point number, the deceleration coefficient after scrolling. The value range is 0-1. If set to 1, then the scrolling will stop immediately, if set to 0, then the scrolling will continue until the content border CancelInnerEvents If it is set to true, then the scroll behavior will cancel the touch events registered on the child node. The default setting is true Content A reference node for the inner content of the ScrollView. It could be a node containing a very large image or long texts. Elastic Boolean value, whether to bounce back or not while scroll to the border. Horizontal Boolean value, whether horizontal scroll is allowed or not HorizontalScrollBar A reference node for creating a scroll bar showing the horizontal position of the content Inertia Is there an accelerating velocity when scrolling ScrollEvents Default list type is null. Each event added by the user is composed of the node reference, component name and a response function. Please see the ScrollView Event section below for details Vertical Boolean value, whether vertical scroll is allowed or not VerticalScrollBar A reference node for creating a scroll bar showing vertical position of the contents ScrollView Event For event structure you can refer to the Button documentation. The ScrollView event callback will have two parameters, the first one is the ScrollView itself and the second one is the event type of ScrollView. ScrollBar Setting ScrollBar is optional. You can choose to set either a Horizontal ScrollBar or a Vertical ScrollBar or of course set them both. To build a connection, you can drag a node with the ScrollBar component in the Hierarchy over to the corresponding field in ScrollView. Detailed Explanation The ScrollView component can only work with the specified content node. It calculates location information during scrolling using both the designated scroll direction and the length of the content node in this direction. The Content node can also set up the auto resize by adding a Widget, or it can arrange the layout of child nodes by adding a Layout, but these two components should not be added to a node at the same time to avoid unintentional consequences. Normally a ScrollView node tree resembles the following: The view here is used to define a scroll area that can be displayed. As a result, the Mask will normally be added to the view. Contents that can scroll can be put in the content node or added to its child node. Add a callback through the script code Method one The event callback added by this method is the same as the event callback added by the editor, all added by code. First you need to construct a EventHandler object, and then set the corresponding target, component, handler and customEventData parameters. import { _decorator, Component, ScrollView, EventHandler } from \"cc\"; const { ccclass, property } = _decorator; @ccclass(\"example\") export class example extends Component { onLoad() { const scrollViewEventHandler = new EventHandler(); // This node is the node to which your event handler code component belongs scrollViewEventHandler.target = this.node; // This is the code file name scrollViewEventHandler.component = 'example'; scrollViewEventHandler.handler = 'callback'; scrollViewEventHandler.customEventData = 'foobar'; const scrollview = this.node.getComponent(ScrollView); scrollview.scrollEvents.push(scrollViewEventHandler); } callback(scrollview, eventType, customEventData){ // here scrollview is a Scrollview component object instance // here the eventType === ScrollView.EventType enum // here the customEventData parameter is equal to the \"foobar\" you set before } } Method two By scrollview.node.on('scroll-to-top', ...) way to add. // Suppose we add an event handler callback to the onLoad method of a component and handle the event in the callback function: import { _decorator, Component, ScrollView } from \"cc\"; const { ccclass, property } = _decorator; @ccclass(\"example\") export class example extends Component { @property(ScrollView) scrollview: ScrollView | null = null; onLoad(){ this.scrollview.node.on('scroll-to-top', this.callback, this); } callback(scrollView: ScrollView) { // The callback parameter is the ScrollView component, note that events registered this way cannot pass customEventData. } } Similarly, you can register events such as scrolling, touch-up, scroll-began, etc. The parameters of the callback function for these events are consistent with the parameters of scroll-to-top. "},"ui-system/components/editor/scrollbar.html":{"url":"ui-system/components/editor/scrollbar.html","title":"ScrollBar Reference","keywords":"","body":"ScrollBar Component Reference The ScrollBar allows the user to scroll by dragging a sliding block. It's a bit similar to the Slider component, but it is mostly used as a part of the ScrollView while Slider is used independently to set values. Click the Add Component button at the bottom of the Inspector panel and select UI/ScrollBar to add the ScrollBar component to the node. Please refer to the ScrollBar API. ScrollBar Properties Property Function Explanation AutoHideTime Time to hide the ScrollBar automatically, need to set Enable Auto Hide to true for it to take effect Direction Scroll direction, including HORIZONTAL and VERTICAL EnableAutoHide Enable or disable auto hide. If this property is enabled, the ScrollBar will automatically disappear after actions stopped for AutoHideTime. Handle ScrollBar foreground picture. The length/width will be calculated according to the content size of ScrollView and the dimensions of the actual display area Detailed Explanation The ScrollBar normally is used together with ScrollView instead of being used alone. Also, ScrollBar needs to assign a Sprite component, i.e. Handle in the Inspector panel. Normally we will also designate a background image to ScrollBar. This can be used to indicate the length or width of the whole ScrollBar. "},"ui-system/components/editor/progress.html":{"url":"ui-system/components/editor/progress.html","title":"ProgressBar Reference","keywords":"","body":"ProgressBar Component Reference ProgressBar is usually used to show the progress of a certain operation in the game. Add the ProgressBar component to a node and associate a Bar Sprite to this component. Then the Bar Sprite can be controlled to show progression in the scene. Click the Add Component button at the bottom of the Inspector panel and select UI/ProgressBar to add the ProgressBar component to the node. To use Progress, please refer to the Mask API documentation and the progress scene of the test-cases-3d project. ProgressBar Properties Property Function Explanation BarSprite The Sprite component needed for rendering ProgressBar. It can be linked by dragging a node with the Sprite component to this property Mode Currently supports the HORIZONTAL, VERTICAL and FILLED modes. The initial direction can be changed by cooperating with the reverse property Progress Floating point. The value range is 0~1, and values outside the range are not allowed. Reverse Boolean value. The default fill direction is from left to right / bottom to top, when enable, it becomes right to left / top to bottom Total Length The total length / total width of the BarSprite when the ProgressBar is at 100%. In FILLED mode, Total Length represents the percentage of the total display range for Bar Sprite, with values ranging from 0 to 1 Detailed Explanation After adding the ProgressBar component, drag a node with the Sprite component from the Hierarchy to the BarSprite property. Then you can control the display of the ProgressBar by dragging the progress sliding block. Bar Sprite could be its own node, child node or any node that comes with the Sprite component. Also, Bar Sprite can freely choose the SIMPLE, SLICED or FILLED render types. If the mode of the progress bar is FILLED, the Type of BarSprite should to be set to FILLED, otherwise a warning will appear. "},"ui-system/components/editor/label-outline.html":{"url":"ui-system/components/editor/label-outline.html","title":"LabelOutline Reference","keywords":"","body":"LabelOutline Component Reference The LabelOutline component will add an outline effect to the Label component on the node. LabelOutline won't have any effect on Label using BMFont. Select a node in the Hierarchy panel, then click the Add Component button at the bottom of the Inspector panel and select LabelOutline from UI. Then you can add the LabelOutline component to the node. LabelOutline Properties Property Function Explanation Color The outline color Width The outline width "},"ui-system/components/editor/toggle.html":{"url":"ui-system/components/editor/toggle.html","title":"Toggle Reference","keywords":"","body":"Toggle Component Reference The Toggle component is a CheckBox, when it's used together with a ToggleGroup, it could be treated as a RadioButton. Click the Add Component button at the bottom of the Inspector panel and select UI/Toggle to add the Toggle component to the node. To use Toggle, please refer to the Toggle API documentation and the toggle scene of the test-cases-3d project. Toggle Properties Properties Function Explanation IsChecked Boolean type. When set to true, enable the check mark component CheckMark Sprite type. The image displayed when Toggle is selected CheckEvents List type, default is null. Each event added by the user is composed of the node reference, component name and a response function. Please see the Toggle Event section below for details Note: because Toggle is inherited from Button, so the properties exists in Button also apply to Toggle, please refer to the Button Component for details. Toggle Event For event structure you can refer to the Button documentation. The Toggle event callback has two parameters, the first one is the Toggle itself and the second is the customEventData. Detailed Explanation The generic node hierarchy of Toggle is as below: Note: the checkMark node needs to be placed on the upper level of the background node in the Scene. Add a callback through the script code Method one The event callback added by this method is the same as the event callback added by the editor, all added by code. First you need to construct a EventHandler object, and then set the corresponding target, component, handler and customEventData parameters. import { _decorator, Component, Event, Node, ToggleComponent, EventHandler } from \"cc\"; const { ccclass, property } = _decorator; @ccclass(\"example\") export class example extends Component { onLoad(){ const checkEventHandler = new EventHandler(); // This Node is the node to which your event processing code component belongs checkEventHandler.target = this.node; // This is the code file name checkEventHandler.component = 'example'; checkEventHandler.handler = 'callback'; checkEventHandler.customEventData = 'foobar'; const toggle = this.node.getComponent(ToggleComponent); toggle.checkEvents.push(checkEventHandler); } callback(event: Event, customEventData: string){ // The event here is a Touch Event object, and you can get the send node of the event by event.target // The customEventData parameter here is equal to the \"foobar\" you set before } } Method two Added by the way of toggle.node.on('toggle', ...). // // Suppose we add an event handler callback inside a component's onLoad method and event handlers in the callback function: import { _decorator, Component, ToggleComponent } from \"cc\"; const { ccclass, property } = _decorator; @ccclass(\"example\") export class example extends Component { @property(ToggleComponent) toggle: ToggleComponent | null = null; onLoad(){ this.toggle.node.on('toggle', this.callback, this); } callback(toggle: ToggleComponnet){ // The callback parameter is the Toggle component, note that events registered this way cannot pass customEventData. } } "},"ui-system/components/editor/toggleContainer.html":{"url":"ui-system/components/editor/toggleContainer.html","title":"ToggleContainer Reference","keywords":"","body":"ToggleContainer Component Reference ToggleContainer is not a visible UI component but it can be used to modify the behavior of a set of Toggle components. Toggles that belong to the same ToggleContainer could only have one of them to be switched on at a time. Note: all the first layer child node containing the Toggle component will auto be added to the container. Click the Add Component button at the bottom of the Inspector panel and select UI/ToggleContainer to add the ToggleContainer component to the node. To use ToggleContainer, please refer to the ToggleContainer API documentation and the toggleContainer scene of the test-cases-3d project. ToggleContainer Properties Property Functions Explanation AllowSwitchOff If it is enabled, then the toggle button can be checked and unchecked repeatedly when it is clicked. If it is disabled, it will make sure there is always only one toggle could be checked and the already checked toggle can't be unchecked CheckEvents List type, default is null. Each event added by the user is composed of the node reference, component name and a response function. Please see the ToggleContainer Event section below for details ToggleContainer Event For event structure you can refer to the Button documentation. The ToggleContainer event callback has two parameters, the first one is the ToggleContainer itself and the second is the customEventData. Detailed Explanation The ToggleContainer won't be used alone and it usually be used with Toggle to implement the RatioButton. Add a callback through the script code The event callback added by this method is the same as the event callback added by the editor, all added by code. First you need to construct a EventHandler object, and then set the corresponding target, component, handler and customEventData parameters. import { _decorator, Component, Event, Node, ToggleContainerComponent, EventHandler } from \"cc\"; const { ccclass, property } = _decorator; @ccclass(\"example\") export class example extends Component { onLoad(){ const containerEventHandler = new EventHandler(); // This Node is the node to which your event processing code component belongs containerEventHandler.target = this.node; // This is the code file name containerEventHandler.component = 'example'; containerEventHandler.handler = 'callback'; containerEventHandler.customEventData = 'foobar'; const container = this.node.getComponent(ToggleContainerComponent); container.checkEvents.push(containerEventHandler); } callback(event: Event, customEventData: string){ // The event here is a Touch Event object, and you can get the send node of the event by event.target // The customEventData parameter here is equal to the \"foobar\" you set before } } "},"ui-system/components/editor/slider.html":{"url":"ui-system/components/editor/slider.html","title":"Slider Reference","keywords":"","body":"Slider Component Reference Slider is a component for the production of UI components such as volume adjustment. Click the Add Component button at the bottom of the Inspector panel and select UI/Slider to add the Slider component to the node. To use Slider, please refer to the Slider API documentation and the slider scene of the test-cases-3d project. Slider Properties Properties Function Explanation Handle The button part of the Slider that allows to adjust value by sliding the button Direction The direction of the slider, including Horizontal and Vertical Progress Current progress value, the value range is 0 ~ 1 SlideEvents Slider component event callback function Slider Event For event structure you can refer to the Button documentation. The Slider event callback has two parameters, the first one is the Slider itself and the second is the customEventData. Detailed Explanation The Slider is usually used to adjust the value of the UI (for example, volume adjustment), and its main component is a slider button, which is used for user interaction. You can adjust the value of the Slider through this part. Usually a Slider node tree as shown below: Add a callback by script code Method one The event callback added by this method is the same as the event callback added by the editor, all added by code. First you need to construct a EventHandler object, and then set the corresponding target, component, handler and customEventData parameters. import { _decorator, Component, Event, Node, SliderComponent, EventHandler } from \"cc\"; const { ccclass, property } = _decorator; @ccclass(\"example\") export class example extends Component { onLoad(){ const sliderEventHandler = new EventHandler(); // This Node is the node to which your event processing code component belongs sliderEventHandler.target = this.node; // This is the code file name sliderEventHandler.component = 'example'; sliderEventHandler.handler = 'callback'; sliderEventHandler.customEventData = 'foobar'; const slider = this.node.getComponent(SliderComponent); slider.slideEvents.push(sliderEventHandler); } callback(event: Event, customEventData: string){ // The event here is a Touch Event object, and you can get the send node of the event by event.target // The customEventData parameter here is equal to the \"foobar\" you set before } } Method two By slider.node.on('slide', ...) way to add. // Suppose we add event handling callbacks to the onLoad method of a component and perform event handling in the callback function: import { _decorator, Component, SliderComponent } from \"cc\"; const { ccclass, property } = _decorator; @ccclass(\"example\") export class example extends Component { @property(SliderComponent) slider: SliderComponent | null = null; onLoad(){ this.slider.node.on('slider', this.callback, this); } callback(slider: SliderComponent){ // The parameter of the callback is the Slider component. Note that events registered this way cannot pass customEventData } } "},"ui-system/components/editor/pageview.html":{"url":"ui-system/components/editor/pageview.html","title":"PageView Reference","keywords":"","body":"PageView Component Reference The PageView component is derived from ScrollView, the difference is that when scrolls it automatically snaps to next page of content. Click the Add Component button at the bottom of the Inspector panel and select UI/PageView to add the PageView component to the node. To use PageView, please refer to the PageView API documentation and the pageView scene of the test-cases-3d project. PageView Properties Properties Function Description AutoPageTurningThreshold Auto page turning velocity threshold. When users swipe the PageView quickly, it will calculate a velocity based on the scroll distance and time, if the calculated velocity is larger than the threshold, then it will trigger page turning Bounce Duration The elapse time of bouncing back. The value range is 0 ~ 10, and when the value is 0, it will bounce back immediately Brake It determines how quickly the content stop moving. A value of 1 will stop the movement immediately. A value of 0 will never stop the movement until it reaches to the boundary of page view Content It is a node reference that is used to contain the contents of the page view Direction The page view direction Elastic When elastic is set, the content will be bounce back when move out of boundary Indicator The Page View Indicator, please refer to PageViewIndicator Setting below for details Inertia When inertia is set, the content will continue to move for a little while when touch ended PageEvents A list of the page view's events callback PageTurningEventTiming Change the timing for sending the PAGE_TURNING event CancelInnerEvents If it's set to true, the scroll behavior will cancel touch events on inner content nodes. It's set to true by default ScrollThreshold This value will be multiplied by the distance between two pages, to get the threshold distance. If user scroll distance is larger than this threshold distance, the page will turn immediately SizeMode Specify the size type of each page in PageView, including Unified and Free PageViewIndicator Setting PageViewIndicator is optional, the component is used to display the number of pages and mark the current page. The association can be done by dragging a node with a PageViewIndicator component into the Indicator property of the PageView component in the Hierarchy panel. PageView Event Properties Function Description Target Node with script component Component Script component name Handler Specifies a callback function that will be called when the PageView event occurs CustomEventData The user specifies an arbitrary string as the last parameter of the event callback The PageView event callback has two parameters, the first parameter is the PageView itself, the second parameter is the event type of the PageView. Detailed Explanation The PageView component must have the specified content node to work. Each child node in content is a separate page, and the size of each page is the size of the PageView node. If the node size is larger than the content size, it may result in an incomplete scroll. Under the PageView component there is a node object, which combines with ScrollThreshold to determine whether the current sliding distance is such that the page can be turned. The operation effect is divided into two kinds: Slow sliding - by dragging the page in the view to reach the specified ScrollThreshold value (the value is the percentage of page size), after the release will automatically slide to the next page. Fast sliding - quickly drag in one direction, automatically slide to the next page. Only slide up to one page at a time. Add callback via script code Method one The event callback added by this method is the same as the event callback added by the editor, all added by code. First you need to construct a EventHandler object, and then set the corresponding target, component, handler and customEventData parameters. import { _decorator, Component, Event, Node, PageView, EventHandler } from \"cc\"; const { ccclass, property } = _decorator; @ccclass(\"example\") export class example extends Component { onLoad(){ const pageChangedEventHandler = new EventHandler(); // This Node is the node to which your event processing code component belongs pageChangedEventHandler.target = this.node; // This is the code file name pageChangedEventHandler.component = 'example'; pageChangedEventHandler.handler = 'callback'; pageChangedEventHandler.customEventData = 'foobar'; const page = this.node.getComponent(PageView); page.clickEvents.push(pageChangedEventHandler); } callback(event: Event, customEventData: string){ // The event here is a Touch Event object, and you can get the send node of the event by event.target const node = event.target as Node; const pageview = node.getComponent(PageView); console.log(customEventData); // foobar } } Method two By pageView.node.on('page-turning', ...) way to add. // Suppose we add event handling callbacks to the onLoad method of a component and perform event handling in the callback function: import { _decorator, Component, Event, Node, PageView } from \"cc\"; const { ccclass, property } = _decorator; @ccclass(\"example\") export class example extends Component { onLoad(){ this.pageView.node.on('page-turning', this.callback, this); } callback(pageView: PageView){ // The parameter of the callback is the PageView component. Note that events registered this way cannot pass customEventData } } "},"ui-system/components/editor/pageviewindicator.html":{"url":"ui-system/components/editor/pageviewindicator.html","title":"PageViewIndicator Reference","keywords":"","body":"PageviewIndicator Component Reference The PageViewIndicator component is used to display the current page number of the PageView and the page where the tag is currently located. Click the Add Component button at the bottom of the Inspector panel and select UI/PageViewIndicator to add the PageViewIndicator component to the node. To use PageView, please refer to the PageView API documentation and the pageView scene of the test-cases-3d project. PageviewIndicator Properties Property Function Description CellSize The cellsize for each element Direction The location direction of PageViewIndicator, including HORIZONTAL and VERTICAL Spacing The distance between each element SpriteFrame The spriteFrame for each element Detailed Explanation PageviewIndicator is not used alone, it needs to be used with PageView to create a tag of the number of pages corresponding to the page. When you slide to a page, PageviewIndicator will highlight its corresponding mark. "},"ui-system/components/editor/ui-model.html":{"url":"ui-system/components/editor/ui-model.html","title":"UIMeshRenderer Reference","keywords":"","body":"UIMeshRenderer Reference UIMeshRenderer is a renderer component with a conversion feature that converts 3D models from 3D render pipeline to 2D. This component supports rendering the 3D model and particle system in the UI, without the component, the 3D model and particle system nodes will not be rendered. The UIMeshRenderer component is added by selecting the node in the Hierarchy panel with the MeshRenderer or classes inherited from it, then clicking the Add Component button below the Inspector panel and selecting UI/Model. And the particles are added to the particle nodes. The usual structure is as below: "},"ui-system/components/editor/ui-opacity.html":{"url":"ui-system/components/editor/ui-opacity.html","title":"UIOpacity Reference","keywords":"","body":"UIOpacity Component References The UIOpacity Component records a transparency modification flag for the node, which is used to influence all the render nodes inside its sub tree. Normally it's used on a non render nodes, otherwise its opacity will be multiplied with the render component's opacity. The render nodes can set transparency individually by setting the alpha channel of color. The method of use is as follows: You can also set transparency by code. Example: const opacityComp = this.getComponent(UIOpacity); opacityComp.opacity = 157; To use UIOpacity, please refer to the UIOpacity API documentation and the UIOpacity scene of the test-cases-3d project. UIOpacity Properties Property Function Description Opacity transparency "},"ui-system/components/editor/block-input-events.html":{"url":"ui-system/components/editor/block-input-events.html","title":"BlockInputEvents Reference","keywords":"","body":"BlockInputEvents Component Reference The BlockInputEvents component will intercept all input events (mouse and touch events) in the bounding box of the node to which it belongs, preventing input from penetrating to the lower-level nodes, generally used in the background of the upper-level UI. When we make a pop-up UI dialog, the background of the dialog does not intercept events by default. That is, although the background is blocking the game scene, when clicked or touched on the background, the blocked game element underneath will still respond to the click event. At this point we can avoid this by simply adding the BlockInputEvents component to the node where the background is located. This component does not have any API interface and is effective when added directly to a scene. "},"ui-system/components/editor/webview.html":{"url":"ui-system/components/editor/webview.html","title":"WebView Reference","keywords":"","body":"WebView Component Reference WebView is a component for displaying web pages, you could use this component to embed a mini web browser in your games. Because different platforms have different authorization, API and control methods for WebView component. And have not yet formed a unified standard, only Web, iOS, and Android platforms are currently supported. Click Add Component at the bottom of Properties panel and select WebView from UI Component to add the WebView component to the node. For more information, please refer to the WebView API documentation. WebView Properties Properties Function Explanation URL A given URL to be loaded by the WebView, it should have a http or https prefix. WebView Events The webview's event callback, it will be triggered when certain webview event occurs. Note: in the Node of the WebView Events property, you should fill in a Node that hangs the user script component, and in the user script you can use the relevant WebView event according to the user's needs. WebView Event WebViewEvents Event Property Function Explanation Target Node with the script component. Component Script component name. Handler Specify a callback, when the WebView is loading the web pages, or the loading is finished or there are errors occurred. The callback will be called. For more information, please refer to Parameter of WebViewEvents. CustomEventData The user specifies that any string is passed in as the last parameter of the event callback. For more information, please refer to the Component.EventHandler Class documentation. Parameter of WebViewEvents Name Function Explanation LOADING WebView is loading. LOADED WebView is finished loading. ERROR Errors occurred when loading web pages. For more information, please refer to the WebView Events documentation or 22.webview example of the test-cases-3d samples bundled with Creator. Details Explanation Currently, this component is only available on Web (Both PC and Mobile, iOS and Android (Not supported in the v2.0.0~2.0.6). It cannot be use on Mac or Windows which means if you preview WebView on these platforms, there is nothing to show. Notes: This component doesn't support load HTML file or execute JavaScript. If you don't use WebView related features in your project, please ensure that the WebView module is removed from the Project -> Project Settings -> Module Config to help your game approval go as smoothly as possible on iOS App Store. If you really needs to use WebView (or the added third-party SDK comes with WebView), and therefore if the game is rejected by App Store, you can still try to appeal through email. Add a callback via script Method one This method uses the same API that editor uses to add an event callback on Button component. You need to construct a Component.EventHandler object first, and then set the corresponding target, component, handler and customEventData parameters. import { _decorator, Component, WebView } from 'cc'; const { ccclass, type } = _decorator; @ccclass('cc.MyComponent') export class MyComponent extends Component { @type(WebView) webview = null; start () { const eventHandler = new Component.EventHandler(); eventHandler.target = newTarget; // This node is the one that the component that contains your event handler code belongs to eventHandler.component = \"MyComponent\"; eventHandler.handler = \"callback\"; eventHandler.customEventData = \"foobar\"; this.webview.webviewEvents.push(eventHandler); } // Note that the order and type of parameters are fixed callback: function(webview, eventType, customEventData) { // here webview is a WebView component instance // here the value of eventType === WebView.EventType enum // The customEventData parameter here is equal to the \"foobar\" } } Method two Add event callback with webview.node.on (WebView.EventType.LOADED, ...) // Suppose we add event handling callbacks in the onLoad method of a component and perform event handling in the callback function: import { _decorator, Component, WebView } from 'cc'; const { ccclass, type } = _decorator; @ccclass('WebViewCtrl') export class WebViewCtrl extends Component { @type(WebView) webview = null; start () { this.webview.node.on(WebView.EventType.LOADED, this.callback, this); } callback (event) { // The event here is an EventCustom object, and you can get the WebView component through event.detail let videoplayer = event.detail; // do whatever you want with webview // Also, note that this way the registered event can not pass customEventData } } Likewise, you can also register WebView.EventType.LOADING, WebView.EventType.ERROR events, and the parameters of the callback function for these events are consistent with the WebView.EventType.LOADED parameters. How to interact with WebView internal pages Calling the WebView internal page import { _decorator, Component, WebView } from 'cc'; const { ccclass, type } = _decorator; @ccclass('WebViewCtrl') export class WebViewCtrl extends Component { @type(WebView) webview = null; start () { // The Test here is a global function defined in your webView's internal page code this.webview.evaluateJS('Test()'); } } Note: cross-domain issues on Web platform need to be resolved by yourself as Cocos Creator does not assist with this. WebView internal pages call external code The current mechanism used by Android and iOS is to determine if the keywords in the URL prefix are the same, and if they are, then a callback is made. Setting the URL prefix keyword through setJavascriptInterfaceScheme The callback function is set by setOnJSCallback, and the function parameter is URL import { _decorator, Component, WebView } from 'cc'; const { ccclass, type } = _decorator; @ccclass('WebViewCtrl') export class WebViewCtrl extends Component { @type(WebView) webview = null; // Setting in onLoad will make the callback useless, so we must set the WebView callback in the start cycle. start () { // Here are the keywords that are agreed with the internal page // Please set the scheme with lower case, the native won't identify the uppercase char scheme. let scheme = \"testkey\"; function jsCallback (target, url) { // The return value here is the URL value of the internal page, and it needs to parse the data it needs. let str = url.replace(scheme + '://', ''); // str === 'a=1&b=2' // webview target console.log(target); } this.webview.setJavascriptInterfaceScheme(scheme); this.webview.setOnJSCallback(jsCallback); } } When you need to interact with WebView through an internal page, you should set the internal page URL: testkey://(the data you want to callback to WebView later). WebView internal page code: function onClick () { // One of them sets up the URL scheme document.location = 'testkey://a=1&b=2'; } Due to limitations of the Web platform, it can not be implemented by this mechanism, but internal pages can interact in the following ways: function onClick () { // The parent here is actually the window of the WebView layer, // so that you can access the function defined in CC parent.cc.TestCode(); // If TestCode is defined on window, then parent.TestCode(); } Note: cross-domain issues on Web platform need to be resolved by yourself as Cocos Creator does not assist with this. "},"ui-system/components/editor/videoplayer.html":{"url":"ui-system/components/editor/videoplayer.html","title":"VideoPlayer Reference","keywords":"","body":"VideoPlayer Component Reference VideoPlayer is a component for playing videos, you could use this component for playing local video and remote videos. Playing a local video: Playing a remote video: Click Add Component at the bottom of Properties panel and select VideoPlayer from UI Component to add the VideoPlayer component to the node. For more information about VideoPlayer's scripting interface, please refer to the VideoPlayer API documentation. VideoPlayer Properties Properties Function Explanation Resource Type The resource type of videoplayer, REMOTE for remote url and LOCAL for local file path. Remote URL Displayed when Resource Type is REMOTE, feed it with a remote video URL. Clip Displayed when Resource Type is LOCAL, feed it with a local video path. Play On Awake Whether the video start playing automatically after loaded? Current Time The current playback time of the now playing item in seconds, you could also change the start playback time. Volume The volume of the video. (0.0 ~ 1.0) Mute Mutes the VideoPlayer. Mute sets the volume=0, Un-Mute restore the original volume. Keep Aspect Ratio Whether keep the aspect ratio of the original video. Full Screen On Awake Whether play video in fullscreen mode. Stay On Bottom Display video below the game view (Only available on web). Video Player Event The video player's callback, it will be triggered when certain event occurs. Please refer to the VideoPlayer Event section below or VideoPlayerEvent API for more details. Note: in the Node of the Video Player Event property, you should fill in a Node that hangs the user script component, and in the user script you can use the relevant VideoPlayer event according to the user's needs. VideoPlayer Event VideoPlayerEvent Event Properties Function Explanation target Node with the script component. component Script component name. handler Specify a callback, when the video player is about to playing or paused, it will be called. There is a parameter in the callback which indicate the state of played videos. customEventData The user specifies that any string is passed in as the last parameter of the event callback For more information, please refer to the Component.EventHandler Class documentation. Parameter of VideoPlayerEvent Name Function Explanation NONE None PLAYING Video is playing. PAUSED Video is paused. STOPPED Video is stopped. COMPLETED Video is completed. META_LOADED Video's meta data is loaded. READY_TO_PLAY Video is ready to play. ERROR Video Trigger Error CLICKED Video is clicked by the user. (Only supports Web platform.) Note: on iOS, due to the platform limitations, the CLICKED event can't be fired when VideoPlayer is in fullscreen mode. If you want to let the Video played in fullscreen and also fire the CLICKED event properly, you should use a Widget component to hack the VideoPlayer's size. For more information, please refer to the VideoPlayer Events documentation or the 21.video-player example in the test-cases-3d samples bundled with Cocos Creator. Detailed Explanation The supported video types is mp4 format. Add a callback via script Method one This method uses the same API that editor uses to add an event callback on Button component. You need to construct a Component.EventHandler object first, and then set the corresponding target, component, handler and customEventData parameters. import { _decorator, Component, VideoPlayer } from 'cc'; const { ccclass, type } = _decorator; @ccclass('cc.MyComponent') export class MyComponent extends Component { @type(VideoPlayer) videoPlayer = null; start () { const eventHandler = new Component.EventHandler(); eventHandler.target = newTarget; eventHandler.component = \"MyComponent\"; eventHandler.handler = \"callback\"; eventHandler.customEventData = \"foobar\"; this.videoplayer.videoPlayerEvent.push(eventHandler); } // the order of parameters should not change callback: function(videoplayer, eventType, customEventData) { // videoplayer is a VideoPlayer component instance // eventType is typed as VideoPlayer.EventType // customEventData is \"foobar\" } } Method two Add event callback with videoplayer.node.on(VideoPlayer.EventType.READY_TO_PLAY, ...) // Suppose we add event handling callbacks in the onLoad method of a component and perform event handling in the callback function: import { _decorator, Component, find, VideoPlayer } from 'cc'; const { ccclass, type } = _decorator; @ccclass('VideoPlayerCtrl') export class VideoPlayerCtrl extends Component { @type(VideoPlayer) videoPlayer = null; start () { this.videoplayer.node.on(VideoPlayer.EventType.READY_TO_PLAY, this.callback, this); } callback (videoplayer) { // The \"videoplayer\" here represents the VideoPlayer component. // do whatever you want with videoplayer // you can't pass customEventData in this way } } Likewise, it is also posible to register the meta-loaded, clicked, playing events, and the parameters of the callback function for these events are consistent with the ready-to-play parameters. Please refer to the VideoPlayer API documentation for details on VideoPlayer events. Note: as VideoPlayer is a special component, it cannot register touch or mouse events on the node with VideoPlayer component. How to display a UI upon a video You can display a UI upon a video in two steps: Make sure the ENABLE_TRANSPARENT_CANVAS checkbox is checked. It can be found in the Macro Config page in Project Settings Check the stayOnBottom property on the VideoPlayer in the Properties panel. Notes: This feature is only supported on Web. The specific effects are not guaranteed to be consistent, depending on whether each browser supports or restricts. After the stayOnBottom is enabled, the clicked event in VideoPlayerEvent cannot be listened normally. For more information, please refer to the 21.video-player example in the test-cases-3d samples bundled with Cocos Creator. Results as shown below: Support platform Because different platforms have different authorization, API and control methods for VideoPlayer component. And have not yet formed a unified standard, only Web, iOS, Android, WeChat Mini Games, Facebook Instant Games and Google Play Instant platforms are currently supported. Questions about autoplay Some mobile browsers or WebView do not allow auto-playing of videos and users need to play the video manually in a touch event. import { _decorator, Node, Component, find, VideoPlayer } from 'cc'; const { ccclass, type } = _decorator; @ccclass('VideoPlayerCtrl') export class VideoPlayerCtrl extends Component { @type(VideoPlayer) videoPlayer = null; start () { let canvas = find('Canvas'); canvas.on(Node.EventType.TOUCH_START, this.playVideo, this); } playVideo () { this.videoplayer.play(); } } "},"ui-system/components/editor/safearea.html":{"url":"ui-system/components/editor/safearea.html","title":"SafeArea Reference","keywords":"","body":"SafeArea component reference This component is used to adjust the layout of current node to respect the safe area of a notched mobile device such as the iPhone X. It is typically used for the top node of the UI interaction area. For specific usage, refer to the SafeArea example in the example-cases. The concept of safe area is to give you a fixed inner rectangle in which you can safely display content that will be drawn on screen. It is strongly discouraged from providing controls outside of this area. But the screen background could embellish edges. The developer only needs to add the component on the node, without any settings. This component internally uses the API cc.sys.getSafeAreaRect(); to obtain the safe area of the current iOS or Android device and implements the adaptation by using the Widget component and set anchor. (If there is no Widget component, it will be added automatically) Please refer to the SafeArea API. "},"scripting/":{"url":"scripting/","title":"Scripting Guide and Event Mechanism","keywords":"","body":"Scripting Cocos Creator scripts are used to implement user-defined (game) behaviors. Script Creation Script Basics Language Support Modules Script Execution Order ccclass Access Node and Other Components Commonly Used Nodes and Component Interfaces Lifecycle Callbacks Creating and Destroying Nodes Loading and Switching Scenes Obtaining and Loading Assets Scheduler Components and Component Order Event System Listening to and launching events Builtin Events Global Events Event API Attribute Parameter Reference Plugin Script CCClass Advanced Reference Add Log Deprecated API Events As a very commonly used system in the engine, we provide a complete and efficient event system for developers to use. For details, please see: Event Mechanism "},"scripting/setup.html":{"url":"scripting/setup.html","title":"Script Creation","keywords":"","body":"Creating scripts Creating component scripts In Cocos Creator, scripts are also part of resources. You can add and select TypeScript to create a component script by clicking the Create button in the Asset panel. Example: A simple component script may look like this example: import { _decorator, Component, Node } from 'cc'; const { ccclass, property } = _decorator; @ccclass('NewScript') export class NewScript extends Component { /* class member could be defined like this */ // dummy = ''; /* use `property` decorator if your want the member to be serializable */ // @property // serializableDummy = 0; start () { // Your initialization goes here. } // update (deltaTime: number) { // // Your update function goes here. // } } Note: it is recommended that users use TypeScript to write scripts. If you wish to use JavaScript to write scripts, they can be created directly in the operating system file manager, or created in a code editor. Editing scripts Users can choose their favorite text-editing tools (such as: Vim, Sublime Text, Web Storm, VSCode...) for script editing according to their own needs, please go to Settings to set. By double-clicking the script resource, the script editor directly opens to allow for editing. When the script is edited and saved, Cocos Creator will automatically detect the changes to the script and compile it quickly. Before writing code, please read Basics of Scripting documentation to learn more about scripts. Add a script to a scene node Adding the script to the scene node is actually adding a component to this node. Let's first rename the newly created NewScript.js to say-hello.js. Then select the scene node we want to add, and the attributes of the node will be displayed in the Attribute Inspector. At the bottom of the Inspector panel, there is a Add component button. Click the button and select Add User Script -> say-hello to add the script component we just wrote. If all goes well, you will see your script displayed in the Inspector panel: Note: users can also add scripts by directly dragging and dropping script resources to the Inspector panel. Default script editing tool configuration "},"scripting/basic.html":{"url":"scripting/basic.html","title":"Scripting Basics","keywords":"","body":"Operating environment The APIs for the Cocos Creator engine all exist in the module cc. They can be imported it using standard ES6 module import syntax. Example: import { Component, // Import class Component _decorator, // mport namespace _decorator } from \"cc\"; import * as cc from \"cc\"; // Import the entire Cocos Creator module as a namespace Cocos Creator @_decorator.ccclass(\"MyComponent\") export class MyComponent extends Component { public v = new cc.Vec3(); } Reserved identifier cc Due to historical reasons, cc is an identifier reserved for Cocos Creator. Its behavior is equivalent to having defined an object named cc at the top of any module. Therefore, developers should not use cc as the name of any global object. Example: /* const cc = {}; // Every Cocos Creator script is equivalent to an implicit definition here */ import * as cc from \"cc\"; // Error: Namespace import name cc is reserved by Cocos Creator const cc = { x: 0 }; console.log(cc.x); // Error: The global object name cc is reserved by Cocos Creator function f () { const cc = { x: 0 }; console.log(cc.x); // Correct: cc can be used as the name of a local object const o = { cc: 0 }; console.log(o.cc); // Correct: cc can be used as a property name } console.log(cc, typeof cc); // error: behavior is undefined "},"scripting/language-support.html":{"url":"scripting/language-support.html","title":"Language Support","keywords":"","body":"Language Support TypeScript Cocos Creator supports TypeScript 4.1.0. The following restrictions are based on TypeScript 4.1.0: tsconfig.json will not be read. The following options are implied for each project: { \"compilerOptions\": { \"target\": \"ES2015\", \"module\": \"ES2015\", \"isolatedModules\": true, \"experimentalDecorators\": true, \"moduleResolution\": /* Cocos Creator's specific module resolution algorithm */, \"forceConsistentCasingInFileNames\": true, }， } The implicit isolatedModules option means that: const enums is not supported. Use export type when re-exporting TypeScript types and interfaces. For example, use export type { Foo } from '. /foo'; instead of export { Foo } from '. /foo';. export = and import = are not supported. Variables derived from namespace must be declared as const, not var or let. Different declarations in the same namespace do not share scope and require explicit use of qualifiers. Type errors during compilation will be ignored. tsconfig.json is not read at compile time, meaning that the compile option for tsconfig.json does not affect compilation. Developers can still use tsconfig.json in their projects to work with the IDE to implement features such as type checking. In order to make the IDE's TypeScript checking compatible with the Creator's behavior, developers need to pay some extra attention to tsconfig. JavaScript Language Features The JavaScript language specification supported by the Creator is ES6. In addition, the following language features or proposals, updated to the ES6 specification, are still supported. Public class fields Promise Optional chaining operator ?. Nullish coalescing operator ?? Logical assignment operators Logical nullish assignment operator ??= Logical AND assignment operator &&= Logical OR assignment operator ||= Global object globalThis The following language features are also supported, but require the relevant compilation options to be turned on: async functions In particular, Creator currently supports Legacy decorator proposals, see babel-plugin-proposal-decorators for their usage and meaning. Since this proposal is still in phase 2, all decorator-related functional interfaces exposed by the engine are under the _decorator namespace starting with an underscore. Compilation Options Creator opens some compilation options that will be applied to the entire project. Option Name Meaning useDefineForClassFields Conforming class fields When enabled, class fields will be implemented using the Define semantics, otherwise they will be implemented using the Set semantics. Only works if the target does not support ES6 class fields. allowDeclareFields Allows declaring class fields When enabled, the declare keyword will be allowed in TypeScript scripts to declare class fields and, when the field is not declared with declare and no explicit initialization is specified, it will be initialized according to the specification to undefined. The Runtime Environment From the user's perspective, Creator does not bind any JavaScript implementation, so it is recommended that developers write scripts strictly according to the JavaScript specification for better cross-platform support. For example, when wishing to use global objects, the standard feature globalThis should be used: globalThis.blahBlah // 'globalThis' must exist in any environment instead of window, global, self or this: typeof window // May be 'undefined' typeof global // May be 'undefined' in the browser environment Again, Creator does not provide a module system for CommonJS, so the following code snippet would pose a problem: const blah = require('./blah-blah'); // Error, require is undefined module.exports = blah; // Error, module is undefined Instead, the standard module syntax should be used: import blah from './blah-blah'; export default blah; Related Tutorials JavaScript Standard Reference Tutorial [cn] JavaScript Garden JavaScript Memory Detailing & Analysis Guide [cn] "},"scripting/modules/":{"url":"scripting/modules/","title":"Module","keywords":"","body":"Modules The engine and editor expose their APIs to developers through modules, which exist as ECMAScript modules. Note: starting from 3.0, engine functions cannot be accessed through the global variable, prefixed with cc! Engine Module Functionality Module 'cc' provide access to engine functionalities. The content of the 'cc' module is dynamic, and its content is related to the setting of Feature crop in Project Settings. Engine logging An example is shown below: import { log } from 'cc'; log('Hello world!'); Constants at build time The engine module 'cc/env' exposes some constants at build time. These constants represent the execution environment, debug level, or platform identification. As these constants are declared with const, it provides a good opportunity for code optimization. Execution environment Name (all types are boolean) Description BUILD Is it running in the built environment. PREVIEW Is it running in the preview environment. EDITOR Is it running in the editor environment. Debug level Name (all types are boolean) Description DEBUG Whether it is in debug mode. It is false only when the debug option is not checked when building, and it is true in all other cases DEV Equivalent to DEBUG/EDITOR/PREVIEW Platform identification The constants listed in the following table represent whether it is running on a particular platform or class of platforms, and all types of these constants are boolean. Name Platform MINIGAME mini game RUNTIME_BASED based on Cocos Runtime SUPPORT_JIT JIT is supported HTML5 Web ❌ ❌ ❌ NATIVE Native platforms ❌ ❌ ❌ ALIPAY Alipay Mini Game ✔️ ❌ ✔️ BAIDU Baidu Mini Game ✔️ ❌ ✔️ BYTEDANCE Bytedance Mini Game ✔️ ❌ ✔️ WECHAT WeChat Mini Game ✔️ ❌ ✔️ XIAOMI Xiaomi Quick Game ✔️ ❌ ✔️ COCOSPLAY Cocos Play ❌ ✔️ ✔️ HUAWEI Huawei Quick Game ❌ ✔️ ✔️ OPPO OPPO Mini Game ❌ ✔️ ✔️ VIVO vivo Mini Game ❌ ✔️ ✔️ Logging in debug mode An example is shown below: import { log } from 'cc'; import { DEV } from 'cc/env'; if (DEV) { log('I am in development mode!'); } Editor Modules The editor modules are all under the 'cce:' protocol (cce stands for \"CocosCreatorEditor\"). All editor modules are only available in the editor environment. For example, the editor module cannot be accessed in the environment after previewing and building, on the contrary, it can be accessed in the Scene panel. "},"scripting/ccclass.html":{"url":"scripting/ccclass.html","title":"ccclass","keywords":"","body":"CCClass When the decorator ccclass is applied to a class, the class is called ccclass. The ccclass injects additional information to control Cocos Creator 3.0's serialization of this kind of object along with the editor's display for these types of objects. ccclass Various characteristics of the ccclass are specified by the ccclass option parameter of ccclass(name). ccclass name The option name specifies the name of the ccclass. The ccclass name should be unique. When you need the corresponding ccclass, you can find it by its ccclass name, for example: Serialization. If the object is a cc object, the ccclass name of the object will be recorded during serialization. During deserialization, the corresponding ccclass will be found for serialization based on this name. When the ccclass is a component class, Node can find the component by its ccclass name. ccattributes When the decorator property is applied to a property or accessor of the ccclass, this property is called a ccproperty. Similar to the ccclass, the ccattribute injects additional information to control the serialization of the attribute in Cocos Creator 3.0 and the display of the attribute in the editor. Property Various characteristics of the ccattribute are specified by the ccattribute option parameter of property(). cctype The option type specifies the cctype of the attribute. The type can be specified by the following parameters: Constructor The type specified by the constructor is directly used as the cctype of the attribute. Note: when Javascript built-in constructors Number, String, Boolean A warning will be given when used as a cctype, and they are regarded as cctypes CCFloat, CCString, and CCBoolean respectively. Cocos Creator 3.0 built-in attribute type identification. CCInteger, CCFloat, CCBoolean, and CCString are built-in attribute type identifiers. CCInteger declares the type as integer. CCFloat declares the type as floating point number. CCString declares the type as string. CCBoolean declares the type as Boolean. Array When using the constructor, built-in property type identification or array as the array element, the properties are specified as Cocos Creator 3.0 array. For example, [CCInteger] declares the type as a array whose elements are integers. If the attribute does not specify the cctype, Cocos Creator 3.0 will derive its cctype from the default value of the attribute or the evaluation result of the initialization formula: If the value type is Javascript primitive type number, string, boolean, the cctypes are Creator floating point, string, and boolean values, respectively. Otherwise, if the value is an object type, it is equivalent to using the object's constructor to specify the cctype. Otherwise, the cctype of the attribute is undefined. Generally, you only need to explicitly declare the cctype in the following situations: When the attribute needs to be displayed as an integer. When the actual value of the attribute may be of multiple types. For how the cctype affects the cc attribute and the treatment of attributes that do not define the cctype, see: Attribute Type Serialization parameter For convenience, the following decorators are additionally provided to quickly declare the cctype: Type Equivalent to @type(t) @property(t) @integer @property(CCInteger) @float @property(CCFloat) @string @property(CCString) @boolean @property(CCBoolean) The following code demonstrates the declaration of ccattributes of different cctypes: import { _decorator, CCInteger, Node } from \"cc\"; const { ccclass, property, integer, float, boolean, string, type } = _decorator; @ccclass class MyClass { @integer // Declare that the cc type of the attribute _id is a Cocos integer private _id = 0; @type(Node) // Declare that the cc type of the attribute _targetNode is Node private _targetNode: Node | null = null; @type([Node]) // declare the cc type of the attribute _children as a Node array private _children: Node[] = []; @property private _count = 0; // the cc type is not declared, and it is inferred from the evaluation result of the initializer as a Cocos floating point number @type(String) // Warning: Constructor should not be used String // equivalent to CCString private _name: string = ''; @property private _children2 = []; // The cc type is not declared, inferred from the evaluation result of the initializer: the element is an undefined Cocos array } Defaults The option default specifies the default value of the cc attribute. Constructor Defined By Constructor The constructor of CCClass is defined by constructor. To ensure that deserialization can always run correctly, constructor is not allowed to define constructor parameters**. Note: if developers really need to use construction parameters, they can get them through arguments, but remember that if this class will be serialized, you must ensure that the object can still be new when the construction parameters are all default. Judging The Type Judgment Example When making type judgments, use TypeScript native instanceof: class Sub extends Base { } let sub = new Sub(); console.log(sub instanceof Sub); // true console.log(sub instanceof Base); // true let base = new Base(); console.log(base instanceof Sub); // false Members Instance Variables The instance variables defined in the constructor cannot be serialized, nor can they be viewed in the Inspector panel. class Sprite { // Declare variables url: string; id: number; constructor() { // assignment this.url = \"\"; this.id = 0; } } Note: if it is a private variable, it is recommended to add an underscore _ in front of the variable name to distinguish it. Example Method Please declare the instance method in the prototype object: class Sprite { text: string; constructor() { this.text = \"this is sprite\" } // Declare an instance method named \"print\" print() { console.log(this.text); } } let obj = new Sprite(); // call instance method obj.print(); Static Variables and Static Methods Static variables or static methods can be declared with static: class Sprite { static count = 0; static getBounds() { } } Static members will be inherited by subclasses. When inheriting, the static variables of the parent class will be shallowly copied to the subclass. Therefore: class Object { static count = 11; static range: { w: 100, h: 100 } } class Sprite extends Object { } console.log(Sprite.count); // The result is 11 because count inherits from the Object class Sprite.range.w = 200; console.log(Object.range.w); // The result is 200, because Sprite.range and Object.range point to the same object If you don't need to consider inheritance, private static members can also be defined directly outside the class: // local method doLoad(sprite) { // ... }; // local variables let url = \"foo.png\"; class Sprite { load() { this.url = url; doLoad(this); }; }; Inheritance Parent Constructor Please note that regardless of whether the subclass has a constructor defined, the constructor of the parent class will be automatically called before the subclass is instantiated. class Node { name: string; constructor() { this.name = \"node\"; } } class Sprite extends Node { constructor() { super(); // Before the child constructor is called, the parent constructor has been called, so this.name has been initialized console.log(this.name); // \"node\" // reset this.name this.name = \"sprite\"; } } let obj = new Sprite(); console.log(obj.name); // \"sprite\" Rewrite All member methods are virtual methods, and child methods can directly override parent methods: class Shape { getName() { return \"shape\"; } }; class Rect extends Shape { getName () { return \"rect\"; } }; let obj = new Rect(); console.log(obj.getName()); // \"rect\" Attributes Attributes are special instance variables that can be displayed in the Inspector panel and can also be serialized. Properties and Constructors The attribute not required is defined in the constructor. Before the constructor is called, the attribute has been assigned a default value and can be accessed in the constructor. If the default value of the attribute cannot be provided when defining the ccclass and needs to be obtained at runtime, you can also re-assign the default value to the attribute in the constructor. class Sprite { constructor() { this.num = 1; } @property({ type: CCInteger }) private num = 0; } However, it should be noted that the process of property deserialization occurs immediately after the execution of the constructor, so the default value of the property can only be obtained and modified in the constructor, and it cannot be obtained and saved before the modification (serialization ) value. Attribute Parameters Default Parameter default is used to declare the default value of the attribute. The attribute with the default value will be implemented as a member variable by ccclass. The default value is only used when the object is created for the first time, which means that when the default value is modified, the current value of the component that has been added to the scene will not be changed. Note: after you add a component to the editor, go back to the script to modify a default value, there is no change in the Inspector panel. Because the current value of the property has been serialized into the scene, it is no longer the default value used when it was first created. If you want to force all properties to be reset to default values, you can select Reset in the component menu of the Inspector panel. default can be set to the following value types: Any number, string or boolean type value null or undefined Subclasses inherited from ValueType, such as instantiated objects of Vec3, Color or Rect: @property({ type: Vec3 }) private pos = null; Empty array [] or empty object {} Visible Parameter By default, whether it is displayed in the Inspector panel depends on whether the attribute name starts with an underscore _. If it starts with an underscore, it will not be displayed in the Inspector panel by default, otherwise it will be displayed by default. If you want to force it to be displayed in the Inspector panel, you can set the visible parameter to true: @property({ visible: true }) private _num = 0; If you want to force hiding, you can set the visible parameter to false: @property({ visible: false }) private num = 0; Serializable Parameters Attributes with a default value of default will be serialized by default. After serialization, the values set in the editor will be saved to resource files such as scenes, and the previously set values will be automatically restored when the scene is loaded. If you don't want to serialize, you can set serializable: false. @property({ serializable: false }) private num = 0; Type Parameter When default cannot provide enough detailed type information, in order to display the correct input control in the Inspector panel, you must use type to explicitly declare the specific type: When the default value is null, set type to the constructor of the specified type, so that the Inspector panel knows that a Node control should be displayed. @property({ type: Node }) private enemy = null; When the default value is a number type, set the type to cc.Integer to indicate that this is an integer, so that the attribute cannot be entered in the decimal point in the Inspector panel. @property({ type: CCInteger }) private num = 0; When the default value is an enumeration (Enum), since the enumeration value itself is actually a number, the type must be set to the enumeration type to be displayed in the Inspector panel enumerate the drop-down box. enum A { c, d } Enum(A); @ccclass(\"test\") export class test extends Component { @property({ type: A }) accx:A=A.c; } Override Parameters All properties will be inherited by the subclass. If the subclass wants to override the property with the same name of the parent class, you need to explicitly set the override parameter, otherwise there will be a duplicate name warning: @property({ type: CCString, tooltip: \"my id\", override: true }) private _id = \"\"; @property({ displayName: \"Name\", override: true }) private _name = null; private get name() { return this._name; } For more parameters, please refer to the Property Parameters documentation. get/set methods After the get or set is set in the property, when the property is accessed, the predefined get or set method can be triggered. get Set the get method in the properties: @property({ type: CCInteger }) private _num = 0; private get num() { return this._num; } The get method can return any type of value. This property can also be displayed in the Inspector panel and can be directly accessed in all codes including the constructor. class Sprite { _width: number; constructor() { this._width = 128; console.log(this.width); // 128 } @property({ type: CCInteger }) private width = 0; private get width() { return this._width; } }; As get accessor is used, this property cannot be serialized, nor can it be assigned a default value, but most parameters except default and serializable can still be attached. @property({ type: CCInteger, tooltip: \"The width of sprite\" }) private _width = 0; private get width() { return this._width; } The get accessor is read-only, but the returned object is not read-only. Users can still modify the internal properties of the object using code, for example: @property _num = 0; private get num() { return this._num; } start() { consolo.log(this.num); } set Set the set method in the properties: @property({ type: CCInteger }) private _width = 0; set(value) { this._width = value } The set method receives an incoming parameter, which can be of any type. set is generally used with get: @property _width = 0; private get width() { return this._width; } set(value) { this._width = value; } Notes: If it is not defined together with get, the set itself cannot be accompanied by any parameters. Like get, after set is set, this property cannot be serialized, nor can it be assigned a default value. "},"scripting/reference/attributes.html":{"url":"scripting/reference/attributes.html","title":"Attributes","keywords":"","body":"Attributes Attributes are used to attach metadata to defined properties, similar to Decorator in scripting languages or Attribute in C#. Related Attributes on Inspector Panel Attribute Name Description Type Default Remarks type Restrict the data type of the property (Any) undefined See type attribute visible Show or hide in the Inspector panel boolean [1] See visible attribute displayName Show as another name in the Inspector panel string undefined - tooltip Add a Tooltip for a property in the Inspector panel string undefined - multiline Use multi-line text boxes in the Inspector panel boolean false - readonly Read-only in the Inspector panel boolean false - min Restrict the minimum value in the Inspector panel number undefined - max Restrict the maximum value in the Inspector panel number undefined - step Restrict the step value in the Inspector panel number undefined - range Set min, max, step [min, max, step] undefined step value optional slide Show as a slider in the Inspector panel boolean false - Serialization-Related Attributes The following attributes cannot be used with the get method. Attribute Name Description Type Default Remarks serializable Serialize this property boolean true See serializable attribute formerlySerializedAs Specify the name of the field used in the previous serialization string undefined Declare this attribute when renaming the property to be compatible with the previously serialized data editorOnly Exclude this property before exporting the project boolean false - Other Attributes Attribute Name Description Type Default Remarks default Define the default value of an attribute (Any) undefined See default attribute notify Trigger the specified method when the property is assigned a value function (oldValue) {} undefined The default attribute needs to be set and its value cannot be an array. Not support ES6 definitions override Define this parameter as true when overriding parent properties boolean false See override parameter animatable Whether this property can be modified by the animation editor boolean undefined - [1]: The default value of visible depends on the property name. When the property name starts with an underscore _, it is hidden by default, otherwise it is shown by default. "},"scripting/access-node-component.html":{"url":"scripting/access-node-component.html","title":"Access Node and Other Components","keywords":"","body":"Access Nodes and Components You can modify Nodes and Components in the Inspector panel, and also dynamically using scripts. The advantage of dynamic modification is that it can continuously modify attributes and transition attributes within a period of time to achieve gradual effects. Scripts can also respond to player input, modify, create and destroy Nodes or Components, and implement various game logic. To achieve these effects, developers need to obtain the Node or Component that needs to be modified in the script. Document topics Obtain the node where the component is located. Obtain other components. Use Inspector panel to set up nodes and components. Find child nodes. Global node search. Access values in existing variables. Obtain the node where the component is located It's easy to get the node where the component is. Just access the this.node variable in the component method: start(){ let node = this.node; node.setPosition(0.0,0.0,0.0); } Obtaining other components It will often be need to get other components on the same node. Use the getComponent API, which will help to find the component that is needed. import { _decorator, Component, LabelComponent } from \"cc\"; const { ccclass, property } = _decorator; @ccclass(\"test\") export class test extends Component { private label: any = null start(){ this.label = this.getComponent(LabelComponent); let text = this.name + 'started'; // Change the text in Label Component this.label.string = text; } } It is also possible to pass in a class name for getComponent. For user-defined components, the class name is the file name of the script and is case sensitive. For example, the component declared in SinRotate.ts, the class name is SinRotate. let rotate = this.getComponent(\"SinRotate\"); There is also ther getComponent method on the node, and their functions are the same: start() { console.log( this.node.getComponent(LabelComponent) === this.getComponent(LabelComponent) ); // true } If the component that is needed is not found on the node, getComponent will return null. If you try to access the value of null, a TypeError error will be thrown at runtime. If you are not sure whether the component exists, please remember to check: import { _decorator, Component, LabelComponent } from \"cc\"; const { ccclass, property } = _decorator; @ccclass(\"test\") export class test extends Component { private label: any =null; start() { this.label = this.getComponent(LabelComponent); if (this.label) { this.label.string = \"Hello\"; } else { console.error(\"Something wrong?\"); } } } Get other nodes and their components It is usually not enough to only have access to the node's own components, and scripts usually require interaction between multiple nodes. For example, a cannon that automatically aims at the player needs to constantly obtain the latest position of the player. Cocos Creator provides some different methods to obtain other nodes or components. Use the Inspector panel to set the node The most straightforward way is to set the objects you need in the Inspector panel. Take node as an example, this only needs to declare an attribute with type Node in the script: // Cannon.ts import { _decorator, Component, Node } from \"cc\"; const { ccclass, property } = _decorator; @ccclass(\"Cannon\") export class Cannon extends Component { // Declare Player properties @property({type:Node}) private player = null; } This code declares a player property in properties, the default value is null, and its object type is specified as Node. This is equivalent to declaring public Node player = null; in other languages. After the script is compiled, this component looks like this in the Inspector panel: Then you can drag any node on the Hierarchy panel to the Player control: The Player property will be set successfully, and can be accessed directly in a script. Example: // Cannon.ts import { _decorator, Component, Node } from \"cc\"; const { ccclass, property } = _decorator; @ccclass(\"Cannon\") export class Cannon extends Component { @property({type:Node}) private player = null; start() { console.log('The player is ' + this.player.name); } } Use the Inspector panel to set up components In the above example, if the type of the attribute is declared as a Player component, when the Player node is dragged to the Inspector panel, the Player attribute will be set to the Player component in this node. This way developers don't need to call getComponent() themselves. // Cannon.ts import { _decorator, Component } from \"cc\"; const { ccclass, property } = _decorator; import { Player } from \"Player\"; @ccclass(\"Cannon\") export class Cannon extends Component { @property({type:Player}) private player = null; start(){ let PlayerComp = this.player; } } The default value of the property can be changed from null to array [], so that multiple objects in the Inspector panel can be set at the same time. However, if dynamically obtaining other objects at runtime is needed, it is also necessary to use the search method described below. Find child nodes Sometimes, there are many objects of the same type in the game scene, such as turrets, enemies, and special effects, and they usually have a global script to manage them uniformly. Using the Inspector panel to associate them with this script one by one, the work will be very tedious. In-order to better manage these objects uniformly, they can be put under a unified parent object, and then obtain all the child objects through the parent object: // CannonManager.ts import { _decorator, Component, Node } from \"cc\"; const { ccclass, property } = _decorator; @ccclass(\"CannonManager\") export class CannonManager extends Component { start() { let cannons = this.node.children; //... } } Using getChildByName: this.node.getChildByName(\"Cannon 01\"); If the child node has a deeper level, find can be used, and will search step by step according to the path passed in: find(\"Cannon 01/Barrel/SFX\", this.node); Global name lookup When find only passes in the first parameter, it will be searched step by step from the scene root node: this.backNode = find(\"Canvas/Menu/Back\"); Accessing values in existing variables If you have saved references to nodes or components in one place, you can also access them directly. Accessing via module Use import to implement script cross-file operations. Example: // Global.ts, now the filename matters import { _decorator, Component, Node } from \"cc\"; const { ccclass, property } = _decorator; @ccclass(\"Global\") export class Global extends Component { public static backNode:any=null; public static backLabel:any=null; } Each script can use import{} from + file name (without path) to get the object of the other party's exports. Example: // Back.ts import { _decorator, Component, Node, LabelComponent } from \"cc\"; const { ccclass, property } = _decorator; // this feels more safe since you know where the object comes from import{Global}from \"./Global\"; @ccclass(\"Back\") export class Back extends Component { onLoad(){ Global.backNode=this.node; Global.backLabel=this.getComponent(LabelComponent); } } // AnyScript.ts import { _decorator, Component, Node } from \"cc\"; const { ccclass, property } = _decorator; // this feels more safe since you know where the object comes from import{Global}from \"./Global\"; @ccclass(\"AnyScript\") export class AnyScript extends Component { start () { const text = \"Back\"; Global.backLabel.string=text; } } "},"scripting/basic-node-api.html":{"url":"scripting/basic-node-api.html","title":"Common Node and Component Interface","keywords":"","body":"Common Node and Component Interface After obtaining a Node or Component instance through the method introduced in the Access Node and Component documentation, there are common interfaces that can be used to achieve the various effects needed through the node and component instance and it's operation. Please review the Node and the Component API documentation. Node Status and Level Operations Suppose you are inside a running component script, to access a node inside the current script use this.node. Activating and Deactivating a Node A node is activated by default. It's activation state can be changed in code by setting the node's active property. Example: this.node.active = false; Setting the active property and switching the active and closed states of the node in the editor have the same effect. When a node is down, all its components will be disabled. At the same time, all its child nodes and components on the child nodes will also be disabled. It should be noted that when child nodes are disabled, their active attributes are not changed, so they will return to their original state when the parent node is reactivated. In other words, active actually represents the active state of the node itself, and whether this node current can be activated depends on its parent node. And if it is not in the current scene, it cannot be activated. We can use the read-only attribute activeInHierarchy on the node to determine whether it is currently activated. Example: this.node.active = true; If the node is in the can be activated state, modifying active to true will immediately trigger the following activation operations: Reactivate the node and all child nodes under the node whose active is true in the scene All components on this node and all child nodes will be enabled, and the update method in them will be executed every frame afterwards If there are onEnable methods on these components, these methods will be executed this.node.active = false; If the node is already activated, changing active to false will immediately trigger the following shutdown operations: Hide the node and all child nodes under the node in the scene All components on this node and all child nodes will be disabled, that is, the code in update in these components will no longer be executed If there are onDisable methods on these components, these methods will be executed Change the Parent Node of a Node Suppose the parent node is parentNode and the child node is this.node. This is valid: // method 1 this.node.parent = parentNode; This is also valid: // method 2 this.node.removeFromParent(); parentNode.addChild(this.node); These two methods are equivalent. Notes: The removeFromParent usually needs to pass a false, otherwise it will empty the bound events and actions, etc. on the node by default. After creating a new node through the method introduced in the Create and Destroy Node documentation, it is a must to set a parent node for the node to correctly initialize the node. Child Nodes of the Parent Node this.node.children will return an array of all child nodes of the node. this.node.childrenCount will return the number of children of the node. Note: the above two APIs will only return the direct child nodes of the node, not the child nodes of the child node. Changing Node Transformations (position, rotation, scaling) Changing Node Location There are two ways: Use the setPosition method: this.node.setPosition(100, 50, 100); // Or this.node.setPosition(new Vec3(100,50,100)); Setting the position variable: this.node.position = new Vec3(100,50,100); The above two usages are equivalent. Changing Node Rotation Example: this.node.setRotation(quaternion); Or set local rotation by Euler angle: this.node.setRotationFromEuler(90,90,90); Changing Node Scale Example: this.node.setScale(2,2,2); Common Component Interface Component is the base class of all components, and any component includes the following common interfaces (assuming that we use this to refer to this component in the script of the component): this.node: The node instance to which this component belongs. this.enabled: Whether to execute the update method of the component every frame, and also to control whether the rendering component is displayed. update(deltaTime: number): As a member method of the component, when the component's enabled property is true, the code in it will be executed every frame. onLoad(): Executed when the node where the component is located is initialized (when the node is added to the node tree). start(): It will be executed before the first update of the component, usually used for logic that needs to be executed after the onLoad of all components is initialized. "},"scripting/life-cycle-callbacks.html":{"url":"scripting/life-cycle-callbacks.html","title":"Life Cycle Callbacks","keywords":"","body":"﻿ Life Cycle Callbacks Cocos Creator provides life cycle callback functions for component scripts. As long as the user defines a specific callback function, Cocos Creator will automatically execute related scripts in a specific period, and the user does not need to call them manually. The life cycle callback functions currently provided to users mainly include (order by life cycle trigger): onLoad() onEnable() start() update() lateUpdate() onDisable() onDestroy() onLoad() In the initialization phase of the component script, the onLoad() callback function is available. The onLoad() callback will be triggered when the node is activated for the first time, such as when the scene is loaded or the node is activated. In the onLoad() stage, it is guaranteed that you can get other nodes in the scene and the resource data associated with the nodes. onLoad() will always be executed before any start method is called, which can be used to arrange the initialization sequence of the script. Usually, some initialization related operations are performed in the onLoad() stage. Example: import { _decorator, Component, Node, SpriteFrame, find } from \"cc\"; const { ccclass, property } = _decorator; @ccclass(\"test\") export class test extends Component { @property({type:SpriteFrame}) bulletSprite=null; @property({type:Node}) gun=null; _bulletRect=null; onLoad(){ this._bulletRect=this.bulletSprite.getRect(); this.gun = find('hand/weapon'),this.node; } } onEnable() When the enabled attribute of the component changes from false to true, or the node's active attribute changes from false to true, the onEnable() callback will be activated. If the node is created for the first time and enabled is true, it will be called after onLoad() but before start(). start() The start() callback function will be triggered before the first activation of the component, that is, before the first execution of update(). start() is usually used to initialize some intermediate state data. These data may change during update and are frequently enabled and disabled. Example: import { _decorator, Component, Node } from \"cc\"; const { ccclass, property } = _decorator; @ccclass(\"starttest\") export class starttest extends Component { private _timer: number = 0.0; start () { this._timer = 1.0; } update (deltaTime: number) { this._timer += deltaTime; if(this._timer >= 10.0){ console.log('I am done!'); this.enabled = false; } } } update() A key point of game development is to update the behavior, state and orientation of objects before each frame of rendering. These update operations are usually placed in the update() callback. Example: import { _decorator, Component, Node } from \"cc\"; const { ccclass, property } = _decorator; @ccclass(\"updatetest\") export class updatetest extends Component { update (deltaTime: number) { this.node.setPosition(0.0,40.0*deltaTime,0.0); } } lateUpdate() update() will be executed before all animations are updated, but if developer's need to perform some additional operations after the animations (such as animation, particles, physics, etc.) are updated, or it is needed to execute the update() of all components after doing other operations, use the lateUpdate() callback. Example: import { _decorator, Component, Node } from \"cc\"; const { ccclass, property } = _decorator; @ccclass(\"lateupdatetest\") export class lateupdatetest extends Component { lateUpdate (deltaTime: number) { this.node.setPosition(0.0,50,0.0); } } onDisable() When the enabled attribute of the component changes from true to false, or the node's active attribute changes from true to false, the onDisable() callback will be activated. onDestroy() When the component or the node where it calls destroy(), the onDestroy() callback will be called, and the component will be recycled when the frame ends. "},"scripting/create-destroy.html":{"url":"scripting/create-destroy.html","title":"Create and destroy nodes","keywords":"","body":"Creating and Destroying Nodes Creating a New Node In addition to creating nodes through the scene editor, it can also dynamically create nodes in scripts using new Node() and adding it to the scene. Example: import { _decorator, Component, Node } from \"cc\"; const { ccclass, property } = _decorator; @ccclass(\"test\") export class test extends Component { start(){ let node =new Node('box'); node.setPosition(0,0,-10); } } Cloning an Existing Node Sometimes it is needed to dynamically clone the existing nodes in the scene, it can be done through the instantiate method. Example: import { _decorator, Component, Node,instantiate, director } from \"cc\"; const { ccclass, property } = _decorator; @ccclass(\"test\") export class test extends Component { @property({type:Node}) private target: Node = null; start(){ let scene = director.getScene(); let node = instantiate(this.target); node.parent = scene; node.setPosition(0, 0,-10); } } Creating a Prefab Node Similar to cloning an existing node, you can set a prefab (Prefab) and generate a node through instantiate. Example: import { _decorator, Component, Prefab, instantiate, director } from \"cc\"; const { ccclass, property } = _decorator; @ccclass(\"test\") export class test extends Component { @property({type:Prefab}) private target: Prefab = null; start(){ let scene = director.getScene(); let node = instantiate(this.target); node.parent = scene; node.setPosition(0,0,0); } } Destroy the node Through the node.destroy() function, nodes can be destroyed. It is worth mentioning that the destroyed node will not be removed immediately, but will be executed uniformly after the logic update of the current frame is completed. When a node is destroyed, the node is in an invalid state. Use isValid to determine whether the current node has been destroyed. Example: import { _decorator, Component, Node } from \"cc\"; const { ccclass, property } = _decorator; @ccclass(\"test\") export class test extends Component { @property({type:Node}) private target: Node = null; private positionz: number = -20; start(){ // Destroy the node after 5 seconds setTimeout(function () { this.target.destroy(); }.bind(this), 5000); } update(deltaTime: number){ console.info(this.target.isValid); this.positionz += 1*deltaTime; if (this.target.isValid) { this.target.setPosition(0.0,0.0,this.positionz); } } } The Difference Between destroy and removeFromParent After calling removeFromParent on a node, it may not be completely released from the memory, because it is possible that the object is still referenced in the program due to some logical problems. If a node is no longer in use, please call its destroy directly instead of removeFromParent. destroy will not only activate onDestroy on the component, it will also reduce the chance of memory leaks and at the same time reduce the consequences of memory leaks. In short, if a node is no longer used, destroy is right, there is no need to removeFromParent nor to set parent to null. "},"scripting/scene-managing.html":{"url":"scripting/scene-managing.html","title":"Load and switch scenes","keywords":"","body":"Loading and Switching Scenes Cocos Creator uses the scene's file name (without extension) to index the scene. Loading and switching scenes is performed using the loadScene() API. Example: director.loadScene(\"MyScene\"); In addition, as of v2.4, the Asset Bundle has added a new loading method: bundle.loadScene('MyScene', function (err, scene) { cc.director.runScene(scene); }); The loadScene provided by the Asset Bundle will only load scenes from the specified bundle and will not automatically run the scenes, you also need to use cc.director.runScene to run the scenes. loadScene also provides more parameters to control the loading process, so developers can control the loading parameters themselves or do some processing after the loading scene. For more information about loading scenes in the Asset Bundle, you can refer to the Asset Bundle documentation. Scene resource management and Persistent Nodes The engine will only run one scene at the same time. When switching scenes, all nodes and other instances in the scene will be destroyed by default. Developer's may need to use a component to control the loading of all scenes, or to transfer parameter data between scenes, mark the node where the component is located as a Persistent Node so that it will not be automatically destroyed when the scene is switched, and will remain in memory. Example: game.addPersistRootNode(myNode); The above interface will turn myNode into a persistent node, so that the components attached to it can continue to function between scenes. This method can be used to store player information, or various things needed for the initialization of the next scene data. Note: the target node must be the root node in the hierarchy, otherwise the setting is invalid. Cancelling the persistece of a node is easy. Example: game.removePersistRootNode(myNode); Note: the above API does not immediately destroy the specified node, but restores the node to a node that can be destroyed when the scene is switched. Scene loading callback When loading a scene, you can attach a parameter to specify the callback function after the scene is loaded. Example: director.loadScene(\"MyScene\", onSceneLaunched); onSceneLaunched is a callback function declared in this script, and can be used for further initialization or data transfer operations after the scene is loaded. Since the callback function can only be written in this script, the scene loading callback is usually used in conjunction with the persistent node and used in the script mounted on the persistent node. Preloading a scene director.loadScene will automatically switch to run the new scene after loading the scene. It is also possible to silently load the new scene in the background and switch manually after the loading is complete. Use the preloadScene interface to preload the scene in advance. Example: director.preloadScene(\"table\", function () { console.log('Next scene preloaded'); }); Then call loadScene at an appropriate time to switch scenes. Example: director.loadScene(\"table\"); Note: if the preloading is not complete, you can also call director.loadScene() directly, and the scene will start after the preloading is complete. "},"scripting/load-assets.html":{"url":"scripting/load-assets.html","title":"Loading Assets","keywords":"","body":"Obtaining and Loading assets Cocos Creator uses the same asset management mechanism as Cocos Creator. In this section, we will introduce: Declaration of asset attributes How to set assets in the Inspector panel Loading assets dynamically Loading remote assets and device assets Dependence and releasing assets Declaration of asset attributes In Cocos Creator, all types that inherit from Asset are collectively called assets, such asTexture2D, SpriteFrame,AnimationClip, Prefab, etc. Loading assets is unified and interdependent assets can be automatically preloaded. For example: when the engine is loading the scene, it will automatically load the assets associated with the scene first. If these assets are associated with other assets, the other will be loaded first, and the scene loading will end after all loading is completed. You can define an Asset property in the script like this: //test.ts import { _decorator, Component, Node, SpriteFrame } from \"cc\"; const { ccclass, property } = _decorator; @ccclass(\"test\") export class test extends Component { @property({type: SpriteFrame}) private spriteFrame: SpriteFrame = null; } How to set Assets in the Inspector panel As long as the type is defined in the script, you can easily set the asset directly in the Inspector panel. Suppose, we create a script like this: //test.ts import { _decorator, Component, Node, SpriteFrame, Texture2D } from \"cc\"; const { ccclass, property } = _decorator; @ccclass(\"test\") export class test extends Component { @property({type: Texture2D}) private texture: Texture2D = null; @property({type: SpriteFrame}) private spriteFrame: SpriteFrame = null; } After adding it to a node, it looks like this in the Inspector panel: Next, we drag a Texture and a SpriteFrame from the Assets panel into the corresponding properties of the Inspector panel: Resulting in: This allows you to get and set assets directly within a script: start () { let spriteFrame = this.spriteFrame; let texture = this.texture; } Although it is intuitive to set assets in the Attributes Inspector, the assets can only be set in the Scene, in advance. This means there is no way to switch assets dynamically. If you need to switch assets dynamically, take a look at this next section on Dynamic loading. Dynamic loading For dynamic loading, please refer to Dynamic Load Resources "},"scripting/scheduler.html":{"url":"scripting/scheduler.html","title":"Scheduler","keywords":"","body":"Scheduler Cocos Creator provides a powerful, flexible and convenient timer component. Using the Scheduler Start a timer this.schedule(function() { // Here this refers to component this.doSomething(); }, 5); The above timer will be executed every 5s. A more flexible timer // time interval in seconds let interval = 5; // number of times to repeat let repeat = 3; // delay starts let delay = 10; this.schedule(function() { // Here this refers to component this.doSomething(); }, interval, repeat, delay); The above timer will start timing after 10 seconds, and execute a callback every 5 seconds, repeating 3 times. Timer that executes only once (shortcut) this.scheduleOnce(function() { // Here this refers to component this.doSomething(); }, 2); The timer above will execute the callback function once after two seconds, and then stop timing. Cancel a timer Developers can use the callback function itself to cancel the timer: this.count = 0; this.callback = function () { if (this.count == 5) { // Cancel this timer when the callback is executed // for the sixth time this.unschedule(this.callback); } this.doSomething(); this.count++; } this.schedule(this.callback, 1); Note: when the component's timer calls the callback, the this of the callback is specified as the component itself, so this can be used directly in the callback. Here is a list of all of the timer functions in Component: schedule: start a timer scheduleOnce: start a timer that is executed only once unschedule: cancel a timer unscheduleAllCallbacks: cancel all timers of this component The detailed description of these APIs can be found in the API documentation. In addition, if developers need to execute a function every frame, please add the update function directly to the Component. This function will be called every frame by default. This is described in Lifecycle Document. Note: Node does not include timer related APIs "},"scripting/component.html":{"url":"scripting/component.html","title":"Component and component execution order","keywords":"","body":"Components and component execution order All classes inherited from Component are called Component Classes. The objects in a Component Class are called Components. Components are implement according to the Cocos Creator Entity Component (EC) system. The component class must inherit from a cc class. Example: import { Component } from \"cc\"; @ccclass(\"MyComponent\") class MyComponent extends Component { } Component creation and destruction The life cycle of a component is completely controlled by the node. Unlike ordinary class objects, components cannot be created by constructors: const component = new MyComponent(); // Error: The component cannot be created by the constructor In contrast, components must be created by nodes and added to nodes as follows const myComponent = node.addComponent(MyComponent); When the component is no longer needed, call the node.removeComponent(myComponent) method to remove the specified component and destroy it. Example: import { Component } from \"cc\"; @ccclass(\"MyComponent\") class MyComponent extends Component { constructor () { console.log(this.node.name); // Error: The component is not attached to the node } public printNodeName () { console.log(this.node.name); } } const myComponent = node.addComponent(MyComponent); myComponent.printNodeName(); // Correct node.removeComponent(myComponent); myComponent.printNodeName(); // Error: The component is not attached to the node Component execution order Use a unified control script to initialize other scripts Generally, developers will have a Game.ts script as the overall control script. If there are three components Configuration.ts, GameData.ts, and Menu.ts, then their initialization process would look like the following example: // Game.ts import { _decorator, Component, Node } from \"cc\"; const { ccclass, property } = _decorator; import { Configuration } from './Configuration'; import { GameData } from './GameData'; import { Menu }from './Menu'; @ccclass(\"Game\") export class Game extends Component { private configuration = Configuration; private gameData = GameData; private menu = Menu; onLoad () { this.configuration.init(); this.gameData.init(); this.menu.init(); } } Among them, the init method needs to be implemented in Configuration.ts, GameData.ts and Menu.ts, and the initialization logic is put in it. In this way, it is guaranteed the initialization sequence of Configuration, GameData and Menu. Use custom methods to control the update sequence in Update Similarly, it is necessary to ensure the update order of each frame of the above three scripts, we can also replace the update scattered in each script with our own defined method: // Configuration.ts static updateConfig (deltaTime: number) { } Then call these methods in the update of the Game.ts script: // Game.ts update (deltaTime: number) { this.configuration.updateConfig(deltaTime); this.gameData.updateData(deltaTime); this.menu.updateMenu(deltaTime); } Control the execution order of components on the same node The execution order of component scripts on the same node can be controlled by the order of the components in the Inspector panel. The components arranged above will be executed before the components arranged below. We can adjust the arrangement order and execution order of the components through the Move Up and Move Down menus in the gear button at the upper right corner of the component. If there are two components: CompA and CompB, their contents may be similar to this example: // CompA.ts import { _decorator, Component, Node } from \"cc\"; const { ccclass, property } = _decorator; @ccclass(\"CompA\") export class CompA extends Component { onLoad () { console.log('CompA onLoad!'); } start () { console.log('CompA start!'); } update (deltaTime: number) { console.log('CompA update!'); } } // CompB.ts import { _decorator, Component, Node } from \"cc\"; const { ccclass, property } = _decorator; @ccclass(\"CompB\") export class CompB extends Component { onLoad () { console.log('CompB onLoad!'); } start () { console.log('CompB start!'); } update (deltaTime: number) { console.log('CompB update!'); } } When CompA is above CompB on the Inspector panel, the output may be this way: CompA onLoad! CompB onLoad! CompA start! CompB start! CompA update! CompB update! After moving CompA under CompB in Inspector by Move Down in the upper right corner of the CompA component settings menu, the output may be this way: CompB onLoad! CompA onLoad! CompB start! CompA start! CompB update! CompA update! Set component execution priority If the above method still cannot provide the required control granularity, developers can also directly set the executionOrder of the component. executionOrder affects the execution priority of the component's life cycle callback. The smaller the executionOrder, the earlier the component will be executed relative to other components. The executionOrder defaults to 0, so if it is set to a negative number, it will execute before other default components. Example: // Configuration.ts import { _decorator, Component, Node } from \"cc\"; const { ccclass, executionOrder } = _decorator; @ccclass(\"Configuration\") @executionOrder(-1) export class Configuration extends Component { onLoad () { console.log('Configuration onLoad!'); } } // Menu.ts import { _decorator, Component, Node } from \"cc\"; const { ccclass, executionOrder } = _decorator; @ccclass(\"Menu\") @executionOrder(1) export class Menu extends Component { onLoad () { console.log('Menu onLoad!'); } } By setting it as above, Configuration.ts's onLoad will be executed before Menu.ts's onLoad method. Note: executionOrder is only valid for onLoad, onEnable, start, update and lateUpdate, but not valid for onDisable and onDestroy. "},"engine/event/event-emit.html":{"url":"engine/event/event-emit.html","title":"Listening to and launching events","keywords":"","body":"Listening to and launching events Listening to events Event processing is done in the Node. Components can register and monitor events by visiting the node this.node. Listen to events can be registered by the function this.node.on(). The methods are as follows: // This event monitor is triggered every time and needs to be unregistered manually. xxx.on(type, func, target?); The type is the event registration string. func is the callback to listen to when the event is executed. And target is the event receive object. If target is not set，then this in the callback refers to the object that is currently executing the callback. The event listener function on can pass to the third parameter target to bind the caller of the response function. The following two calling methods have the same effect: // Using Function Binding this.node.on(Node.EventType.MOUSE_DOWN, function ( event ) { this.enabled = false; }.bind(this)); // Using the third parameter this.node.on(Node.EventType.MOUSE_DOWN, (event) => { this.enabled = false; }, this); Besides listening with on, we can also use the once method. The once listener will shut the event being listened to after the listener function responds. Canceling listeners We can shut the corresponding event listener using off when we don't care about a certain event anymore. The off method can be used in two ways // Cancel all registered events of this type on the object. xxx.off(type); // Cancels events on objects with this type of callback designation target. xxx.off(type, func, target); One thing to note is that the parameter of off must be in one-to-one correspondence with the parameter of on in order to cancel it. Example: import { _decorator, Component, Node } from \"cc\"; const { ccclass } = _decorator; @ccclass(\"Example\") export class Example extends Component { onEnable () { this.node.on('foobar', this._sayHello, this); } onDisable () { this.node.off('foobar', this._sayHello, this); } _sayHello () { console.log('Hello World'); } } Event Dispatching There are two ways to trigger an event: emit and dispatchEvent. The difference between the two is that the latter can do event passing. Let's start with a simple example of the emit event. // At most 5 args could be emit. xxx.emit(type, ...args); Explanation for event arguments When emitting events, start passing the event parameters as the second argument of the emit function. import { _decorator, Component, Node } from \"cc\"; const { ccclass } = _decorator; @ccclass(\"Example\") export class Example extends Component { onLoad () { this.node.on('foo', (arg1, arg2, arg3) => { console.log(arg1, arg2, arg3); // print 1, 2, 3 }); } start () { let arg1 = 1, arg2 = 2, arg3 = 3; // At most 5 args could be emit. this.node.emit('foo', arg1, arg2, arg3); } } Note: only up to 5 event parameters can be passed here for the performance of the underlying event distribution. Therefore, care should be taken to control the number of parameters passed when passing a parameter. Event delivery Events launched by the dispatchEvent method, mentioned above, would enter the event delivery stage. In Cocos Creator's event delivery system, bubble delivery is used. Bubble delivery will pass the event from the initiating node continually on to its parent node, until the root node is reached or an interrupt event.propagationStopped = true is made in the response function of a node. As shown in the picture above, when we send the event “foobar” from node c, if both node a and b listen to the event “foobar”, the event will pass to node b and a from c. For example: // In the component script of node c this.node.dispatchEvent( new Event.EventCustom('foobar', true) ); To stop the event delivery after node b intercepts the event, call the function event.propagationStopped = true to do this. Detailed methods are as follows: // In the component script of node b this.node.on('foobar', (event: EventCustom) => { event.propagationStopped = true; }); Note: to dispatch a custom event, do not use Event because it's an abstract class. Instead, use Event.EventCustom to dispatch a custom event. Event object In the call-back of the event listener, the developer will receive an event object event of the Event type. propagationStopped is the standard API of Event, other important API include: API Name Type Meaning type String The event type (event name). target Node The original target that received the event. currentTarget Node The current object that received the event. The current target of the event during the bubbling phase may be different from the original target. getType Function Get the event type. propagationStopped Boolean Whether or not stop the bubbling phase. The parent node of the current target no longer receives the corresponding event. propagationImmediateStopped Boolean Whether or not stop passing the current event immediately. The current target no longer receives the event either. detail Function The information of the custom event, which belongs to Event.EventCustom. setUserData Function Set the information of the custom event, which belongs to Event.EventCustom. getUserData Function Get the information of the custom event, which belongs to Event.EventCustom. Please refer to the Event and API files of its child category for a complete API list. System built-in event Above are the general rules for listening to events and emitting events. Cocos Creator has built in system events. Please refer to the following documents: Node System Events Global System Events "},"engine/event/event-builtin.html":{"url":"engine/event/event-builtin.html","title":"Builtin Events","keywords":"","body":"Node System Events Node has a complete set of event listeners and dispatch mechanisms. Based on this mechanism, basic system events are provided. Cocos Creator supports four types of system events: mouse, touch, keyboard, device motion. They are called Global Events. The usage of touch and mouse events dispatched by Node is discussed in this document. System events follow the general register method, developers can register event listener not only by using the enumeration type but also by using the event name directly. It is recommended to use enumeration for event registration to avoid event registration failure due to writing problems. // Use enumeration type to register node.on(Node.EventType.MOUSE_DOWN, (event) => { console.log('Mouse down'); }, this); // Use event name to register node.on('mouse-down', (event) => { console.log('Mouse down'); }, this); Mouse event type and event object Mouse events will only be triggered on desktop platforms, the event types the system provides are as follows: Enumerated Object Definition Corresponding event Name Timing of Event Triggering Node.EventType.MOUSE_DOWN mouse-down When a button on the mouse is pressed in the target node region Node.EventType.MOUSE_ENTER mouse-enter When the cursor enters the target node region, whether or not the button is pressed Node.EventType.MOUSE_MOVE mouse-move When the cursor is moved in the target node region, whether or not the button is pressed Node.EventType.MOUSE_LEAVE mouse-leave When the cursor is moved out of the target node region, whether or not the button is pressed Node.EventType.MOUSE_UP mouse-up When a button on the mouse is released Node.EventType.MOUSE_WHEEL mouse-wheel When the mouse wheel is scrolled The important APIs of mouse events (Event.EventMouse) are described in the Mouse Events API (Event standard events API excluded). Touch event types and event objects Touch events can be triggered on both mobile platforms and desktop platforms. Developers can better debug on the desktop platform, by simply listening for touch events and responding to both mobile touch events and desktop mouse events at the same time. The types of touch events provided by the system are as follows: Enumerated Object Definition Corresponding Event Name Timing of Event Triggering Node.EventType.TOUCH_START touch-start When one or more touch points are placed in the target node region Node.EventType.TOUCH_MOVE touch-move When one or more touch points are moved along the screen Node.EventType.TOUCH_END touch-end When one or more touch points are removed from the screen in the target node region Node.EventType.TOUCH_CANCEL touch-cancel When one or more touch points are removed from the screen outside the target node region The important APIs of a touch event (Event.EventTouch) are described in the Mouse Events API (Event standard event API excluded): Note: touch events support multi-touch, each touch spot will send one event to the event listener. Touch event propagation Touch event bubbles Touch events support the event bubbles on the node tree, take the pictures below as an example: In the scene shown in the picture, suppose node A has a child node B which has a child node C. The developer sets the touch event listeners for all these three nodes (each node has a touch event listener in examples below by default). When the mouse or finger was applied in the node C region, the event will be triggered at node C first and the node C listener will receive the event. Then the node C will pass this event to its parent node, so the node B listener will receive this event. Similarly the node B will also pass the event to its parent node A. This is a basic event bubbling phase. It needs to be emphasized that there is no hit test in parent nodes in the bubbling phase, which means that the node A and B can receive touch events even though the touch location is out of their node region. The bubbling phase of touch events is no different than the general events. Calling event.propagationStopped = true; can force to stop the bubbling phase. Ownership of touch points among brother nodes Suppose the node B and C in the picture above are brother nodes, while C partly covers over B. Now if C receives a touch event, it is announced that the touch point belongs to C, which means that the brother node B won't receive the touch event any more, even though the touch location is also inside its node region. The touch point belongs to the top one among brother nodes. At the same time, if C has a parent node, it will also pass the touch event to its parent node through the event bubble mechanism. Point of Contact Attribution for Different Canvas Contact interception between different Canvas is determined by priority. In the scene in the figure below, Canvas 1-5 in the node tree corresponds to priority 1-5 of the image display. It can be seen that even though Canvas nodes 3, 4, and 5 are arranged in scrambled order, the order of response of the contacts is still Canvas5 -> Canvas4 -> Canvas3 -> Canvas2 -> Canvas1, according to the priority relationship on the Canvas. The sorting between Canvas is done in the order of the node tree only if the priority is the same. Register touch or mouse events in the capturing phase Sometimes, it is necessary to dispatch touch or mouse events to parent node event listeners before dispatching to any child nodes beneath it in hierarchy, like the design of ScrollView component. Event bubbling cannot meet all demands. When this happens, register the parent node event listeners in the capturing phase. To achieve this goal, passing in true as the useCapture parameter (a fourth parameter) when registering touch or mouse event on the node. For example: this.node.on(Node.EventType.TOUCH_START, this.onTouchStartCallback, this, true); When the node fires the touch-start event, the touch-start event will be first dispatched to all the parent node event listeners registered in the capturing phase, then dispatched to the node itself, and finally comes the event bubbling phase. Only touch or mouse events can be registered in the capturing phase, while the other events can't be. Event Interception Normal events are dispensed as described above. However, if the node has components such as Button, Toggle or BlockInputEvents on it, it will stop event bubbling. Look at the picture below. There are two buttons, priority 1 for Canvas0 and priority 2 for Canvas1. If you click on the intersection of the two buttons, which is the blue area in the picture, it appears that button priority 2 received the contact event successfully, while button priority 1 did not. That's because according to the event reception rules above, button priority 2 receives contact events first and intercepts them（event.propagationStopped = true) to prevent event penetration. If the node is a non-button node, events can also be intercepted by adding the BlockInputEvents component to prevent penetration. Example for touch events Using the example below, summarizing touch events is easy. There are four nodes A, B, C and D in the picture above, where A and B are brother nodes. The specific hierarchical relationship should be like this: If one touch is applied in the overlapping area between A and B, now B won't receive the touch event, so that propagating order of the touch event should be A -> C -> D. If the touch location is in node B (the visible green area), the order should be B -> C -> D. If the touch location is in node C, the order should be C -> D. As a precondition to the second case, we register touch events on C D node in the capturing phase, then the order should be D -> C -> B. Other events of Node All node built-in events can get event names from Node.EventType. 3D Node Events Enumerated Object Definition Corresponding Event Name Timing of Event Triggering TRANSFORM_CHANGED transform-changed When a transform attribute is modified, an enum value TransformBit is assigned that defines the modified transform based on the enum value. Definition of Transformation Enumeration Values: Enumeration Value Meaning Transformations TransformBit.NONE The properties remain unchanged. TransformBit.POSITION The node position changes. TransformBit.ROTATION The node rotation changes. TransformBit.SCALE The node scale changes. TransformBit.RS The node rotation and scale change. TransformBit.TRS The node position, rotation and scale change. 2D Node Events Enumeration Value Meaning Corresponding Event Name Timing of Event Triggering SIZE_CHANGED size-changed When the width/height property is modified. The width/height property is located on the UITransform component. ANCHOR_CHANGED anchor-changed When the X/Y properties of the anchor is modified. The width/height property is located on the UITransform component. COLOR_CHANGED color-changed When the color property is modified. The width/height property is located on the UITransform component. Multi-touch event The engine has a multi-touch event blocking switch. Multi-touch events are enabled by default. For projects that do not require multi-touch, you can disable allowing multi-touch with the following code: macro.ENABLE_MULTI_TOUCH = false; Alternatively, it can be configured via Project Setting/Macro Config. Pause or resume node system events Pause node system events // Pause all node system events registered on the current node. Node system events include Touch and Mouse Events. // If a parameter true is passed, the API will pause node system events on this node and all its children. // Example this.node.pauseSystemEvents(); Resume node system events // Resume all node system events registered on the current node. Node system events include Touch and Mouse Events. // If a parameter true is passed, the API will resume node system events on this node and all its children. // Example this.node.resumeSystemEvents(); "},"engine/event/event-input.html":{"url":"engine/event/event-input.html","title":"Global Events","keywords":"","body":"Global System Events In this section, the global system events of Cocos Creator will be introduced. Global system events are irrelevant with the node hierarchy, so they are dispatched globally by systemEvent, currently supported: Mouse Touch Keyboard DeviceMotion The global mouse and touch events are very similar to the node events, except that the area of action is different. The following is a description of these events. The difference between node events and global mouse and touch events Note: before beginning this section, read up on Auto fit for multi-resolution and understand the screen area and UI display area. When listening for global mouse/touch events, the acquired contacts are calculated based on the bottom left corner of the screen area (device display resolution). The contacts fetched by the UI node listener are not the same as the contacts fetched by the global event, which are converted to the points calculated in the lower left corner of the adapted UI viewable area. Global touch points are better suited for manipulating the behavior of 3D nodes by tapping directly on the screen, without having to add UI nodes to the scene to listen for mouse/touch events. How to define the input events Use systemEvent.on(type, callback, target) to register Keyboard and DeviceMotion event listeners. Event types included: SystemEventType.KEY_DOWN SystemEventType.KEY_UP SystemEventType.DEVICEMOTION Keyboard events Type: SystemEventType.KEY_DOWN and SystemEventType.KEY_UP Call Back: Custom Event: callback(event); Call Back Parameter: KeyCode: API Reference Event: API Reference import { _decorator, Component, Node, systemEvent, SystemEventType, EventKeyboard, macro } from \"cc\"; const { ccclass } = _decorator; @ccclass(\"Example\") export class Example extends Component { onLoad () { systemEvent.on(SystemEventType.KEY_DOWN, this.onKeyDown, this); systemEvent.on(SystemEventType.KEY_UP, this.onKeyUp, this); } onDestroy () { systemEvent.off(SystemEventType.KEY_DOWN, this.onKeyDown, this); systemEvent.off(SystemEventType.KEY_UP, this.onKeyUp, this); } onKeyDown (event: EventKeyboard) { switch(event.keyCode) { case macro.KEY.a: console.log('Press a key'); break; } } onKeyUp (event: EventKeyboard) { switch(event.keyCode) { case macro.KEY.a: console.log('Release a key'); break; } } } Device motion Type: SystemEventType.DEVICEMOTION Call back: Custom event: callback(event);; Call back parameter: Event: API Reference import { _decorator, Component, Node, systemEvent, SystemEventType, log } from \"cc\"; const { ccclass } = _decorator; @ccclass(\"Example\") export class Example extends Component { onLoad () { systemEvent.setAccelerometerEnabled(true); systemEvent.on(SystemEventType.DEVICEMOTION, this.onDeviceMotionEvent, this); } onDestroy () { systemEvent.off(SystemEventType.DEVICEMOTION, this.onDeviceMotionEvent, this); } onDeviceMotionEvent (event: EventAcceleration) { log(event.acc.x + \" \" + event.acc.y); } } Please review the test-cases-3d (This includes the keyboard, accelerometer, single point touch, multi-touch examples). "},"engine/event/event-api.html":{"url":"engine/event/event-api.html","title":"Event API","keywords":"","body":"Global and Node Touch and Mouse Events API Mouse Event API Function Name Return value type Meaning getScrollY Number Get the scrolling distance of the mouse wheel on the y-axis, valid only when scrolling. getButton Number Event.EventMouse.BUTTON_LEFT or Event.EventMouse.BUTTON_RIGHT or Event.EventMouse.BUTTON_MIDDLE. ｜ Global Mouse Events API Function Name Return value type Meaning getLocation Vec2 Get the mouse position, which contains the x and y properties. getLocationX Number Get the mouse position on x-axis. getLocationY Number Get the mouse position on y-axis. getPreviousLocation Vec2 Get the position of the last triggered mouse event, which contains the x and y properties. getDelta Vec2 Get the distance the mouse has moved relative to the lower-left corner since the last event, which contains the x and y properties. getDeltaX Number Get the x-axis distance the mouse has moved relative to the lower-left corner since the last event. getDeltaY Number Get the y-axis distance the mouse has moved relative to the lower-left corner since the last event. Node Mouse Events API Function Name Return value type Meaning getUILocation Vec2 Get the current mouse position relative to the lower-left corner of the UI window, which contains the x and y properties. getUILocationX Number Get the position of the touch point on the x-axis relative to the lower-left corner of the UI window. getUILocationY Number Get the current mouse position on y-axis relative to the lower-left corner of the UI window. getUIPreviousLocation Vec2 Get the previous mouse position relative to the lower-left corner of the UI window, which contains the x and y properties. getUIDelta Vec2 Get the distance the mouse has moved relative to the lower-left corner of the UI window since the last event, which contains the x and y properties. getUIDeltaX Number Get the x-axis distance the mouse has moved relative to the lower-left corner of the UI window since the last event. getUIDeltaY Number Get the y-axis distance the mouse has moved relative to the lower-left corner of the UI window since the last event. Touch Events API API Name Type Meaning touch Touch The touch point related to the current event. getID Number Get the ID of the touch point, which is used for multi-touch logic. Global Touch Events API Function Name Return value type Meaning getLocation Vec2 Get the mouse position, which contains the x and y properties. getLocationX Number Get the position of the touch point on the x-axis. getLocationY Number Get the position of the touch point on the y-axis. getStartLocation Vec2 Get the initial position of the touch point, which contains the x and y properties. getPreviousLocation Vec2 Get the position of the last triggered touch point event, which contains the x and y properties. getDelta Vec2 Get the distance the mouse has moved relative to the lower-left corner since the last event, which contains the x and y properties. Node Touch Events API Function Name Return value type Meaning getUILocation Vec2 Get the current mouse position relative to the lower-left corner of the UI window, which contains the x and y properties. getUILocationX Number Get the current mouse position on x-axis relative to the lower-left corner of the UI window. getUILocationY Number Get the current mouse position on y-axis relative to the lower-left corner of the UI window. getUIStartLocation Vec2 Get the position of the initial touch point relative to the lower-left corner of the UI window, which contains the x and y properties. getUIPreviousLocation Vec2 Get the position of the last touch point relative to the lower-left corner of the UI window, which contains the x and y properties. getUIDelta Vec2 Get the distance the mouse has moved relative to the lower-left corner of the UI window since the last event, which contains the x and y properties. "},"scripting/external-scripts.html":{"url":"scripting/external-scripts.html","title":"Plugin script","keywords":"","body":"External code support Plugin script When the script resource is imported with import as a plug-in, this script resource is called plug-in script. Plug-in scripts are usually used to import third-party libraries. Currently only supports JavaScript plug-in scripts. Unlike other scripts in the project, Cocos Creator will not modify the content of the plug-in script, but some code may be inserted to adapt to Creator itself; in particular, Cocos Creator will shield the global variables module, exports, define. Execution timing Developers can control whether plug-in scripts are executed in certain environments. Options Affected Platform Remarks Allow web platform to load Browser, Web page preview, Editor Enabled by default, when disabled, it will be disabled with Allow editor to load Allow editor to load Editor Disabled by default. If other common scripts in the editor depend on the current script during the loading process, you need to manually enable this option. After opening, local variables that are not declared in any function in the script will not be exposed as global variables, so global variables need to be defined with window.abc = 0 to take effect. Allow Native platform to load Native platform, emulator preview Enabled by default In the import checker, developers can specify dependencies to ensure the execution order of scripts. Usability and cross-platform The plug-in script is copied to the build directory almost intact, so the usability and cross-platform of the plug-in script are not guaranteed by Cocos Creator. For example, when plug-in scripts use language features that are not supported by certain platforms, errors will result, especially: The target platform does not provide native node.js support For example, many npm modules directly or indirectly depend on node.js, so they cannot be used after being published to native or web platforms. Plugins that rely on the DOM API will not be able to publish to the native platform A large number of front-end plug-ins can be used in web pages, such as jQuery, but they may depend on the browser's DOM API. Plugins that rely on these APIs cannot be used on the native platform. Interaction Plug-in scripts and non-plug-in scripts cannot interact in the form of import. For example, even if the developer knows that their target platform actually supports CommonJS, nor can it be used in a non-plug-in script forcibly through the relative path of require. Therefore, plug-in scripts generally communicate in the form of global variables (also known as IIFE module format), but the following points need to be noted: Developers should use global variables very carefully. When you want to use global variables, you should be very clear about what you are doing. We do not recommend abusing global variables. Even if you want to use them, it is best to ensure that global variables are read only. When adding global variables, please be careful not to have the same name with the existing global variables in the system. Developers can freely encapsulate or extend the Cocos Creator engine in the plug-in script, but this will increase the cost of team communication and make the script difficult to reuse. Import options Many third-party JavaScript libraries provide library functions in the form of global variables. These libraries often write global variables window, global, self and this. However, these global variables are not necessarily cross-platform. For convenience, when importing plug-in scripts, the option Simulate global variables is provided. After opening, Cocos Creator will insert the necessary code to simulate these global variables. Example: (function() { const window = globalThis; const global = globalThis; const self = globalThis; (function() { /* Original code */ }).call(this); }).call(this); "},"scripting/log.html":{"url":"scripting/log.html","title":"Logging","keywords":"","body":"Adding Logging to the Engine This document mainly explains how to add new Log messages (including log, warning, and error) to the internal code of the engine according to the correct specifications. Log Information Mechanism and Background Currently, the Log information in Cocos Creator is stored in the form of an error message table independent of the engine, which is stored in the EngineErrorMap.md under the engine directory. In the engine code, it is not allowed to write logs, warnings, errors and other information directly in the form of strings. It must be written in the following three APIs: import {logID, warnID, errorID} from'core/platform/debug'; logID(id, ...params); warnID(id, ...params); errorID(id, ...params); The main purpose of this is to reduce the package body occupied by the string in the engine source code. EngineErrorMap writing specifications EngineErrorMap is divided into large modules according to one hundred bits, a total of four bits, from 0000 to 9900, which means that it supports up to 100 large modules. The tens digit is used to divide the sub-modules, or it can be arranged in a continuous form, which is determined by the person in charge of the module. Due to historical reasons, there is currently no strict priority order for sorting, and newly-built modules can simply be postponed. In the future, we will do better sorting management and sorting. The specifications for writing specific error messages are as follows: ### 4 number ID Message in english. Example: ### 8300 Should only one camera exists, please check your project. The information supports the use of parameter receivers such as %s, %d, and %f. When running the output LOG, it will be spliced ​​into the information in the order of the parameters. Maintenance of EngineErrorMap After EngineErrorMap is modified, if you want the call in the code to take effect, you need to execute it in the engine directory > gulp build-debug-infos Changes to EngineErrorMap.md should also be submitted to git following other changes to the engine. "},"scripting/deprecated.html":{"url":"scripting/deprecated.html","title":"Deprecated APIs","keywords":"","body":"Deprecated API Frame description In order to maintain the abandoned API while making it more friendly and convenient, it will be implemented through three functions: markAsWarning embeds a warning in the attribute on the given object, and the attribute needs to exist on the given object. removeProperty redefines the removed property on the given object, and embeds an error message. The property should not exist on the given object. replaceProperty redefines the removed property on the given object, and embeds a warning and calls the new property. Incompatible parameters need to be adapted. The given object should not have the property. Function signature interface IRemoveItem { /** The name of the obsolete attribute */ name: string; /** Number of warnings */ logTimes?: number; /** Additional suggestions */ suggest?: string; } interface IMarkItem { /** The name of the obsolete attribute */ name: string; /** Number of warnings */ logTimes?: number; /** Additional suggestions */ suggest?: string; } interface IReplacement { /** The name of the obsolete attribute */ name: string; /** Number of warnings */ logTimes?: number; /** Additional suggestions */ suggest?: string; /** The object of the discarded attribute */ target?: object; /** The name of the object of the discarded attribute */ targetName?: string; /** Custom replacement attribute (function) */ customFunction?: Function; /** Setter of custom replacement properties */ customSetter?: (v: any) => void; /** Getter for custom replacement attributes */ customGetter?: () => any; } export let removeProperty: (owner: object, ownerName: string, properties: IRemoveItem[]) => void; export let markAsWarning: (owner: object, ownerName: string, properties: IMarkItem[]) => void; export let replaceProperty: (owner: object, ownerName: string, properties: IReplacement[]) => void; /** This function is used to set the global default information output times */ export function setDefaultLogTimes (times: number): void; Terms of Use According to the module division, each module maintains an obsolete file. In order to facilitate maintenance, the name is unified as deprecated.ts and placed in the directory of the corresponding module, and the file needs to be import in the index.ts file of the corresponding module, such as import'./deprecated'. Note: the deprecated.ts file in the cocos\\utils directory is a declaration and implementation file. Usage example // For APIs that are not compatible with replacement parameters, adapt them through appropriate custom functions replaceProperty(AnimationComponent.prototype, 'AnimationComponent.prototype', [ { name: 'removeClip', newName: 'removeState', customFunction: function (...args: any) { const arg0 = args[0] as AnimationClip; return AnimationComponent.prototype.removeState.call(this, arg0.name); } } ]); replaceProperty(vmath, 'vmath', [ { name: 'vec2', newName: 'Vec2', target: math, targetName: 'math', 'logTimes': 1 }, { name: 'EPSILON', target: math, targetName: 'math', 'logTimes': 2 } ]); removeProperty(vmath, 'vmath', [ { 'name': 'random', 'suggest': 'use Math.random.' } ]); markAsWarning(math, 'math', [ { 'name': 'toRadian' } ]); Usage Notes The operation targets are all objects. If you want to modify the member functions of the class, please pass in target.prototype. replaceProperty does not pass in newName or newTarget, which means it is consistent with name or target. If you want to control the number of times, it is best to call setDefaultLogTimes before use, because other modules may change the default times. "},"asset/":{"url":"asset/","title":"Asset Manual","keywords":"","body":"About Assets This section will introduce the overall workflow of the assets in Cocos Creator in detail, and explain the use of various types of assets and items that may require attention. Assets Manager The Assets panel is an important tool for accessing and managing assets, developers are recommended to familiarize themselves with the use of the Assets panel for managing assets. Read the Assets Manager documentation for a detailed introduction. Assets Workflow Assets Workflow - the general Assets workflow including importing assets, synchronizing assets, locating assets, etc. can be found in the Assets Workflow documentation. Common Assets type workflow Next we will introduce the main Asset types and related workflows in Cocos Creator: Scene assets Image Assets Texture Map assets Sprite Frame Assets Cube Map assets Auto crop of image assets Atlas assets Render texture Prefabricated assets Script Assets Font Assets Sound assets Material Assets Model assets Export model assets from third-party tools Animation assets Asset Management Of Runtime Asset Manager AssetManager Upgrade Guide Asset Bundle Upgrade Guide Dynamic load asset Asset Bundle Release Of Resources Download and Parse Loading and Preloading Cache Manager Optional Parameters Pipeline and Task Resource Management Considerations --- meta files "},"asset/asset-workflow.html":{"url":"asset/asset-workflow.html","title":"Asset workflow","keywords":"","body":"Assets workflow Importing assets There are three ways to import assets: Create a new file through the Assets panel in Cocos Creator. Use the Create button to start the importing process. By copying files, in the file manager of the operating system, to the project asset folder, and then open the editor or activate the editor window to automatically refresh the asset list of the Assets panel to finish importing assets. Drag and drop asset files from the file manager of the operating system to a folder location on the Assets panel. This will trigger an import of the selected assets. Syncing Assets The assets in the Assets panel are synchronized with the project asset files seen in the file manager of the operating system. Assets are moved, renamed, and deleted in the Assets panel. If deleted in Cocos Creator, it will be deleted in the file manager of the operating system. If deleted in the file manager of the operating system, it will be deleted in Cocos Creator. Asset Configuration Information .meta File All asset files will generate a .meta configuration file with the same name when imported. This configuration file provides the unique identification (uuid) of the asset in the project, small image references, cropping data of texture assets, as well as other configuration information. This data is a necessary factor in identifying a legitimate asset that Cocos Creator is using. The .meta file is not visible in the Assets panel. When operating in the Assets panel, the renaming, moving, and deleting of an asset will automatically synchronize the .meta file that corresponds to the asset by the Editor. To ensure that configuration information such as the uuid remains unchanged, that is, it does not affect existing references. It is not recommended to operate the asset file directly in the file manager of the operating system. If there is such an operation, please manually operate the corresponding .meta file along with the asset file. The following suggestions are recommended: Close the editor you are using to avoid update failures due to file locks or identical asset names. When deleting, renaming, or moving assets, please delete, rename, and move the .meta file as needed. When copying assets together with .meta files, the copied .meta files will be used directly instead of generating new .meta files; if only the asset files are copied, a new .meta file with the corresponding name will be generated when you re-open the editor. This asset will become a new asset to the editor. Assets in Library After the asset is imported, new data will be generated and stored in the project's Library folder. The structure and assets of the files in Library are engine-oriented and the format required for the final game, that is, machine-friendly, but not human-friendly. When a library is lost or damaged, just delete the entire library folder and open the project, and the asset library will be rebuilt. How to locate assets A asset has a unique uuid, used to locate the asset, but this method is not intuitive enough. There is another intuitive way: Database URL format, such as an asset-db. The corresponding protocol header is db://assets, the protocol header for internal-db is db://internal. There are folder-level asset formats, such as db://assets/prefabs/fire.prefab SVN or GIT syncing of assets Note: there are line breaks in the .meta file. It is recommended to unify the line break styles and rules of the team members' computers to avoid opening the project after synchronizing the project assets. "},"asset/asset-manager.html":{"url":"asset/asset-manager.html","title":"Asset Manager","keywords":"","body":"Asset Manager Overview Author: Santy-Wang, Xunyi During the development of the game, it is generally necessary to use a large number of images, audio and other resources to enrich the entire game, and a large number of resources can cause management difficulties. That's why Creator provides the Asset Manager resource management module to help developers manage the use of their resources and greatly improve the development efficiency and experience. Asset Manager is a new resource manager from Creator in v2.4 that replaces the previous loader. The new Asset Manager resource management module has features for loading resources, finding resources, destroying resources, caching resources, Asset Bundle, and more. Compared with previous loader, Asset Manager has better performance, easier-to-use APIs, and greater extensibility. All functions and methods are accessible via assetManager and all types and enumerations are accessible via the AssetManager namespace. Note: we will maintain compatibility with loader for a period of time, but we strongly recommend using Asset Manager consistently for new projects. you can refer to the following articles for upgrading: AssetManager Upgrade Guide Asset Bundle Upgrade Guide Load Resources Dynamic Loading Of Resources In addition to applying resources to the corresponding components while editing scenes, Creator also supports dynamic loading and setting up of resources while the game is running. Asset Manager provides two ways to dynamically load resources: By placing resources in the resources directory, and working with APIs such as resources.load to achieve dynamic loading. developers can plan their own resource creation as Asset Bundle and load resources through the Asset Bundle's load family of APIs. For example: resources.load('images/background', SpriteFrame, (err, asset) => { this.getComponent(Sprite).spriteFrame = asset; }); The relevant APIs are listed below: Type Support Loading Releasing Preloading Querying Search Single Asset Asset Bundle load release preload get getInfoWithPath Directory Asset Bundle loadDir releaseAsset preloadDir N/A getDirWithPath Scene Asset Bundle loadScene N/A preloadScene N/A getSceneInfo Single Asset resources load release preload get getInfoWithPath Directory resources loadDir releaseAsset preloadDir N/A getDirWithPath Script Asset Manager loadScript N/A N/A N/A N/A Remote Asset Asset Manager loadRemote releaseAsset N/A N/A N/A References documentations: Dynamic Load Asset All loaded resources are cached in assetManager. Preloading To reduce download latency, assetManager and Asset Bundle not only provides interfaces for loading resources, each interface also provides a corresponding preloaded version. You can preload in game and then finish loading when you really need it. Preloading will only download the necessary resources and will not perform deserialization or initialization. Therefore, it consumes less performance and is suitable for use during the game. start () { resources.preload('images/background', SpriteFrame); setTimeOut(this.loadAsset.bind(this), 10000); } loadAsset () { resources.load('images/background', SpriteFrame, (err, asset) => { this.getComponent(Sprite).spriteFrame = asset; }); } For more information on preloading, please refer to the Preloading and Loading documentation. Asset Bundle You can partition your scenes, resources, and code into multiple Asset Bundles and load resources dynamically at runtime, resulting in modularity of resources, so that you can load corresponding resources when needed. For example: assetManager.loadBundle('testBundle', function (err, bundle) { bundle.load('textures/background', (err, asset) => { // ... }); }); Please refer to the Asset Bundle documentation for more information on Asset Bundle. Release of resources Asset Manager provides a more convenient mechanism for releasing resources. When releasing a resource, you only need to focus on the resource itself and no longer on its dependent resources. The engine attempts to release its dependent resources based on the number of references, to reduce the complexity of managing resource releases for users. For example: resources.load('prefabs/enemy', Prefab, function (err, asset) { assetManager.releaseAsset(asset); }); Creator also provides a reference counting mechanism to help you control the reference and release of resources. For example: When you need to hold a resource, call addRef to add a reference to ensure that the resource is not automatically released by other references to it. resources.load('textures/armor', Texture2D, function (err, texture) { texture.addRef(); this.texture = texture; }); When you no longer need to hold the resource, call decRef to reduce reference, decRef will also attempt an automatic release based on the reference count. this.texture.decRef(); this.texture = null; Please refer to the Release of Resources documentation for more details. Cache Manager On some platforms, such as WeChat, it is possible to use the file system to cache some remote resources because a file system exists. In this case, a cache manager is required to manage all cache resources, such as caching resources, clearing cache resources, modifying cache cycles, etc. . Creator provides a cache manager on all platforms where file systems exist, so that you can add, delete, change, and check the cache. For example: // Get the cache of a resource. assetManager.cacheManager.getCache('http://example.com/bundle1/import/9a/9aswe123-dsqw-12xe-123xqawe12.json'); // Clear the cache of a resource. assetManager.cacheManager.removeCache('http://example.com/bundle1/import/9a/9aswe123-dsqw-12xe-123xqawe12.json'); Please refer to the Cache Manager documentation for more information on Cache Manager. Optional Parameters Some of the interfaces for assetManager and Asset Bundle have an additional options parameter, which greatly increase the flexibility and extend the space. In addition to configuring the builtin parameters of Creator, you can also customize any of the parameters in options, and these parameters will be provided to the downloader, parser, and loading pipeline. bundle.loadScene('test', {priority: 3}, callback); For more information on options parameter, please refer to the Optional Parameters documentation. If you don't need to configure the engine's builtin parameters or custom parameters to extend the engine's functionality, you can ignore it and use the simpler API interfaces, such as resources.load. Loading Pipeline To make it easier to extend the resource loading process, the underlying layer of Asset Manager uses mechanisms called Pipeline and Task and Download and Parse to load resources, greatly increasing flexibility and scalability. If you want to expand the load pipeline or customize it, you can refer to the following documentation: Pipeline and Task Download and Parse More Reference Asset Bundle Release Of Resources Download and Parse Loading and Preloading Cache Manager Optional Parameters Pipeline and Task "},"asset/asset-manager-upgrade-guide.html":{"url":"asset/asset-manager-upgrade-guide.html","title":"AssetManager Upgrade Guide","keywords":"","body":"Asset Manager Upgrade Guide Author: Santy-Wang, Xunyi This article details what to expect when upgrading from loader to assetManager. Before Creator v2.4, Acquire and load asset was implemented through the loader module (including the APIs loader.load, loader.loadRes, loader.loadResDir, etc.), which was primarily used to load resources. However, with the continuous development of Creator, developers' demands for resource management have been increasing. The original loader module has been unable to meet a large number of resource management needs, and a new resource management module is in the air. Therefore, Creator in v2.4 introduced a new resource management module -- Asset Manager. Compared to the previous loader module, Asset Manager not only provides better loading performance, but also supports Asset Bundle, preload resources and more convenient resource release management. And Asset Manager also has strong extensibility, which greatly improves the development efficiency and user experience of developers. We recommend that all developers upgrade. To bring a smooth upgrade experience, we will maintain compatibility with loader related APIs, and most of the game project can run as usual, except for a few that use incompatible special usage APIs that must be manually upgraded. And we will only remove full compatibility with loader when the time comes. If you are temporarily uncomfortable upgrading due to the project cycle, etc., you can keep the original writing while making sure the test passes. Currently, when using those old APIs, the engine will output warnings and suggestions for upgradation. Please adjust the code according to the warnings and the instructions in this document and upgrade to the new usage. Unfortunately, due to an upgrade of the underlying layer, we have left behind a few incompatible APIs that will output error messages while running. If you have decided to make the upgrade, then please read the following carefully. For the Artist and Game Designer, all resources in your project (e.g. scenes, animations, prefab) do not need to be modified or upgraded. For Programmers, all APIs in the loader module that were used in the original code need to be changed to APIs from assetManager. The related content will be described in detail in this document. Note: as v2.4 supports Asset Bundle, the subpackage feature in the project also needs to be upgraded, please refer to the Subpackage Upgrade Guide documentation for details. Situations that require upgrading manually You use APIs that start with loader in your own code, such as loader.loaderRes, loader.loadResDir, loader.release, etc. You use APIs that start with AssetLibrary in your own code, such as AssetLibrary.loadAsset. You use an API that starts with url in your own code, such as url.raw. You use types such as Pipeline, LoadingItems in your own code. You have used the macro.DOWNLOAD_MAX_CONCURRENT property in your own code. Upgrade steps Back up your old projects Use Cocos Creator v2.4 in the Dashboard to open the project that needs to be upgraded, Creator will reimport the affected resources. The first import will take a little longer, and the main editor window will open after the import is complete. And more error or warning may appear on the Console panel, don't worry, open the code editor to update your code according to the error or warning message. Replace the loader related API with the assetManager related API. As of v2.4, loader is no longer recommended and will be completely removed in subsequent releases, please replace it with the new resource management module assetManager. The relevant interface replacement about loading If you use loader.loadRes, loader.loadResArray, loader.loadResDir in your own code, use the corresponding API in assetManager for the replacement. You can refer to the following replacements. loader.loadRes The parameters of resources.load are exactly equal to loader.loadRes. Replace with the following: // before loader.loadRes(...); // after resources.load(...); loader.loadResArray For reducing learning costs, loadResArray has been merged with load and the first parameter of resources.load can support multiple paths, use resources.load to replace. // before loader.loadResArray(...); // after resources.load(...); loader.loadResDir The parameters of resources.loadDir are equal to those of loader.loadResDir. // before loader.loadResDir(...); // after resources.loadDir(...); Note: to simplify the interface, the load completion callback for resources.loadDir will no longer provide a list of paths. Please avoid using the following: loader.loadResDir('images', Texture2D, (err, assets, paths) => console.log(paths)); If you want to query the paths list, use the following form: const infos = resources.getDirWithPath('images', Texture2D); let paths = infos.map(function (info) { return info.path; }); loader.load If you use loader.load to load remote images or audios in your own code, there is a special API for this in the assetManager for ease of understanding, as follows: Loading remote images // before loader.load('http://example.com/remote.jpg', (err, texture) => console.log(texture)); // after assetManager.loadRemote('http://example.com/remote.jpg', (err, texture) => console.log(texture)); Loading remote audio // before loader.load('http://example.com/remote.mp3', (err, audioClip) => console.log(audioClip)); // after assetManager.loadRemote('http://example.com/remote.mp3', (err, audioClip) => console.log(audioClip)); Loading remote text // before loader.load('http://example.com/equipment.txt', (err, text) => console.log(text)); // after assetManager.loadRemote('http://example.com/equipment.txt', (err, textAsset) => console.log(textAsset.text)); Notes: If you use loader.downloader.loadSubpackage in your own code to load a subpackage, please refer to the Subpackage Upgrade Guide to upgrade it. To avoid unnecessary errors, loader.onProgress has no equivalent implementation in assetManager. You can implement your own global callback mechanism, but it is recommended that you pass callbacks to each load function to avoid interfering with each other during concurrent loading. The relevant interface replacement about releasing If you use loader.release, loader.releaseAsset, loader.releaseRes, loader.releaseResDir in your own code, please use the corresponding API in assetManager for replacement. You can refer to the following replacements. loader.release loader.release can be replaced with assetManager.releaseAsset. Note: in order to avoid user attention to some obscure properties of the resource, assetManager.releaseAsset no longer accepts arrays, resource UUIDs, resource URLs for release, only the resource itself can be accepted for release. // before loader.release(texture); // after assetManager.releaseAsset(texture); // before loader.release([texture1, texture2, texture3]); // after [texture1, texture2, texture3].forEach(t => assetManager.releaseAsset(t)); // before const uuid = texture._uuid; loader.release(uuid); // after assetManager.releaseAsset(texture); // before const url = texture.url; loader.release(url); // after assetManager.releaseAsset(texture); Note: to increase ease of use, releasing resource dependencies in assetManager will no longer require manual access to resource dependencies, and an attempt will be made within assetManager.releaseAsset to automatically release the associated dependencies, for example: // before const assets = loader.getDependsRecursively(texture); loader.release(assets); // after assetManager.releaseAsset(texture); loader.releaseAsset loader.releaseAsset can be replaced directly with assetManager.releaseAsset. // before loader.releaseAsset(texture); // after assetManager.releaseAsset(texture); loader.releaseRes operator.releaseRes can be replaced directly with resources.release. // before loader.releaseRes('images/a', Texture2D); // after resources.release('images/a', Texture2D); loader.releaseAll loader.releaseAll can be replaced directly with assetManager.releaseAll. // before loader.releaseAll(); // after assetManager.releaseAll(); Notse: For security reasons, loader.releaseResDir does not have a corresponding implementation in assetManager, please use assetManager.releaseAsset or resources.release for individual resource releases. Since the assetManager.releaseAsset automatically releases dependent resources, you no longer need to explicitly call loader.getDependsRecursively. If you need to find the dependency of the resource, please refer to the relevant API in assetManager.dependUtil. For security reasons, assetManager only supports the Auto Release property set in the scene, and loader.setAutoRelease, loader.setAutoReleaseRecursively, loader.isAutoRelease APIs have been removed. It is recommended that you use the new auto-release mechanism based on reference counting. Please refer to the Release Of Resources documentation for details. Extension-related interface replacements Pipeline If you have methods in your code that use loader.insertPipe, loader.insertPipeAfter, loader.appendPipe, loader.addDownloadHandlers, loader.addLoadHandlers series APIs to extend the loading process of loader, or directly use loader.assetLoader, loader.md5Pipe, loader.downloader, loader.loader, loader.subPackPipe, here are the detailed alternatives. Because assetManager is a more general module and no longer inherits from Pipeline, assetManager no longer implements handler.insertPipe, handler.insertPipeAfter, handler.appendPipe. Please replace with the following code: // before const pipe1 = { id: 'pipe1', handle: (item, done) => { let result = doSomething(item.uuid); done(null, result); } }; const pipe2 = { id: 'pipe2', handle: (item, done) => { let result = doSomething(item.content); done(null, result); } }; loader.insertPipe(pipe1, 1); loader.appendPipe(pipe2); // after function pipe1 (task, done) { let output = []; for (let i = 0; i Notes: assetManager no longer inherits by Pipeline, but by multiple Pipeline instances owned under assetManager. Please refer to the Pipeline and Task documentation for details. For ease of use, the definition of Pipe no longer requires the definition of an object with a handle method and an id, just a single method. See Pipeline and Task documentation for details. In order to simplify the logic and improve performance, what is processed in Pipe is no longer a item but a task object, see Pipeline and Task documentation for details. In order to reduce learning costs, APIs in the form of insertPipeAfter are no longer supported in Pipeline, so please use insert to insert the specified location. addDownloadHandlers, addLoadHandlers For modularity reasons, addDownloadHandlers and addLoadHandlers are not implemented in assetManager, please refer to the following for replacement: // before const customHandler = (item, cb) => { let result = doSomething(item.url); cb(null, result); }; loader.addDownloadHandlers({png: customHandler}); // after const customHandler = (url, options, cb) => { let result = doSomething(url); cb(null, result); }; assetManager.downloader.register('.png', customHandler); Or: // before const customHandler = (item, cb) => { let result = doSomething(item.content); cb(null, result); }; loader.addLoadHandlers({png: customHandler}); // after const customHandler = (file, options, cb) => { let result = doSomething(file); cb(null, result); }; assetManager.parser.register('.png', customHandler); Notes: Since both the download module and the parsing module rely on extensions to match the corresponding processing method. So when calling register, the incoming first parameter needs to start with .. For the sake of modularity, the custom processing method will no longer pass in an item object, but will pass in its associated information directly. The custom processing method of downloader passes in the URL to be downloaded, and parser passes in the file to be parsed. For more information about downloader and parser, please refer to the Download and Parse documentation. The new expansion mechanism provides an additional options parameter that can greatly increase flexibility. However, if you don't need to configure the engine's built-in or custom parameters, you can ignore it. Please refer to the Optional parameter documentation for details. downloader, loader, md5Pipe, subPackPipe loader.downloader can be replaced by assetManager.downloader, and loader.loader can be replaced by assetManager.parser. For details, see Download and Parse documentation or the corresponding API documentation assetManager.downloader and assetManager.parser. Note: for performance, modularity and readability reasons, loader.assetLoader, loader.md5Pipe, loader.subPackPipe have been merged into assetManager.transformPipeline and you should avoid using any of the methods and properties in these three modules. Details about assetManager.transformPipeline can be found in Pipeline and Tasks documentation. Other changes The url and AssetLibrary have been removed, so avoid using any methods and properties of url and AssetLibrary. Pipeline can be replaced by AssetManager.Pipeline: // before const pipe1 = { id: 'pipe1', handle: function (item, cb) { let result = doSomething(item); cb(null, result); } } const pipeline = new Pipeline([pipe1]); // after function pipe1 (task, cb) { task.output = doSomething(task.input); cb(null); } const pipeline = new AssetManager.Pipeline('test', [pipe1]); Note: LoadingItem is no longer supported in assetManager, please avoid using this type. To support more loading strategies, macro.DOWNLOAD_MAX_CONCURRENT has been removed from macro and you can replace it with the following: // before macro.DOWNLOAD_MAX_CONCURRENT = 10; // after assetManager.downloader.maxConcurrency = 10; Or: // before macro.DOWNLOAD_MAX_CONCURRENT = 10; // after (set a preset value) assetManager.presets['default'].maxConcurrency = 10; Please refer to the Download and Parse documentation for details. "},"asset/subpackage-upgrade-guide.html":{"url":"asset/subpackage-upgrade-guide.html","title":"Asset Bundle Upgrade Guide","keywords":"","body":"Subpackage upgrade guide Author: Santy-Wang, Xunyi This article details the considerations for upgrading mini game sub-package to the Asset Bundle. Before v2.4, the Subpackage Loading only supported various mini game platforms, such as WeChat Mini Games, OPPO Mini Games, etc.. However, with the continuous development of Creator, developers' demands for subpackage have been increasing, such as multi-platform support, and the original subpackage loading is no longer enough. Therefore, starting from v2.4, the Creator officially supports the more complete Asset Bundle. For the Artist and Game Designer, all resources in your project (e.g. scenes, animations, prefab) do not need to be modified or upgraded. For Programmers, the loader.downloader.loadSubpackage needs to be changed to the assetManager.loadBundle from Asset Manager. The related content will be described in detail in this document. Note: If you used Subpackage Loading in your old project, that is, if you checked the Subpackage option in the Properties panel, then when the project is upgraded to the v3.0, it will automatically convert to an normal folder. You can configure the Asset Bundle as following reference. Configura Asset Bundle Situations that require upgrading manually You used the API loader.downloader.loadSubpackage in your own code to load the subpackage. Upgrade steps Back up your old projects Use Cocos Creator v3.0 in the Dashboard to open an old project that needs to upgrade the subpackage, Creator will reimport the affected resources. The first import will take a little longer, and the main editor window will open after the import is complete. And then you can open the code editor to replace all loader.downloader.loadSubpackage with assetManager.loadBundle. // before loader.downloader.loadSubpackage('sub1', (err) => { loader.loadRes('sub1/sprite-frames/background', SpriteFrame); }); // after assetManager.loadBundle('sub1', (err, bundle) => { // The relative path to the Asset Bundle root bundle.load('sprite-frames/background', SpriteFrame); }); How to use the Asset Bundle For details on how to use the Asset Bundle, please refer to the Asset Bundle documentation. For APIs related to the Asset Bundle, please refer to the Asset Bundle API documentation. "},"asset/dynamic-load-resources.html":{"url":"asset/dynamic-load-resources.html","title":"Dynamic load asset","keywords":"","body":"Asset Loading Dynamic loading of resources Usually we will place the resources that need to be dynamically loaded in the project in the resources directory, along with interfaces such as resources.load to load them dynamically. You just need to pass in the path relative to resources directory, and the end of the path must not contain the file extension. // load Prefab resources.load(\"test assets/prefab\", Prefab, (err, prefab) => { const newNode = instantiate(prefab); director.getScene().addChild(newNode); }); // load AnimationClip resources.load(\"test assets/anim\", AnimationClip, (err, clip) => { this.node.getComponent(Animation).addClip(clip, \"anim\"); }); All resources that need to be dynamically loaded by script must be placed in the resources folder or one of its subfolders. resources needs to be created manually in the assets folder and must be located in the assets root directory, like this: The assets in the resources folder can refer to other assets outside the folder, and can also be referenced by external scenes or assets. When the project is built, all assets in the resources folder, along with assets outside the resources folder they are associated with, will be exported, in addition to the scenes that have been checked in the Build panel. If an asset is only depended on by other assets in the resources and does not need to be called directly by resources.load, then please don't put it in the resources folder. Otherwise, the size of config.json will increase, and useless assets in the project will not be automatically culled during the build process. At the same time, in the build process, the automatic merge strategy of JSON will also be affected, unable to merge the fragmented JSON as much as possible. The second to note is that compared to previous Cocos2d-JS, dynamic loading of resources in Creator is asynchronous, you need to get the loaded resources in the callback function. This is done because in addition to the resources associated with the scene, Creator has no additional resources preload list, and the dynamically loaded resources are really dynamically loaded. Note: as of v2.4, the loader interface is deprecated, please use assetManager instead. You can refer to the Asset Manager Upgrade Guide documentation for details. Loading a SpriteFrame or a Texture2D After the image is set to a spriteframe, texture or other image types, an asset of the corresponding type will be generated in the Assets Panel. But if test assets/image is loaded directly, and the type will be ImageAsset. You must specify the full path of sub asset, then the generated SpriteFrame can be loaded. // load a SpriteFrame，image is ImageAsset，spriteFrame is image/spriteFrame, texture is image/texture resources.load(\"test assets/image/spriteFrame\", SpriteFrame, (err, spriteFrame) => { this.node.getComponent(Sprite).spriteFrame = spriteFrame; }); // load a texture resources.load(\"test assets/image/texture\", Texture2D ,(err: any, texture: Texture2D) => { const spriteFrame = new SpriteFrame(); spriteFrame.texture = texture; this.node.getComponent(Sprite).spriteFrame = spriteFrame; }); Note: If a type parameter is specified, an asset of the specified type will be found under the path. When you are in the same path includes multiple names simultaneously under a resource (for example, contains both player.clip and player.psd), should need to declare types. When you need to get a \"sub-asset\" (such as getting the sub-asset SpriteFrame of ImageAsset), you need to specify the path of the sub-asset. Load SpriteFrames from Atlas For an atlas imported from a third-party tool such as Texturepacker, if you want to load the SpriteFrame, you can only load the atlas first, and then get the SpriteFrame. This is a special case. // load SpriteAtlas, and get one of them SpriteFrame // Note Atlas resource file (plist) usually of the same name and a picture file (PNG) placed in a directory, // So should need to in the second parameter specifies the resource type. resources.load(\"test assets/sheep\", SpriteAtlas, (err, atlas) => { const frame = atlas.getSpriteFrame('sheep_down_0'); this.node.getComponent(Sprite).spriteFrame = frame; }); Load resources in the FBX or glTF model After importing the FBX model or glTF model into the editor, it will parse out the related resources which includes meshes, materials, skeletons, animations, etc. contained in the model, as shown in the following figure. It is possible to dynamically load a single resource in the model at runtime by simply specifying the path to a specific sub-resource, as follows. // Load the mesh in the model resources.load(\"Monster/monster\", Mesh, (err, mesh) => { this.node.getComponent(MeshRenderer).mesh = mesh; }); // Load the material in the model resources.load(\"Monster/monster-effect\", Material, (err, material) => { this.node.getComponent(MeshRenderer).material = material; }); // Load the skeleton in the model resources.load(\"Monster/Armature\", Skeleton, (err, skeleton) => { this.node.getComponent(SkinnedMeshRenderer).skeleton = skeleton; }); Resource bulk loading resources.loadDir can load multiple resources under the same path: // loading all resource in the test assets directory resources.loadDir(\"test assets\", function (err, assets) { // ... }); // Load all SpriteFrames in the `test assets` directory and get their urls resources.loadDir(\"test assets\", SpriteFrame, function (err, assets) { // ... }); Preload resources Starting with v2.4, in addition to scenes that can be preloaded, other resources can also be preloaded. Preloading has the same loading parameters as normal loading, but it will only download the necessary resources, and will not perform deserialization or initialization. Therefore, it consumes less performance and is suitable for use during the game. resources provides preload and preloadDir for preloading resources. resources.preload('test assets/image', SpriteFrame); // wait for while resources.load('test assets/image', SpriteFrame, (err, spriteFrame) => { this.node.getComponent(Sprite).spriteFrame = spriteFrame; }); Use the preload related interface to load resources in advance, without waiting for the preload to finish. Then use the normal load interface to load, the normal load interface will directly reuse the content that has been downloaded during the preload process to shorten the load time. For more information on preloading, please refer to the Preloading and Loading documentation. How to load remote assets or files in device Currently in Cocos Creator, we support loading the remote image files, which is very useful to load user picture from social network websites. To load files from such urls, you should call assetManager.loadRemote. At the same time the same API can be used to load resources on the local device storage. The resources.load APIs mentioned above only apply to the application package resources and hot update resources. Here is how to load remote assets and local device files: // Remote texture url with file extensions let remoteUrl = \"http://unknown.org/someres.png\"; assetManager.loadRemote(remoteUrl, function (err, texture) { // Use texture to create sprite frame }); // Remote texture url without file extensions, then you need to define the file type explicitly remoteUrl = \"http://unknown.org/emoji?id=124982374\"; assetManager.loadRemote(remoteUrl, {type: 'png'}, function () { // Use texture to create sprite frame }); // Use absolute path to load files on device storage let absolutePath = \"/dara/data/some/path/to/image.png\" assetManager.loadRemote(absolutePath, function () { // Use texture to create sprite frame }); // Remote Audio remoteUrl = \"http://unknown.org/sound.mp3\"; assetManager.loadRemote(remoteUrl, function (err, audioClip) { // play audio clip }); // remote Text remoteUrl = \"http://unknown.org/skill.txt\"; assetManager.loadRemote(remoteUrl, function (err, textAsset) { // use string to do something }); There still remains some restrictions currently, the most important are: This loading method supports only native resource types such as textures, audios, text, etc., and does not support direct loading and analysis of resources such as SpriteFrame, SpriteAtlas, Tilemap. (If you want to load all resources remotely, use the Asset Bundle) Remote loading ability on Web is limited by the browser's CORS cross-domain policy restriction. If the server forbid cross-domain access, loading request will fail, and due to WebGL security policy restrictions, even if the server allows CORS http request, textures loaded can not be rendered. "},"asset/bundle.html":{"url":"asset/bundle.html","title":"Asset Bundle","keywords":"","body":"Asset Bundle Overview Author: Santy-Wang, Xunyi Starting with v2.4, Creator officially supports Asset Bundle. The Asset Bundle is a modular resource tool that allows developers to divide the resources such as textures, scripts, scenes, etc. into different Asset Bundles according to the project requirements. Then, as the game runs, load different Asset Bundles as needed to minimize the number of resources to be loaded at startup. thus reducing the time required for the first download and loading of the game. The Asset Bundle can be placed in different places as needed, such as on a remote server, locally, or in a subpackage of a mini game platform. It also can be reused across projects to load Asset Bundle in subprojects. The built-in Asset Bundle In addition to the custom Asset Bundle, there are three built-in Asset Bundles in the project, which like other custom Asset Bundles, can be configured for different platforms. Built-in Asset Bundle Function Explanation Configuration main Store all scenes checked in the Included Scenes selection box of the Build panel and their dependent resources By configuring the Main Bundle Compression Type and Main Bundle Is Remote options of the Build panel. resources Store all resources in the resources directory and their dependent resources By configuring the assets -> resources folder in the Assets panel. start-scene If you check the Start Scene Asset Bundle option in the Build panel, the first scene will be built into the start-scene folder. Cannot be configured. After the build, the built-in Asset Bundle will be generated in different locations depending on the configuration, see the Configure the Asset Bundle documentation for the configuration methods and generation rules. The built-in Asset Bundle is loaded in application.js, and you can modify the code in application.js by using the custom build template feature, as shown below. // ... function loadAssetBundle (hasResourcesBundle, hasStartSceneBundle) { let promise = Promise.resolve(); const mainBundleRoot = 'http://myserver.com/assets/main'; const resourcesBundleRoot = 'http://myserver.com/assets/resources'; const bundleRoot = hasResourcesBundle ? [resourcesBundleRoot, mainBundleRoot] : [mainBundleRoot]; return bundleRoot.reduce((pre, name) => pre.then(() => loadBundle(name)), Promise.resolve()); } function loadBundle (name) { return new Promise((resolve, reject) => { assetManager.loadBundle(name, (err, bundle) => { if (err) { return reject(err); } resolve(bundle); }); }); } Configuration The custom Asset Bundle is configured in folders. When we select a folder in the Assets panel, the Properties panel will show a Is Bundle option, if set, the folder-related configuration options will appear: Configuration Options Function Explanation Bundle Name The name of the Asset Bundle after it is built, which will use the name of this folder by default, can be modified as needed. Bundle Priority Creator opens up 10 configurable priorities, and the Asset Bundle will be built in descending order of priority. For more detail, see Asset Bundle -- Priority documentation. Target Platform An Asset Bundle can have different settings on different platforms and the editor will choose the corresponding setting at build time. Compression Type Determines the final output form of the Asset Bundle, including the five compression types Merge Depend, None, Merge All JSON, Mini Game Subpackage、Zip. For more detail, see Asset Bundle -- Compression Type documentation. Is Remote Bundle Whether to configure the Asset Bundle as a remote package and not support the Web platform.If checked, the Asset Bundle will be placed in the remote folder after the build, and you will need to place the entire remote folder on the remote server.When building mini game platforms such as OPPO, vivo, Huawei, etc., the Asset Bundle will not be packaged into rpk if this option is checked. After the configuration, click on the Apply button at the top right and the folder will be configured as an Asset Bundle, then select the corresponding platform in the Build panel to build. Notes: There are three built-in Asset Bundles in the Creator, including resources, main and start-scene. When setting the Bundle Name, do not use these three names. The mini game subpackage can only be placed locally and cannot be configured as remote packages. So the Is Remote Bundle option cannot be checked when the compression type is set to Mini Game Subpackage. The Zip compression type is primarily used to reduce the number of network requests and is used by default with the Is Remote Bundle option. Since the package doesn't need network requests if it's local, there's no need to use Zip compression. Priority When the folder is set to Asset Bundle, the resources in the folder and the related dependent resources outside the folder are merged into the same Asset Bundle. It is possible to have a resource that is not in the Asset Bundle folder, but belongs to both Asset Bundles, because it is depended upon by both Asset Bundles. As shown in the figure: Another possibility is that a resource is in one Asset Bundle folder, but is also depended upon by other Asset Bundles. As shown in the figure: In both cases, resource c belongs to both Asset Bundle A and Asset Bundle B. So which Asset Bundle does resource c actually exist in? This needs to be specified by adjusting the priority of the Asset Bundle. Creator opens up 10 configurable priorities, and the editor will build the Asset Bundle in descending order of priority at build time. When the same resource is referenced by multiple Asset Bundles with different priorities, the resource will be placed in the high-priority Asset Bundle, while the lower-priority Asset Bundle stores only one record message. In this case the lower-priority Asset Bundle relies on the higher-priority Asset Bundle. If you want to load this shared resource in a lower-priority Asset Bundle, you must load the higher-priority Asset Bundle before loading the lower-priority Asset Bundle. When the same resource is referenced by multiple Asset Bundles of the same priority, the resource will be copied in each Asset Bundle, with no dependencies between the different Asset Bundles, and they can be loaded in any order. So try to make sure that the Asset Bundle that the shared resource (e.g. Texture, SpriteFrame, Audio, etc.) is in has a higher priority, so that more lower-priority Asset Bundles can share resources, thus minimizing the package size. The four built-in Asset Bundle folders are prioritized as follows: Asset Bundle Priority main 7 resources 8 start-scene 20 When the four built-in Asset Bundles contain the same resources, the resources are stored in the higher priority Asset Bundle. It is recommended that other custom Asset Bundle priorities are not higher than the built-in Asset Bundle, so that the resources in the built-in Asset Bundle can be shared whenever possible. Compression Type Creator currently provides Merge Depend, None, Merge All Json, Mini Game Subpackage, and Zip compression types for optimizing the Asset Bundle. All Asset Bundles use the Merge Depend compression type by default, and you can reset the compression type for all Asset Bundles including the built-in Asset Bundle. Compression Type Function Explanation Merge Depend When building the Asset Bundle, JSON files for interdependent resources are merged together to reduce the number of load requests at runtime. None When building the Asset Bundle, there is no compression operation. Merge All Json When building the Asset Bundle, the JSON files for all resources are merged into one, which minimizes the number of requests, but may increase the load time for a single resource. Mini Game Subpackage On a mini game platform that provides subpackaging, the Asset Bundle will be set as a subpackage of the mini game. Zip On some mini game platforms, the resource file will be compressed into a Zip file when building the Asset Bundle, reducing the number of load requests at runtime. If you use different compression types for the Asset Bundle on different platforms, then the Asset Bundle will be built according to the settings of the corresponding platform. Building of the Asset Bundle At build time, resources (including scenes, code, and other resources) in the folder configured as an Asset Bundle, as well as relevant dependent resources outside the folder, are merged into the same Asset Bundle folder. For example, if \"scene A\" is placed in \"folder a\", when \"folder a\" is configured as an Asset Bundle, \"scene A\" and its dependent resources will be merged into the \"Asset Bundle a\" folder. All the code and resources in the folder configured as the Asset Bundle are treated as follows. Code: All the code in the folder is merged into an entry script file named index.js or game.js, depending on the release platform, and removed from the main package. Resources: All resources in the folder and the related dependent resources outside the folder are placed in the import or native directory. Resource Configuration: All resource configuration information including path, type, and version information is merged into a file named config.json. The structure of the Asset Bundle directory generated after build is shown below: After building, the Asset Bundle folder will be packaged into the assets folder in the release package directory of the corresponding platform. However, there are two special cases. If the Is Remote Bundle option is checked when configuring the Asset Bundle, this Asset Bundle folder will be packaged into the remote folder in the release package directory of the corresponding platform. If the Compression Type is set to Mini Game Subpackage when configuring the Asset Bundle, this Asset Bundle folder will be packaged into the subpackages folder in the release package directory of the corresponding platform. Each folder contained within these three folders assets, remote and subpackages is an Asset Bundle. For example, if the cases/01_graphics folder in the example-case is configured as an Asset Bundle on the Web Mobile platform, then after the project is built, a 01_graphics folder is generated in the assets folder in the release package directory, and the 01_graphics folder is an Asset Bundle. Scripts in the Asset Bundle The Asset Bundle supports script subpackaging. If your Asset Bundle includes the script files, then all the scripts will be merged into a single js file and removed from the main package. When loading the Asset Bundle, this js file will be attempted to be loaded. Notes: Some platforms do not allow the loading of remote script files, such as the WeChat Mini Game, and Creator will copy the code of the Asset Bundle to the src/bundle-scripts directory to ensure normal loading. It is recommended that scripts in the different Asset Bundles do not reference each other, otherwise you may not find the corresponding script at runtime. If you need to reference certain classes or variables, you can share them by exposing them in your own global namespace. Load the Asset Bundle The engine provides a unified API assetManager.loadBundle to load the Asset Bundle, which you need to pass in either the Asset Bundle's URL or the Bundle Name set in the Asset Bundle configuration panel, but if you want to reuse Asset Bundles from other projects, you can only do so through the URL. The usage is as follows: assetManager.loadBundle('01_graphics', (err, bundle) => { bundle.load('xxx'); }); // Reuse Asset Bundles from other projects assetManager.loadBundle('https://othergame.com/remote/01_graphics', (err, bundle) => { bundle.load('xxx'); }); assetManager.loadBundle also supports loading an Asset Bundle from user space with the path in user space. Use the download interface provided by the corresponding platform to pre-download the Asset Bundle into your user space and then use loadBundle to load it, so that you can manage the download and cache process of the Asset Bundle by yourself. // Download an Asset Bundle in advance to the \"pathToBundle\" directory in your user space, and it's necessary to ensure // that the structure and content of the Asset Bundle in your user space is identical to that of the original Asset Bundle. // ... // Load with the path of the Asset Bundle in user space // On native platform assetManager.loadBundle(jsb.fileUtils.getWritablePath() + '/pathToBundle/bundleName', (err, bundle) => { // ... }); // On WeChat Mini Game assetManager.loadBundle(wx.env.USER_DATA_PATH + '/pathToBundle/bundleName', (err, bundle) => { // ... }); Note: if you check the Is Remote Bundle option when configuring the Asset Bundle, then please fill in the Resource Server Address in the Build panel when building. When you load the Asset Bundle via the API, instead of loading all the resources in the Asset Bundle, the engine loads the Asset Bundle's resource manifest and all the scripts it contains. When the Asset Bundle is loaded, the engine triggers a callback and returns an error message and an instance of AssetManager.Bundle class, which is the main entrance of the Asset Bundle API that can be used to load the various resources in the Asset Bundle. Versions of the Asset Bundle The Asset Bundle continues the MD5 scheme of the Creator for updates. When you need to update the Asset Bundle on the remote server, check the MD5 Cache option in the Build panel. Then the filename of the config.json in the built Asset Bundle will come with a Hash value. As shown in the following figure: It is not necessary to provide an additional Hash value when loading the Asset Bundle, Creator will search for the corresponding Hash value in the settings.js and make adjustments automatically. However, if you want to store the relevant version configuration information on the server and dynamically fetch the version information at startup for hot updates, you can manually specify a version Hash value and pass in the loadBundle, and the Asset Bundle will be built based on the incoming Hash value: assetManager.loadBundle('01_graphics', {version: 'fbc07'}, function (err, bundle) { if (err) { return console.error(err); } console.log('load bundle successfully.'); }); Then you can bypass the old version files in the cache and redownload the latest version of the Asset Bundle. Load the resources in the Asset Bundle After the Asset Bundle is loaded, the engine returns an instance of AssetManager.Bundle class. You can load the resources in the Asset Bundle by using load method of the instance, which has the same arguments as the resources.load, you just need to pass in the path of the resource relative to the Asset Bundle, and the end of the path must not contain the file extension. // Load Prefab bundle.load(`prefab`, Prefab, function (err, prefab) { let newNode = instantiate(prefab); director.getScene().addChild(newNode); }); // Load Texture bundle.load(`image`, Texture2D, function (err, texture) { console.log(texture) }); Like the resources.load, the load method also provides a type parameter, which is useful for loading resources with the same name or loading a SpriteFrame. // Load SpriteFrame bundle.load(`image`, SpriteFrame, function (err, spriteFrame) { console.log(spriteFrame); }); Bulk load resources The Asset Bundle provides loadDir method to bulk load multiple resources in the same directory. The arguments of this method are similar to the resources.loadDir, you just need to pass in the path of the directory relative to the Asset Bundle. // Load all resources in the \"textures\" directory bundle.loadDir(\"textures\", function (err, assets) { // ... }); // Load all Texture resources in the \"textures\" directory bundle.loadDir(\"textures\", Texture2D, function (err, assets) { // ... }); Load scenes The Asset Bundle provides loadScene methods for loading scenes from the specified bundle, you just need to pass in the scene name. The difference between loadScene and director.loadScene is that loadScene will only load the scene from the specified bundle and will not run the scene, you also need to use director.runScene to run the scene. bundle.loadScene('test', function (err, scene) { director.runScene(scene); }); Get the Asset Bundle After the Asset Bundle has been loaded, it will be cached, and the name can be used to get the Asset Bundle. For example: let bundle = assetManager.getBundle('01_graphics'); Preload resources In addition to scenes, other resources can also be preloaded. The loading arguments for preloading are the same as for normal loading, but because preloading only downloads the necessary resources, and does not perform the resources' deserialization and initialization, so it consumes less performance and is suitable for use during gameplay. The Asset Bundle provides preload and preloadDir interfaces to preload the resources in the Asset Bundle, which are used in the same way as the assetManager, see Loading and Preloading documentation for details. Release resources in the Asset Bundle After loading the resources, all the resources are temporarily cached in assetManager to avoid reloading. Of course, the resources in the cache also occupy memory, and some resources you can release in the following three ways if they are no longer needed: Use the regular assetManager.releaseAsset method for release. bundle.load(`image`, SpriteFrame, function (err, spriteFrame) { assetManager.releaseAsset(spriteFrame); }); Use release method provided by the Asset Bundle, then pass in the path and type to release resources, but can only release the single resource in the Asset Bundle. The arguments can be the same as those used in the load method of the Asset Bundle. bundle.load(`image`, SpriteFrame, function (err, spriteFrame) { bundle.release(`image`, SpriteFrame); }); Use releaseAll method provided by the Asset Bundle, which is similar to the assetManager.releaseAll, but the releaseAll will release all resources that belong to the Asset Bundle (including resources in the Asset Bundle and the related dependent resources outside the Asset Bundle), so please use caution. bundle.load(`image`, SpriteFrame, function (err, spriteFrame) { bundle.releaseAll(); }); Note: when releasing a resource, Creator will automatically handle the resource's dependent resources, and you don't need to manage their dependency resources. For more information about releasing resources, see Release of Resources documentation. Remove the Asset Bundle After the Asset Bundle is loaded, it will remain in the entire gameplay, unless you manually remove it from the game. When an unneeded Asset Bundle is manually removed, the cache for the bundle is also removed. If you need to use it again, you must reload it again. let bundle = assetManager.getBundle('bundle1'); assetManager.removeBundle(bundle); Note: when you destroy an Asset Bundle, the resources already loaded in the bundle are not released. If you need to release it, use the Asset Bundle's release/releaseAll method first. let bundle = assetManager.getBundle('bundle1'); // Releases a single resource in the Asset Bundle. bundle.release(`image`, SpriteFrame); assetManager.removeBundle(bundle); let bundle = assetManager.getBundle('bundle1'); // Releases all resources belonging to the Asset Bundle. bundle.releaseAll(); assetManager.removeBundle(bundle); FAQ Q: What is the difference between Asset Bundle and resource subpackage? A: Resource subpackage is actually splitting out some textures, meshs into a separate packages, but the package is incomplete and illogical and cannot be reused. while Asset Bundle is modularizing resources through logical division. The Asset Bundle includes resources, scripts, metadata and resource lists, so it is complete, logical and reusable, and we can load an entire scene or any other resources from Asset Bundle. By splitting the Asset Bundle, you can greatly reduce the number of json and the size of settings.js in the first package. Resource subpackage is essentially a basic function controlled by the mini game platform. For example, the WeChat Mini Game supports subpackage, and then Creator made a layer of encapsulation on top of that to help the developers set up resource subpackage. If the WeChat Mini Game doesn't support subpackage anymore, neither does the Creator. While the Asset Bundle is designed and implemented entirely by Creator, it is a modular tool to help developers divide their resources, independent of the platform, and can theoretically be supported on all platforms. Resource subpackage is related to the platform, meaning that it needs to be set up in the way required by the platform. For example, the subpackage of the WeChat Mini Game cannot be placed on the remote server, and can only be placed on Tencent's server. While the Asset Bundle doesn't have these restrictions, the Asset Bundle can be placed locally, on a remote server, or even in a subpackage of the WeChat Mini Game. Q: Does the Asset Bundle support the lobby plus sub games mode? A: Absolutely, subgame scenes can be placed in the Asset Bundle and loaded when needed, and subgames can even be pre-built as an Asset Bundle in other projects and then loaded for use in the main project. Q: Can the Asset Bundle reduce the size of settings.js? A: Absolutely. In fact, as of v2.4, the packaged project is entirely based on the Asset Bundle, and the setting.js no longer stores any configuration information related to the resource, all configuration informations are stored in the config.json of each Asset Bundle. Each config.json stores only the resource information in the respective Asset Bundle, which reduces the size of the first package. This can simply be understood as all the config.json combined equal to the previous settings.js. Q: Does the Asset Bundle support cross project reuse? A: Absolutely support, but the following conditions must be met: The engine version is the same All scripts referenced in the Asset bundle are placed under the Asset bundle. The Asset Bundle has no other external dependency bundle, and if it does, it must be loaded. Q: Does the Asset Bundle support split first scene? A: Currently only supported on mini game platforms. You can check the Start Scene Asset Bundle in the Build panel and the first scene will be put into the start-scene of the built-in Asset Bundle to separate the first scene. Q: Does the Asset Bundle support nesting? For example, if there is a folder B in folder A, can both A and B be set as Asset Bundle? A: Asset Bundle does not support nesting, please avoid using it as such. "},"asset/release-manager.html":{"url":"asset/release-manager.html","title":"Release Of Resources","keywords":"","body":"Release Of Resources Author: Santy-Wang, Xunyi A resource release module is provided in Asset Manager to manage the release of resources. When a resource is loaded, it is temporarily cached in assetManager for the next reuse. However, this also causes a constant growth in memory and video memory, so some resources can be released either by Auto Release or Manual Release if you don't need to use them. Releasing a resource will destroy all internal properties of the resource, such as data associated with the rendering layer, and move out of the cache, thus freeing up memory and video memory (for textures). First and most important: Resources depends on each other. For example, in the following graph, the Prefab resource contains the Sprite component, the Sprite component depends on the SpriteFrame, the SpriteFrame resource depends on the Texture resource, then the Prefab, SpriteFrame, and Texture resources are all cached by the asset manager. The advantage of doing so is that there may be another SpriteAtlas resource that depends on the same SpriteFrame and Texture, then when you manually load the SpriteAtlas, asset manager do not need to request the existing SpriteFrame and Texture again it will use the cache directly. Auto Release The automatic release of a scene can be set directly in the editor. When you select the scene in the Assets panel, the Auto Release Assets option appears in the Properties panel. Once checked, click the Apply button on the top right, and then all dependent resources of the scene will be automatically released when you switch the scene. It is recommended to check the Auto Release Assets option for all scenes to ensure low memory consumption, except for some high usage scenes (such as the main scene). In addition, all Asset instances have member functions Asset.addRef and Asset.decRef for increasing and decreasing the reference count, respectively. Once the reference count is 0, Creator will automatically release the resource (it needs to pass a release check first, see the following section for details) start () { resources.load('images/background', Texture2D, (err, texture) => { this.texture = texture; // Add references to resources when you need to use them. texture.addRef(); // ... }); } onDestroy () { // Reduce references to resources when you don't need to use them. Creator will try to auto-release them after calling decRef. this.texture.decRef(); } The advantage of auto-release is that you don't have to explicitly call the release interface, you just need to maintain the reference count of the resource and Creator will release it automatically based on the reference count. This greatly reduces the possibility of releasing resources by mistake, and you don't need to understand the complex referencing relationships between resources. For projects with no special requirements, it is recommended that you use automatic release to release resources as much as possible. Release Check To prevent rendering or other problems caused by incorrectly releasing resources being used, Creator will perform a series of checks before auto-releasing resources: If the reference count of the resource is 0, that is, there are no references to it elsewhere, then no follow-up check is required, the resource is destroyed directly and the cache is removed. Once the resource is removed, a release check for its dependent resources is triggered synchronously, and the reference counts of all direct dependent resources (excluding descendants) of the resource after the cache is removed are reduced by 1, and a release check is triggered synchronously. If the reference count of the resource is not 0, that is, there are references to it elsewhere, a circular reference check is required at this point to avoid having its own offspring refer to it. If the reference count is still not 0 after the cyclic reference check, terminate the release. Otherwise, destroy the resource directly, remove the cache, and trigger a release check for its dependent resources (as in step 2). Manual Release When a more complex resource release mechanism is used in a project, you can call the relevant interfaces of the Asset Manager to manually release resources. For example: assetManager.releaseAsset(texture); Since the resource management module was upgraded in v2.4, the release interface differs slightly from the previous version: The assetManager.releaseAsset interface can only release a single resource, and for the sake of uniformity, the interface can only release resources through the resource itself, not via attributes such as resource uuid, resource url, etc. When releasing a resource, you only need to focus on the resource itself and the engine will automatically release its dependent resources instead of fetching them manually via getDependsRecursively. Note: the release series interfaces (such as release, releaseAsset, releaseAll) will release the resource directly without a release check, only resource's dependent resources will have a release check. So when the release series interfaces are called explicitly, you can be sure that the resource itself will always be released. Reference Count Statistics Before v2.4, Creator chose to give the developer control over the release of all resources, both the resource itself and its dependencies, and the developer had to manually obtain all the dependencies of the resource and select the dependencies to be released. This way gave the developer the most control, and worked well for small projects. But as Creator grows, the size of the project grows, the resources referenced by the scene grows, and other scenes may reuse those resources, which causes increasing complexity in releasing resources and it is very difficult for the developer to master the usage of all resources. To address this pain point, the Asset Manager provides a set of resource release mechanism based on the reference counting, so that developers can release resources simply and efficiently, without worrying about rapid expansion of the project size. It should be noted that the Asset Manager only automatically counts static references between resources and does not truly reflect how the resources are dynamically referenced in the game, you need to control the dynamic references yourself to ensure that the resources are released correctly. The reasons are as follows: JavaScript is a language with a garbage collection mechanism that manages its memory, so the engine has no way of knowing if a resource has been destroyed in the browser environment. JavaScript does not provide the assignment operator overloading, which the reference count statistics are highly dependent on. Static Referencing of Resources When you edit the resources in the editor (such as the scene, prefab, material, etc.), you need to configure some other resources in the properties of those resources, such as setting the texture in the materials, setting the SpriteFrame on the Sprite component of the scene. Then these references will be recorded in the serialized data of the resources, which the engine can use to analyze the list of dependent resources, and a reference relationship like this is the static reference. The statistics for the static references of resources by the engine are as follows: When loading a resource using assetManager or Asset Bundle, the engine records all direct dependent resources for the resource in the underlying load pipe, adds 1 to the reference count of all direct dependent resources, and then initializes the reference count to 0 for the resource. When releasing a resource, obtain all the direct dependent resources information recorded previous for the resource, and subtract the reference count of all dependent resources by 1. This is because a resource can only be auto-released if its reference count is 0 in the release check. So the above steps ensure that the dependent resources of the resource cannot be released before the resource itself, because the reference count of the dependent resources is definitely not 0. That is, as long as a resource itself is not released, its dependent resources will not be released, thus ensuring that the release will not be done incorrectly when reusing the resource. For example: Suppose you now have a Prefab A that depends on both Material a and Material b. Material a references Texture α, and Material b references Texture β. After loading Prefab A, the reference count for both Material a and Material b are 1, and the reference count for both Texture α and Texture β are also 1. Suppose you now add a Prefab B that depends on both Material b and Material c. After you load the Prefab B, the reference count to Material b is 2, because it is referenced by both the Prefab A and B. The reference count to Material c is 1, and the reference counts for Textures α and β are still 1. When the Prefab A is released, the reference count for the Materials a and b each decreases by 1. The reference count of the Material a changes to 0 and is released; so the reference count of the Texture α minus 1 changes to 0 and is also released. The reference count of the Material b changes to 1 and is retained, so the reference count of the Texture β is still 1 and is also retained. Because the Prefab B is not released, the reference count for the Material c remains at 1 and is retained. Dynamic Referencing of Resources When you do not make any settings for a resource in the editor, but instead dynamically load the resource and set it to the component of the scene via code, the reference relationships of the resource are not recorded in the serialization data, and the engine cannot count this part of the reference relationships, which are dynamic references. If you are using dynamically loaded resources in your project for dynamic referencing, for example: resources.load('images/background', SpriteFrame, function (err, spriteFrame) { self.getComponent(Sprite).spriteFrame = spriteFrame; }); At this point, the SpriteFrame resource is set to the Sprite component and the engine does not do anything special, the reference count of the SpriteFrame remains 0. If the dynamically loaded resources need to be referenced, held, or reused over time, it is recommended to use the addRef interface to manually increase the reference count. For example: resources.load('images/background', SpriteFrame, function (err, spriteFrame) { self.getComponent(Sprite).spriteFrame = spriteFrame; spriteFrame.addRef(); }); Increasing the reference count ensures that the resource will not be released early by mistake. Always remember to use decRef to remove the reference count and set the resource reference to null if you do not need to reference the resource and related components, or if the node is destroyed. For example: this.spriteFrame.decRef(); this.spriteFrame = null; "},"asset/downloader-parser.html":{"url":"asset/downloader-parser.html","title":"Download and Parse","keywords":"","body":"Download and Parse Author: Santy-Wang, Xunyi The underlying of the Asset Manager uses multiple loading pipelines to load and parse resources, each of which uses the downloader and parser modules, that is, the downloader and the parser. You can access them via assetManager.downloader and assetManager.parser. Downloader The downloader is a global single instance with features such as download retry, download priority, and download concurrency limits. Download retry If the downloader fails to download a resource, it will automatically retry the download, and you can set the parameters for the download retry via maxRetryCount and retryInterval. maxRetryCount is used to set the maximum number of retry downloads, the default is 3. If you do not need to retry the download, set to 0 and an error will be returned immediately if the download fails. assetManager.downloader.maxRetryCount = 0; retryInterval is used to set the interval of retry downloads, the default is 2000 ms. If it is set to 4000 ms, it will wait for 4000 ms before re-downloading if the download fails. assetManager.downloader.retryInterval = 4000; Download priority Creator opens up four download priorities, and the downloader will download resources in descending order of priority. Resource Priority Explanation Script or Asset Bundle 2 Highest priority first Scene resource 1 Include all resources in the scene, ensuring that the scene loads quickly Manually loaded resource 0 Preload resource -1 The lowest priority, because preloading is more like loading resources in advance, and time requirements are relatively lenient You can also control the load order by passing a priority over the default setting with the optional parameter priority. For details, refer to the \"Set by optional parameters\" section below. Set the number of concurrent downloads You can set limits such as the maximum number of concurrent downloads in the downloader via maxConcurrency and maxRequestsPerFrame. maxConcurrency is used to set the maximum number of concurrent connections for the download, if the current number of connections exceeds the limit, a waiting queue will be entered. assetManager.downloader.maxConcurrency = 10; maxRequestsPerFrame is used to set the maximum number of requests that can be initiated per frame, which spreads the CPU overhead of initiating requests, avoiding too much jams in a single frame. If the maximum number of connections initiated in this frame has been reached, the request will be delayed until the next frame. assetManager.downloader.maxRequestsPerFrame = 6; In addition, downloader uses an instance of the jsb.Downloader class to download resources from the server on native platforms. jsb.Downloader is similar to the Web's XMLHttpRequest. Currently the jsb.Downloader class instances have a default download concurrency limit of 32 and a default timeout of 30s, if you want to change the default values, you can do so in main.js. // main.js assetManager.init({ bundleVers: settings.bundleVers, remoteBundles: settings.remoteBundles, server: settings.server, jsbDownloaderMaxTasks: 32, // Max concurrency jsbDownloaderTimeout: 60 // Timeout }); Parser The parser is used to parse the files into the resources that can be recognized by the engine, and you can access them via assetManager.parser. Set by optional parameters The settings in both the downloader and the parser are global, if you need to set up a resource individually, you can override the global settings by passing in the proprietary settings via the optional parameters. For example: assetManager.loadAny({'path': 'test'}, {priority: 2, maxRetryCount: 1, maxConcurrency: 10}, callback); For details, refer to the Optional Parameters documentation. Preset Creator presets the download/parsing parameters for the six load cases: normal loading, preloading, scene loading, Asset Bundle loading, remote resource loading, and script loading, and preloading is more restrictive because of performance considerations, and the maximum number of concurrency is smaller. As shown below: { 'default': { priority: 0, }, 'preload': { maxConcurrency: 2, maxRequestsPerFrame: 2, priority: -1, }, 'scene': { maxConcurrency: 8, maxRequestsPerFrame: 8, priority: 1, }, 'bundle': { maxConcurrency: 8, maxRequestsPerFrame: 8, priority: 2, }, 'remote': { maxRetryCount: 4 }, 'script': { priority: 2 } } In addition to the above, you can also set each preset via assetManager.presets. Note that the restrictions can be different for each preset, so presets is a table and you need to pass the name of the preset to access the corresponding parameter options, for example: // Modify the preset priority of the preload to 1. let preset = assetManager.presets.preload; preset.priority = 1; You can also add custom presets and pass them in with the optional parameter preset. // Customize the preset and pass it in with the optional parameter preset. assetManager.presets.mypreset = {maxConcurrency: 10, maxRequestsPerFrame: 6}; assetManager.loadAny({'path': 'test'}, {preset: 'mypreset'}, callback); Note: parameters related to the download and parsing process (e.g. number of download concurrent, number of download retries, etc.) can be set via optional parameters, presets, and the downloader/parser itself. When the same parameter is set in multiple ways, the engine selects to use it in the order of selectable optional parameter > preset > downloader/parser. That is, if the engine can't find the relevant settings in the optional parameter, it will look in the preset, and if it can't find them in the preset, it will look in the downloader/parser. Custom handlers Both the downloader and the parser have a registration table. When you use downloader or parser, the downloader and parser will look for the corresponding download and parsing methods in the registry based on the incoming suffix name, and pass the parameters into the corresponding handler, so you can extend the engine by registering the custom handlers when you need to add a custom format to your project, or modify the handlers of the current format. Both the downloader and the parser provide register interfaces for registration handlers, which are used as follows: assetManager.downloader.register('.myformat', function (url, options, callback) { // Download the resource ...... }); assetManager.parser.register('.myformat', function (file, options, callback) { // Parsing a downloaded file ...... }); A custom handler needs to receive three arguments: The first argument is the handler object, which is the URL in the downloader and the file in the parser. The second argument is optional, and optional parameters can be specified when you call the load interface. The third argument is to complete the callback, which needs to be called when you register the handler and pass in an error message or result. After registered the handler, the corresponding handler will be used if the downloader/parser encounters a request with the same extension, and these custom handlers will be available to all loading pipelines globally. For example: assetManager.loadAny({'url': 'http://example.com/myAsset.myformat'}, callback); Note that the handler can receive incoming optional parameters, which can be used to implement custom extensions, see the Optional Parameters documentation for details. "},"asset/preload-load.html":{"url":"asset/preload-load.html","title":"Loading and Preloading","keywords":"","body":"Loading and Preloading Author: Santy-Wang, Xunyi In order to minimize download times, most of the loading interfaces in Asset Manager, including load, loadDir, and loadScene have their own corresponding preloaded versions. The parameters used for the loading interfaces and the preloading interfaces are exactly the same, with the following differences: Preloading will only download the resources and will not parse or initialize them. Preloading will be more limited during the loading process, e.g. the maximum number of download concurrently will be smaller. Preloading has a lower priority, and when multiple resources are waiting to be downloaded, the preloaded resources will be downloaded last. Since the preload does not do any parsing, no available resources are returned when all the preloads load are complete. Compared to previous versions of Creator v2.4, these optimizations reduce the preloading performance loss and ensure a smooth gaming experience. You can make full use of the network bandwidth during the game to reduce the loading time of subsequent resources. Since the preload does not parse the resources, you need to parse and initialize the resources with the loading interface to complete the resource loading after the preload is complete. For example: resources.preload('images/background', SpriteFrame); // Wait for while resources.load('images/background', SpriteFrame, function (err, spriteFrame) { spriteFrame.addRef(); self.getComponent(Sprite).spriteFrame = spriteFrame; }); Note: loading does not need to wait until the preload is complete, you can load at any time. The normal loading interface will directly reuse the content that was already downloaded during the preload process, reducing the load time "},"asset/cache-manager.html":{"url":"asset/cache-manager.html","title":"Cache Manager","keywords":"","body":"Cache Manager Author: Santy-Wang, Xunyi For Web platforms, resources cache are managed by the browser after download, not the engine. However, on some non-Web platforms, such as WeChat Mini Game, these platforms have a file system, which can be used to cache some remote resources, but do not implement a caching mechanism for resources. In this case, the engine needs to implement a set of caching mechanisms for managing resources downloaded from the network, including caching resources, cleaning cached resources, querying cached resources and other features. Since v2.4, Creator provides a Cache Manager on all platforms where file systems exist, and you can access it via assetManager.cacheManager. Resource download process The logic of the engine downloading resources is as follows: Determine if the resource is in the game package, if so, use it directly; If not, check if the resource is in the cache, and if it is, use it directly; If not, check if the resource is in a temporary directory, and if it is, use it directly (the native platform does not have the temporary directory and skips this step); If not, download the resources from the remote server and use them directly after downloading them to the temporary directory (the native platform downloads the resources to the cache directory); Slowly save the resources from the temporary directory to the local cache directory in the background (the native platform skips this step); When the cache space is full, the older resources will be deleted using the LRU algorithm at this point (there is no size limit on the native platform's cache space, so skip this step, you can call manually for cleanup if needed). Query cache files The Cache Manager provides a getCache interface to query all cache resources, and you can query the cache path of a resource by passing in its original path, for example: resources.load('images/background', Texture2D, function (err, texture) { const cachePath = assetManager.cacheManager.getCache(texture.nativeUrl); console.log(cachePath); }); Query temporary files After a resource is downloaded locally, it may be stored as a temporary file in a temporary directory. The Cache Manager provides a tempFiles interface to query all resources downloaded to the temporary directory, which you can do by passing in the original path of the resource, for example: assetManager.loadRemote('http://example.com/background.jpg', function (err, texture) { const tempPath = assetManager.cacheManager.getTemp(texture.nativeUrl); console.log(tempPath); }); Cache resources A number of parameters are provided in the Cache Manager to control the caching of resources. cacheManager.cacheDir -- Controls the storage directory for cached resources. cacheManager.cacheInterval -- Controls the period of caching a single resource, the default is once every 500ms. cacheManager.cacheEnabled -- Controls whether or not to cache resources, which defaults to caching. Alternatively, you can override the global settings by specifying the optional parameter cacheEnabled, for example: assetManager.loadRemote('http://example.com/background.jpg', {cacheEnabled: true}, callback); Clear cache The cache manager provides three interfaces removeCache, clearCache and clearLRU to clean up cache resources. removeCache -- Clean up a single cached resource, and you need to provide the original path of the resource when using it. assetManager.loadRemote('http://example.com/background.jpg', function (err, texture) { assetManager.cacheManager.removeCache(texture.nativeUrl); }); clearCache -- Clean up all cache resources, please use it carefully. clearLRU -- Clean up older resources. The mini game platform will automatically call clearLRU when the cache space is full. "},"asset/options.html":{"url":"asset/options.html","title":"Optional Parameters","keywords":"","body":"Optional Parameters Author: Santy-Wang, Xunyi For added flexibility and extensibility, most of the load interfaces in Asset Manager, including assetManager.loadAny and assetManager.preloadAny, provide options parameters. In addition to configuring the built-in parameters of Creator, options also allows you to customize any parameters to extend engine functionality. If you do not need to configure the engine's built-in parameters or extend the engine's functionality, you can ignore it and just use the simpler API interfaces, such as resources.load. Parameters that are currently used by the engine in options include the following: uuid, url, path, dir, scene, type, priority, preset, audioLoadMode, ext, bundle, onFileProgress, maxConcurrency, maxRequestsPerFrame, maxRetryCount, version, xhrResponseType, xhrWithCredentials, xhrMimeType, xhrTimeout, xhrHeader, reloadAsset, cacheAsset, cacheEnabled, Please DO NOT use the above fields as your custom parameter names to avoid conflicts with engine functions. Control loading pipeline The optional parameters serve as a communication tool between the upper level business logic and the lower level load pipeline. The upper level business logic provides parameters to control the operation of the lower level load pipeline. Controls downloader and parser The optional parameters priority, maxConcurrency, maxRequestsPerFrame, maxRetryCount are used to control the downloader's prioritization of download requests, the limit on the number of concurrent loads, the limit on the number of requests that can be initiated per frame, and the maximum number of retries, respectively. For example: assetManager.loadAny({'path': 'image/background'}, {priority: 2, maxRetryCount: 10}, callback); Controls the handler of downloader and parser The handler for resources such as text files and binary files in the downloader/parser, accepting optional parameters xhrResponseType, xhrWithCredentials, xhrMimeType, xhrTimeout, xhrHeader, onFileProgress to set the XHR's return type, header, download progress callback and other parameters. // Get a download progress callback for XHR assetManager.loadAny({ 'path': 'image/background' }, { onFileProgress: function (loaded, total) { console.log(loaded/total); } }, callback); While the optional parameter audioLoadMode controls whether or not the audio file's handler uses WebAudio to load audio. // Load audio remotely using WebAudio. assetManager.loadRemote('http://example.com/background.mp3', {audioLoadMode: AudioClip.LoadMode.WEB_AUDIO}, callback); Note: loading progress of the resources must be configured on the server if you want to get it. For more information about the handler, please refer to document Download and Parse. Control loading process The optional parameters reload, cacheAsset, and cacheEnabled are used to control the loading pipeline whether to reuse the resources in the cache, whether to cache the resources, and whether to cache the files. assetManager.loadRemote(url, {reload: true, cacheAsset: false, cacheEnabled: true}, (err, asset) => {}); While the optional parameters uuid, url, path, dir, scene, type, ext, bundle, etc. are used to search for resources. assetManager.loadAny({'path': 'images/background', type: SpriteFrame, bundle: 'resources'}, callback); assetManager.loadAny({'dir': 'images', type: SpriteFrame, bundle: 'resources'}, callback); This approach is exactly equivalent to using resources.load and resources.loadDir directly. Engine Extension You can extend the loading capabilities of the engine by using optional parameters in the Pipeline and Custom Handlers. For example: // Extend the pipeline assetManager.pipeline.insert(function (task, done) { let input = task.input; for (let i = 0; i The engine can be extremely extensible by using optional parameters, combined with pipelines and custom handlers, and Asset Bundle can be seen as the first instance of extension using optional parameters. "},"asset/pipeline-task.html":{"url":"asset/pipeline-task.html","title":"Pipeline and Task","keywords":"","body":"Pipeline and Task Author: Santy-Wang, Xunyi This article is for advanced developers who have customization needs for their loading process. To make it easier to modify or extend the loading process of engine, the underlying layer of Asset Manager uses a mechanism called Pipeline and Task, Download and Parser to load resources. This article will focus on Pipeline and Task. Although loader used before v2.4 already used the concept of Pipeline for resource loading, in Asset Manager we have refactored the pipeline to make the logic clearer and easier to extend. You can extend an existing pipeline, or customize a pipeline using the class AssetManager.Pipeline provided by the engine. Pipeline The Pipeline (defined in AssetManager.Pipeline) can be understood as a series of processes in series, and as a request passes through the pipeline, it is processed in turn by each stage of the pipeline, with the result of the processing finally being output. The schematic is as follows: The advantage of a pipeline over a regular fixed process is that all the links in the pipeline are spliceable and combinable, which means you can insert new stages or remove old stages at any point in the existing pipeline, greatly increasing flexibility and scalability. The built-in Pipeline There are three pipelines built into the Asset Manager, as shown in the figure: The first pipeline is used to convert resource paths and find the real resource paths. The second pipeline is used for the normal loading process. The third pipeline is used for the preload process. Note: the second pipeline uses a downloader and a parser, and the third pipeline uses a downloader. See document Download and Parse for details. Custom Pipeline You can extend the built-in pipeline to achieve your own customization needs: assetManager.pipeline.insert(function (task, done) { task.output = task.input; for (let i = 0; i You can also build a new pipeline: const pipeline = new AssetManager.Pipeline('test', [(task, done) => { console.log('first stage'); done(); }, (task, done) => { console.log('second stage'); done(); }]); Building the pipeline requires a series of methods, each of which requires passing in a task parameter and a completion callback parameter. You can access everything about the task in the method and just call the completion callback on completion. Task Task is a request flowing in the pipeline, a task contains inputs, outputs, completion callbacks, optional parameters and so on. As the task flows through the pipeline, each stage of the pipeline takes out the input of the task, makes some processing and saves it back to the output. For example: assetManager.pipeline.insert(function (task, done) { for (let i = 0; i For details, please refer to the type AssetManager.Task. "},"asset/meta.html":{"url":"asset/meta.html","title":"Resource Management Considerations --- meta files","keywords":"","body":"Resource Management Considerations --- meta files Note: the full text of this article is reproduced from WeChat Official Account: Quetta Planet [cn], authorized by the author before reprinting Author: Shawn Zhang Cocos Creator will generate a meta file with the same name for every file and directory in the assets directory. Understanding the role and mechanics of Cocos Creator's generation of meta files can help developers solve resource conflicts, file loss, and missing component properties that are often encountered with team development. What is the meta file used for? Let's take a look! The Role of a Meta File Let's first look at what the meta file looks like in the scene: { \"ver\": \"1.0.0\", //version \"uuid\": \"911560ae-98b2-4f4f-862f-36b7499f7ce3\", //global unique id \"asyncLoadAssets\": false, // asynchronous loading \"autoReleaseAssets\": false, // automatically release resources \"subMetas\": {} // child metadata } The meta file for the prefab is the same as the scene. Let's take a look at the meta file of the png image: { \"ver\": \"1.0.0\", \"uuid\": \"19110ebf-4dda-4c90-99d7-34b2aef4d048\", \"type\": \"sprite\", \"wrapMode\": \"clamp\", \"filterMode\": \"bilinear\", \"subMetas\": { \"img_circular\": { \"ver\": \"1.0.3\", \"uuid\": \"a2d1f885-6c18-4f67-9ad6-97b35f1fcfcf\", \"rawTextureUuid\": \"19110ebf-4dda-4c90-99d7-34b2aef4d048\", \"trimType\": \"auto\", \"trimThreshold\": 1, \"rotated\": false, \"offsetX\": 0, \"offsetY\": 0, \"trimX\": 0, \"trimY\": 0, \"width\": 100, \"height\": 100, \"rawWidth\": 100, \"rawHeight\": 100, \"borderTop\": 0, \"borderBottom\": 0, \"borderLeft\": 0, \"borderRight\": 0, \"subMetas\": {} } } } The meta file for the png image has more information. In addition to the basic ver and uuid, it also records the width, height, offset, and borders of the image. There is a lot of information that is stored. uuid and it is particularly important. uuid: Universally Unique Identifier uuids in Cocos Creator are used to manage the resources of the game. It assigns a unique id to each file. This means that in the Cocos Creator engine, identifying a file is not simply by path + filename, but by uuid. Therefore, you can delete and move files at will in Asset Resource Management. When will a meta file be updated Cocos Creator generates meta files the following situations: 1. when opening the project When you open a project, Cocos Creator, scans the assets directory first, and if it does not have a meta file, one will be generated. 2. when updating resources Updating resources also triggers updates to the corresponding meta files: In Assets, you can modify the file name of a resource, change the directory a resource belongs in, delete resources, and add new resources. You can also drag files directly into Assets from your desktop or the operating system's file manager. Please refer to Assets. Files in the assets directory can be added, deleted, changed, on your local file-system. When the changes are complete, switch to the Creator editor interface, where you can see the process of Assets panel refresh. The Assets panel is refreshed with each change, as to always show the current state of the resources. If a file's meta file does not exist, the above two conditions will trigger the engine to generate a new meta file automatically. Meta File Error Cases And Solutions Let's analyze several possible cases that produce a meta file error. UUID Conflict uuid is globally unique. A conflict occurs if, by chance, two files have the same uuid. If this problem occurs, the Cocos Creator resource manager directory structure is incompletely loaded. As shown in the figure below, when this happens, the errors look scary: uuid conflicts can be viewed from the Console, and then opened from your local file-system or favorite code editor. Once opened you can search for the conflicting uuid: At this point, close the Cocos Creator editor then delete one of the meta files. Next, open the Cocos Creator editor. Even though this method can solve the problem, if the resource is referenced in the editor, a resource loss will occur. This means the resource needs to be re-edited or reconfigured again. It is best to restore this meta file with the version management tool. There are two reasons for this problem: When moving files on the file-system, copying and pasting operations also result in the meta file also being copied. This causes two identical meta files to appear simultaneously in the project. When you have multi-person collaboration, from the version management tool, when you update the resource, you may encounter that the uuid has been generated by someone else as well as by the file on your computer. This is a very rare occurence, but could still happen. In general, to reduce the occurrence of uuid conflicts, it is best to add and move files in the Cocos Creator resource management tool. uuid Changes Another situation is when the uuid has changed, so that the resources corresponding to the old uuid cannot be found. In this case, the interface you have edited will have the resources, but the pictures may be lost as well as the components properties may also be lost. If you can't find the resources corresponding to the old uuid, you can see that Cocos Creator gives a very detailed warning message in the console. These details include the scene file name, node path, component, uuid, etc. The warning message allows you to quickly locate the error. How is this situation caused exactly? When someone adds a new resource to the project, they forget to switch to the editor interface to generate a meta file, and at the same time submit the new file to version management (without the meta file). Then, another person updates the resources he/she submitted and switches to the editor interface for editing. At this point, Cocos Creator will check that the new resource is generated without a meta file. The meta file is also generated when the first person switches to the editor, so that the two people have the same file on the computer, but the uuid in the generated meta file is different. In this case, those who submit or update resources later will certainly encounter conflicts. If they are unclear, they will forcibly resolve the conflicts, and the problems mentioned above will arise. The following sequence diagram depicts this erroneous workflow: A classmate forgets to submit the meta file to version control. Other classmates then edit the project resulting in everyone having the file on their computer, each with a different uuid. To solve this problem, note the following: When submitting resources, pre-check for new files. If there are new documents, pay attention to whether meta files need to be submitted together. When pulling files, pay attention to whether there are new files, and if there are meta files in pairs. If not, remind team-mates who submitted the files to submit the files and meta files together. When submitting, if you find that there is only one new meta file, then the meta file must have been generated by yourself. You need to pay attention to whether the resource corresponding to the meta file (the file with the same name) has been used. If you haven't used it, please submit the meta file to the first submitter. Never submit this meta file. Note that the above points can basically eliminate the engineering error caused by the meta file uuid change. Summary The meta file is an important tool for Cocos Creator to use for resource management. It is easy to generate resource errors when it is slightly inadvertent in a multi-person collaborative development. To solve this problem, you not only need to understand the mechanism that generates the meta file but also the cause of the conflict. Proper thought and control of resource submission helps too. "},"asset/scene.html":{"url":"asset/scene.html","title":"Scene","keywords":"","body":"Scene Assets In Cocos Creator, the Scene is the cornerstone for organizing game content during development, and presenting all game content to the players. The Scene itself is a file, also considered a game asset, and saves most of the game's information. Creating a Scene There are three ways to create a Scene: Select the folder where you want to create the Scene file in the Assets. On the folder Right click --> New --> Scene file, and then type the desired Scene name. In order to have a good directory structure in your project, it is strongly recommend that you use this method to create a Scene. Click the Create menu in the Assets to create a new Scene. Select File -> New Scene, a new Scene will appear directly in the Hierarchy panel, but a new Scene will not appear in the Assets. You need to save it in the root of the asset folder. A New Scene.scene Scene file appears in the directory. Saving a Scene While creating Scenes, you can quickly save Scenes with the shortcut keys Ctrl + S (Windows) or Command + S (Mac). Switching Scenes In the Assets, double-click the Scene you want to open. When needing to switch Scenes in the game, use the director.loadScene() API to implement dynamic scene loading and switching in the game. For further details, please see the API documentation. Scene Asset Properties Since the Scene is an Asset a property can be set in the Assets to load assets asynchronously. After opening the Scene file, Scene is the root node of the Scene node tree. Select the Scene node in the Hierarchy panel. In the Inspector panel on the left, you can set the properties of the entire Scene, including ambient light settings, shadow settings and sky box settings. For a detailed description of each attribute, see the following documents: Ambient light Shadow Global Fog Skybox "},"asset/image.html":{"url":"asset/image.html","title":"Images","keywords":"","body":"Images Image assets are generally created using image processing software (such as Photoshop, Paint on Windows, etc) and output into file formats that Cocos Creator can use, currently including .jpg and .png. Importing image assets After importing images into Cocos Creator, they can be seen in Assets panel. Types of image assets On the right side of the Inspector panel, you can choose different ways to use the image asset. There are currently 4 ways to use it for developers, as shown below: The details of each type of image asset are described in detail in the following sections: The raw type is the original picture type. It has no effect and users do not need to use it. The texture type is the image asset type, which is also the default type for import. For details, see: Texture normal map type is normal map type The sprite-frame type is a sprite frame asset, which is used for UI production. For details, see: SpriteFrame The texture cube type is a cube map type, which is used on the panorama to make a sky box. For details, see: Sky Box In the Assets panel, a triangle icon similar to a folder will be displayed on the left of the image. Click to expand to see its sub-assets. After each image is imported, the editor will automatically create a selected type asset of the same name. Select the asset itself to change the asset type, set the image flip, and set the quality of the image on each platform. For detailed descriptions of sub-assets, please refer to the Sub-asset Properties Panel documentation. "},"asset/texture.html":{"url":"asset/texture.html","title":"Textures","keywords":"","body":"Texture Map Assets Texture mapping assets are assets used for procedural sampling, such as textures on models and the UI on Sprites. When the UI or model are rendered, the corresponding texture is sampled, then filled on the model grid, plus a series of processing such as lighting to render the entire scene. Texture assets can be generated from ImageAsset. Some common image formats, including .png, .jpeg, etc. can be used in ImageAsset. Texture2D Texture2D is a type of texture asset that is usually used for rendering of 3D models, such as reflection maps, ambient light mask maps, etc. in model materials. Texture2D in Cocos Creator: Note: the texture type is a Texture2D asset. Adjusting the Properties of a Texture2D When importing an ImageAsset, it will be set to Texture2D by default. At this same time, one or more sub-assets will be generated on the original asset. Click the arrow in front of the original asset to see all the sub-assets. Example: After selecting the generated Texture2D sub-asset, you can see the following panel: Sub-Asset Texture2D Properties Panel The following describes the properties of the panel: Property Explanation anisotropy Anisotropy value minFilter Narrowing Filter Algorithm magFilter Magnification Filter Algorithm mipFilter Multi-level texture filtering algorithm wrapS S (U) direction texture addressing mode wrapT T (V) direction texture addressing mode Using Texture2D Texture2D is a very widely used asset. Any property marked as Texture2D in the Inspector panel can be dragged into a Texture2D asset type. The usage scenario is mainly in the Editor environment and for dynamic acquisition: In the Editor, just drag the assets in; For dynamic acquisition, you need to obtain the ImageAsset asset first, and then instantiate the Texture2D asset based on the obtained ImageAsset. TextureCube TextureCube is a cube texture, which can be used to set the scene's Skybox. It can be obtained by setting the panorama ImageAsset to the TextureCube type. It can also be obtained by making CubeMap assets. TextureCube obtained from a panorama in Cocos Creator: TextureCube obtained by making a CubeMap in Cocos Creator: To learn more about the use of TextureCube and CubeMaps, please refer to the Skybox documentation. "},"asset/sprite-frame.html":{"url":"asset/sprite-frame.html","title":"Sprite Frames","keywords":"","body":"Sprite Frame Assets Sprite Frame is a container for UI rendering and basic graphics, which manages the clipping and tiling data on top of a Texture2D asset (by holding a reference to it). Importing Sprite Frame Assets Use the default asset import method to import image assets into the project, then set the type of image as sprite-frame and can then be seen in the Assets panel. Image assets will use thumbnails of their own pictures as icons in the Assets panel. When the image sub-asset is selected in the Assets panel, a thumbnail of the image is displayed below the Inspector panel. Using a Sprite Frame The object contained in the container is using textures In the editor, drag the SpriteFrame asset to the Sprite Frame property of the Sprite component to switch the image displayed by the Sprite. At runtime, taking the content picture in the above picture as an example, The entire asset is divided into image asset (content), its sub-asset (spriteFrame) and sub-asset (texture). The assets in the game package can be obtained by the following methods: Method 1: (load ImageAsset): const self = this; const url = 'test_assets/test_altas/content'; resources.load(url, ImageAsset, (err: any, imageAsset) => { const sprite = this.getComponent(Sprite); const spriteFrame = new SpriteFrame(); const tex = new Texture2D(); tex.image = imageAsset; spriteFrame.texture = tex; sprite.spriteFrame = spriteFrame; }); Method 2: (load SpriteFrame): const self = this; const url = 'test_assets/test_altas/content/spriteFrame'; resources.load(url, SpriteFrame, (err: any, spriteFrame) => { const sprite = this.getComponent(Sprite); sprite.spriteFrame = spriteFrame; }); Assets on the server can only be loaded into ImageAsset. For specific methods, please refer to the dynamic load asset documentation. Cocos Creator will provide a way to package an Image Asset as a SpriteFrame in a later release to make it easier for users to use image assets. The container contains objects that are used by RenderTexture RenderTexture is a rendering texture that renders content from the camera directly to a texture instead of the screen. SpriteFrame can easily display 3D camera content on the UI by managing RenderTexture. Use is as follows: const cameraComp = this.getComponent(Camera); const renderTexture = new RenderTexture(); const size = view.getVisibleSize(); renderTexture.reset({ width: size.width, height: size.height, colorFormat: RenderTexture.PixelFormat.RGBA8888, depthStencilFormat: RenderTexture.DepthStencilFormat.DEPTH_24_STENCIL_8 }); cameraComp.targetTexture = renderTexture; const spriteFrame = new SpriteFrame(); spriteFrame.texture = renderTexture; const sprite = this.getComponent(Sprite); sprite.spriteFrame = spriteFrame; API interface document: SpriteFrame. "},"ui-system/components/engine/trim.html":{"url":"ui-system/components/engine/trim.html","title":"Texture Auto Trim","keywords":"","body":"Auto Trim for SpriteFrame Once a texture is imported, the SpriteFrame asset generated with the texture will be trimmed automatically. Any fully transparent pixels around the image will be cropped. This will help us get the exact node size we need for Sprites. Trim Related Properties in Sprite Component There are two properties related to trim setting in Sprite component: Trim If checked, the node's bounding box will not include transparent pixels around the image. Instead the bounding box will be an exact fit to trimmed image. If unchecked the bounding box will be showing original texture including transparent pixels. Size Mode Use the options in this property to set node's size to the original texture size or trimmed image size. Options are: TRIMMED Select this option will set the size of the node to use trimmed image size of the current SpriteFrame used by Sprite component. RAW Select this option will set the size of the node to use the original texture size, including transparent pixels. CUSTOM This option make sure the size of the node will not be changed along with SpriteFrame, and should be managed by yourself. If you use the Rect Transform Tool to drag and change the size of the node, or modify the size property in Inspector panel, or modify the width or height in the script, the Size Mode property will be automatically set to CUSTOM. The following picture shows the comparison of two size modes: Sprite Animation with offset There are a lot of animator prefer to draw the moving motion in texture, commonly seen in attack animations. Usually animator will use a large texture and put character on different positions on the texture for different animation frames. In this case, we need to set the Sprite component's Trim property to false, and set the Size Mode to RAW. In this way, the animation will use the original texture size when playing each sequence frame, and retain the information of transparent pixels around the image. So that the character's position drawn in the texture can be displayed correctly. When Trim property is set to true, it is more suitable for animation where the displacement is completely controlled by the character's position property. TexturePacker Setting We recommend users to use sprite sheet tools such as TexturePacker for generating sprite animation texture assets. In TexturePacker before you publish your sprite sheet, please make sure you choose Trim in Trim Mode setting of Sprites section. Please do not use Crop, flush position, or the trim information will be lost and you can't get back originial texture offset anymore. It is currently recommended to use version 4.x or higher for packaging to prevent the import failure caused by inconsistent export data in the lower version. "},"asset/compress-texture.html":{"url":"asset/compress-texture.html","title":"Compressed textures","keywords":"","body":"Compress texture Cocos Creator 3.0 can set the compression method required for textures directly in the editor, and then automatically compress the textures when the project is released. For the web platform, multiple image formats can be exported at the same time, and the engine will automatically download the appropriate format according to different browsers. Configure compressed texture Cocos Creator 3.0 supports importing images in multiple formats (see the table below for details), but in an actual running game, we do not recommend using the original images as assets to load. For example, on a mobile platform, only 80% or less of the original image quality may be required, or a .png without the transparent channel can be converted into a .jpg, which can reduce the storage space required. Image format Android iOS Mini Game Web Mac & Windows PNG Supported Supported Supported Supported Supported JPG Supported Supported Supported Supported Supported WEBP Native Supported for Android 4.0+Other versions can use this library can use this library Supported Partially Supported Not Supported PVR Not Supported Supported Supported iOS Supported iOS Mac Supported ETC1 Supported Not Supported Supported Android Supported Android Not Supported ETC2 Partially Supported Not Supported Not Supported Supported Android Not Supported ASTC Partially Supported Partially Supported Not Supported Partially Supported Mac Supported By default, Cocos Creator 3.0 outputs the original image during build. If you need to compress an image during the build process, you can select this image in the Assets panel and then manage it in the Inspector to edit the compress texture format of the image. The editor will provide a preset by default. If you need to add more presets, you can click the Edit preset button to open Project Settings -> Compress Texture to add and edit presets. The compression format here is readonly. For how to add texture compression presets, please refer to the Project Settings documentation. The compress-texture options on the image asset will be stored in the asset's meta file. PresetId is the ID of the selected compressed texture preset. Detailed compression textures If you want to use compressed textures, you need to turn on the compressed texture option when you build the project: When Cocos Creator 3.0 builds the image, it will find whether the current image has been already configured to use compressed textures. If not, it will output the original image. If the configuration of the compressed texture is founded, the image will be compressed according to the configuration.The compress texture configuration in the project settings is divided into different platforms, and the support of in the actual platform is also difference. builder will make certain elimination and priority selection of the configured texture format according to the actual build platformand the current image texture transparency channel. You can refer to the following example to understand this rule. Multiple texture formats can be specified on one platform, and each texture format is compressed to generate an image of the specified format when it is constructed. These generated images will not all be loaded into the engine during runtime, the engine will choose to load the appropriate image according to the configuration in macro.SUPPORT_TEXTURE_FORMATS. macro.SUPPORT_TEXTURE_FORMATS enumerates all the image formats supported by the current platform. When the engine loads the images, it will find, from the generated images in this list, the format with the highest priority (that is, the order is higher) to load. The user can customize the supported image assets for a platform and the priority of the loading order, by modifying macro.SUPPORT_TEXTURE_FORMATS. Example Example (1): As the compress presets of the MiniGame platform shown in the figure, if the build target is Huawei Quick Game, Builder will not package the PVR texture format. For more details about the support of platforms, please refer to Details of compressed texture support for platforms Example (2): In the example picture above, both ETC1 and PVR types are configured with RGB and RGBA two types of texture formats. In this case, Builder will be according to whether the current picture has a transparent channel to choose one of the same types of formats. The image asset in the example is with a transparent channel, then Builder will only pack a compressed texture format with REGA type. Of course, if there is only RGB picture format in the configuration, even if the current picture is with a transparent channel, it will be packaged normally. Details of compressed texture support for platforms Except for the JPG and PNG supported by all platforms, the details of other formats are as follows: Platform TextureCompressTypes Web Desktop ASTC / ETC2 / ETC1 / PVR / WEBP Web Mobile ASTC / ETC2 / ETC1 / PVR / WEBP WeChat Game ETC1 / PVR AliPay Mini Game ETC1 / PVR Baidu Mini Game ETC1 / PVR OPPO Mini Game ETC1 vivo Mini Game ETC1 Huawei Quick Game ETC1 Cocos Play ETC1 Xiaomi Quick Game ETC1 iOS ASTC / PVR / WEBP Android ASTC / ETC2 / ETC1 / WEBP Mac ASTC / PVR "},"asset/atlas.html":{"url":"asset/atlas.html","title":"Atlas","keywords":"","body":"Atlas assets Atlas, also called a Sprite Sheet, is a common art asset in game development. Atlas is an asset for merging multiple pictures into a large picture through a special tool, and indexing through a file such as a .plist. Atlas assets available for Cocos Creator consist of a .plist and at least one .png file, although usually many .png files make up an Atlas. The following is an image file used in an Atlas: Why use atlas assets In a game, using an Atlas composed of multiple pictures as art assets has the following advantages: The blank area around each picture will be removed when synthesizing the Atlas, plus various optimization algorithms can be implemented as a whole. After synthesizing the Atlas, the game package and memory consumption can be greatly reduced. When multiple Sprites are rendering pictures from the same atlas, these Sprites can be processed using the same rendering batch, which greatly reduces the CPU's computing time and improves operating efficiency. For a more comprehensive explanation, you can watch a teaching video: What is a Sprite Sheet from CodeAndWeb. Atlas Assets To generate an Atlas, you should first prepare a set of original pictures. Example: Next, use special software to generate the Atlas. Examples: TexturePacker 4.x Zwoptex When using these software packages to generate an Atlas, please select a .plist file in Cocos2d-x format. The resulting Atlas files are a .plist and .png with the same name. Example: myAtlas.plist and myAtlas.png. When using TexturePacker software, please note that use v4.x only, v3.x and below is not supported. Importing Atlas Assets Drag the .plist and the .png files shown above into the Assets panel at the same time. You can generate Atlas assets that can be used in the editor and scripts. Atlas and SpriteFrame In the Image Resource Document, the relationship between Texture and SpriteFrame was introduced. After importing the Atlas, we can see that the Atlas is of type Atlas and can be expanded by clicking the triangle icon on the left. After expanding, we can see that the Atlas contains many sub-assets of type SpriteFrame. Assets are pictures that can be used and referenced individually. The use of the Sprite Frame is the same as that described in the image asset. Please refer to the related documents. "},"asset/auto-atlas.html":{"url":"asset/auto-atlas.html","title":"Auto Atlas","keywords":"","body":"Auto Atlas Auto Atlas Assets is the picture-combining method that comes as part of Cocos Creator. You can pack a specified series of images into a sprite sheet. This capability is very similar to the function of Texture Packer. Creating Auto Atlas Assets Right-click in the Assets panel, select New -> Auto Atlas Configuration in the menu. Selecting this option will create a new asset similar to AutoAtlas.pac. AutoAtlas will pack all SpriteFrame assets in the same folder into a big Sprite Atlas asset during the build process. We might add other ways to choose assets for packing in the future. If the original SpriteFrame asset have been configured, then all configurations will be preserved. Configuring Auto Atlas Assets After selecting an Auto Atlas Resource in the Assets panel, the Inspector panel will display all of the configurable items for the Auto Atlas Resource. Property Functional Description Maximum Width Single Atlas Maximum Width Maximum Height Maximum Height of a Single Atlas Spacing Spacing between shreds in the atlas Allow Rotation Whether Rotate Fragments Output size is square Whether to force the size of the atlas to be square The output size is a power of two Whether to set the size of the atlas to a multiple of a square Algorithm Atlas packaging strategy, currently only one option Output format Atlas image generation format, the available formats are [png, jpg, webp...] Expand the edge Expand a pixel outer frame outside the border of the broken image, and copy the adjacent broken image pixels to the outer frame. This feature is also called \"Extrude\". Does not include unreferenced assets In preview, this option will not take effect, this option will take effect after building After the configuration is complete, you can click the Preview button to preview the packaged results. The related results generated according to the current automatic atlas configuration will be displayed in the area below the Properties Inspector. Please note that after each configuration, you can re-click Preview to update the preview image. (Generating a preview is not required). The results are divided into: Packed Textures: Display the packaged atlas pictures and picture-related information. If there are multiple pictures to be generated, they will be listed below in the Inspector panel. Unpacked Textures: Display the broken image assets that cannot be packed into the atlas. The cause may be that the size of these broken image assets is larger than the size of the atlas assets. At this time, the configuration or fragmentation of the following atlas may need to be adjusted. The size of the figure is increased. Generating an Atlas When inside the editor or previewing the project Cocos Creator is directly using the split SpriteFrame assets, only after you build the project with the option AutoAtlas enabled, the Atlas asset will be generated and be used instead of all split assets. In general, after Atlas asset is generated, the Texture2D assets and Image assets related by the original split assets will be deleted in the package. The following two special cases will have special process: When Atlas asset is in a resources directory, the Texture2D assets and Image assets related by the original SpriteFrame assets in the AutoAtlas asset's directory will also be generated. When any Texture2D asset depended by SpriteFrame assets in the Atlas asset's folder is directly used by another asset, the dependent Texture2D asset and Image asset will also be generated. The two situations above will increase the package size, please do not use an Atlas like this unless necessary, Builder will also produce a console warning to prompt you to consider your package size. "},"asset/label-atlas.html":{"url":"asset/label-atlas.html","title":"Label Atlas","keywords":"","body":"LabelAtlas Asset LabelAtlas asset is a user-defined asset, it's used for configuring a LabelAtlas. Create LabelAtlas Asset In the Assets panel right-click on a folder, and click the context menu item Create -> Label Atlas. It will create a LabelAtlas.labelatlas asset. Before using the LabelAtlas asset, it needs some configuration. Configure a pre-drawn picture that contains the font style, as shown below: Configuration of LabelAtlas asset After selecting a LabelAtlas asset in the Assets panel, the Inspector panel will display all configurable properties for the LabelAtlas asset. Properties Description SpriteFrame Specify a pre-drawn picture that contains the font style you want Item Width Specify the width of each character Item Height Specify the height of each character Start Char Specify the start char, even if the start char is a space, you also need insert a space. When the configuration is complete, click the tick button at the top right of the Inspector panel to save the settings. Using LabelAtlas asset It's quite simple to use the LabelAtlas asset. You just need setup a new Label component and drag the LabelAtlas asset to the Font attribute of the Label component. Please refer to the Label Component documentation for details. "},"asset/render-texture.html":{"url":"asset/render-texture.html","title":"Render-texture","keywords":"","body":"RenderTexture A rendered texture is a texture on the GPU. Usually, we set it to the camera's target texture, so that the content illuminated by the camera is drawn to the texture through the frambuffer off the screen. Using RenderTexture // Method 1: Draw the content illuminated by the 3D camera // onto the UI sprite frame export class CaptureToWeb extends Component { @property(Sprite) sprite: Sprite = null; @property(Camera) camera: Camera = null; protected _renderTex: RenderTexture = null; start () { const spriteframe = this.sprite.spriteFrame; const sp = new SpriteFrame(); sp.reset({ originalSize: spriteframe.getOriginalSize(), rect: spriteframe.getRect(), offset: spriteframe.getOffset(), isRotate: spriteframe.isRotated(), borderTop: spriteframe.insetTop, borderLeft: spriteframe.insetLeft, borderBottom: spriteframe.insetBottom, borderRight: spriteframe.insetRight, }); const rendetTex = this._renderTex = new RenderTexture(); rendetTex.reset({ width: 256, height: 256, colorFormat: RenderTexture.PixelFormat.RGBA8888, depthStencilFormat: RenderTexture.DepthStencilFormat.DEPTH_24_STENCIL_8 }); this.camera.targetTexture = rendetTex; sp.texture = rendetTex; this.sprite.spriteFrame = sp; } } // Method 2: Draw the content illuminated by the 3D camera onto the 3D model export class RenderCameraToModel extends Component { @property(MeshRenderer) model: MeshRenderer = null; start () { // Your initialization goes here. const renderTex = new RenderTexture(); renderTex.reset({ width: 256, height: 256, colorFormat: RenderTexture.PixelFormat.RGBA8888, depthStencilFormat: RenderTexture.DepthStencilFormat.DEPTH_24_STENCIL_8, }); const cameraComp = this.getComponent(Camera); cameraComp.targetTexture = renderTex; const pass = this.model.material.passes[0]; const binding = pass.getBinding('mainTexture'); pass.bindTextureView(binding, renderTex.getGFXTextureView()); } } For more Render Texture examples, please see these test casees. "},"asset/prefab.html":{"url":"asset/prefab.html","title":"Prefab","keywords":"","body":"Prefab Prefab is used to store some scene objects that can be reused, it can contain nodes, components, and data in components. The instances generated by the prefab asset can not only inherit the data of the template, but also have it's own customized data modification. Basic Concepts Name Description Example Prefab Asset The asset of prefab in Assets panel, which is the serialize file of Prefab. Prefab Instance When the Prefab Asset is drag to the Hierarchy panel, it will generate a Prefab Instance.Its root node is currently marked in bright green, and its child nodes are dark green Prefab Editing Mode Double-click the Prefab Asset to enter the prefab editing mode. At this time, all non-nested prefab nodes are displayed in dark green Nested Prefab Instance When a child node in a Prefab Asset is an instance of another Prefab Asset, we call this child prefab a nested prefab instance Creating a Prefab After editing the Node in the Scene, drag the Nodes directly from the Hierarchy panel to the Assets panel to complete the creation of the Prefab. After the creation is complete, the original Node will automatically become a Prefab Instance, its root node is currently marked in bright green, and its child nodes are dark green. Using Prefabs Drag a Prefab Asset from the Assets panel to the Hierarchy panel or Scene panel to create a Prefab Node in the Scene. In the Scene, the Prefab Instance objects data source comes from the deserialization of the Prefab Asset , so its data is synchronized with the Prefab Asset by default. If the attributes in the prefab instance are modified, the modified data will be stored In the Prefab Instance, it will not affect the Prefab Asset and the data of other Prefab Instance generated by it. Entering prefab editing mode Double-click the Prefab Asset in the Assets panel to switch from Scene editing mode to Prefab editing mode. You can edit the Prefab Assets in the Editor. After editing, click Save button in the Scene panel to save the edited Prefab Assets. Next, click Close button to return to the Scene editing mode. Status of prefab nodes Prefab Nodes in the Inspector panel render green to indicate normal association with assets and render red to indicate that the associated assets no longer exist. Editing Prefab Nodes in a Scene General Operations In the Hierarchy panel, select the Prefab Node, and notice there are several buttons that can be clicked at the top of the Inspector panel: Icon Description Revert to normal node. Prefab Instance can become ordinary Nodes, that is, completely separated from the relationship between assets. This function is also available in the top-level menu Node. Locating assets.Its convenient to quickly locate Prefab Asset in the Assets panel. Restore from asset. Restore the data of the current Prefab Instance to the data in the Prefab Asset, but the name, location, and rotation will not be restored. Update to asset. Update all data of the current Prefab Instance to the associated Prefab Asset. Add New Node A new node added under the Prefab Instance will have a + sign in the lower right corner of the node name., and its data is stored under the Prefab Instance, so it will not affect the data of the associated Prefab Asset. Some Current Restrictions Add/remove components in the Prefab Instance Delete the node created from the Prefab Asset in the Prefab Instance Change the hierarchical relationship of nodes created from the Prefab Asset in the Prefab Instance Do not allow prefabs to nest themselves "},"asset/script.html":{"url":"asset/script.html","title":"Scripting","keywords":"","body":"Script Assets In Cocos Creator, scripts are also part of the Asset. For a detailed introduction to scripting, please refer to the Scripting Guide documentation. For details on the creation and use of script assets, please refer to the Script Creation documentation. "},"asset/font.html":{"url":"asset/font.html","title":"Fonts","keywords":"","body":"Fontss There are three types of font assets available to games made with Cocos Creator: system fonts, dynamic fonts, and bitmap fonts. The system font renders text by calling the system font that comes with the game running platform, and does not require the user to add any related assets to the project. To use system fonts, use the Use System Font property in the Label documentation. Importing font assets Dynamic fonts Cocos Creator currently supports dynamic fonts in True Type format. Simply drag a font file with an extension of .ttf into the Assets panel, and you can import the font asset. Bitmap fonts The bitmap font is composed of a font file in .fnt format and a .png image. The .fnt file provides an index of each character thumbnail. Fonts in this format can be generated by specialized software, please refer to: Glyph Designer Hiero BMFont (Windows) When importing bitmap fonts, be sure to drag both the .fnt file and the .png file into the Assets panel at the same time. Note: after importing the bitmap font, you need to change the type of the .png file to sprite-frame, otherwise the bitmap font will not work properly. The imported fonts are displayed in the Assets panel, as follows: Note: in order to improve the efficiency of asset management, it is recommended that the imported .fnt and .png files be stored in separate directories and not mixed with other assets. Using font assets The font asset needs to be rendered through the Label component. Here is how to create a Node with a Label component in the scene. Creating a Label (Font) Node Using the Menu Click on the Create Node button in the upper left corner of the Hierarchy panel and select Create Render Node --> Label (Text), and a component with Label will be created in the Scene node. You can also complete the creation through Node --> Create Render Node --> Label (Text) of the main menu, the effect is the same as the above method. Associated Font Assets The font components created using the above method use the system font as the associated asset, by default. If you want to use a TTF or bitmap fonts in the project, you can drag your font assets to the created Label component. At this time, the font used in a scene will be immediately rendered using the font asset specified. You can also freely switch the Font property of the same Label component to use TTF or bitmap fonts according to the needs of the project. When switching font files, other properties of the Label component are not affected. If you want to restore the use of system fonts, you can click the property check box of Use System Font to clear the font file specified in the Font property. Dragging and droping to create a Label node Another quick way to create font nodes using specified assets is to directly drag and drop font files, either TTF or bitmap fonts, from the Assets panel into the Hierarchy panel. The only difference from the menu created above is that text nodes created using drag and drop will automatically use the dragged font asset to set the Font property of the Label component. "},"asset/audio.html":{"url":"asset/audio.html","title":"Audio","keywords":"","body":"Audio Sound assets are audio files. An audio system has two main functions: playing background music and playing short sound effects. For sound assets, there is no difference between the two. After all, audio assets are imported into the editor, AudioClip assets perform related audio operations through the AudioSource system component. To use the audio system, please refer to the Audio System documentation. Supported audio asset formats Currently, the engine's audio system can support the following formats: .ogg .mp3 .wav .mp4 .m4a Loading Modes of Audio Resources on the Web Platform Audio resources on the Web platform are special because the Web standard supports loading audio resources in two different ways as follows: Web Audio: provides a relatively more modern audio control interface, and the audio resource is cached in the engine as an audio buffer. The advantage of this approach is good compatibility and robust. DOM Audio: plays the sound resource by generating a standard audio element, which is cached. When using the standard audio element to play audio resources, some compatibility issues may be encountered in some browsers. For example, browsers on iOS do not support setting volume, and all volume related properties will not be available. The engine currently tries to load audio resources as Web Audio by default. If it detects that the browser does not support loading Web Audio, it will fall back to the DOM Audio mode. If the project needs to force using DOM Audio mode, use the following to load the audio resources dynamically: assetManager.loadRemote('http://example.com/background.mp3', { audioLoadMode: AudioClip.AudioType.DOM_AUDIO, }, callback); "},"asset/material.html":{"url":"asset/material.html","title":"Material","keywords":"","body":"Material assets Material creation Material is created as follows: or The Material controls the final shading of each model. The Material is composed of Effects, and the shading process of an Effect is controlled by the Material. The Material itself can also be regarded as a container of Effect assets. The Material can switch the Effect assets to be used at will. The following figure is the Effect asset of the Material we have selected by default. At the same time, we can also switch the Effect of the current Material by clicking the box to the right of the Effect property. Effect Creation Effects are created in a similar way to Materials. The created Effect is a PBR Effect by default. "},"asset/mesh.html":{"url":"asset/mesh.html","title":"Mesh","keywords":"","body":"Model assets Currently, model files in FBX and glTF formats. For how to export these two model files from third-party tools, you can refer to the DCC Export Mesh documentation. Model importing After importing into the editor, from the outside, the corresponding model asset file can be obtained in the Assets panel. It's directory structure is as follows: The structure of a model file without animations is as follows: The structure of the model file that contains animations is as follows: .material -- Material files .mesh -- Model files .texture -- Model texture files .animation -- Model animation files .skeleton -- Model bone files .prefab -- Prefab files that are automatically generated on import Using Models After importing a model file, drag the root node of the model file directly from the Assets panel to the node you want to place in the Hierarchy panel to complete the node creation. At this point the model is successfully created in the scene. Alternatively, you can expand the node of the model file, select the .prefab file under the model file node, and drag it from the Assets panel into the Hierarchy panel to complete the creation. Model asset Properties panel description When the model asset file (.fbx or .gltf) is selected in the Assets panel, the properties of the model asset can be set in the Inspector panel. Model module Normals -- Normals information, including Optional, Exclude, Require, Recalculate Tangents -- Tangents information, including Optional, Exclude, Require, Recalculate SkipValidation -- SkipValidation, whether to skip standard checks Animation Module The above image is all the animation asset information under the current model, and the editing area of ​​the specific frame number information of the currently selected animation. You can change the animation name or perform simple animation cropping here. To do so: Click the + button in the red box on the image to add an animation clip asset. The new file added by default copies a complete clip data. You can input the number of frames in the Start and End input box to crop the animation. (Drag and drop animation is not currently supported) Click the - button in the red box on the image to delete the currently selected animation file Material module DumpMaterial: When you are not satisfied with the material that comes with the model file and want to modify it, you need to enable this option to dump the material files in the file structure directory out of the model assets. You can adjust and modify the materials. Dumper Directory: Here you can specify or view the directory location for the dumped files. "},"asset/anim.html":{"url":"asset/anim.html","title":"Animation assets","keywords":"","body":"Animation assets Editor Custom Animation For creating custom animations in the Cocos Creator editor, please refer to the Animation Creation documentation. Information about the Format is also important to understand. Bone animations attached after a model import After a model with animations is imported, the animation on the corresponding model will be generated. The imported animations can be used in the same way as those created in editor. For cutting a skeletal animation, please refer to Introduction of Animation Modules for Model Assets documentation. "},"editor/extension/readme.html":{"url":"editor/extension/readme.html","title":"Extended Editor","keywords":"","body":"Extending the editor This chapter focuses on extending the editor. The First Extension Install And Share Extension Description Extended Panel Compose Panel Panel Message Communication with the panel Contributions Message Shortcuts Menu Basic Extension Message I18n Profile Editor UI "},"editor/extension/first.html":{"url":"editor/extension/first.html","title":"The First Extension","keywords":"","body":"First Extension Through this article, we will learn to create a Cocos Creator extension and execute a custom script through the extension. Creating and Installing Extensions First, find the folder ~/.CocosCreator/extensions (Mac) or C:\\Users\\${your user name}\\.CocosCreator\\extensions (Windows) in the global directory, or the ${your project path}/extensions folder. If the extensions folder does not exist, create a new one. Second, create an empty folder inside the extensions folder named hello-world. Third, create two files browser.js and package.json in the folder. These files will be empty. Use any text editor to create these files or on MacOS use touch browser.js and touch package.json from a command prompt. The structure of the directory where the extension is located should be the following: hello-world |--browser.js |--package.json Define the Description File package.json Every extension needs a package.json file to describe the purpose of the extension. Only after the description file package.json is fully defined, can Cocos Creator 3.0 know the specific functions defined in this extension, loading entry and other information. Although the definition of many fields in package.json is similar to that of node.js's npm package, they are obviously customized for different products and services. The npm module downloaded from the npm community cannot be directly put into Cocos Creator 3.0 to become an extension, but one can use the modules in the npm community in the Cocos Creator 3.0 extension. To continue creating an extension, fill in the content in the newly created package.json file: { \"name\": \"hello-world\", \"version\": \"1.0.0\", \"main\": \"./browser.js\", \"description\": \"A simple extension\", \"contributions\": { \"menu\": [{ \"path\": \"Develop\", \"label\": \"test\", \"message\": \"log\" }], \"messages\": { \"log\": { \"methods\": [\"log\"] } } } } The meanings of the fields are as follows: name String -- Defines the package name, which is globally unique and relates to the login name on the official website server in the future. Note: if the plugin will be uploaded to the Cocos Store, there are certain restrictions on the package name. The name only allows lowercase letters, numbers, hyphens (-), underscores (_), dots (.), and begin with a lowercase letter or number. version String -- The version number. We recommend using the semver standard to manage your package versions. main String (optional) -- The entry file description String (optional) -- Describe your package in one sentence. contributions Object (optional) -- Configuration objects that extend the existing functionality of the editor. Next, it is necessary to define a messages object in contributions, which is the method of editor message registration. This message can be bound to one or more methods defined in the extension. For more definition data, please refer to the Message documentation. Next, define a menu array in contributions to provide basic information of a menu to the menu component. Finally, bind this menu to a message. For more details, please refer to the Menu documentation. Careful that after the menu is pressed, the triggered action is notified by the message between the extensions, and the message system is the way of interaction between the extensions. For a detailed package.json format definition, please refer to the Extension documentation. Entry program browser.js After defining the description file, the next step is to write the entry program browser.js. The content is as follows: 'use strict'; // The method defined in the extension exports.methods = { log() { console.log('Hello World'); }, }; // Execute when the extension is started exports.load = function() {}; // Execute when the extension is closed exports.unload = function() {}; This entry program will be loaded during the startup of Cocos Creator. The methods defined in methods will be used as the operation interface, which can be called across extensions through messages or communicate with the panel. Runing an extension First, open Cocos Creator 3.0, find and open the Extension -> Extension Manager at the top, and select the extension location (global or project) on the panel. Second, find the Refresh button at the top and click to manually update the extended list information at that location. Then the extension list will show the extensions that have been found. Extensions can be started, closed, or restarted from the list control. If the extension has been started, a Develop menu will appear in the top menu area with a tester menu item. After clicking, the message will be triggered according to the definition, and the corresponding method in the extension will be executed according to the message definition, and then the log information of Hello World will be printed out on the console. "},"editor/extension/install.html":{"url":"editor/extension/install.html","title":"Install And Share","keywords":"","body":"Installation and Sharing Cocos Creator will search for and automatically load extensions in both Global and Project extension package paths during project startup. If you want to apply the extension to all projects, you can put the extension package under the Global path: Windows: %USERPROFILE%\\.CocosCreator\\extensions Mac: $HOME/.CocosCreator/extensions If you only want to apply the extension to the specified project, you can put the extension package under the Project path: $Your project address/extensions Package Extension After writing an extension, if you want to share the extension with others, you need to compress the extension package. For example, the directory structure of the extension package hello-world, if placed in the project extension package path, is as follows: MyProject |--assets |--extensions |--hello-world |--package.json |--browser.js ... Select all the internal files for hello-world (package.json and browser.js), and compress all the files into a zip file named hello-world.zip. The content format of the hello-world.zip is the same as the file format of hello-world. hello-world.zip |--package.json |--browser.js Please be careful not to nest another layer of extension directory inside the zip package Install Extension First, click Extension -> Extension Manager in the top menu bar of the editor to open the Extension Manager panel. Then select the Project/Global tab in the Extension Manager, click the + button, select the packaged extension .zip file in the pop-up file selection window, and click Open. The imported extension .zip file will be unpacked and placed in the specified location (Project/Global extensions path). Finally, find the extension in the Project/Global tab of the Extension Manager panel, click the Enable button on the right, and the extension you just imported will run normally. Uninstall the Installed Extension Find the extension that needs to be deleted in the Extension Manager panel, click the \"Delete\" icon button, and the folder where the extension is located will be deleted as well. If you only need to disable the extension, you can just select the \"Disable\" button on the right. Overload Extension During the development process, sometimes it is necessary to modify the content of the extension, but after the modification, the logic of the extension will not be automatically updated. At this point it is necessary to reload the extension manually in the editor. Find the corresponding extension in the Extension Manager panel and click the \"Reload\" icon button, and the extension in the editor will be re-run with the latest code and files. "},"editor/extension/define.html":{"url":"editor/extension/define.html","title":"Extension Description","keywords":"","body":"Definition of extension The extension package needs to be pre-defined with some basic information that needs to be filled in and stored in the package.json file. { \"name\": \"hello-world\", \"version\": \"1.0.0\", \"author\": \"Creator\", \"description\": \"description\", \"main\": \"./browser.js\", \"panels\": { \"default\": { ... }, \"list\": { ... } }, \"contributions\": {} } name Type: {string} Required The name of the extension, this name needs to correspond to the extension folder one-to-one. version Type {string} Required The version number of the extension is used to submit the version verification of the extension, as well as some upgrades of the extension itself, and the data migration is used as the basis for comparison. author Type {string} Optional The name of the extension author will be displayed in the Extension Manager. description Type {string} Optional The description of the extension, briefly summarize the function of the extension. Support i18n:key grammar. main Type {string} Optional The relative path of a js file defines the function entry file. When the extension starts, the JavaScript file pointed to by the main field will be executed, and the corresponding method will be triggered or executed according to the process. panels Type {[name: string]: PanelInfo} Optional Panel information defined in the extension. Use Editor.Panel.open('hello-world.list'); to open the defined panel. For more information, please refer to the Panel documentation. contributions Type {[name: string]: any} Optional Extend existing functions, and customize some other function modules that are open to the outside world. For more information, please refer to the Contributions documentation. "},"editor/extension/panel.html":{"url":"editor/extension/panel.html","title":"Extended Panel","keywords":"","body":"Extension panel When implementing a function, it is likely to require UI interaction on the interface. Cocos Creator also provides this ability for extensions. Declare the panel in the extension The panels field can be defined in package.json. Example: { \"name\": \"hello-world\", \"panels\": { \"default\": { \"title\": \"world panel\", \"type\": \"dockable\", \"main\": \"./panels/default.js\", \"icon\": \"./static/default.png\" }, \"list\": { \"title\": \"world list\", \"type\": \"simple\", \"main\": \"./panels/list.js\", \"icon\": \"./static/list.png\", \"flags\": {}, \"size\": {} } } } This field is an object, defined as the following: // panels definition interface PanelMap { [name: string]: PanelInfo; } // The definition of each panel interface PanelInfo { // Panel title, supports i18n:key format title: string; // Panel entry, a relative path main: string; // Panel icon, a relative path icon?: string; // Panel type, default dockable type?:'dockable' |'simple'; flags?: PanelFlags; size?: PanelSize; } // Some tags in the panel interface PanelFlags { // Whether to allow zoom, default true resizable?: boolean; // Need to save, default false save?: boolean; } // Some size limitations of panel interface PanelSize { width?: number; height?: number; 'min-width'?: number; 'min-height'?: number; } Panel The panel entry file was defined above when we registered it. Example: // Listen for panel events exports.linsteners = { // The hook triggered when the panel is displayed show() {}, // The hook triggered when the panel is hidden hide() {}, }; // The contents of the panel exports.template = 'Hello'; // Styles on the panel exports.style = 'div { color: yellow; }'; // Quick selector exports.$ = { elem: 'div', }; // The hook function that is triggered when the panel starts exports.ready = function() { this.$.elem.innerHTML = 'Hello World'; }; // A function that fires when the panel is ready to close, and returns false terminates the panel exports.beforeClose = function() {}; // The hook function after the panel is closed exports.close = function() {}; In addition, we have defined a list panel, and we also need to write a list.js file in the above format. "},"editor/extension/panel-boot.html":{"url":"editor/extension/panel-boot.html","title":"Compose Panel","keywords":"","body":"Creating a Custom Panel How a compose panel is defnined can be found by reading the package.json documentation. Identify the main entry file in the panel definition and fill in its content. Example: 'use strict'; // html text exports.template =''; // style text exports.style =''; // html selector after rendering exports.$ = {}; // method on the panel exports.methods = {}; // event triggered on the panel exports.listeners = {}; // Triggered when the panel is rendered successfully exports.ready = async function() {}; // Triggered when trying to close the panel exports.beforeClose = async function() {}; // Triggered when the panel is actually closed exports.close = async function() {}; Template An HTML string. Example: exports.template = ` Header Section `; It is possible to read an HTML file directly. Example: const {readFileSync} = require('fs'); const {join} = require('path'); exports.template = readFileSync(join(__dirname,'../static/default.html'),'utf8'); The template is defined, when the panel is opened, the content of the template will be automatically rendered on the interface. In addition, the editor also provides some custom elements, please refer to the UI documentation. Style With HTML, it is possible to customize some styles. Style is a string style template. Example: exports.style = ` header {padding: 10px;} `; It is also posible to read a CSS file directly. Example: const {readFileSync} = require('fs'); const {join} = require('path'); exports.template = readFileSync(join(__dirname,'../static/default.css'),'utf8'); $ This is an HTML element selector, directly call querySelector to find the specified element and use it as a shortcut. Example: exports.$ = { header:'header', test:'.test', }; First, define the selector. After the template is rendered, the editor will automatically call document.querySelector to find the corresponding element and hang it on this.$. Example: exports.ready = function() { console.log(this.$.header); // console.log(this.$.test); // } Methods The method defined on the panel. The external functions of the panel need to be encapsulated into methods and provided externally in units of functions. Messages can also directly trigger the methods on the panel. For details, please refer to the Message Communication documentation. This object is full of functions, do not attach other types of objects here. Example: exports.methods = { open() { Editor.Panel.open('hello-world'); }, }; Listeners After the basic layout is completed, it is sometimes necessary to update the status on some panels according to some situations. It is necessary to use the listeners function. Example: exports.listeners = { /** * Triggered when the panel is hidden */ hide() { console.log(this.hidden); }, /** * Triggered when the panel is displayed */ show() { console.log(this.hidden); }, /** * Triggered when the panel size changes */ resize() { console.log(this.clientHeight); console.log(this.clientWidth); }, }; beforeClose When the panel tries to be closed, this function will be triggered. BeforeClose can be an async function that can be used for asynchronous judgment. If it returns false, the current closing operation will be terminated. Do not execute the actual destruction and close-related logic code in this function. This step is just for inquiry. Please put the actual destruction in the close function. Note: please use with caution, if the judgment is wrong, the editor or panel window may not close normally. Close When all the panels in the window are allowed to be closed, the panel close will be triggered. Once the close is triggered, the window will be forcibly closed after the end, please save the data in the close. If an abnormal close occurs, please make a backup of the data in order to restore data as much as possible when restarting. "},"editor/extension/panel-messages.html":{"url":"editor/extension/panel-messages.html","title":"Panel Message","keywords":"","body":"Panel and extension communication Some useful tools or simple functions can be written directly on the panel, but the panel is not a reliable data storage location. The window may be closed at any time, and the panel will also be closed. The most common example is that a panel is dragged and docked to the main window. At this time, the panel will be closed first and then reopened in the main window. If the data in the memory used on the panel is not stored and backed up, it will be lost with restart. At this time, a certain degree of data interaction is required with the extended main body. Before reading this chapter, please review the Message System documentation. Define the method of extending the top and panel First, define a package.json: { \"name\": \"hello-world\", \"main\": \"./browser.js\", \"panels\": { \"default\": { \"title\": \"hw\", \"main\": \"./panel.js\" } }, \"contributions\": { \"messages\": { \"upload\": { \"methods\": [\"saveData\"] }, \"query\": { \"methods\": [\"queryData\"] } } } } Second, define the extended main file browser.js: exports.methods = { saveData(path, data) { // Cache it after receiving the data this.cache[path] = data; }, queryData(path) { const result = this.cache[path]; delete this.cache[path]; return result; }, }; exports.load = function() {}; exports.unload = function() {}; Last, define the main file of the panel: exports.ready = async () => { const tab = await Editor.Message.request('hello-world', 'query', 'tab'); const subTab = await Editor.Message.request('hello-world', 'query', 'subTab'); // Print the queried data console.log(tab, subTab): // TODO uses these two data to initialize }; exports.close() { // Upload the data to the extension process after receiving the data Editor.Message.send('hello-world', 'upload', 'tab', 1); Editor.Message.send('hello-world', 'upload', 'subTab', 0); }; Send a message After defining the extension and the panels in the extension, we can try to trigger these messages. Press ctrl(cmd) + shift + i to open the console. Open the panel in the console: // Default can be omitted, if the panel name is not default, you need to fill in'hello-world.xxx' Editor.Panel.open('hello-world'); After opening the panel, the console will print out a sentence: undefined, undefined This is because the data has not yet been submitted. Now, close this panel and open it again. At this time, the console prints out the data: 1, 0 Because when the panel is closed, two messages are sent: Editor.Message.send('hello-world', 'upload', 'tab', 1); Editor.Message.send('hello-world', 'upload', 'subTab', 0); Through these two messages, the Message system first saves the data to the extension process according to the upload definition in messages \"methods\": [\"saveData\"]. When opening the panel again, use the following code to query for the data you just saved, initialize the interface, and print to the console. const tab = await Editor.Message.send('hello-world', 'query', 'tab'); const subTab = await Editor.Message.send('hello-world', 'query', 'subTab'); At this point, we have completed an interaction between the panel and the extension process. "},"editor/extension/contributions.html":{"url":"editor/extension/contributions.html","title":"Contributions","keywords":"","body":"Extend existing functionality Cocos Creator supports contributions between extensions. When we are writing an extension, we can query whether the existing functions in the editor provide the function of receiving external contributions. If the function provides contributions function, use these functions when writing extensions. Contribution data definition In package.json the contribution field can be defined. { \"name\": \"hello-world\", \"contributions\": {} } contributions definition: interface contributions { [name: string]: any; } The name is the name of the function or extension, and the value is of any type, which is defined by the author of the name function (extension). At this stage, only contributions to the internal functions of the editor are opened. In the future, we will provide the ability to use contributions between extensions. "},"editor/extension/contributions-messages.html":{"url":"editor/extension/contributions-messages.html","title":"Message","keywords":"","body":"Message In the Cocos Creator, all interactions are done through Message. The message needs to be defined in contributions before it can be used. View public messages In the top menu Developer -> Message List, the editor presets a Message Manager panel that displays public messages and descriptions of each function definition. Define a message { \"name\": \"hello-world\", \"contributions\": { \"messages\": { \"messageName\": { \"public\": false, \"description\": \"\", \"doc\": \"\", \"methods\": [] } } } } public Type {string} Optional Whether to display this message externally, if true, the basic information of this message will be displayed on the message list interface. description Type {string} Optional If public is true, some simple descriptions will be displayed in the message list, supporting i18n: key syntax. doc Type {string} Optional If public is true, some documents of this message will be displayed, supporting i18n:key syntax. This document is written and rendered in markdown format. methods Type {string[]} Optional The method queue triggered by the message. This is an array of strings. The strings are methods on the extension or panel. If it is a method on the extension, directly define methodName, if you want to trigger a method on the panel, you must fill in panelName.methodName. For example, the ready method of the scene manager is scene:ready. Define broadcast message When developing an extension, you need to send some notifications to other extension after completing an action. If these notifications also need to be displayed on the Developer -> Message List panel, you can define the message like this: { \"name\": \"hello-world\", \"contributions\": { \"messages\": { \"hello-world:ready\": { \"public\": true, \"description\": \"hello-world ready notification\" } } } } "},"editor/extension/contributions-shortcuts.html":{"url":"editor/extension/contributions-shortcuts.html","title":"Shortcuts","keywords":"","body":"Shortcuts The shortcut keys in the editor are managed uniformly by the Shortcut Key Manager. Each shortcut key needs to be bound to a message. When the shortcut key is pressed, the bound message is triggered. Define { \"name\": \"hello-world\", \"panels\": { \"default\": { \"main\": \"./panel.js\" } }, \"contributions\": { \"messages\": { \"undo\": { \"title\": \"i18n:hello.messages.undo.title\", \"methods\": [\"say-undo\"] } }, \"shortcuts\": [ { \"message\": \"undo\", \"when\": \"panel.hello-world\", \"win\": \"ctrl+z\", \"mac\": \"cmd+z\", } ] } } For details, please refer to the Message documentation. contributions.shortcuts Parameter Description: message Type {string} Required The message bound to the shortcut key is sent when the shortcut key is triggered. when(experimental) Type {string} Optional Experimental feature, this functional syntax may be adjusted This shortcut will only be triggered under certain conditions. panel.hello-world will only take effect when the hello-world panel gets the focus. win Type {string} Required On the windows platform, the monitored button. mac Type {string} Required On MacOS, monitor keystrokes. "},"editor/extension/contributions-menu.html":{"url":"editor/extension/contributions-menu.html","title":"Menu","keywords":"","body":"Main Menu There is a main menu bar at the top of the editor, which can be used in the extensions. Register When the extension needs to add a menu, just fill in the contributions.menu object. For example, we add a menu item in the Extension: { \"name\": \"hello-world\", \"contributions\": { \"message\": { \"open-panel\": { \"methods\": [\"openPanel\"] } }, \"menu\": [ { \"path\": \"i18n:menu.extension\", \"label\": \"Open Hello World\", \"icon\": \"./static/icon.png\", \"message\": \"open-panel\" } ] } } Then the editor will add an Open Hello World menu in the Extension. After clicking this menu, an openPanel message will be sent to the registered extension. Then trigger the openPanel method in the extension. path Type {string} Required Search path of the top menu: i18m:menu.project i18n:menu.node i18n:menu.panel i18n:menu.extension i18n:menu.develop You can also fill in multi-level menus, such as i18n:menu.extension/Hello World. label Type {string} Required The name of the menu item. Supports i18n:key syntax. icon Type {string} Optional Menu icon, passing in an icon relative path. message Type {string} Optional Message triggered after menu click. "},"editor/extension/basic.html":{"url":"editor/extension/basic.html","title":"Basic","keywords":"","body":"Basic Many functions are provided within the editor, here are some of the most commonly used features. Extension Message Multilingual Profile UI "},"editor/extension/package.html":{"url":"editor/extension/package.html","title":"Extension","keywords":"","body":"Extended system Before writing an extension, first understand the basic structure of extensions in Cocos Creator. The Cocos Creator editor is based on the Electron kernel. Electron is a cross-platform development framework that integrates Node.js and Chromium. In Electron's architecture, an application consists of a main process and a rendering process. The main process is responsible for managing platform-related scheduling, such as opening and closing windows, menu options, basic dialog boxes, and so on. Each newly opened window is an independent rendering process. In Electron, each process independently enjoys its own JavaScript content and cannot directly access each other. When you need to transfer data between processes, you need to use inter-process communication (IPC). Related functions can be read in the Electron's introduction document to have a deeper understanding of the main process and rendering process in Electron relationship. To put it simply, the main process of Electron is equivalent to a Node.js server program, and each window (rendering process) is equivalent to a client web program. The Cocos Creator editor follows the structural design of Electron's main process and rendering process. When the extension starts and runs in the editor, the main defined by the extension is actually started in the main process, and the panel defined by panels is started in the rendering process. The process structure is briefly summarized as follows: Browser |- panelA |- panelB ... Communication As previously mentioned, the JavaScript content between the two processes is independent of each other, and data must be exchanged by means of inter-process communication. Inter-process communication is actually the process of sending messages in one process, and then listening for messages in another process. Electron provides modules ipcMain and ipcRenderer corresponding to inter-process communication to help us accomplish this task. Since these two modules only complete very basic communication functions, and cannot meet the communication requirements between the editor, the expansion panel and the main process, Cocos Creator has been encapsulated on top of this, and the inter-process messaging is expanded. The method is convenient for extension developers and editor developers to create more complex scenarios. For more instructions, please see the Message documentation. Extended Ability The extension has a complete nodejs environment, which makes it easy to use a large number of tools on the npm market. Used to complete the function you want. If you need to interact with other functions, you need to open the corresponding operation message for the corresponding function. In extensions, use the messages to trigger, query, and process the functions or data in the editor. The open message list can be viewed in the top menu Developer -> Message List panel. In addition, you can also use some tools to facilitate the development of extensions, such as: Use TypeScript to develop extensions. After compiling into js, ​​fill the compiled js into package.json for the editor to run. After the template rendering in the panel is completed, use vue to bind the data to facilitate interactive development of the panel. The extension only agrees to the entrance, during which a large number of external libraries can be used to optimize the development process. "},"editor/extension/messages.html":{"url":"editor/extension/messages.html","title":"Message","keywords":"","body":"Message system There are many independently running processes in Cocos Creator, and these processes are isolated from each other. When you need to interact with other functions in the editor, you need to interact through messages. The message system in the editor is a function expansion package of IPC (Interprocess Communication). This system bears the burden of communication and interaction in the entire editor. Message Types Message interaction is divided into two situations: General message: Actively send a message to a function (extended) Broadcast message: After a certain function (extension) completes an operation, a notification is sent to everyone to inform that the operation has been completed General Message It can be understood as a kind of external api, for example, scene editor defines a message API query-node. { \"name\": \"scene\", \"contributions\": { \"messages\": { \"query-node\": { \"methods\": [\"queryNode\"] } } } } When writing an extension, use this API to send messages: const info = await Editor.Message.request('scene', 'query-node', uuid); At this time, a promise object will be returned. After await, the info object obtained is part of the data on the node actually queried. This message is similar to a remote API call. Broadcast message Broadcast message is a kind of notification to the outside after the operation in a certain function is completed. Take the scene editor as an example. After starting a scene, the scene editor informs everyone that the scene has been started: Editor.Message.broadcast('scene: ready', sceneUUID); It needs to be defined like this in the extension: { \"name\": \"hello-world\", \"contributions\": { \"messages\": { \"scene:ready\": { \"methods\": [\"initData\"] } } } } After that, whenever the scene is ready, broadcasting scene:ready will trigger the initData method in the hello-world extension. Message Naming Conventions General Message Please use lowercase words and cannot contain special characters. Use - to connect between words. Broadcast Message Cannot contain special characters other than :. The format is packageName: actionName. The packageName is added to prevent naming conflicts. In your own extension, you need to directly indicate which broadcast (action) of which extension is monitored when monitoring. In this way, you can more intuitively understand the message processing flow of the extension in package.json. Editor and extended open message list The functions in the editor and the list of messages open to the outside world can be viewed through the Developer -> Message List panel. For detailed definition rules, please refer to the contributions.messages documentation. Send a message Editor.Message.send(pkgName, message, ...args) The send method only sends a message, and does not wait for the return. If you do not need to return data and do not care whether the execution is complete, please use this method. await Editor.Message.request(pkgName, message, ...args) The request method returns a promise object, this promise will receive the data returned after the message is processed. Editor.Message.broadcast(${pkgName}:${actionName}, ...args) The broadcast method only sends, and sends it to all extensions that monitor the corresponding message. "},"editor/extension/i18n.html":{"url":"editor/extension/i18n.html","title":"I18n","keywords":"","body":"Multilingual (i18n) The built-in multi-language solution in the editor extension system allows the extension to configure multiple language key-value mappings, and use different language texts in the extension according to the current language setting of the editor. To enable the multilingual function (here-in-after referred to as i18n), please create a new folder named i18n under the extended directory, and add a corresponding JavaScript file for each language as key-value mapping data. The data file name should be consistent with the language code, such as en.js corresponding to English mapping data. The following is an example of a key-value mapping data source: en.js module.exports = { 'search':'Search', 'edit':'Edit', }; zh.js exports.search ='Search'; exports.edit ='Edit'; Assuming that the registered extension name is hello-world, the corresponding text translation key is hello-world.search Editor.I18n.t('hello-world.search'); Display the text in the corresponding language Use in script In JavaScript or TypeScript scripts, you can obtain the translated text corresponding to the current language through the Editor.I18n.t interface: Editor.I18n.t('hello-world.search'); Use in the template If you need to translate in the html template, use the ui-label element to translate: ui-label is a normal inline element, similar to span. Use in json or other text definitions Some text information, for example, when you need to use the translation function when registering the menu path in the package.json of the extension package, as long as this field supports the path in the i18n format, the path can be expressed in the form of i18n:${key}. We can write i18n:menu.extension/i18n:hello-world.edit, and the corresponding function module will help find the correct string for replacement. "},"editor/extension/profile.html":{"url":"editor/extension/profile.html","title":"Profile","keywords":"","body":"Configuration system When writing an extension, it may be necessary to save configurations and provide some configurations for users to customize settings. Therefore, a configuration management mechanism is provided in the editor. Configuration Type The configuration in the editor is divided into two types: Editor settings Project Settings Editor settings Store some editor-related function settings. This part is also the main configuration of the editor. The editor settings are divided into three levels, with priority from high to low: local -> global -> default Project Settings Store some project-related configurations, which are allowed and need to be shared between projects. local -> default Register Configuration { \"name\": \"hello-world\", \"contributions\": { \"profile\": { \"editor\": { \"test.a\": { \"default\": 0, \"message\": \"editorTestAChanged\", \"label\": \"Test Editor Configuration\" } }, \"project\": { \"test.a\": { \"default\": 1, \"message\": \"projectTestAChanged\", \"label\": \"Test project configuration\" } } } }, } interface ProfileInfo { editor: {[key: string ]: ProfileItem }; project: {[key: string ]: ProfileItem }; } interface ProfileItem { // Configured default data default: any; // After configuration changes, this message will be automatically sent to notify message: string; // Simply describe the role of configuration information, support i18n:key syntax label: string; } contributions.profile is divided into editor and project configurations. The definitions of these two configurations are object objects. The key of the object is the key of the configuration, and the value is the basic information describing the configuration. default Type {any} optional The default value of the configuration. It can be of any type. message Type {string} optional When the message is modified, the defined message will be triggered. Used to dynamically update some data when configuration changes. label Type {string} optional Briefly describe this configuration. Where the configuration can be displayed, this description may be displayed. Support i18n:key format Read configuration Read editor configuration // await Editor.Profile.getConfig(pkgName, key, protocol); await Editor.Profile.getConfig('hello-world','test.a'); // 0 await Editor.Profile.getConfig('hello-world','test.a','local'); // undefined await Editor.Profile.getConfig('hello-world','test.a','global'); // undefined Read project configuration // await Editor.Profile.getConfig(pkgName, key, protocol); await Editor.Profile.getProject('hello-world','test.a'); // 1 await Editor.Profile.getProject('hello-world','test.a','project'); // undefined "},"editor/extension/ui.html":{"url":"editor/extension/ui.html","title":"Editor UI","keywords":"","body":"UI components In order to facilitate the layout, many preset UI components are provided in the editor. When writing html, it is easy to use these UI components. For specific usage, please refer to the main menu Developer --> UI Components at the top of the editor. "},"advanced-topics/":{"url":"advanced-topics/","title":"Advanced Topics","keywords":"","body":"Advanced Topics Hot Update Hot update tutorial AssetManager Dynamic Atlas Engine Customization Workflow The Tutorial for JSB 2.0 JavaScript to Java Reflection JavaScript to Objective-C Reflection "},"advanced-topics/hot-update.html":{"url":"advanced-topics/hot-update.html","title":"Hot Update Tutorial","keywords":"","body":"Assets Hot Update Tutorial Preface In current Cocos Creator version, assets hot update workflow has not been fully integrated into the editor. But the engine itself has complete support for hot update system, so with some of the external script and tool the workflow is complete. The sample project for this document is available from Github Repo. Usage scenarios and design ideas Game developers are very familiar with the pattern that the game has been released in app market but each time user launch the game it will automatically look for updates from the server, to keep the client always updated. Of course, there are some other usage scenarios for hot update, but are not related to what we discuss here. We will mainly discuss how to implement hot update system in Cocos Creator. Hot update in Cocos Creator comes mainly from the AssetsManager module in the Cocos engine. It has a very important feature: Server and client both keep a full list of the game asset (manifest), during hot update process, by comparing server and client asset manifest, the client should know what to download to get the latest content. This can naturally support cross-version updates, such as when client version is A, remote version is C, then we can directly update the assets from A to C. We do not need to generate A to B and B to C update package. Therefore, when we push new asset version to server, we can save new version files discreately on server, and during update the client will download each file needed seprately. Please be aware that hot update system is for native games only, since Web game would always request assets from web server. So AssetsManager class exists only in the jsb namespace, please check runtime environment before implement these API. Manifest file For different versions of file-level differences, AssetsManager uses a manifest file for version control. The client and server manifest files each contains an asset file list and version for each file. So that you can compare the version of each file to determine whether we should download a file. The manifest file contains the following important information: The root path of remote assets Remote manifest file url Remote version file url (optionally) Major version number File list: index of file pathes, including file version information. We recommend using the file md5 as the version number List of search path. The version file can be part of the contents of the manifest file and do not contain a list of files. But the manifest file may be large, each time client need to download the whole file for checking version update. So developer can provide a very small version file for version check only. AssetsManager will first check the version number provided by the version file to determine if you need to continue downloading the manifest file and update it. Implement hot update in the Cocos Creator project In this tutorial, we will provide a hot update workflow for Cocos Creator project. We have also opened Downloader JavaScript interface in cocos2d-x engine, so users are free to develop their own hot update solution. Before starting to explain in detail, developers can take a look at the directory structure of published native version of any game in Cocos Creator. The Creator published directory structure and cocos2d-x JS project directory is exactly the same. For Cocos Creator, engine scripts will be packaged into the src directory, and other assets will be exported to the assets directory. Based on this project structure, the hot update process in this tutorial is simple: Generate the local manifest file based on the assets and src directories in the native published directory. Create a component script to be responsible for the hot update logic. After release of the game, if you need to update the version, you need to generate a set of remote asset versions, including the assets directory, src directory and manifest file. Then deploy these files to your server. When the hot update script detects that the server manifest version does not match local version, the hot update starts To show the hot update process, the example project used in the tutorial has a full version with 1.1.0 information saved in the remote-assets directory, and the default build of the project generates version 1.0.0. At the beginning of the game it will check whether there is a version of the remote update, if you find a remote version the user is prompted to update. When update is complete, the user re-enter the game and see the version 1.1.0 information. Note: the project contains remove-assets is for debug mode, the developer must use the debug mode when building the test project, otherwise the release mode jsc file priority will be higher than remove-assets in the assets and cause the script to fail. Use the version generator to generate the manifest file In the example project, we provided a version_generator.js script file, which is a Nodejs script for generating manfiest file. Use as follows: > node version_generator.js -v 1.0.0 -u http://your-server-address/tutorial-hot-update/remote-assets/ -s native/package/ -d assets/ The following is a description of the parameters: -v Specifies the major version number of the manifest file. -u Specifies the url of the server remote package, which needs to be the same as the remote package url of the manifest file in the original release version, otherwise the update can not be detected. -s local native published directory relative to the current path. -d the path of the output manifest file. Hot update component script In the example project, the implementation of the hot update component is located at assets/hotupdate/HotUpdate.ts, the developer can refer to this implementation, but also free to modify according to their own needs. In addition, the sample project is also equipped with a Scene/Canvas/update node for prompting to update and display the progress of the update. Deploy to remote server In order to allow the game to detect remote versions, you can simulate a remote server on the machine, there are a variety of server solutions (such as SimpleHTTPServer for Python). We will not discuss detail here, developers can use their own prefered way. Once your remote server is up, you need to modify the following places to allow the game to successfully find the remote package: assets/project.manifest: packageUrl, remoteManifestUrl and remoteVersionUrl in the client manifest file of the game remote-assets/project.manifest: packageUrl, remoteManifestUrl and remoteVersionUrl in the manifest file of the remote package remote-assets/version.manifest: packageUrl, remoteManifestUrl and remoteVersionUrl in the remote package's version file Publish the original version After downloading the sample project, you can use Cocos Creator to open the project directly. Open Build panel, build for native platform, you can choose Windows / Mac as target to test. Note: Do not check MD5 Cache when building, otherwise it will cause the hot update to be invalid. Make sure to import editor plugin hot-update into the extensions folder (the demo project has imported the plugin) The editor plugin automatically adds the search path logic and fix code to main.js everytime we build a successful native version: // Add the following code at the beginning of main.js (function () { if (typeof window.jsb === 'object') { var hotUpdateSearchPaths = localStorage.getItem('HotUpdateSearchPaths'); if (hotUpdateSearchPaths) { var paths = JSON.parse(hotUpdateSearchPaths); jsb.fileUtils.setSearchPaths(paths); var fileList = []; var storagePath = paths[0] || ''; var tempPath = storagePath + '_temp/'; var baseOffset = tempPath.length; if (jsb.fileUtils.isDirectoryExist(tempPath) && !jsb.fileUtils.isFileExist(tempPath + 'project.manifest.temp')) { jsb.fileUtils.listFilesRecursively(tempPath, fileList); fileList.forEach(srcPath => { var relativePath = srcPath.substr(baseOffset); var dstPath = storagePath + relativePath; if (srcPath[srcPath.length] == '/') { cc.fileUtils.createDirectory(dstPath) } else { if (cc.fileUtils.isFileExist(dstPath)) { cc.fileUtils.removeFile(dstPath) } cc.fileUtils.renameFile(srcPath, dstPath); } }) cc.fileUtils.removeDirectory(tempPath); } } } })(); This step must be done because the essence of the hot update is to replace the files in the original game package with a remotely downloaded file. Cocos2d-x search path just meet this demand, it can be used to specify the remote package download url as the default search path, so the game will run the process of downloading a good remote version. In addition, the search path is used in the last update process using localStorage (which conforms to the WEB standard Local Storage API) to store on the user's machine. The HotUpdateSearchPaths key is specified in HotUpdate.js, and the name used for the save and read process must match. In addition, if you encounter this warning during the opening of the project, you can ignore: loader for [.manifest] not exists!. Run the example project If everything is alright, you can run the native version of the sample project. You will encounter a new version detected, suggesting that the update will automatically restart the game after the game, then enter the table scene. Conclusion The above is a hot update solution, Cocos Creator in the future version to provide more mature hot update process, directly integrated into the editor. Of course, the underlying Downloader API will also be provided to allow users to freely implement their own hot update scheme and to build a complete visual workflow in the editor through the plug-in mechanism. This tutorial and sample project is for your reference and we encourage developers to customize their own workflows. If you have questions and communication also welcome feedback to Forum. Next Step AssetsManager Document "},"advanced-topics/hot-update-manager.html":{"url":"advanced-topics/hot-update-manager.html","title":"AssetManager for Hot Update","keywords":"","body":"Hot Update AssetsManager This document will fully cover the AssetsManager module for hot update, includes technical details and usage. As the requirements of the hot update process for developers may be different, and each developer may also face different problems. Developers need to fully understand the details of the hot update mechanism to be able to customize the workflow to meet their needs. This document is relatively long, it tries to introduce the hot update mechanism gradually, but will not introduce too much user level code. First, understand how to use the hot update mechanism to update a game, try the simple tutorial example to get started. Design goals and basic principles The hot update mechanism essentially downloads the required assets from the server to the client, and can execute new game logic so that new assets can be used by the game. This means two of the most central goals are: to download new assets, overwrite game logic and assets. At the same time, since the hot update mechanism was originally designed in Cocos2d-JS, we considered what kind of hot update mechanism was more suitable for Cocos's JavaScript user base. Finally, we decided to use a mechanic similar to how Web page update its content to update the game content. Let's take a look at the Web content update mechanic: The server has complete files of all the page content The browser requests a web page to cache its content locally When the browser re-request this page, it will query the version on server version by the last modified time (Last-Modified) or unique identification (Etag). If these two value are different, then download a new file to update the local cache, if not, continue to use the cache. The browser cache mechanism is more complex than the above description, but we can use similar basic idea. For game assets, you can also keep a copy of complete assets on the asset server. The client compare the version list with the server during updates, and download the different files and replace the cache. For the rest continues to use the client version or the cached file. So here's what we need to update the game: The server keeps the latest version of all the game assets (the developer can update the server at any time) The client sends request to get the asset different file list compare to server version Download all assets changed in the new version from the server Overwrite the old cache with the new assets and the files in the application package This is the whole hot update process. Of course, there are very many specific details we will introduce later. What the take away here is: Cocos default hot update mechanism is not based on the patch update mechanism, the traditional hot update is often generate patches between multiple version of packages. Client need to download patches one by one according to the order of versions. Cocos's hot update mechanism generates a list of differences by updating the differences between the latest remote version and current local version directly. This can naturally support cross-version update, such as the local version is A, remote version is C, then directly update the difference between A and C, do not need to generate A to B and B to C update patches. Therefore, in this design, we can upload new version of the game files separately to the server. Hot update basic workflow After understand the basic design above, we can take a look at a typical hot update process. We use the manfiest description file to describe the asset file list and asset version that is stored locally or remotely. The manifest file definition is described later. The runtime environment assumes that the installer version is updated for the first time after the user has installed the app: The figure is divided into three parts, the middle is the hot update process, the left is the process of updating the AssetsManager to send the message to the user, the right is the middle output of each step. The bold words indicates the location of the middle output, such as in memory / temporary folder / cache folder. After reading this picture you may have a lot of questions. We will discuss details of the various steps that need to pay attention to or not easy to understand in the first place. Technical details Manifest format The manifest file is a json format that we use to compare local and remote asset differences, including master version information, engine version information, asset file lists, and asset information: { \"packageUrl\": The local cache root path of the remote asset \"remoteVersionUrl\": [optional] the path of the remote version of the file used to determine whether the server has a new version of the assets \"remoteManifestUrl\": Path of the remote asset manifest file, including version information and all asset information \"version\": the version of the asset \"engineVersion\": engine version \"assets\": all asset lists \"key\": the relative path of the asset (relative to the asset root) \"md5\": The md5 hash represents the version information of the asset file \"compressed\": [optional] If the value is true, the file is automatically downloaded after being extracted, currently only supports zip compression format \"size\": [optional] The byte size of the file used to quickly get progress information \"searchPaths\": A list of search paths that need to be added to FileUtils } The manifest files can be generated by using the Version generator script in the hot update example. It is important to note that the remote information (including packageUrl, remoteVersionUrl, remoteManifestUrl) is for the remote package. That is, the manifest only takes effect when installed or downloaded with a local package. (you can also update the remote package url during version update). In addition, md5 key is only for file identification so you can use other algorithm or rule to generate the file identification, such as modified date. When client compare manifest with the remote version, as long as the md5 information is different, we think this file has changed. The difference between the assets in the project and the published package Everyone in the creation of a Cocos Creator project, you can see it catalog under the assets of the catalog, which saved your scenes, scripts, prefab, etc., corresponding to the editor in the assets of the panel. But these engineering assets are not the same as the packaged assets, in the use of building a building to build the original version, we will find the directory to find res and src folder, these two folders are saved really let the game run up Of the game package within the assets. Where src contains all the scripts, res contains all the assets. So our asset hot update should naturally update the built assets, not the project's assets directory. Package assets, local cache assets and temporary assets When the player's game is installed on the user's phone, its game is in the form of .ipa (iOS) or .apk (Android), which, after installation, can not be modified or added Of any assets within the application package will always exist. So the hot update mechanism, we can only update the local cache to the phone's writable directory (application storage space or SD card specified directory), and through the FileUtils search path mechanism to complete the local cache on the package of assets coverage. At the same time in order to protect the reliability of the update, we will update the process will first put the new version of the assets into a temporary folder, only when the update is completed, will be replaced to the local cache folder. If the midrange interrupt update or update fails, the failed version will not pollute the existing local cache. This step is described in detail in the previous section of the flow chart: In the case of long-term updates, the local cache will always be replaced with the latest version, and the application package only until the user in the application store to update to the new version will be modified. Progress information In the previous section of the flow chart, you can see the hot update manager has sent UPDATE_PROGRESSION message to the user. In the current version, the progress information received by the user contains: byte-level progress (percentage) File level progress (percentage) The number of bytes received The total number of bytes The number of files received The total number of documents function updateCb (event) { switch (event.getEventCode ()) { case jsb.EventAssetsManager.UPDATE_PROGRESSION: cc.log(\"Byte progression : \" + event.getPercent() / 100); cc.log(\"File progression : \" + event.getPercentByFile() / 100); cc.log(\"Total files : \" + event.getTotalFiles()); cc.log(\"Downloaded files : \" + event.getDownloadedFiles()); cc.log(\"Total bytes : \" + event.getTotalBytes()); cc.log(\"Downloaded bytes : \" + event.getDownloadedBytes()); break; } } Resume broken transfer Definitely a developer will ask, if the process of updating the network will be how? The answer is that the hot update manager supports resume broken transfer, and also supports file-level and byte-level breakpoints. So what exactly is it done? First of all, we use the manifest file to identify the status of each asset, such as not started, download, download success, in the hot update process, the file download will be identified to the memory of the manifest, when the number of files to download each The progress node (defaults to 10% of a node) will serialize manifest in memory and save it to a temporary folder. The concrete steps are shown in the flowcharts of the multithreaded concurrent download asset section: After the interruption, start the hot update process again, it will check whether there is an outstanding update in the temporary folder. After checking the version and the remote match, use the manifest in the temporary folder to continue the update as the Remote manifest. At this point, for the download status is completed, will not re-download, for the downloaded file, will try to send a request to the server (the server needs to support Accept-Ranges, or start from scratch). Control concurrency Hot update manager provide control to download the number of concurrent API, the use of the following: assetsManager.setMaxConcurrentTask(10); Version comparison function A very important step in the hot update process is to compare the client and server versions, by default only when the primary version of the server is updated over the client major version. The engine implements a version of the comparison function, support the x.x.x.x four sequence versions of the comparison function (x is a pure number), do not conform to this version number mode will continue to use the string comparison function. In addition, we also allow users to use their own version of the contrast: // both versionA and versionB are string types. assetsManager.setVersionCompareHandle(function (versionA, versionB) { var sub = parseFloat(versionA) - parseFloat(versionB); // When the return value is greater than 0, versionA > versionB. // When the return value is equal to 0, versionA = versionB // When the return value is less then 0, versionA Verify file after downloaded During the download process, problems with the downloaded file contents may occur due to network problem or other network libraries. So we provide the user file verification interface, which is called by the Assets Manager after the file is downloaded (in the case of user implementation). If returning true indicates that the file is OK, returning false indicates that there is a problem with the file. assetsManager.setVerifyCallback(function (filePath, asset) { var md5 = calculateMD5(filePath); if (md5 === asset.md5) return true; else return false; }); The asset version in manifest is recommended to use md5. You can determine whether the file is correct by calculating the md5 code of the downloaded file in the verify function and comparing it with the md5 of the asset. In addition to md5, the asset object also contains the following properties: Property Function Explanation path The relative path of the server side compressed Whether it is compressed size File state downloadState Download size, includes UNSTARTED, DOWNLOADING, SUCCESSED, UNMARKED Error message handling and download retry In the left side of the flowchart, you can see a number of user messages that can be notified through the event listener of the Assets Manager. For details, you can refer to the example. The flowchart identifies the trigger and cause of all error messages, and you can handle them according to your system design. The most important thing is that when an exception occurs during the download process, such as a failed download, a failed decompression, or a failed verification, the UPDATE_FAILED event will be triggered. And a list of all assets that failed to download will be recorded in the Assets Manager and can be downloaded again as follows: assetsManager.downloadFailedAssets(); When the interface is called, it will restart the hot update process and only download the assets failed before. The entire process is the same as the normal hot update process. The necessity of restart If you want to use hot updated assets, you need to restart the game. There are two reasons, the first is that the updated script requires a clean JS environment. The second is the assets configuration that used by AssetManager needs to be updated to the latest to load the scene and assets properly. Refresh of JS script Before the hot update, all the scripts in the game have been executed, and all the classes, components, objects have already been stored in JS context. So if you load the script directly after the hot update without restarting the game, the classes and objects of the same name will be overwritten, but the objects created by the old scripts will still exist. Further, as a result of the overwriting, their dynamic state is also reset, causing the two versions of the objects to mix together, which comes with an overhead of memory usage. Refresh of asset configuration Creator's scenes and assets depend on the Asset Bundle. That is, the game will not be able to load the new scenes and assets without the Asset Bundle being reloaded and parsed by Asset Manager. Enabling new assets relies on the search path mechanism of the Cocos engine. All files in the Cocos are read by FileUtils, which finds files in the priority order of the search path. So we add the hot update cache directory to the search path and promote it so that the assets in the cache directory are searched first. Here is the code example: if (jsb) { // Create AssetsManager var assetsManager = new jsb.AssetsManager(manifestUrl, storagePath); // The local manifest in the initialized AssetsManager is the manifest in the cache directory var hotUpdateSearchPaths = assetsManager.getLocalManifest().getSearchPaths(); // The search path by default var searchPaths = jsb.fileUtils.getSearchPaths(); // Insert hotUpdateSearchPaths to the beginning of searchPaths array Array.prototype.unshift.apply(searchPaths, hotUpdateSearchPaths); jsb.fileUtils.setSearchPaths(searchPaths); } Note: that this code must be placed in main.js and executed before it require other script, otherwise it will still load the script from the application package. Advanced Topics The above sections describe most of the implementation and usage of the Hot Update AssetsManager. But in some special scenarios, you may need some special tricks to avoid the problems caused by hot updates. But in some specific application scenes, you may need some special techniques to avoid problems caused by hot updates. Iterative upgrade Hot update is a frequent requirement for game developers, and multiple hot updates may be released during the upgrade from one major version to another. So the following two questions are of more concern to developers: What happens during a local cache coverage? When a local cached version already exists in the user's environment, the Assets Manager compares the cached version and the in-app version, and then uses the newer version as the local version. If the remote version is updated at this time, the Assets Manager uses a temporary folder to download the remote version during the update process. When the remote version is successfully updated, the contents of the temporary folder are copied to the local cache folder. If there are files of the same name in the local cache folder, they are overridden. And the other files are retained, because these files may still be valid, they just have not been modified in this release. Finally delete the temporary folder. So, in theory, there's no problem with continuous hot update for minor version. How to clean the local cache during a game's major release? During a package update, there are various ways to thoroughly clean up the local hot update cache, such as recording the current game version number, checking if it matches the saved version in cc.sys.localStorage, and performing the following cleanup if they don't match: // The version number previously saved in local Storage, if not, is considered as new version var previousVersion = parseFloat(cc.sys.localStorage.getItem('currentVersion')); // game.currentVersion is the current version's number. if (previousVersion Update engine Upgrading the engine version can have a huge impact on the hot update, and you may have noticed that there is a src/cocos-js/cc.js file in the native project, which is compiled by the JS engine and contains some interface encapsulations for the JS engine framework. In different versions of engine, its code will be quite different, and the bottom layer of C++ will also change simultaneously. Once the C++ engine version in the game pack does not match the engine version in the src/cocos-js/cc.js, it can cause serious problems and even prevent the game from running. It is recommended to publish the major version to app stores as much as possible after updating the engine. If you decide to use hot update, please carefully complete the test of updating the old version to the new version. "},"advanced-topics/dynamic-atlas.html":{"url":"advanced-topics/dynamic-atlas.html","title":"Dynamic Atlas","keywords":"","body":"Dynamic Atlas Reducing the number of DrawCalls is a very direct and effective way to improve game rendering efficiency. One of the most important factors for two DrawCalls to be merged into one is whether both DrawCalls use the same texture. Cocos Creator provides Dynamic Atlas, which dynamically merges the textures into one large texture at project runtime. When a map is rendered, the Dynamic Atlas system automatically detects if the map has been merged into an atlas (collection of images). If not, the system merges the texture into the atlas if it meets the conditions for dynamic atlas. Dynamic atlas selects which textures are merged into a larger image in rendering order, which ensures that adjacent DrawCalls are merged into a single DrawCall (aka \"batching\"). Enable and Disable Dynamic Atlas During initialization, Cocos Creator sets different CLEANUP_IMAGE_CACHE parameter for different platforms, and when CLEANUP_IMAGE_CACHE is disabled, dynamic atlas will be enabled by default. Enabling dynamic atlas will take up extra memory, and the size of the memory used varies by platform. It is currently disabled by default on mini games and native platforms, but it is recommended to turn it on if your project still has room in memory. If you want to force dynamic atlas to be enabled, please add the following code to your code: macro.CLEANUP_IMAGE_CACHE = false; dynamicAtlasManager.enabled = true; Note: write the code above in the outermost part of the project script, not in the onLoad/start class functions, to ensure that they take effect instantly during the project loading process. Otherwise, it may cause an error if the dynamic atlas is enabled only when part of the texture cache has been released. To forcibly disable dynamic atlas, control it directly by code: dynamicAtlasManager.enabled = false; Texture Restrictions The dynamic atlas system limits the size of the texture that can be merged. By default, only textures with a width and height less than 512 can be entered into the dynamic atlas system. This limit can be modified by the developer as required with the following code. dynamicAtlasManager.maxFrameSize = 512; For details, look up DynamicAtlasManager in the API documentation. "},"advanced-topics/engine-customization.html":{"url":"advanced-topics/engine-customization.html","title":"Engine Customization Workflow","keywords":"","body":"Engine Customization Workflow The engine part of Cocos Creator 3.0 includes TypeScript, engine-native, and an adapter (adapter engine customization is not supported at this time). The engine is all open-source on GitHub. The addresses are as follows: TypeScript engine engine-native engine Adapter It is recommended to maintain custom code using the GitHub's Fork workflow. This workflow allows developers to easily update custom engine parts when the engine is upgraded in the future. This workflow is described in the Fork a repo documentation. If you would like to help Cocos get better, feel free to submit changes to GitHub, see the How to Submit Code to Cocos documentation. For more GitHub-related workflows, please refer to the GitHub Help. Also, depending on the Creator version, developers may need to switch to a different engine branch, it is recommended to use the same branch that corresponds to the version of Creator being used. 1 Customize the TypeScript engine If you only need to customize the engine functionality of the web version of the game, or if you only need to modify the pure TypeScript layer logic (e.g. UI system, animation system), simply modify the TypeScript engine by following the procedure below: 1.1 Get the TypeScript engine You can modify the engine based on the one built in Cocos Creator 3.0 if you just need to make some adjustments based on the current version. Click the App button at the top right of the Creator editor, and then copy the built-in engine directory to another local path. To get the latest official version in development, fork or clone the original version of the TypeScript engine from GitHub (see above), and switch the corresponding branch of the TypeScript engine according to the Creator version before using it. Once downloaded, store it to any local path. 1.2 Modify the TypeScript Engine Path Set the path of the TypeScript engine to be customized via the Engine Manager tab of Cocos Creator -> Preferences. 1.3 Install Compilation Dependencies ### Go to the engine path in the command line cd E:/engine # Install the gulp build tool npm install -g gulp # Install dependent modules npm install Note: the gulp build tool is required to generate debuginfos. 1.4 Make changes and compile Next, customize the engine modifications and then click Developer -> Compile the engine in the Cocos Creator editor menu bar to compile. This command will generate a bin folder under the engine directory and compile the engine source code under the bin directory. 2 Customize the engine-native Engine If you need to customize the engine features related to the native platform, you may need to modify the engine-native engine in parallel with the TypeScript engine. 2.1 Get the engine-native Engine If you only need to make some tweaks based on the current version, you can modify the engine-native engine built into Cocos Creator 3.0. The procedure is the same as for the TypeScript engine, click the App button at the top right of the Creator editor, then copy the built-in cocos2d-x-lite directory to another local path. To get the latest official version in development, download or clone it from the GitHub repository specified above. Similar to the TypeScript engine, the engine-native engine should be checked for the current branch before use. 2.2 Initialization After downloading or cloning the engine-native engine repository, go to the engine path at the command line and execute the following command: Note: if you copied the built-in cocos2d-x-lite directory from the editor, you can skip this step. # Go to the engine-native engine path at the command line cd E:/cocos2d-x-lite # Install the gulp build tool npm install -g gulp # Install dependent modules npm install # Initialize the repository gulp init 2.3 Configure a custom engine-native in Cocos Creator 3.0 Set the path to the engine-native engine to be customized via the Engine Manager tab of Cocos Creator -> Preferences. 2.4 Modify the Engine It is possible to customize the engine-native engine. Since the code is only compiled during the build release process, directly open the Build panel after modifying the engine and select the link template to build and compile. "},"advanced-topics/JSB2.0-learning.html":{"url":"advanced-topics/JSB2.0-learning.html","title":"The Tutorial for JSB 2.0","keywords":"","body":"The Tutorial for JSB 2.0 This document is based on v2.x. It may change slightly on Cocos Creator 3.0 and will be updated as soon as possible. The Abstraction Layer of Script Engine Architecture Macro The abstraction layer is bound to take more CPU execution time than using the JS engine API directly. How to minimize the overhead of the abstraction layer becomes the first goal of the design. Most of work in JS binding is actually setting JS related operations with CPP callbacks and associating CPP object within the callback function. In fact, it mainly contains the following two situation: Register JS functions (including global functions, class constructors, class destructors, class member functions, and class static member functions), binding revevant CPP callbacks Register accessors for JS properties, bind CPP callbacks for reading and writing properties respectively How to achieve the minimum overhead for the abstract layer and expose the unified API? For example, to register a JS function in CPP, there are different definitions in JavaScriptCore, SpiderMonkey, V8, ChakraCore as follows: JavaScriptCore JSValueRef JSB_foo_func( JSContextRef _cx, JSObjectRef _function, JSObjectRef _thisObject, size_t argc, const JSValueRef _argv[], JSValueRef* _exception ); SpiderMonkey bool JSB_foo_func( JSContext* _cx, unsigned argc, JS::Value* _vp ); V8 void JSB_foo_func( const v8::FunctionCallbackInfo& v8args ); ChakraCore JsValueRef JSB_foo_func( JsValueRef _callee, bool _isConstructCall, JsValueRef* _argv, unsigned short argc, void* _callbackState ); We evaluated several options and eventually decided to use macros to reduce the differences between the definition and parameter types of different JS engine callbacks, regardless of which engine is used, and developers could use an unified callback definition. We refer to the definition of Lua callback function. The definition of all JS to CPP callback functions in the abstract layer is defined as: bool foo(se::State& s) { ... ... } SE_BIND_FUNC(foo) // Binding a JS function as an example After a developer has bound a JS function, remember to wrap the callback function with the macros which start with SE_BIND_. Currently, we provide the following macros: SE_BIND_PROP_GET: Wrap a JS object property read callback function SE_BIND_PROP_SET: Wrap a JS object property written callback function SE_BIND_FUNC: Wrap a JS function that can be used for global functions, class member functions or class static functions SE_DECLARE_FUNC: Declare a JS function, generally used in the header file SE_BIND_CTOR: Wrap a JS constructor SE_BIND_SUB_CLS_CTOR: Wrap the constructor of a JS subclass by using cc.Class.extend. SE_FINALIZE_FUNC: Wrap the finalize function of a JS object, finalize function is invoked when the object is released by Garbage Collector SE_DECLARE_FINALIZE_FUNC: Declares the finalize function of a JS object _SE: The macro for making callback be recognized by different JS engine. Note that the first character is underscored, similar to _T ('xxx') in Windows for wrapping Unicode or MultiBytes string API CPP Namespace All types of the abstraction layer are under the se namespace, which is an abbreviation of ScriptEngine. Types se::ScriptEngine se::ScriptEngine is the JS engine administrator, responsible for JS engine initialization, destruction, restart, native module registration, loading scripts, doing garbage collection, JS exception cleanup and whether to enable the debugger. It is a singleton that could be accessed via se::ScriptEngine::getInstance(). se::Value se::Value can be understood as a JS variable reference in the CPP layer. There are six types of JS variables: object, number, string, boolean, null, undefined, so se::Value uses an union to include object, number, string, boolean these 4 kinds of value types, non-value types like null and undefined can be represented by _type directly. namespace se { class Value { enum class Type : char { Undefined = 0, Null, Number, Boolean, String, Object }; ... ... private: union { bool _boolean; double _number; std::string* _string; Object* _object; } _u; Type _type; ... ... }; } If a se::Value stores the underlying data types, such as number, string, boolean, which is directly stored by value copy. The storage of object is special because it is a weak reference to JS objects via se::Object*. se::Object se::Object extends from se::RefCounter which is a class for reference count management. Currently, only se::Object inherits from se::RefCounter in the abstraction layer. As we mentioned in the last section, se::Object is a weak reference to the JS object, therefore I will explain why it's a weak reference. Reason 1: The requirement of controlling the life cycle of CPP objects by JS objects After creating a Sprite in the script layer via var sp = new cc.Sprite(\"a.png\");, we create a se::Object in the constructor callback and leave it in a global map (NativePtrToObjectMap), this map is used to query the cocos2d::Sprite* to get the corresponding JS object se::Object*. static bool js_cocos2d_Sprite_finalize(se::State& s) { CCLOG(\"jsbindings: finalizing JS object %p (cocos2d::Sprite)\", s.nativeThisObject()); cocos2d::Sprite* cobj = (cocos2d::Sprite*)s.nativeThisObject(); if (cobj->getReferenceCount() == 1) cobj->autorelease(); else cobj->release(); return true; } SE_BIND_FINALIZE_FUNC(js_cocos2d_Sprite_finalize) static bool js_cocos2dx_Sprite_constructor(se::State& s) { cocos2d::Sprite* cobj = new (std::nothrow) cocos2d::Sprite(); // cobj will be released in the finalize callback s.thisObject()->setPrivateData(cobj); // setPrivateData will make a mapping between se::Object* and cobj return true; } SE_BIND_CTOR(js_cocos2dx_Sprite_constructor, __jsb_cocos2d_Sprite_class, js_cocos2d_Sprite_finalize) Imagine if you force se::Object to be a strong reference to a JS object that leaves JS objects out of GC control and the finalize callback will never be fired because se::Object is always present in map which will cause memory leak. It is precisely because the se::Object holds a weak reference to a JS object so that controlling the life of the CPP object by JS object can be achieved. In the above code, when the JS object is released, it will trigger the finalize callback, developers only need to release the corresponding CPP object in js_cocos2d_Sprite_finalize, the release of se::Object has been included in the SE_BIND_FINALIZE_FUNC macro by automatic processing, developers do not have to manage the release of se::Object in JS Object Control CPP Object mode, but in CPP Object Control JS Object mode, developers have the responsibility to manage the release of se::Object. I will give an example in the next section. Reason 2: More flexible, supporting strong reference by calling the se::Object::root method manually se::Object provides root/unroot method for developers to invoke, root will put JS object into the area not be scanned by the GC. After calling root, se::Object* is a strong reference to the JS object. JS object will be put back to the area scanned by the GC only when se::Object is destructed or unroot is called to make root count to zero. Under normal circumstances, if CPP object is not a subclass of cocos2d :: Ref, CPP object will be used to control the life cycle of the JS object in binding. Binding the engine modules, like spine, dragonbones, box2d and other third-party libraries uses this method. When the CPP object is released, you need to find the corresponding se::Object in the NativePtrToObjectMap, then manually unroot and decRef it. Take the binding of spTrackEntry in spine as an example: spTrackEntry_setDisposeCallback([](spTrackEntry* entry){ se::Object* seObj = nullptr; auto iter = se::NativePtrToObjectMap::find(entry); if (iter != se::NativePtrToObjectMap::end()) { // Save se::Object pointer for being used in cleanup method. seObj = iter->second; // Unmap native and js object since native object was destroyed. // Otherwise, it may trigger 'assertion' in se::Object::setPrivateData later // since native obj is already released and the new native object may be assigned with // the same address. se::NativePtrToObjectMap::erase(iter); } else { return; } auto cleanup = [seObj](){ auto se = se::ScriptEngine::getInstance(); if (!se->isValid() || se->isInCleanup()) return; se::AutoHandleScope hs; se->clearException(); // The mapping of native object & se::Object was cleared in above code. // The private data (native object) may be a different object associated with other se::Object. // Therefore, don't clear the mapping again. seObj->clearPrivateData(false); seObj->unroot(); seObj->decRef(); }; if (!se::ScriptEngine::getInstance()->isGarbageCollecting()) { cleanup(); } else { CleanupTask::pushTaskToAutoReleasePool(cleanup); } }); se::Object Types Native Binding Object The creation of native binding object has been hidden in the SE_BIND_CTOR and SE_BIND_SUB_CLS_CTOR macros, if developers need to use the se::Object in the binding callback, just get it by invoking s.thisObject(). Where s is se::State& which will be described in the following chapters. In addition, se::Object currently supports the manual creation of the following objects: Plain Object: Created by se::Object::createPlainObject, similar to var a = {}; in JS Array Object: Created by se::Object::createArrayObject, similar to var a = []; in JS Uint8 Typed Array Object: Created by se::Object::createTypedArray, like var a = new Uint8Array(buffer); in JS Array Buffer Object: Created by se::Object::createArrayBufferObject similar to var a = new ArrayBuffer(len); in JS The Release of The Objects Created Manually se::Object::createXXX is unlike the create method in cocos2d-x, the abstraction layer is a completely separate module which does not rely on the autorelease mechanism in cocos2d-x. Although se::Object also inherits the reference count class se::RefCounter, developers need to handle the release for objects created manually. se::Object* obj = se::Object::createPlainObject(); ... ... obj->decRef(); // Decrease the reference count to avoid memory leak se::HandleObject se::HandleObject is the recommended helper class for managing the objects created manually. If using manual creation of objects in complex logic, developers often forget to deal with decRef in different conditions bool foo() { se::Object* obj = se::Object::createPlainObject(); if (var1) return false; // Return directly, forget to do 'decRef' operation if (var2) return false; // Return directly, forget to do 'decRef' operation ... ... obj->decRef(); return true; } Plus adding decRef to different return condition branches can result in logically complex and difficult to maintain, and it is easy to forget about decRef if you make another return branch later. If the JS engine did a GC operationJS engine right after se::Object::createXXX, which will result in the se::Object reference to an illegal pointer, the program may crash. In order to solve the above problems, the abstraction layer defines a type that assists in the management of manually created objects, namely se::HandleObject. se::HandleObject is a helper class for easier management of the release (decRef), root, and unroot operations of manually created se::Object objects. The following two code snippets are equivalent, the use of se::HandleObject significantly smaller amount of code, and more secure. { se::HandleObject obj(se::Object::createPlainObject()); obj->setProperty(...); otherObject->setProperty(\"foo\", se::Value(obj)); } Is equal to: { se::Object* obj = se::Object::createPlainObject(); obj->root(); // Root the object immediatelly to prevent the object being garabge collected. obj->setProperty(...); otherObject->setProperty(\"foo\", se::Value(obj)); obj->unroot(); // Call unroot while the object is needed anymore. obj->decRef(); // Decrease the reference count to avoid memory leak. } NOTES: Do not try to use se::HandleObject to create a native binding object. In the JS controls of CPP mode, the release of the bound object will be automatically handled by the abstraction layer. In the CPP controls JS mode, the previous chapter has already described. The se::HandleObject object can only be allocated on the stack, and a se::Object pointer must be passed in. se::Class se::Class is used to expose CPP classes to JS, it creates a constructor function in JS that has a corresponding name. It has the following methods: static se::Class* create(className, obj, parentProto, ctor) Creating a Class. If the registration is successful, we could create an object by var xxx = new SomeClass (); in the JS layer. bool defineFunction(name, func): Define a member function for a class. bool defineProperty(name, getter, setter): Define a property accessor for a class. bool defineStaticFunction(name, func): Define a static function for a class, the JS function could be accessed by SomeClass.foo() rather than the method of var obj = new SomeClass(); obj.foo(), means it's a class method instead of an instance method. bool defineStaticProperty(name, getter, setter): Define a static property accessor which could be invoked by SomeClass.propertyA, it's nothing about instance object. bool defineFinalizeFunction(func): Define the finalize callback function after JS object is garbage collected. bool install(): Install a class JS engine. Object* getProto(): Get the prototype of JS constructor installed, similar to Foo.prototype of function Foo(){} in JS. const char* getName() const: Get the class name which is also the name of JS constructor. NOTE: you do not need to release memory manually after se::Class type is created, it will be automatically encapsulated layer. You could look through the API documentation or code comments for more specific API instructions. se::AutoHandleScope The se::AutoHandleScope object type is purely a concept introduced to address V8 compatibility issues. In V8, any action that calls v8::Local<> on a CPP function that needs to trigger a JS related operation, such as calling a JS function, accessing a JS property, etc, requires a v8::HandleScope function be invoked before calling these operations, otherwise it will cause the program to crash. So the concept of se::AutoHandleScope was introduced into the abstraction layer, which is implemented only on V8, and the other JS engines are currently just empty implementations. Developers need to remember that in any code execution from CPP, you need to declare a se::AutoHandleScope before calling JS's logic. For example: class SomeClass { void update(float dt) { se::ScriptEngine::getInstance()->clearException(); // Clear JS exceptions se::AutoHandleScope hs; // Declare a handle scope, it's needed for V8 se::Object* obj = ...; obj->setProperty(...); ... ... obj->call(...); } }; se::State In the previous section, we have mentioned the se::State type, which is an environment in the binding callback. We can get the current CPP pointer, se::Object object pointer, parameter list and return value reference through se::State argument. bool foo(se::State& s) { // Get native object pointer bound with the current JS object. SomeClass* cobj = (SomeClass*)s.nativeThisObject(); // Get se::Object pointer that represents the current JS object. se::Object* thisObject = s.thisObject(); // Get argument list of the current function. const se::ValueArray& args = s.args(); // Set return value for current function. s.rval().setInt32(100); // Return true to indicate the function is executed successfully. return true; } SE_BIND_FUNC(foo) Does The Abstraction Layer Depend on Cocos2D-X? No. This abstraction layer was originally designed as a stand-alone module which is completely independent of Cocos2D-X engine. Developers can copy the abstraction layer code in cocos/scripting/js-bindings/jswrapper directory and paste them to other projects directly. Manual Binding Define A Callback Function static bool Foo_balabala(se::State& s) { const auto& args = s.args(); int argc = (int)args.size(); if (argc >= 2) // Limit the number of parameters must be greater than or equal to 2, or throw an error to the JS layer and return false. { ... ... return true; } SE_REPORT_ERROR(\"wrong number of arguments: %d, was expecting %d\", argc, 2) ; return false; } // If binding a function, we use SE_BIND_FUNC macro. For binding a constructor, destructor, subclass constructor, please use SE_BIND_balabala macros memtioned above. SE_BIND_FUNC(Foo_balabala) Set A Property Value for JS object se::Object* globalObj = se::ScriptEngine::getInstance()->getGlobalObject(); // We get the global object just for easiler demenstration. globalObj->setProperty(\"foo\", se::Value(100)); // Set a property called `foo` with a value of 100 to the global object. Then, you can use the foo global variable in JS directly. cc.log(\"foo value: \" + foo); // Print `foo value: 100`. Set A Property Accessor for JS Object // The read callback of \"foo\" property of the global object static bool Global_get_foo(se::State& s) { NativeObj* cobj = (NativeObj*)s.nativeThisObject(); int32_t ret = cobj->getValue(); s.rval().setInt32(ret); return true; } SE_BIND_PROP_GET(Global_get_foo) // The write callback of \"foo\" property of the global object static bool Global_set_foo(se::State& s) { const auto& args = s.args(); int argc = (int)args.size(); if (argc >= 1) { NativeObj* cobj = (NativeObj*)s.nativeThisObject(); int32_t arg1 = args[0].toInt32(); cobj->setValue(arg1); // Do not need to call \"s.rval().set(se::Value::Undefined)\" for functions without return value. return true; } SE_REPORT_ERROR(\"wrong number of arguments: %d, was expecting %d\", argc, 1) ; return false; } SE_BIND_PROP_SET(Global_set_foo) void some_func() { se::Object* globalObj = se::ScriptEngine::getInstance()->getGlobalObject(); // We get the global object just for easiler demenstration. globalObj->defineProperty(\"foo\", _SE(Global_get_foo), _SE(Global_set_foo)); // Use _SE macro to package specific function name. } Define A Function for JS Object static bool Foo_function(se::State& s) { ... ... } SE_BIND_FUNC(Foo_function) void some_func() { se::Object* globalObj = se::ScriptEngine::getInstance()->getGlobalObject(); // We get the global object just for easiler demenstration. globalObj->defineFunction(\"foo\", _SE(Foo_function)); // Use _SE macro to package specific function name. } Register A CPP Class to JS Virtual Machine static se::Object* __jsb_ns_SomeClass_proto = nullptr; static se::Class* __jsb_ns_SomeClass_class = nullptr; namespace ns { class SomeClass { public: SomeClass() : xxx(0) {} void foo() { printf(\"SomeClass::foo\\n\"); Director::getInstance()->getScheduler()->schedule([this](float dt){ static int counter = 0; ++counter; if (_cb != nullptr) _cb(counter); }, this, 1.0f, CC_REPEAT_FOREVER, 0.0f, false, \"iamkey\"); } static void static_func() { printf(\"SomeClass::static_func\\n\"); } void setCallback(const std::function& cb) { _cb = cb; if (_cb != nullptr) { printf(\"setCallback(cb)\\n\"); } else { printf(\"setCallback(nullptr)\\n\"); } } int xxx; private: std::function _cb; }; } // namespace ns { static bool js_SomeClass_finalize(se::State& s) { ns::SomeClass* cobj = (ns::SomeClass*)s.nativeThisObject(); delete cobj; return true; } SE_BIND_FINALIZE_FUNC(js_SomeClass_finalize) static bool js_SomeClass_constructor(se::State& s) { ns::SomeClass* cobj = new ns::SomeClass(); s.thisObject()->setPrivateData(cobj); return true; } SE_BIND_CTOR(js_SomeClass_constructor, __jsb_ns_SomeClass_class, js_SomeClass_finalize) static bool js_SomeClass_foo(se::State& s) { ns::SomeClass* cobj = (ns::SomeClass*)s.nativeThisObject(); cobj->foo(); return true; } SE_BIND_FUNC(js_SomeClass_foo) static bool js_SomeClass_get_xxx(se::State& s) { ns::SomeClass* cobj = (ns::SomeClass*)s.nativeThisObject(); s.rval().setInt32(cobj->xxx); return true; } SE_BIND_PROP_GET(js_SomeClass_get_xxx) static bool js_SomeClass_set_xxx(se::State& s) { const auto& args = s.args(); int argc = (int)args.size(); if (argc > 0) { ns::SomeClass* cobj = (ns::SomeClass*)s.nativeThisObject(); cobj->xxx = args[0].toInt32(); return true; } SE_REPORT_ERROR(\"wrong number of arguments: %d, was expecting %d\", argc, 1); return false; } SE_BIND_PROP_SET(js_SomeClass_set_xxx) static bool js_SomeClass_static_func(se::State& s) { ns::SomeClass::static_func(); return true; } SE_BIND_FUNC(js_SomeClass_static_func) bool js_register_ns_SomeClass(se::Object* global) { // Make sure the namespace exists se::Value nsVal; if (!global->getProperty(\"ns\", &nsVal)) { // If it doesn't exist, create one. Similar as `var ns = {};` in JS. se::HandleObject jsobj(se::Object::createPlainObject()); nsVal.setObject(jsobj); // Set the object to the global object with the property name `ns`. global->setProperty(\"ns\", nsVal); } se::Object* ns = nsVal.toObject(); // Create a se::Class object, developers do not need to consider the release of the se::Class object, which is automatically handled by the ScriptEngine. auto cls = se::Class::create(\"SomeClass\", ns, nullptr, _SE(js_SomeClass_constructor)); // If the registered class doesn't need a constructor, the last argument can be passed in with nullptr, it will make `new SomeClass();` illegal. // Define member functions, member properties. cls->defineFunction(\"foo\", _SE(js_SomeClass_foo)); cls->defineProperty(\"xxx\", _SE(js_SomeClass_get_xxx), _SE(js_SomeClass_set_xxx)); // Define finalize callback function cls->defineFinalizeFunction(_SE(js_SomeClass_finalize)); // Install the class to JS virtual machine cls->install(); // JSBClassType::registerClass is a helper function in the Cocos2D-X native binding code, which is not a part of the ScriptEngine. JSBClassType::registerClass(cls); // Save the result to global variable for easily use in other places, for example class inheritence. __jsb_ns_SomeClass_proto = cls->getProto(); __jsb_ns_SomeClass_class = cls; // Set a property \"yyy\" with the string value \"helloyyy\" for each object instantiated by this class. __jsb_ns_SomeClass_proto->setProperty(\"yyy\", se::Value(\"helloyyy\")); // Register static member variables and static member functions se::Value ctorVal; if (ns->getProperty(\"SomeClass\", &ctorVal) && ctorVal.isObject()) { ctorVal.toObject()->setProperty(\"static_val\", se::Value(200)); ctorVal.toObject()->defineFunction(\"static_func\", _SE(js_SomeClass_static_func)); } // Clear JS exceptions se::ScriptEngine::getInstance()->clearException(); return true; } How to Bind A CPP Callback Function static bool js_SomeClass_setCallback(se::State& s) { const auto& args = s.args(); int argc = (int)args.size(); if (argc >= 1) { ns::SomeClass* cobj = (ns::SomeClass*)s.nativeThisObject(); se::Value jsFunc = args[0]; se::Value jsTarget = argc > 1 ? args[1] : se::Value::Undefined; if (jsFunc.isNullOrUndefined()) { cobj->setCallback(nullptr); } else { assert(jsFunc.isObject() && jsFunc.toObject()->isFunction()); // If the current SomeClass is a class that can be created by \"new\", we use \"se::Object::attachObject\" to associate jsFunc with jsTarget to the current object. s.thisObject()->attachObject(jsFunc.toObject()); s.thisObject()->attachObject(jsTarget.toObject()); // If the current SomeClass class is a singleton, or a class that always has only one instance, we can not associate it with \"se::Object::attachObject\". // Instead, you must use \"se::Object::root\", developers do not need to unroot since unroot operation will be triggered in the destruction of lambda which makes the \"se::Value\" jsFunc be destroyed, then \"se::Object\" destructor will do the unroot operation automatically. // The binding function \"js_cocos2dx_EventDispatcher_addCustomEventListener\" implements it in this way because \"EventDispatcher\" is always a singleton. // Using \"s.thisObject->attachObject(jsFunc.toObject);\" for binding addCustomEventListener will cause jsFunc and jsTarget varibales can't be released, which will result in memory leak. // jsFunc.toObject()->root(); // jsTarget.toObject()->root(); cobj->setCallback([jsFunc, jsTarget](int counter) { // Add the following two lines of code in CPP callback function before passing data to the JS. se::ScriptEngine::getInstance()->clearException(); se::AutoHandleScope hs; se::ValueArray args; args.push_back(se::Value(counter)); se::Object* target = jsTarget.isObject() ? jsTarget.toObject() : nullptr; jsFunc.toObject()->call(args, target); }); } return true; } SE_REPORT_ERROR(\"wrong number of arguments: %d, was expecting %d\", argc, 1); return false; } SE_BIND_FUNC(js_SomeClass_setCallback) After SomeClass is registered, you can use it in JS like the following: var myObj = new ns.SomeClass(); myObj.foo(); ns.SomeClass.static_func(); cc.log(\"ns.SomeClass.static_val: \" + ns.SomeClass.static_val); cc.log(\"Old myObj.xxx:\" + myObj.xxx); myObj.xxx = 1234; cc.log(\"New myObj.xxx:\" + myObj.xxx); cc.log(\"myObj.yyy: \" + myObj.yyy); var delegateObj = { onCallback: function(counter) { cc.log(\"Delegate obj, onCallback: \" + counter + \", this.myVar: \" + this.myVar); this.setVar(); }, setVar: function() { this.myVar++; }, myVar: 100 }; myObj.setCallback(delegateObj.onCallback, delegateObj); setTimeout(function(){ myObj.setCallback(null); }, 6000); // Clear callback after 6 seconds. There will be some logs outputed in console: SomeClass::foo SomeClass::static_func ns.SomeClass.static_val: 200 Old myObj.xxx:0 New myObj.xxx:1234 myObj.yyy: helloyyy setCallback(cb) Delegate obj, onCallback: 1, this.myVar: 100 Delegate obj, onCallback: 2, this.myVar: 101 Delegate obj, onCallback: 3, this.myVar: 102 Delegate obj, onCallback: 4, this.myVar: 103 Delegate obj, onCallback: 5, this.myVar: 104 Delegate obj, onCallback: 6, this.myVar: 105 setCallback(nullptr) How to Use The Helper Functions in Cocos2D-X Binding for Easiler NativeJS Type Conversions The helper functions for nativeJS type conversions are located in cocos/scripting/js-bindings/manual/jsb_conversions.hpp/.cpp, it includes: Convert se::Value to CPP Type bool seval_to_int32(const se::Value& v, int32_t* ret); bool seval_to_uint32(const se::Value& v, uint32_t* ret); bool seval_to_int8(const se::Value& v, int8_t* ret); bool seval_to_uint8(const se::Value& v, uint8_t* ret); bool seval_to_int16(const se::Value& v, int16_t* ret); bool seval_to_uint16(const se::Value& v, uint16_t* ret); bool seval_to_boolean(const se::Value& v, bool* ret); bool seval_to_float(const se::Value& v, float* ret); bool seval_to_double(const se::Value& v, double* ret); bool seval_to_long(const se::Value& v, long* ret); bool seval_to_ulong(const se::Value& v, unsigned long* ret); bool seval_to_longlong(const se::Value& v, long long* ret); bool seval_to_ssize(const se::Value& v, ssize_t* ret); bool seval_to_std_string(const se::Value& v, std::string* ret); bool seval_to_Vec2(const se::Value& v, cocos2d::Vec2* pt); bool seval_to_Vec3(const se::Value& v, cocos2d::Vec3* pt); bool seval_to_Vec4(const se::Value& v, cocos2d::Vec4* pt); bool seval_to_Mat4(const se::Value& v, cocos2d::Mat4* mat); bool seval_to_Size(const se::Value& v, cocos2d::Size* size); bool seval_to_Rect(const se::Value& v, cocos2d::Rect* rect); bool seval_to_Color3B(const se::Value& v, cocos2d::Color3B* color); bool seval_to_Color4B(const se::Value& v, cocos2d::Color4B* color); bool seval_to_Color4F(const se::Value& v, cocos2d::Color4F* color); bool seval_to_ccvalue(const se::Value& v, cocos2d::Value* ret); bool seval_to_ccvaluemap(const se::Value& v, cocos2d::ValueMap* ret); bool seval_to_ccvaluemapintkey(const se::Value& v, cocos2d::ValueMapIntKey* ret); bool seval_to_ccvaluevector(const se::Value& v, cocos2d::ValueVector* ret); bool sevals_variadic_to_ccvaluevector(const se::ValueArray& args, cocos2d::ValueVector* ret); bool seval_to_blendfunc(const se::Value& v, cocos2d::BlendFunc* ret); bool seval_to_std_vector_string(const se::Value& v, std::vector* ret); bool seval_to_std_vector_int(const se::Value& v, std::vector* ret); bool seval_to_std_vector_float(const se::Value& v, std::vector* ret); bool seval_to_std_vector_Vec2(const se::Value& v, std::vector* ret); bool seval_to_std_vector_Touch(const se::Value& v, std::vector* ret); bool seval_to_std_map_string_string(const se::Value& v, std::map* ret); bool seval_to_FontDefinition(const se::Value& v, cocos2d::FontDefinition* ret); bool seval_to_Acceleration(const se::Value& v, cocos2d::Acceleration* ret); bool seval_to_Quaternion(const se::Value& v, cocos2d::Quaternion* ret); bool seval_to_AffineTransform(const se::Value& v, cocos2d::AffineTransform* ret); //bool seval_to_Viewport(const se::Value& v, cocos2d::experimental::Viewport* ret); bool seval_to_Data(const se::Value& v, cocos2d::Data* ret); bool seval_to_DownloaderHints(const se::Value& v, cocos2d::network::DownloaderHints* ret); bool seval_to_TTFConfig(const se::Value& v, cocos2d::TTFConfig* ret); //box2d seval to native convertion bool seval_to_b2Vec2(const se::Value& v, b2Vec2* ret); bool seval_to_b2AABB(const se::Value& v, b2AABB* ret); template bool seval_to_native_ptr(const se::Value& v, T* ret); template bool seval_to_Vector(const se::Value& v, cocos2d::Vector* ret); template bool seval_to_Map_string_key(const se::Value& v, cocos2d::Map* ret) Convert C++ Type to se::Value bool int8_to_seval(int8_t v, se::Value* ret); bool uint8_to_seval(uint8_t v, se::Value* ret); bool int32_to_seval(int32_t v, se::Value* ret); bool uint32_to_seval(uint32_t v, se::Value* ret); bool int16_to_seval(uint16_t v, se::Value* ret); bool uint16_to_seval(uint16_t v, se::Value* ret); bool boolean_to_seval(bool v, se::Value* ret); bool float_to_seval(float v, se::Value* ret); bool double_to_seval(double v, se::Value* ret); bool long_to_seval(long v, se::Value* ret); bool ulong_to_seval(unsigned long v, se::Value* ret); bool longlong_to_seval(long long v, se::Value* ret); bool ssize_to_seval(ssize_t v, se::Value* ret); bool std_string_to_seval(const std::string& v, se::Value* ret); bool Vec2_to_seval(const cocos2d::Vec2& v, se::Value* ret); bool Vec3_to_seval(const cocos2d::Vec3& v, se::Value* ret); bool Vec4_to_seval(const cocos2d::Vec4& v, se::Value* ret); bool Mat4_to_seval(const cocos2d::Mat4& v, se::Value* ret); bool Size_to_seval(const cocos2d::Size& v, se::Value* ret); bool Rect_to_seval(const cocos2d::Rect& v, se::Value* ret); bool Color3B_to_seval(const cocos2d::Color3B& v, se::Value* ret); bool Color4B_to_seval(const cocos2d::Color4B& v, se::Value* ret); bool Color4F_to_seval(const cocos2d::Color4F& v, se::Value* ret); bool ccvalue_to_seval(const cocos2d::Value& v, se::Value* ret); bool ccvaluemap_to_seval(const cocos2d::ValueMap& v, se::Value* ret); bool ccvaluemapintkey_to_seval(const cocos2d::ValueMapIntKey& v, se::Value* ret); bool ccvaluevector_to_seval(const cocos2d::ValueVector& v, se::Value* ret); bool blendfunc_to_seval(const cocos2d::BlendFunc& v, se::Value* ret); bool std_vector_string_to_seval(const std::vector& v, se::Value* ret); bool std_vector_int_to_seval(const std::vector& v, se::Value* ret); bool std_vector_float_to_seval(const std::vector& v, se::Value* ret); bool std_vector_Touch_to_seval(const std::vector& v, se::Value* ret); bool std_map_string_string_to_seval(const std::map& v, se::Value* ret); bool uniform_to_seval(const cocos2d::Uniform* v, se::Value* ret); bool FontDefinition_to_seval(const cocos2d::FontDefinition& v, se::Value* ret); bool Acceleration_to_seval(const cocos2d::Acceleration* v, se::Value* ret); bool Quaternion_to_seval(const cocos2d::Quaternion& v, se::Value* ret); bool ManifestAsset_to_seval(const cocos2d::extension::ManifestAsset& v, se::Value* ret); bool AffineTransform_to_seval(const cocos2d::AffineTransform& v, se::Value* ret); bool Data_to_seval(const cocos2d::Data& v, se::Value* ret); bool DownloadTask_to_seval(const cocos2d::network::DownloadTask& v, se::Value* ret); template bool Vector_to_seval(const cocos2d::Vector& v, se::Value* ret); template bool Map_string_key_to_seval(const cocos2d::Map& v, se::Value* ret); template bool native_ptr_to_seval(typename std::enable_if::value,T>::type* v, se::Value* ret, bool* isReturnCachedValue = nullptr); template bool native_ptr_to_seval(typename std::enable_if::value,T>::type* v, se::Class* cls, se::Value* ret, bool* isReturnCachedValue = nullptr) template bool native_ptr_to_seval(typename std::enable_if::value,T>::type* v, se::Value* ret, bool* isReturnCachedValue = nullptr); template bool native_ptr_to_seval(typename std::enable_if::value,T>::type* v, se::Class* cls, se::Value* ret, bool* isReturnCachedValue = nullptr); template bool native_ptr_to_rooted_seval(typename std::enable_if::value,T>::type* v, se::Value* ret, bool* isReturnCachedValue = nullptr); template bool native_ptr_to_rooted_seval(typename std::enable_if::value,T>::type* v, se::Class* cls, se::Value* ret, bool* isReturnCachedValue = nullptr); // Spine conversions bool speventdata_to_seval(const spEventData& v, se::Value* ret); bool spevent_to_seval(const spEvent& v, se::Value* ret); bool spbonedata_to_seval(const spBoneData& v, se::Value* ret); bool spbone_to_seval(const spBone& v, se::Value* ret); bool spskeleton_to_seval(const spSkeleton& v, se::Value* ret); bool spattachment_to_seval(const spAttachment& v, se::Value* ret); bool spslotdata_to_seval(const spSlotData& v, se::Value* ret); bool spslot_to_seval(const spSlot& v, se::Value* ret); bool sptimeline_to_seval(const spTimeline& v, se::Value* ret); bool spanimationstate_to_seval(const spAnimationState& v, se::Value* ret); bool spanimation_to_seval(const spAnimation& v, se::Value* ret); bool sptrackentry_to_seval(const spTrackEntry& v, se::Value* ret); // Box2d bool b2Vec2_to_seval(const b2Vec2& v, se::Value* ret); bool b2Manifold_to_seval(const b2Manifold* v, se::Value* ret); bool b2AABB_to_seval(const b2AABB& v, se::Value* ret); Auxiliary conversion functions are not part of the abstraction layer (Script Engine Wrapper), they belong to the Cocos2D-X binding layer and are encapsulated to facilitate more convenient conversion in the binding code. Each conversion function returns the type bool indicating whether the conversion was successful or not. Developers need to check the return value after calling these interfaces. You can know the specific usage directly according to interface names. The first parameter in the interface is input, and the second parameter is the output parameter. The usage is as follows: se::Value v; bool ok = int32_to_seval(100, &v); // The second parameter is the output parameter, passing in the address of the output parameter int32_t v; bool ok = seval_to_int32(args[0], &v); // The second parameter is the output parameter, passing in the address of the output parameter (IMPORTANT) Understand The Difference Between native_ptr_to_seval and native_ptr_to_rooted_seval Developers must understand the difference to make sure these conversion functions not being misused. In that case, JS memory leaks, which is really difficult to fix, could be avoided. native_ptr_to_seval is used in JS control CPP object life cycle mode. This method can be called when a se::Value needs to be obtained from a CPP object pointer at the binding code. Most subclasses in the Cocos2D-X that inherit from cocos2d::Ref take this approach to get se::Value. Please remember, when the binding object, which is controlled by the JS object's life cycle, need to be converted to seval, use this method, otherwise consider using native_ptr_to_rooted_seval. native_ptr_to_rooted_seval is used in CPP controlling JS object lifecycle mode. In general, this method is used for object bindings in third-party libraries. This method will try to find the cached se::Object according the incoming CPP object pointer, if the cached se::Objectis not exist, then it will create a rooted se::Object which isn't controlled by Garbage Collector and will always keep alive until unroot is called. Developers need to observe the release of the CPP object, and unroot se::Object. Please refer to the section introduces spTrackEntry binding (spTrackEntry_setDisposeCallback) described above. Automatic Binding Configure Module .ini Files The configuration method is the same as that in Creator v1.6. The main points to note are: In Creator v1.7 script_control_cpp field is deprecated because script_control_cpp field affects the entire module. If the module needs to bind the cocos2d::Ref subclass and non-cocos2d::Ref class, the original binding configuration in v1.6 can not meet the demand. The new field introduced in v1.7 is classes_owned_by_cpp, which indicates which classes need to be controlled by the CPP object's life cycle. An additional, there is a configuration field in v1.7 is persistent_classes to indicate which classes are always present during game play, such as: SpriteFrameCache, FileUtils, EventDispatcher, ActionManager, Scheduler. Other fields are the same as v1.6. For more specific, please refer to the engine directory tools/tojs/cocos2dx.ini file. Understand The Meaning of Each Field in The .ini file # Module name [cocos2d-x] # The prefix for callback functions and the binding file name. prefix = cocos2dx # The namspace of the binding class attaches to. target_namespace = cc # Automatic binding tools is based on the Android NDK. The android_headers field configures the search path of Android header file. android_headers = -I%(androidndkdir)s/platforms/android-14/arch-arm/usr/include -I%(androidndkdir)s/sources/cxx-stl/gnu-libstdc++/4.8/libs/armeabi-v7a/include -I%(androidndkdir)s/sources/cxx-stl/gnu-libstdc++/4.8/include -I%(androidndkdir)s/sources/cxx-stl/gnu-libstdc++/4.9/libs/armeabi-v7a/include -I%(androidndkdir)s/sources/cxx-stl/gnu-libstdc++/4.9/include # Configure building parameters for Android. android_flags = -D_SIZE_T_DEFINED_ # Configure the search path for clang header file. clang_headers = -I%(clangllvmdir)s/%(clang_include)s # Configure building parameters for clang clang_flags = -nostdinc -x c++ -std=c++11 -U __SSE__ # Configure the search path for Cocos2D-X header file cocos_headers = -I%(cocosdir)s/cocos -I%(cocosdir)s/cocos/platform/android -I%(cocosdir)s/external/sources # Configure building parameters for Cocos2D-X cocos_flags = -DANDROID # Configure extra building parameters extra_arguments = %(android_headers)s %(clang_headers)s %(cxxgenerator_headers)s %(cocos_headers)s %(android_flags)s %(clang_flags)s %(cocos_flags)s %(extra_flags)s # Which header files needed to be parsed headers = %(cocosdir)s/cocos/cocos2d.h %(cocosdir)s/cocos/scripting/js-bindings/manual/BaseJSAction.h # Rename the header file in the generated binding code replace_headers=CCProtectedNode.h::2d/CCProtectedNode.h,CCAsyncTaskPool.h::base/CCAsyncTaskPool.h # Which classes need to be bound, you can use regular expressions, separated by space. classes = # Which classes which use cc.Class.extend to inherit, separated by space. classes_need_extend = # Which classes need to bind properties, separated by commas field = Acceleration::[x y z timestamp] # Which classes need to be skipped, separated by commas skip = AtlasNode::[getTextureAtlas], ParticleBatchNode::[getTextureAtlas], # Which functions need to be renamed, separated by commas rename_functions = ComponentContainer::[get=getComponent], LayerColor::[initWithColor=init], # Which classes need to be renamed, separated by commas rename_classes = SimpleAudioEngine::AudioEngine, SAXParser::PlistParser, # Which classes do not have parents in JS classes_have_no_parents = Node Director SimpleAudioEngine FileUtils TMXMapInfo Application GLViewProtocol SAXParser Configuration # Which C++ base classes need to be skipped base_classes_to_skip = Ref Clonable # Which classes are abstract classes which do not have a constructor in JS abstract_classes = Director SpriteFrameCache Set SimpleAudioEngine # Which classes are singleton or always keep alive until game exits persistent_classes = SpriteFrameCache FileUtils EventDispatcher ActionManager Scheduler # Which classes use `CPP object controls JS object's life cycle`, the unconfigured classes will use `JS controls CPP object's life cycle`. classes_owned_by_cpp = Remote Debugging and Profile The remote debugging and profile are valid in debug mode, if you need to enable in release mode, you need to manually modify the macro in cocos/scripting/js-bindings/jswrapper/config.hpp. #if defined(COCOS2D_DEBUG) && COCOS2D_DEBUG > 0 #define SE_ENABLE_INSPECTOR 1 #define SE_DEBUG 2 #else #define SE_ENABLE_INSPECTOR 0 #define SE_DEBUG 0 #endif Change to: #if 1 // Change to 1 to force enable remote debugging #define SE_ENABLE_INSPECTOR 1 #define SE_DEBUG 2 #else #define SE_ENABLE_INSPECTOR 0 #define SE_DEBUG 0 #endif Remote Debugging V8 in Chrome Windows/Mac Compile, run the game (or run directly in the Creator simulator) Open with Chrome: devtools://devtools/bundled/js_app.html?v8only=true&ws=127.0.0.1:5086/00010002-0003-4004-8005-000600070008. (If you are using an older version of Chrome, you need to change the devtools at the beginning of the address to chrome-devtools) Breakpoint debugging: Catch JS Heap: Profile: Android/iOS Make sure your Android/iOS device is on the same network as your PC or Mac Compile and run your game Open with Chrome: devtools://devtools/bundled/js_app.html?v8only=true&ws=xxx.xxx.xxx.xxx:6086/00010002-0003-4004-8005-000600070008, xxx.xxx.xxx.xxx is the IP address of Android/iOS device. (If you are using an older version of Chrome, you need to change the devtools at the beginning of the address to chrome-devtools) The remote debugging interface is the same as debugging Windows. Q & A What's The Difference between se::ScriptEngine and ScriptingCore? Why to keep ScriptingCore? In Creator v1.7, the abstraction layer was designed as a stand-alone module that had no relation to the engine. The management of the JS engine was moved from the ScriptingCore to se::ScriptEngine class. ScriptingCore was retained in hopes of passing engine events to the abstraction layer, which acts like a adapter. ScriptingCore only needs to be used once in AppDelegate.cpp, and all subsequent operations only require se::ScriptEngine. bool AppDelegate::applicationDidFinishLaunching() { ... ... director->setAnimationInterval(1.0 / 60); // These two lines set the ScriptingCore adapter to the engine for passing engine events, such as Node's onEnter, onExit, Action's update ScriptingCore* sc = ScriptingCore::getInstance(); ScriptEngineManager::getInstance()->setScriptEngine(sc); se::ScriptEngine* se = se::ScriptEngine::getInstance(); ... ... } What's The Difference between se::Object::root/unroot and se::Object::incRef/decRef? root/unroot is used to control whether JS objects are controlled by GC, root means JS object should not be controlled by GC, unroot means it should be controlled by GC. For a se::Object, root and unroot can be called multiple times, se::Object's internal _rootCount variables is used to indicate the count of root operation. When unroot is called and _rootCount reach 0, the JS object associated with se::Object is handed over to the GC. Another situation is that if se::Object destructor is triggered and _rootCount is still greater than 0, it will force the JS object to be controlled by the GC. incRef/decRef is used to control the life cycle of se::Object CPP object. As mentioned in the previous section, it is recommended that you use se::HandleObject to control the manual creation of unbound objects's life cycle. So, in general, developers do not need to touch incRef/decRef. The Association and Disassociation of Object's Life Cycle Use se::Object::attachObject to associate object's life cycle. Use se::Object::dettachObject to disassociate object's life cycle. objA->attachObject(objB); is similar as objA.__ nativeRefs[index] = objB in JS. Only when objA is garbage collected, objB will be possible garbage collected. objA->dettachObject(objB); is similar as delete objA.__nativeRefs[index]; in JS. After invoking dettachObject, objB's life cycle will not be controlled by objA. What's The Difference of Object Life Management between The Subclass of cocos2d::Ref and non-cocos2d::Ref class? The binding of cocos2d::Ref subclass in the current engine adopts JS object controls the life cycle of CPP object. The advantage of doing so is to solve the retain/release problem that has been criticized in the JS layer. Non-cocos2d::Ref class takes the way of CPP object controls the life of a JS object. This method requires that after CPP object is destroyed, it needs to notify the binding layer to call the clearPrivateData, unroot, and decRef methods corresponding to se::Object. JS code must be careful operation of the object, when there may be illegal object logic, use cc.sys.isObjectValid to determine whether the CPP object is released. NOTE of Binding The Finalize Function for cocos2d::Ref Subclass Calling any JS engine's API in a finalize callback can lead to a crash. Because the current engine is in garbage collection process, which can not be interrupted to deal with other operations. Finalize callback is to tell the CPP layer to release the memory of the corresponding CPP object, we should not call any JS engine API in the CPP object's destructor either. But if that must be called, how should we deal with? In Cocos2D-X binding, if the native object's reference count is 1, we do not use the release, but using autorelease to delay CPP object's destructor to be executed at the end of frame. For instance: static bool js_cocos2d_Sprite_finalize(se::State& s) { CCLOG(\"jsbindings: finalizing JS object %p (cocos2d::Sprite)\", s.nativeThisObject()); cocos2d::Sprite* cobj = (cocos2d::Sprite*)s.nativeThisObject(); if (cobj->getReferenceCount() == 1) cobj->autorelease(); else cobj->release(); return true; } SE_BIND_FINALIZE_FUNC(js_cocos2d_Sprite_finalize) Please DO NOT Assign A Subclass of cocos2d::Ref on The Stack Subclasses of cocos2d::Ref must be allocated on the heap, via new, and then released by release. In JS object's finalize callback function, we should use autorelease or release to release. If it is allocated on the stack, the reference count is likely to be 0, and then calling release in finalize callback will result delete is invoked, which causing the program to crash. So in order to prevent this behavior from happening, developers can identify destructors as protected or private in the binding classes that inherit from cocos2d::Ref, ensuring that this problem can be found during compilation. E.g: class CC_EX_DLL EventAssetsManagerEx : public cocos2d::EventCustom { public: ... ... private: virtual ~EventAssetsManagerEx() {} ... ... }; EventAssetsManagerEx event(...); // Compilation ERROR dispatcher->dispatchEvent(&event); // Must modify to: EventAssetsManagerEx* event = new EventAssetsManagerEx(...); dispatcher->dispatchEvent(event); event->release(); How to Observe JS Exception? In AppDelegate.cpp, using se::ScriptEngine::getInstance()->setExceptionCallback(...) to set the callback of JS exception. bool AppDelegate::applicationDidFinishLaunching() { ... ... se::ScriptEngine* se = se::ScriptEngine::getInstance(); se->setExceptionCallback([](const char* location, const char* message, const char* stack){ // Send exception information to server like Tencent Bugly. // ... // ... }); jsb_register_all_modules(); ... ... return true; } "},"advanced-topics/java-reflection.html":{"url":"advanced-topics/java-reflection.html","title":"JavaScript to Java Reflection","keywords":"","body":"How to Call Java methods using JavaScript on Android This document is based on v2.x. It may change slightly with Cocos Creator 3.0 and will be updated as soon as possible. With the Cocos Creator Android build, developers can call Java static methods directly in JavaScript. Doing so is very simple: var result = jsb.reflection.callStaticMethod(className, methodName, methodSignature, parameters...) In callStaticMethod method, pass the Java class name, method name, method signature with parameters, and get the return value from Java. The Java class name and method signature may be a little strange without having experience with JNI, but that is the Java specification. Class name The class name must contain Java package path. For example, if a class, Test, exists in the package org.cocos2dx.javascript: package org.cocos2dx.javascript; public class Test { public static void hello(String msg) { System.out.println(msg); } public static int sum(int a, int b) { return a + b; } public static int sum(int a) { return a + 2; } } The correct class name of Test is org/cocos2dx/javascript/Test. Please note that using a slash / is required, NOT using a dot .. Method name The method name is very simple. For example, the method names of the above two sum methods are both sum. Method signature The method signature is a little complex. The simplest signature is ()V, it represents a method which has no parameters and no return value. Examples: (I)V represents a method which has a int parameter and no return value. (I)I represents a method which has a int parameter and a int return value. (IF)Z represents a method which has a int parameter and a float parameter, and returns boolean. The symbols in brackets represent the type of parameters, and the symbol after bracket represent the type of return value. Because methods are allowed to be overloaded in Java, there can be multiple methods which hava the same method name, but different parameters and return value. The method signature is used to help identifying these methods. Currently, Cocos Creator supports four Java types: Java type signature int I float F boolean Z String Ljava / lang / String; Parameters The number of parameters can be 0 or more than one. And when we use callStaticMethod, we can use number, boolean and string of JavaScript directly. Usage Here is an example of invoking the static methods of Test class: //call hello method jsb.reflection.callStaticMethod(\"org/cocos2dx/javascript/Test\", \"hello\", \"(Ljava/lang/String;)V\", \"this is a message from JavaScript\"); //call the first sum method var result = jsb.reflection.callStaticMethod(\"org/cocos2dx/javascript/Test\", \"sum\", \"(II)I\", 3, 7); cc.log(result); //10 //call the second sum method var result = jsb.reflection.callStaticMethod(\"org/cocos2dx/javascript/Test\", \"sum\", \"(I)I\", 3); cc.log(result); //5 Take a look on the Console, there should be correct output. Attention A very important thing that must be paid attention to is thread safety! With a Cocos Creator Android app, the engine and JavaScript VM works in the gl thread, and Android update its UI in the ui thread. If a Java method is called which will update the app UI, it must run in ui thread. For example, calling a Java method which shows an Android AlertDialog: //make some modification in AppActivity class public class AppActivity extends Cocos2dxActivity { private static AppActivity app = null; @Override public void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); app = this; } public static void showAlertDialog(final String title,final String message) { //we must use runOnUiThread here app.runOnUiThread(new Runnable() { @Override public void run() { AlertDialog alertDialog = new AlertDialog.Builder(app).create(); alertDialog.setTitle(title); alertDialog.setMessage(message); alertDialog.setIcon(R.drawable.icon); alertDialog.show(); } }); } } Next, calling showAlertDialog in JavaScript: jsb.reflection.callStaticMethod(\"org/cocos2dx/javascript/AppActivity\", \"showAlertDialog\", \"(Ljava/lang/String;Ljava/lang/String;)V\", \"title\", \"hahahahha\"); An Android native AlertDialog should show now. One more thing Now that it is possible to successfully called Java methods in JavaScript, is it possible to call JavaScript in Java? Of course! The engine contains class CocosJavascriptJavaBridge, which has an evalString method that can execute JavaScript, and is located in the resources\\3d\\cocos2d-x-lite\\cocos\\platform\\android\\java\\src\\com\\cocos\\lib\\CocosJavascriptJavaBridge.java file in the engine directory. Please note that this time JavaScript code should be run in the gl thread. Consider an example of adding an OK button for the AlertDialog, and using evalString in its OnClickListener: alertDialog.setButton(\"OK\", new DialogInterface.OnClickListener() { public void onClick(DialogInterface dialog, int which) { // We must use runOnGLThread here app.runOnGLThread(new Runnable() { @Override public void run() { CocosJavascriptJavaBridge.evalString(\"cc.log(\\\"JavaScript Java bridge!\\\")\"); } }); } }); Note: the engine does not promise security in multi-threaded currently, avoid JavaScript code being called in other threads during development to avoid various memory errors. To call evalString in C++, please refer to the following method to ensure that evalString is executed in the thread where the JavaScript engine is: Application::getInstance()->getScheduler()->performFunctionInCocosThread([=](){ se::ScriptEngine::getInstance()->evalString(script.c_str()); }); After clicking OK button, notice the output. evalString can run any JavaScript code, and can access JavaScript variables. "},"advanced-topics/oc-reflection.html":{"url":"advanced-topics/oc-reflection.html","title":"JavaScript to Objective-C Reflection","keywords":"","body":"How to call Objective-C functions using JavaScript on iOS/Mac This document is based on v2.x. It may change slightly on Cocos Creator 3.0 and will be updated as soon as possible. With native iOS or Mac applications packaged with Cocos Creator, JavaScript calling Objective-C functions directly through the native language's reflection mechanism can be achieved with the following sample code: var ojb = jsb.reflection.callStaticMethod(className, methodName, arg1, arg2, .....); Use jsb.reflection.callStaticMethod to call Native Objective-C method by sending className, methodName and parameters. Note: pay attention to Apple Developer Program License Agreement (section 3.3.2) when using reflection features. The usage of respondsToSelector: and performSelector: might cause problem in App Store review process, review this related discussion in React-Native's issue tracker. Objective-C Classes It is necessary to provide functionality in an Objective-C class as per the example below. The className parameter in this case should be NativeOcClass. import @interface NativeOcClass : NSObject +(BOOL)callNativeUIWithTitle:(NSString *)title andContent:(NSString *)content; @end Objective-C Methods Reflection from JavaScript to Objective-C supports only static methods of an Objective-C class. methodName parameter in the previous example are the Objective-C method names in your class, take NativeOcClass as an example, notice the method: +(BOOL)callNativeUIWithTitle:(NSString *)title andContent:(NSString *)content; The methodName should be callNativeUIWithTitle:addContent: which is the definition for this method, and don't forget the :. Search for an Objective-C programming guide for more details. Another example below, the methodName should be callNativeWithReturnString. +(NSString *)callNativeWithReturnString; Usage In JavaScript code, for invoking the native method callNativeUIWithTitle:andContent: of NativeOcClass, use the jsb.reflection.callStaticMethod API. Example: var ret = jsb.reflection.callStaticMethod(\"NativeOcClass\", \"callNativeUIWithTitle:andContent:\", \"cocos2d-js\", \"Yes! you call a Native UI from Reflection\"); This method can show an alert dialog and return a boolean status. Here is its implementation, title and content parameters will receive the strings sent from JavaScript: +(BOOL)callNativeUIWithTitle:(NSString *) title andContent:(NSString *)content{ UIAlertView *alertView = [[UIAlertView alloc] initWithTitle:title message:content delegate:self cancelButtonTitle:@\"Cancel\" otherButtonTitles:@\"OK\", nil]; [alertView show]; return true; } Executing JavaScript in Objective-C Conversely, JavaScript code can be executed in C++/Objective-C by using evalString. Example: Application::getInstance()->getScheduler()->performFunctionInCocosThread([=](){ se::ScriptEngine::getInstance()->evalString(script.c_str()); }); Note: unless it is clear that the current thread is the main thread, the function needs to be distributed to the main thread for execution. Type Support Types supported for parameters and return value are limited in Cocos2d-JS reflection. To use float, int, double as parameter types in your native method, change to use NSNumber instead. To use bool as parameter type, change to use BOOL instead. Here is an example using NSNumber instead of int, float or double. +(float) addTwoNumber:(NSNumber *)num1 and:(NSNumber *)num2 { float result = [num1 floatValue] + [num2 floatValue]; return result; } For return values only int, float, bool, string are supported in the current version. "},"asset/dcc-export-mesh.html":{"url":"asset/dcc-export-mesh.html","title":"Importing models exported from DCC tools","keywords":"","body":"Importing models exported from DCC tools Currently, most Digital Content Creation (DCC) tools (3DS Max, Maya, Blender) can export models in FBX and glTF formats. These formats, exported by these tools, can be well received in Cocos Creator 3.0. Exporting FBX Because the coordinate system of the DCC tool and the game engine's coordinate system are not necessarily the same, some transformations are required when exporting a model to get the desired result in the engine. For example, Blender's coordinate system is x-axis right, y-axis outward, z-axis right-hand coordinate system, and Cocos Creator 3.0 is x-axis right, y-axis, z-axis right-hand coordinate system, so rotation is required to make the axes consistent. The following uses Blender 2.8 as an example to introduce the model import process. First we create a model in Blender. In Blender's FBX Export Options documentation, we choose up as y up and forward as -z forward. Imported into Cocos Creator, you can see that the nodes are rotated by -90 on the x-axis in order to combine the axis with Cocos Creator. The axes are aligned. If you don't want this rotation value, Blender's FBX export plugin provides an experimental function, Apply Transform, which can directly transform the rotation data into the model's vertex data. You can see that the rotation data is gone in Cocos Creator 3.0. Exporting glTF Please read ther following documents: glTF also uses a right-handed coordinate system Options for exporting glTF in Blender. It is relatively simple, as long as the +y up option is checked, there is no rotation value in the exported data. Possible issues During the game development process, the orientation of the model may be used. For example, if you want some objects to face the player (using the LookAt() method), you need to consider the initial orientation of the model. Here are two methods to adjust the initial orientation of the model. In Cocos Creator 3.0, the -z-axis is used as the forward direction, while in Blender, the forward direction is +y-axis, so when making a model, the positive direction of the y-axis should be used as the orientation of the object, and the derived transformation later, in Cocos Creator, the -z-axis will be used as the front direction. If you do not want to change the orientation in the DCC tool, you can try adding a parent node to the imported model in the scene, and then rotate the model so that the initial orientation of the model is the -z-axis. All subsequent rotation-related operations are based on the parent. A node is an operation object. Artist's production specifications Reasonably formulating a sub-assets name under model assets (e.g mesh or material). Each modification of the sub-assets name will result in the loss of the place associated with the sub-assets in the project. When a part of the model needs to be transparent and a part does not need to be transparent, it should be exported into two materials. If it is a material export that is prone to model penetration, you need to manually adjust the material. External asset references, use relative path when exporting. Otherwise, under the cooperation of multiple people, the original asset path will not be recognized, resulting in the model's built-in materials cannot obtain the texture correctly and appear yellow. Autodesk 3ds Max export local path is modified as follows: "},"concepts/scene/node.html":{"url":"concepts/scene/node.html","title":"Node","keywords":"","body":"Node Nodes are the basic building blocks of a scene. Nodes are organized in a tree-like relationship. Each Node can have multiple child nodes and correspond to a parent node at the same time. Nodes have the following characteristics: Nodes contain a set of basic information (displacement, rotation, scaling), and Nodes are organized together through a set of relative transformation relationships. The previous transform information of a Node is relative to it's parent node. The update order between Nodes follows the tree hierarchy order. The update of child nodes depends on the parent node, and the world transformation of child nodes is the combination of their local transformation and the world transform of their parent node. The parent/child relationship is very important. Components can be added to Nodes to associate multiple components with Nodes In short, Nodes are the basic means of organizing the structure of any game. We can classify multiple elements through Nodes, and perform hierarchical operations on Nodes, or perform batch operations on a group of Nodes, such as: transform, delete, or hiding and showing them as needed, etc. "},"concepts/scene/scene.html":{"url":"concepts/scene/scene.html","title":"Scene structure","keywords":"","body":"Scene structure Cocos Creator adds a 3D scene structure to Creator’s EC (entity component) framework. The 3D scene is represented by RenderScene. The corresponding Component in the EC structure references the Model, Camera, and Light are maintained in RenderScene. Other elements are also linked together through Node, including the Transformations in RenderScene is also manipulated through the Node API. Note: the differences between Scene in EC structure and RenderScene in a 3D scene structure. Scene in EC structure is the logical organization structure of the Node hierarchy. RenderScene in 3D is the organization structure of scene rendering elements. Elements in EC scene's contain references to the correspond rendering objects in RenderScene. The relationship between EC structure and 3D scene structure is shown in the following figure: The entire 3D scene structure is encapsulated under Component, and the organizational relationship is established through Node. This is completely transparent relationship between EC structure and a 3D scene. "},"editor/extension/scene-script.html":{"url":"editor/extension/scene-script.html","title":"Call the engine API and project script","keywords":"","body":"Call the engine API and project script In a plugin, you can declare a special script file called scene script, which has the same environment as the scripts in the assets directory of the project. That is, in this script you can call the engine API and other project scripts to achieve special functionality, including: Traverse the nodes in the scene to get or change the data. Call the other scripts in the project to complete the job. Registering the scene script First, add a scene field to the contributions property of pacakge.json, the value of which is the path to a script file, relative to the extension package directory. Example: { \"name\": \"engine\", \"contributions\": { \"scene\": { \"script\": \"./scene.js\" } } } Adding code to the scene script Define scene.js as follows: // Function triggered when the module is loaded exports.load = function() {}; // Function triggered when the module is unloaded exports.unload = function() {}; // Methods defined within the module exports.methods = { log() { const scene = cc.director.getScene(); if (scene) { scene.walk(target => console.log(target.name)); } else { console.warn('Scene not found'); } } }; Note: due to the upgrade of the scripting system, the cc.require method, which used the same module reference mechanism as the project script, has been deprecated. Sending a message to the scene.js Next, the following interface can be used to send messages to scene.js in both the main process and the rendering process of the extension package application. For example, assuming the name of the extension is foobar: interface ExecuteSceneScriptMethodOptions { // Name of extension name: string; method: string; args: any[]; } const options: ExecuteSceneScriptMethodOptions = { name: 'foobar', method: 'log', args: [] }; await Editor.Message.request('scene', 'execute-scene-script', options); This allows retreiving the names of all the nodes of the scene in the extended package, and of course can be used to perform more queries and operations on the scene nodes. Note: because communication is based on the underlying IPC implementation of Electron, remember that the transmitted data cannot contain native objects, otherwise it can cause process crashes or memory explosion. It is recommended to only transfer pure JSON objects. "},"editor/extension/to-panel-messages.html":{"url":"editor/extension/to-panel-messages.html","title":"Communicate with the Panel","keywords":"","body":"Communicate with the Panel In general, the interaction model is dominated by extension process and panel for data presentation. Similarly to the traditional Web, the plug-in function is the server side, and the panel function is the browser on the client's computer. In this case, there is usually no direct data sent to the panel, the majority is some state synchronization, just using broadcast to broadcast. But for simple extensions, or extensions to the browser environment, the actual functionality may be on the panel, and a request needs to be sent to the panel. Some level of understanding of the Message System is required before reading this section. Define methods on extensions and panels First we define the file: package.json { \"name\": \"hello-world\", \"panels\": { \"default\": { \"title\": \"hw\", \"main\": \"./panel.js\" } }, \"contributions\": { \"messages\": { \"console\": { \"methods\": [\"default.console\"] } } } } The method name defined by methods in messages.console is default.console. Represents a console method issued to the default panel. (to send to the plug-in process, fill in methdName directly) Then define the panel.js file of the panel: exports.template = ''; exports.style = ''; exports.methods = { console(str) { console.log(str); }, }; exports.ready = async function() {}; exports.close = function() {}; Send a message Once we have defined the extension and the panels within the extension, we can try to trigger these messages. Press CTRL (CMD) + Shift + I to open the console. Open the panel in the console: Editor.Panel.open('hello-world'); Editor.Message.send('hello-world', 'console', 'log'); When the Hello World plug-in receives a message, it passes it to the methods.console in panel.js for processing. The result is printing a string to the log on the console. "},"editor/gameview/":{"url":"editor/gameview/","title":"GameView description","keywords":"","body":"GameView description GameView is a game view function embedded in the editor. It can run the game in the editor without opening the browser. The advantage is that it can adjust the model and state of the game in real time through gizmo or other plugins of the editor, etc, achieving what you see, is what you get when the game is running. GameView open method To open the GameView panel, click the GameView in the drop-down box of the run mode, on the top toolbar in the editor. Button operation instructions After opening the GameView window, you can find there are three extra buttons on the top toolbar, play/stop, pause, and step: play/stop: Click this button to run the game in the editor, and during this state of the button you can switch to the stop state, just click the stop button to stop the game. pause: Click this button to pause the running game. step: Click this button to run the game step by step, which is convenient for debugging. GameView synchronization The GameView before running can exist as a preview function. When adjusting the gizmo or adjusting the scene through other plugins, the GameView screen can be synchronized in real time. GameView runtime When running the game, GameView can run the life cycle of each node component in real time, which includes mouse and keyboard events and UI event response. "},"editor/project/joint-texture-layout.html":{"url":"editor/project/joint-texture-layout.html","title":"Joint Texture Layout Settings","keywords":"","body":"Joint Texture Layout Settings To ensure that the Skeletal Animation can also participate fully and correctly in Dynamic Instancing, requiring the user to manually specify how the data for each joint texture is assigned. For example, consider a scene with a large number of identical characters to draw, each of which may be walking, jumping, or attacking. If you want to be able to draw all characters correctly with one drawcall, an important prerequisite is that the data for all three animations is stored in the same joint texture. Currently, in the default pre-baked skeletal animation mode, the joint textures are automatically reused globally, but the size of each texture and which animations they store are unpredictable. If instancing of the skinned model is turned on directly without any processing, the final runtime effect is that some animations are correct and some are completely wrong and unpredictable. Therefore, we introduce the Joint Texture Layout Settings panel, which is used to manually specify which animation information is stored for which skeletons in each joint texture. Note: the Joint Texture Layout Settings panel provides what is essentially a runtime \"memory allocation guideline\". For the specified skeletons and animation resources, they are guaranteed to be allocated according to the specified rules, but if a resource is used at runtime that is not specified by the rules, it will go back to the automatic allocation mode of global reuse. As an example, using the instanced-skinning scenario of the show-case project to show the setup process and how it works in practice. The figure below shows a sample scenario with multiple instances from the same model, each playing a completely different animation at the same time. These models use the real-time computation animation mode and do not have instancing turned on. As you can see, the current scene plus the UI has a total drawcall of 60 and an instance count of 0. This state will be used as a baseline for later changes as a comparison. To create a model with the instancing turned on, you need to: Make sure useBakedAnimation is checked on the SkeletalAnimationComponent. Check USE_INSTANCING for all materials used by SkinningModel. In the example scene (referenced above) two sets of prefabs are made and the material diffuse color set to blue in the instancing version in order to see and distinguish between the two systems at the same time. Notice that the effect has been exactly correct and that only 5 drawcalls (each model is divided into 5 parts) were used, with 45 instances. Note: the reason all models are rendered correctly here is that the amount of animation data is relatively small, and the global reuse logic of the generic joint texture already writes all animation data to the same texture, so the effect is correct. However, if the size of the default joint texture is exceeded by new animations that may be added at any time, the animation will definitely go wrong, which is why the joint texture layout panel must exist. For display purposes, we can intentionally place each animation on a separate texture in the layout panel to see the final rendering effect. Open the Skeletal Texture Layout settings panel via menu Panel -> Animation -> Joint Texture Layout: Click the plus sign ① to add a Texture unit, which is composed of multiple Skeleton units. Click the plus sign ② to add a Skeleton unit, which consists of a Skeleton resource and one to more AnimationClip resources. Click the plus sign ③ to add an AnimationClip resource slot. Here we have 9 different animations separated into 9 Texture cells: Re-running the scene, the effect becomes: As you can see, there is a problem with the animation, all the animations become attack actions, and there is a problem with the model disappearing from time to time. The reason behind this can be precisely analyzed: Each drawcall draws 9 instances, which are playing 9 different animations. But the skeletal animation texture can only be use one per drawcall. It is obvious that Texture unit 0 is used here and there is only one attack animation. And the length of different animation clips is different, some clips longer than attack will be read outside the valid area of Texture unit 0 in the last period. The data here is not defined (usually all 0 by default), which is not valid skeleton transformation data, so naturally it cannot be rendered correctly. Note: all 9 textures here have only the same skeletal animation information, so only the actions are wrong in the final result, even if the textures are not right; but if there are multiple skeletons with animation information in one texture, and the texturs doesn't match at the same time, the rendering effect will be completely wrong. For this example scene, since the model does need to play the 9 animation clips simultaneously on the same screen, the correct joint texture layout is set as follows: This will now be able to guarantee that it renders correctly. Observe the change in the relevant data on the panel: Texture cell 0 has a total size of 276 x 276 (automatically generated by the algorithm, the minimum size sufficient to hold all the specified animation data). the specified 9 groups of animation data take up 94.41% of this texture, with 5.59% excess space; (this space does not participate in global reuse at runtime) In addition, the color of the icon next to the texture size indicates the device adaptation of the current texture. Green (side length less than 1024): supported on all devices. Yellow (side length between 1024 and 2048): may not supported on some mobile devices or mini-game platforms that do not support floating point texture. Red (side length more than 2048): not supported on many mobile devices. Note: here are only 9 animations for one set of skeletons on one texture, but you can put any number of animations for any number of skeletons on each texture as long as the total size does not exceed the device limit. Usually it is more common to put multiple sets of skeletons on a single texture, for example for flat shadows of skinned models. We can continue to increase the number of instances in more scenes. We can see that the number of drawcalls does not change, and only the number of instances increases: Feel free to try it out! This test scenario is the instanced-skinning scenario of the show-cases project in the showcase repository. "},"editor/publish/subpackage.html":{"url":"editor/publish/subpackage.html","title":"Mini Game Subpackage","keywords":"","body":"Mini Game Subpackage Some mini game platforms support subpackaging to divide resources, scripts and scenes. Including WeChat Mini Game, Baidu Mini Game, Xiaomi Quick Game, Bytedance Mini Game, Huawei Quick Game, OPPO Mini Game and vivo Mini Game. Cocos Creator supports Asset Bundle starting in v2.4, which allows developers to divide contents that need to be subpackaged into multiple Asset Bundles, and these Asset Bundles will be built into subpackages of the mini game. Only the necessary main packages will be downloaded when you startup the game, and these subpackages will not be loaded, but will be manually loaded by the developer during the game. This effectively reduces the time for the game startup. Configuration The Asset Bundle is configured in folders. When we select a folder in the Assets panel, the Inspector panel will show a Is Bundle option, if set, the folder-related configuration options will appear: In addition to the general Asset Bundle Configuration, the main settings to focus on for the mini game subpackage are: Set the Target Platform to the mini game platform that you want to subpackage, and set the Compression Type to the Mini Game Subpackage. The mini game subpackage can only be placed locally and cannot be configured as remote packages, so the Is Remote Bundle option cannot be checked. Once configured, click the Check button on the top right and the folder will be configured as a Asset Bundle. Build After the project is built, this Asset Bundle folder is packaged into the subpackages folder in the release package directory of the mini game platform. Each folder contained in this folder is an Asset Bundle. For example, if the assets/scene folder in the Hello World project is configured as an Asset Bundle on the WeChat Mini Game, then after the project is built, a scene folder is generated in the subpackages folder in the release package directory, and the scene folder is an Asset Bundle. WeChat Mini Games When building for the WeChat Mini Game, the configuration of the Asset Bundle will be automatically generated into the game.json configuration file of the WeChat Mini Games release package directory according to the rules. Note: WeChat Mini Games require a specific version to support the Subpackage feature. WeChat 6.6.7 client, 2.1.0 and above base library support, please update to the latest client version. Developer tools please use version 1.02.1806120 and above. After updating the developer tools, don't forget to modify the version of Details -> Local Settings -> Debug Base library to 2.1.0 and above in the WeChat DevTools: Subpackage Load Packet Size Limit Currently, the size of the WeChat Mini Game subpackage has following restrictions: The size of all subpackage of the entire Mini Game can not exceed 16M The size of single subpackage/main package can not exceed 4M Please refer to the WeChat Mini Game Subpackage Loading documentation for details. vivo Mini Games When building for the vivo Mini Game, the configuration of the Asset Bundle will be automatically generated into the manifest.json configuration file in the vivo-mini-game/src directory of the vivo Mini Game release package according to the rules. Notes: Starting with 1051 version, Quick App & vivo Mini Game Debugger supports the subpackage loading of vivo Mini Game. Versions lower than 1051 do not support subpackage loading, but they are also compatible. If a subpackage is configured in the editor's Properties panel, it will not affect the normal operation of the game. Please refer to the vivo Mini Game Subpackage Loading -- Runtime Compatibility [cn] documentation for details. Unlike other mini game platforms, the Asset Bundle folder for the vivo Mini Game will be generated in the src directory of release package vivo-mini-game directory after the project is built. Subpackage Load Packet Size Limit Currently, the size of the vivo Mini Game subpackage has following restrictions: The size of all subpackage and main package of the entire Mini Game can not exceed 8M (The compressed package after packaging contains whole package no more than 16M, please refer to vivo Mini Game Subpackage Loading -- Compatibility [cn] documentation for details. The size of single subpackage/main package can not exceed 4M. Please refer to the vivo Mini Game Subpackage Loading [cn] documentation for details. "},"editor/scene/camera-gizmo.html":{"url":"editor/scene/camera-gizmo.html","title":"Camera Gizmo","keywords":"","body":"Camera Gizmo Camera Gizmo is used to show the clip area of a camera, you can read the Camera Introduction documentation for more information about camera. Perspective Camera Gizmo Perspective Camera Gizmo shows the shape of frustum, which is calculate by the distance of the near clip plane, far clip plane and fov. You can edit them by dragging the control quad. Ortho Camera Gizmo Ortho Camera Gizmo shows the shape of box, which is calculated by the distance of the near clip plane, far clip plane and the height of ortho camera. You can edit them by dragging the control quad. "},"editor/scene/collider-gizmo.html":{"url":"editor/scene/collider-gizmo.html","title":"Collider Gizmo","keywords":"","body":"Collider Gizmo For more information about the collider of Cocos Creator, you can read the Physics Introduction documentation. Box Collider Box Collider Gizmo shows the length, width, height of the box. You can edit them by dragging the control quad. Sphere Collider Sphere Collider Gizmo shows the size of sphere, you can edit the radius of sphere by dragging the control quad. "},"editor/scene/light-gizmo.html":{"url":"editor/scene/light-gizmo.html","title":"Light Gizmo","keywords":"","body":"Light Gizmo For more information about the light of Cocos Creator, please refer to the Light Introduction documentation. Directional Lights The Directional Light Gizmo shows the direction of the directional light. Sphere Lights The Sphere light Gizmo shows the color and area of light, you can edit the area of light by dragging the control quad. Spotlights The Spotlight Gizmo shows the color, area and spot angle of spotlight, you can edit the area and angle of light by dragging the control quad. "},"editor/scene/particle-system-gizmo.html":{"url":"editor/scene/particle-system-gizmo.html","title":"Particle System Gizmo","keywords":"","body":"Particle System Gizmo Particle System Gizmo is used for the visualization of the ShapeModule of particle system. Box Box Gizmo shows the length, width, height of box, you can edit them by dragging the control quad. Sphere Sphere Gizmo shows the size of sphere, you can edit the radius of sphere by dragging the control quad. Hemisphere Hemisphere Gizmo shows the size of hemisphere, you can edit the radius of sphere by dragging the control quad. Circle Circle Gizmo shows the size of circle, you can edit the radius of circle by dragging the control quad. Cone Cone Gizmo shows the shape of cone, you can edit the radius,angle,height of cone by dragging the control quad. "},"editor/scene/transform-gizmo.html":{"url":"editor/scene/transform-gizmo.html","title":"Transform Gizmo","keywords":"","body":"Transform Gizmo We mainly use the Transform Tool on the toolbar which is in the left top of main window to arrange the node in the scene. Move transform tool Move transform tool is the default active transform tool. This tool can be activated by clicking the first button on top left corner of main window's tool bar, or press the keyboard shortcut W in scene editor. After you selected a node, You can see three move handle which is made up of red, green, blue arrow and plane in the center(or the anchor position) of the node. Gizmo refers to a controller that can interactive with mouse and appears in certain editing states in the scene editor. These controllers are only to assist editing without being shown in the game while it is running. When the move transform tool is active: Press red, green, blue arrow and drag mouse, then the node will be moved on the x, y, z axis. Press red, green, blue plane and drag mouse, then the node will be moved freely on y-z, x-z, x-y plane. Rotate transform tool Click the second button on the tool bar located at the main window's top left corner or press the keyboard shortcut E in scene editor and you can activate Rotate transform tool. The gizmo of rotate transform tool is made up of three orthogonal circles(an arrow and a circle in 2D view).By dragging arrow or any point in the circle, you can rotate the node and you can see the rotation area on gizmo before you release the mouse. When the move transform tool is active: Press red, green, blue circle and drag mouse, then the node will be rotated on the x, y, z axis. Scale transform tool Click the third button on the tool bar located at main window's top left corner or press the keyboard shortcut R in the scene editor and you can activate scale transform tool. The gizmo of scale transform tool is made up of red,green,blue cube align the three axis and a gray cube in the center. When the scale transform tool is active: Press red, green, blue cube and drag mouse, then the node will be scaled on the x, y, z axis. Press gray cube and drag mouse, then the node will be scaled on all the x, y, z axis at the same time. Rect transform tool Click the fourth button on the tool bar located at the main window's top left corner or press the keyboard shortcut T in scene editor and you can activate rect transform tool. The gizmo of rect transform tool is made up of four conner control point, four edge control point and one center control point. When the rect transform tool is active: Drag any conner control point of the gizmo so you can change the attributes of width and height in node size while the opposite angles end points position keep the same. Drag any side control point of the gizmo so you can change the attributes of width and height in node size while the opposite sides position keep the same. In UI elements layout, rect transform tool is always used to precisely control the position and length of the node's dimensions. As to the image elements that must keep original image aspect ratio, the rectangle transform tool is normally not the best choice for size adjustment. Transform Gizmo Based Point Configure Transform Gizmo Based Point Configure is used to set the position and rotation of transform gizmo. Position Click the Pivot/Center button to toggle between Pivot and Center. Pivot: use the world position of node. Center: use the center position of all selected nodes. Rotation Click the Local/Global button to toggle between Local and Global. Local: use the rotation of node. Global: use the rotation of world space. "},"module-map/light.html":{"url":"module-map/light.html","title":"Lighting","keywords":"","body":"Lighting Lighting Overview Physically-based Lighting Main Directional Lights Sphere Lights Spotlights Ambient Lights "},"scripting/execution-order-general.html":{"url":"scripting/execution-order-general.html","title":"Script execution order","keywords":"","body":"Script execution order The script loading sequence is as follows: The Cocos Creator engine module \"cc\" will be imported for the first time. Plug-in scripts - All plug-in scripts will be executed in the order of the specified plug-in script dependencies; plug-in scripts that do not have dependencies are disordered. Common scripts All common scripts will be imported concurrently. Import will strictly follow the reference relationship and execution order determined by import. "},"scripting/tsconfig.html":{"url":"scripting/tsconfig.html","title":"tsconfig.json","keywords":"","body":"tsconfig.json The majority of compilation options in tsconfig.json in the project do not affect the compilation of TypeScript. Therefore, some options need to configured carefully to make the IDE's inspection function consistent with the compilation behavior in Cocos Creator. The following options should not be modified explicitly: compilerOptions.target compilerOptions.module For example, if tsconfig.json is set to: { \"compilerOptions\": { \"target\": \"es5\", \"module\": \"cjs\" } } Script code: const myModule = require(\"path-to-module\"); It will not cause an error in the IDE (using tsc as a checker) because compilerOptions.module is set to cjs. However, the implicit compilerOptions.module in Cocos Creator is es2015, therefore, it may prompt errors such as required undefine at runtime. Script code: const mySet = new Set(); This is legal in Cocos Creator, but the IDE may report an error: Because compilerOptions.target is set to es5: ES6 introduced Set. It is also possible to freely modify options. For example, when it is needed to prohibit the use of implicit any in all Typscript scripts in your project. Set compilerOptions.noImplicitAny to true in tsconfig.json, as using an IDE (such as Visual Studio Code), the corresponding error prompt will be received. For most projects, some options in tsconfig are fixed. For example, compilerOptions.target, compilerOptions.module and Cocos Creator type declarations, file location, etc. Due to the good design of tsc, the extends option allows tsconfig.json to be cascadable. Cocos Creator supports this, therefore, the fixed tsconfig option is placed under {project path}/tmp/tsconfig.cocos.json and managed by Cocos Creator. Therefore, tsconfig.json under the project root path can be configured as follows to share these fixed options: { extends: './tmp/tsconfig.cocos.json', compilerOptions: { /* Custom tsconfig.json options*/ } } Fortunately, when you create a new project, the editor will automatically generate a tsconfig.json file automatically. "},"ui-system/components/editor/graphics/arc.html":{"url":"ui-system/components/editor/graphics/arc.html","title":"Arc","keywords":"","body":"Arc The arc() method creates an arc/curve (used to create circles or partial circles). Note: to create a circle with arc(), set the start angle to 0 and the end angle to 2 * Math.PI. Parameter Description x The x coordinate of the center of the circle. y The y coordinate of the center of the circle. r Radius of the circle. sAngle Start angle in radians (The arc's three o'clock position is 0 degrees). eAngle End angle in radians. counterclockwise Optional. Specifies whether draw the arc counterclockwise or clockwise. False = clockwise, true = counterclockwise. Example const ctx = node.getComponent(Graphics); ctx.arc(100,75,50,0,1.5 * Math.PI); ctx.stroke(); Return to the Graphics Component Reference documentation. "},"ui-system/components/editor/graphics/bezierCurveTo.html":{"url":"ui-system/components/editor/graphics/bezierCurveTo.html","title":"Bezier Curves","keywords":"","body":"Bezier Curves The bezierCurveTo() method adds a bezier curve to the current path by using the specified control point that can generate the cubic bezier curve. Note: Cubic Bezier curves require three control points. The first two points are for the control points in the cubic Bezier calculation, and the third point is the end point of the curve. The starting point of the curve is the last point in the current path. Parameter Description cp1x The x coordinate of the first bezier control point. cp1y The y coordinate of the first bezier control point. cp2x The x coordinate of the second Bezier control point. cp2y The x coordinate of the second Bezier control point. x The x coordinate of the end point. y The y coordinate of the end point. Example const ctx = node.getComponent(Graphics); ctx.moveTo(20,20); ctx.bezierCurveTo(20,100,200,100,200,20); ctx.stroke(); Return to the Graphics Component Reference documentation. "},"ui-system/components/editor/graphics/circle.html":{"url":"ui-system/components/editor/graphics/circle.html","title":"Circles","keywords":"","body":"Circles The circle() method is used to create a circle. Parameter Description cx The x coordinate of the center of the circle. cy The y coordinate of the center of the circle. r Radius of the circle. Example const ctx = node.getComponent(Graphics); ctx.circle(200,200, 200); ctx.stroke(); Return to the Graphics Component Reference documentation. "},"ui-system/components/editor/graphics/clear.html":{"url":"ui-system/components/editor/graphics/clear.html","title":"Clears","keywords":"","body":"Clears The clear() function is used to clear all paths. Example update: function (dt) { const ctx = node.getComponent(Graphics); ctx.clear(); ctx.circle(200,200, 200); ctx.stroke(); } Return to the Graphics Component Reference documentation. "},"ui-system/components/editor/graphics/close.html":{"url":"ui-system/components/editor/graphics/close.html","title":"Close","keywords":"","body":"Close The close() method is used to create a path from a current point to the beginning point. Example const ctx = node.getComponent(Graphics); ctx.moveTo(20,20); ctx.lineTo(20,100); ctx.lineTo(70,100); ctx.close(); ctx.stroke(); Return to the Graphics Component Reference documentation. "},"ui-system/components/editor/graphics/ellipse.html":{"url":"ui-system/components/editor/graphics/ellipse.html","title":"Ellipse","keywords":"","body":"Ellipse The ellipse() method is used to create an ellipse. Parameter Description cx The x coordinate of the center of the ellipse. cy The y coordinate of the center of the ellipse. rx The x radius of the ellipse. ry The y radius of the ellipse. Example const ctx = node.getComponent(Graphics); ctx.ellipse(200,100, 200,100); ctx.stroke(); Return to the Graphics Component Reference documentation. "},"ui-system/components/editor/graphics/fill.html":{"url":"ui-system/components/editor/graphics/fill.html","title":"Fill","keywords":"","body":"Fill The fill() method is used to fill the current image (path). The color used is fillColor. Note: if the path is not closed, the fill() method adds a line from the end of the path to the start point to close the path and then fills the path. Example const ctx = node.getComponent(Graphics); ctx.rect(20,20,150,100); ctx.fillColor = Color.GREEN; ctx.fill(); Return to the Graphics Component Reference documentation. "},"ui-system/components/editor/graphics/fillColor.html":{"url":"ui-system/components/editor/graphics/fillColor.html","title":"Fill Color","keywords":"","body":"Fill Color The fillColor property represents the color used for the fill function. Example const ctx = node.getComponent(Graphics); ctx.fillColor = new Color().fromHEX('#0000ff'); ctx.rect(20,20,250,200); ctx.stroke(); Return to the Graphics Component Reference documentation. "},"ui-system/components/editor/graphics/lineCap.html":{"url":"ui-system/components/editor/graphics/lineCap.html","title":"Line Cap","keywords":"","body":"Line Cap The lineCap property represents the style of the line end cap. Possible line cap options Description Graphics.LineCap.BUTT Default. Add a straight edge to each end of the line. Graphics.LineCap.ROUND Add a circular cap to each end of the line. Graphics.LineCap.SQUARE Add a square line cap to each end of the line. Example const ctx = node.getComponent(Graphics); ctx.lineCap = Graphics.LineCap.ROUND; ctx.lineWidth = 10; ctx.moveTo(100, 100); ctx.lineTo(300, 100); ctx.stroke(); Return to the Graphics Component Reference documentation. "},"ui-system/components/editor/graphics/lineJoin.html":{"url":"ui-system/components/editor/graphics/lineJoin.html","title":"Line Join","keywords":"","body":"Line Join The lineJoin property represents the style of the joint between two line segments. Possible line join options Description Graphics.LineJoin.BEVEL Creates a bevel Graphics.LineJoin.ROUND Create a fillet Graphics.LineJoin.MITER Default. Create sharp corners Example const ctx = node.getComponent(Graphics); ctx.lineJoin = Graphics.LineJoin.ROUND; ctx.moveTo(20,20); ctx.lineTo(100,50); ctx.lineTo(20,100); ctx.stroke(); Return to the Graphics Component Reference documentation. "},"ui-system/components/editor/graphics/lineTo.html":{"url":"ui-system/components/editor/graphics/lineTo.html","title":"Line To","keywords":"","body":"Line To The lineTo() method is used to add a new point, and then create a line from the current graphic cursor to that point. Parameter Description x The x coordinate of the target location of the path. y The y coordinate of the target position of the path. Example const ctx = node.getComponent(Graphics); ctx.moveTo(20,100); ctx.lineTo(20,20); ctx.lineTo(70,20); ctx.stroke(); Return to the Graphics Component Reference documentation. "},"ui-system/components/editor/graphics/lineWidth.html":{"url":"ui-system/components/editor/graphics/lineWidth.html","title":"Line Width","keywords":"","body":"Line Width The lineWidth defines the width of drawing line for stroke function. Parameter Description number The width of the current line, in pixels. Example const ctx = node.getComponent(Graphics); ctx.lineWidth = 20; ctx.rect(20,20,80,100); ctx.stroke(); Return to the Graphics Component Reference documentation. "},"ui-system/components/editor/graphics/miterLimit.html":{"url":"ui-system/components/editor/graphics/miterLimit.html","title":"Miter Limit","keywords":"","body":"Miter Limit The miterLimit represents the maximum miter length. The miter length refers to the distance between the inner and outer corners of the intersection of the two lines. Note: miterLimit is valid only if the lineJoin property is miter. When the angle of the corners is smaller, the length of the miter is greater. To avoid miter length getting too long, we can use the miterLimit property. If the miter length exceeds the value of miterLimit, the corners are displayed with the bevel type of lineJoin. Parameter Description number Positive number. Specifies the maximum miter length. If the miter length exceeds the value of miterLimit, the corners are displayed with the bevel type of lineJoin. Example const ctx = node.getComponent(Graphics); ctx.miterLimit = 10; ctx.moveTo(20,20); ctx.lineTo(100,50); ctx.lineTo(20,100); ctx.stroke(); Return to the Graphics Component Reference documentation. "},"ui-system/components/editor/graphics/moveTo.html":{"url":"ui-system/components/editor/graphics/moveTo.html","title":"Move To","keywords":"","body":"Move To The moveTo() method sets the starting point of a path. Parameter | Description | | :-------------- | :----------- | | x | The x coordinate of the target location of the path. | | y | The y coordinate of the target position of the path. | Example const ctx = node.getComponent(Graphics); ctx.moveTo(0,0); ctx.lineTo(300,150); ctx.stroke(); Return to the Graphics Component Reference documentation. "},"ui-system/components/editor/graphics/quadraticCurveTo.html":{"url":"ui-system/components/editor/graphics/quadraticCurveTo.html","title":"Quadratic Curve To","keywords":"","body":"Quadratic Curve To The quadraticCurveTo() method adds a point to the current path by using the specified control point that represents the Quadratic Bezier curve. Note: the Quadratic Bezier curve requires two points. The first point is for the control point in the second bessel calculation, and the second point is the end point of the curve. The starting point of the curve is the last point in the current path. Parameter Description cpx The x coordinate of the Bezier control point. cpy The y coordinate of the Bezier control point. x The x coordinate of the end point. y The y coordinate of the end point. Example const ctx = node.getComponent(Graphics); ctx.moveTo(20,20); ctx.quadraticCurveTo(20,100,200,20); ctx.stroke(); Return to the Graphics Component Reference documentation. "},"ui-system/components/editor/graphics/rect.html":{"url":"ui-system/components/editor/graphics/rect.html","title":"Rect","keywords":"","body":"Rect The rect() method is used to create a rectangle. Parameter Description x The x coordinate of the lower left point of the rectangle. y The y coordinate of the lower left point of the rectangle. width The width of rectangle. height The height of rectangle. Example const ctx = node.getComponent(Graphics); ctx.rect(20,20,150,100); ctx.stroke(); const ctx = node.getComponent(Graphics); // Red rectangle ctx.lineWidth = 6; ctx.strokeColor = Color.RED; ctx.rect(5,5,290,140); ctx.stroke(); // Green rectangle ctx.lineWidth=4; ctx.strokeColor = Color.GREEN; ctx.rect(30,30,50,50); ctx.stroke(); // Blue rectangle ctx.lineWidth = 10; ctx.strokeColor = Color.BLUE; ctx.rect(50,50,150,80); ctx.stroke(); Return to the Graphics Component Reference documentation. "},"ui-system/components/editor/graphics/stroke.html":{"url":"ui-system/components/editor/graphics/stroke.html","title":"Stroke","keywords":"","body":"Stroke The stroke() method draws the previous path generated by path related functions like lineTo, rect etc. The color used is strokeColor and the line width is defined by lineWidth. Example const ctx = node.getComponent(Graphics); ctx.moveTo(20,100); ctx.stroke(20,20); ctx.stroke(70,20); ctx.stroke(); Return to the Graphics Component Reference documentation. "},"ui-system/components/editor/graphics/strokeColor.html":{"url":"ui-system/components/editor/graphics/strokeColor.html","title":"Stroke Color","keywords":"","body":"Stroke Color The strokeColor defines the color used for the stroke function. Example const ctx = node.getComponent(Graphics); ctx.lineWidth = 2; ctx.strokeColor = hexToColor('#0000ff'); ctx.rect(20,20,250,200); ctx.stroke(); Return to the Graphics Component Reference documentation. "}}